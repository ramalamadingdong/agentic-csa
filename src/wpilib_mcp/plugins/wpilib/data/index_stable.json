{
  "vendor": "wpilib",
  "version": "stable",
  "built_at": "2025-12-04T21:23:33.286306",
  "pages": [
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/index.html",
      "title": "Command",
      "section": "Command-Based Programming",
      "language": "Java",
      "content": "Command-Based Programming This sequence of articles serves as an introduction to and reference for the WPILib command-based framework. For a collection of example projects using the command-based framework, see Command-Based Examples . What Is “Command-Based” Programming? Commands Command Compositions Subsystems Binding Commands to Triggers Structuring a Command-Based Robot Project Organizing Command-Based Robot Projects The Command Scheduler A Technical Discussion on C++ Commands PID Control in Command-based Motion Profiling in Command-based Combining Motion Profiling and PID in Command-Based Passing Functions As Parameters In order to provide a concise inline syntax, the command-based library often accepts functions as parameters of constructors, factories, and decorators. Fortunately, both Java and C++ offer users the ability to pass functions as objects : Method References (Java) In Java, a reference to a function that can be passed as a parameter is called a method reference. The general syntax for a method reference is object::method or Class::staticMethod . Note that no method parameters are included, since the method itself is passed. The method is not being called - it is being passed to another piece of code (in this case, a command) so that that code can call it when needed. For further information on method references, see Method References . Lambda Expressions (Java) While method references work well for passing a function that has already been written, often it is inconvenient/wasteful to write a function solely for the purpose of sending as a method reference, if that function will never be used elsewhere. To avoid this, Java also supports a feature called “lambda expressions.” A lambda expression is an inline method definition - it allows a function to be defined inside of a parameter list . For specifics on how to write Java lambda expressions, see Lambda Expressions in Java . Lambda Expressions (C++) Warning Due to complications in C++ semantics, capturing this in a C++ lambda can cause a null pointer exception if done from a component command of a command composition. Whenever possible, C++ users should capture relevant command members explicitly and by value. For more details, see here . C++ lacks a close equivalent to Java method references - pointers to member functions are generally not directly usable as parameters due to the presence of the implicit this parameter. However, C++ does offer lambda expressions - in addition, the lambda expressions offered by C++ are in many ways more powerful than those in Java. For specifics on how to write C++ lambda expressions, see Lambda Expressions in C++ .",
      "content_preview": "Command-Based Programming This sequence of articles serves as an introduction to and reference for the WPILib command-based framework. For a collection of example projects using the command-based framework, see Command-Based Examples ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/binding-commands-to-triggers.html",
      "title": "Binding Commands to Triggers",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Binding Commands to Triggers Apart from autonomous commands, which are scheduled at the start of the autonomous period, and default commands, which are automatically scheduled whenever their subsystem is not currently in-use, the most common way to run a command is by binding it to a triggering event, such as a button being pressed by a human operator. The command-based paradigm makes this extremely easy to do. As mentioned earlier, command-based is a declarative programming paradigm. Accordingly, binding buttons to commands is done declaratively; the association of a button and a command is “declared” once, during robot initialization. The library then does all the hard work of checking the button state and scheduling (or canceling) the command as needed, behind-the-scenes. Users only need to worry about designing their desired UI setup - not about implementing it! Command binding is done through the Trigger class ( Java , C++ ). Getting a Trigger Instance To bind commands to conditions, we need a Trigger object. There are three ways to get a Trigger object: HID Factories The command-based HID classes contain factory methods returning a Trigger for a given button. CommandGenericHID has an index-based button(int) factory ( Java , C++ ), and its subclasses CommandXboxController ( Java , C++ ), CommandPS4Controller ( Java , C++ ), and CommandJoystick ( Java , C++ ) have named factory methods for each button. JAVA CommandXboxController exampleCommandController = new CommandXboxController ( 1 ); // Creates a CommandXboxController on port 1. Trigger xButton = exampleCommandController . x (); // Creates a new Trigger object for the `X` button on exampleCommandController C++ frc2 :: CommandXboxController exampleCommandController { 1 } // Creates a CommandXboxController on port 1 frc2 :: Trigger xButton = exampleCommandController . X () // Creates a new Trigger object for the `X` button on exampleCommandController JoystickButton Alternatively, the regular HID classes can be used and passed to create an instance of JoystickButton Java , C++ ), a constructor-only subclass of Trigger : JAVA XboxController exampleController = new XboxController ( 2 ); // Creates an XboxController on port 2. Trigger yButton = new JoystickButton ( exampleController , XboxController . Button . kY . value ); // Creates a new JoystickButton object for the `Y` button on exampleController C++ frc :: XboxController exampleController { 2 } // Creates an XboxController on port 2 frc2 :: JoystickButton yButton ( & exampleStick , frc :: XboxController :: Button :: kY ); // Creates a new JoystickButton object for the `Y` button on exampleController Arbitrary Triggers While binding to HID buttons is by far the most common use case, users may want to bind commands to arbitrary triggering events. This can be done inline by passing a lambda to the constructor of Trigger : JAVA DigitalInput limitSwitch = new DigitalInput ( 3 ); // Limit switch on DIO 3 Trigger exampleTrigger = new Trigger ( limitSwitch :: get ); C++ frc :: DigitalInput limitSwitch { 3 }; // Limit switch on DIO 3 frc2 :: Trigger exampleTrigger ([ & limitSwitch ] { return limitSwitch . Get (); }); Trigger Bindings Note The C++ command-based library offers two overloads of each button binding method - one that takes an rvalue reference ( CommandPtr&& ), and one that takes a raw pointer ( Command* ). The rvalue overload moves ownership to the scheduler, while the raw pointer overload leaves the user responsible for the lifespan of the command object. It is recommended that users preferentially use the rvalue reference overload unless there is a specific need to retain a handle to the command in the calling code. There are a number of bindings available for the Trigger class. All of these bindings will automatically schedule a command when a certain trigger activation event occurs - however, each binding has different specific behavior. Trigger objects do not need to survive past the call to a binding method , so the binding methods may be simply called on a temp. Remember that button binding is declarative : bindings only need to be declared once, ideally some time during robot initialization. The library handles everything else. Note The Button subclass is deprecated, and usage of its binding methods should be replaced according to the respective deprecation messages in the API docs. onTrue This binding schedules a command when a trigger changes from false to true (or, accordingly, when a button changes is initially pressed). The command will be scheduled on the iteration when the state changes, and will not be scheduled again unless the trigger becomes false and then true again (or the button is released and then re-pressed). JAVA 65 // Retract the intake with the Y button 66 m_driverController . y (). onTrue ( m_intake . retractCommand ()); C++ 28 // Deploy the intake with the X button 29 m_driverController . X (). OnTrue ( m_intake . IntakeCommand ()); The onFalse binding is identical, only that it schedules on false instead of on true . whileTrue This binding schedules a command when a trigger changes from false to true (or, accordingly, when a button is initially pressed) and cancels it when the trigger becomes false again (or the button is released). The command will not be re-scheduled if it finishes while the trigger is still true . For the command to restart if it finishes while the trigger is true , wrap the command in a RepeatCommand , or use a RunCommand instead of an InstantCommand . JAVA 49 // Schedule `exampleMethodCommand` when the Xbox controller's B button is pressed, 50 // cancelling on release. 51 m_driverController . b (). whileTrue ( m_exampleSubsystem . exampleMethodCommand ()); C++ 27 // Schedule `ExampleMethodCommand` when the Xbox controller's B button is 28 // pressed, cancelling on release. 29 m_driverController . B (). WhileTrue ( m_subsystem . ExampleMethodCommand ()); The whileFalse binding is identical, only that it schedules on false and cancels on true . toggleOnTrue This binding toggles a command, scheduling it when a trigger changes from false to true (or a button is initially pressed), and canceling it under the same condition if the command is currently running. Note that while this functionality is supported, toggles are not a highly-recommended option for user control, as they require the driver to keep track of the robot state. The preferred method is to use two buttons; one to turn on and another to turn off. Using a StartEndCommand or a ConditionalCommand is a good way to specify the commands that you want to be want to be toggled between. JAVA 78 // Toggle compressor with the Start button 79 m_driverController . start (). toggleOnTrue ( m_pneumatics . disableCompressorCommand ()); C++ 41 // Toggle compressor with the Start button 42 m_driverController . Start (). ToggleOnTrue ( 43 m_pneumatics . DisableCompressorCommand ()); The toggleOnFalse binding is identical, only that it toggles on false instead of on true . Chaining Calls It is useful to note that the command binding methods all return the trigger that they were called on, and thus can be chained to bind multiple commands to different states of the same trigger. For example: JAVA exampleButton // Binds a FooCommand to be scheduled when the button is pressed . onTrue ( new FooCommand ()) // Binds a BarCommand to be scheduled when that same button is released . onFalse ( new BarCommand ()); C++ exampleButton // Binds a FooCommand to be scheduled when the button is pressed . OnTrue ( FooCommand (). ToPtr ()) // Binds a BarCommand to be scheduled when that same button is released . OnFalse ( BarCommand (). ToPtr ()); Composing Triggers The Trigger class can be composed to create composite triggers through the and() , or() , and negate() methods (or, in C++, the && , || , and ! operators). For example: JAVA // Binds an ExampleCommand to be scheduled when both the 'X' and 'Y' buttons of the driver gamepad are pressed exampleCommandController . x () . and ( exampleCommandController . y ()) . onTrue ( new ExampleCommand ()); C++ // Binds an ExampleCommand to be scheduled when both the 'X' and 'Y' buttons of the driver gamepad are pressed ( exampleCommandController . X () && exampleCommandController . Y ()) . OnTrue ( ExampleCommand (). ToPtr ()); Debouncing Triggers To avoid rapid repeated activation, triggers (especially those originating from digital inputs) can be debounced with the WPILib Debouncer class using the debounce method: JAVA // debounces exampleButton with a 0.1s debounce time, rising edges only exampleButton . debounce ( 0.1 ). onTrue ( new ExampleCommand ()); // debounces exampleButton with a 0.1s debounce time, both rising and falling edges exampleButton . debounce ( 0.1 , Debouncer . DebounceType . kBoth ). onTrue ( new ExampleCommand ()); C++ // debounces exampleButton with a 100ms debounce time, rising edges only exampleButton . Debounce ( 100 _ms ). OnTrue ( ExampleCommand (). ToPtr ()); // debounces exampleButton with a 100ms debounce time, both rising and falling edges exampleButton . Debounce ( 100 _ms , Debouncer :: DebounceType :: Both ). OnTrue ( ExampleCommand (). ToPtr ());",
      "content_preview": "Binding Commands to Triggers Apart from autonomous commands, which are scheduled at the start of the autonomous period, and default commands, which are automatically scheduled whenever their subsystem is not currently in-use, the most common way to run a command is by binding it to a triggering..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/debouncer.html",
      "title": "Debouncer",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Debouncer A debouncer is a filter used to eliminate unwanted quick on/off cycles (termed “bounces,” originally from the physical vibrations of a switch as it is thrown). These cycles are usually due to a sensor error like noise or reflections and not the actual event the sensor is trying to record. Debouncing is implemented in WPILib by the Debouncer class ( Java , C++ , Python ), which filters a boolean stream so that the output only changes if the input sustains a change for some nominal time period. Modes The WPILib Debouncer can be configured in three different modes: Rising (default): Debounces rising edges (transitions from false to true ) only. Falling: Debounces falling edges (transitions from true to false ) only. Both: Debounces all transitions. Usage JAVA // Initializes a DigitalInput on DIO 0 DigitalInput input = new DigitalInput ( 0 ); // Creates a Debouncer in \"both\" mode. Debouncer m_debouncer = new Debouncer ( 0.1 , Debouncer . DebounceType . kBoth ); // So if currently false the signal must go true for at least .1 seconds before being read as a True signal. if ( m_debouncer . calculate ( input . get ())) { // Do something now that the DI is True. } C++ // Initializes a DigitalInput on DIO 0 frc :: DigitalInput input { 0 }; // Creates a Debouncer in \"both\" mode. frc :: Debouncer m_debouncer { 100 _ms , frc :: Debouncer :: DebounceType :: kBoth }; // So if currently false the signal must go true for at least .1 seconds before being read as a True signal. if ( m_debouncer . calculate ( input . Get ())) { // Do something now that the DI is True. } PYTHON from wpilib import DigitalInput from wpimath.filter import Debouncer # Initializes a DigitalInput on DIO 0 self . input = DigitalInput ( 0 ) # Creates a Debouncer in \"both\" mode with a debounce time of 0.1 seconds self . debouncer = Debouncer ( 0.1 , Debouncer . DebounceType . kBoth ) # If currently false, the signal must go true for at least 0.1 seconds before being read as a True signal. if self . debouncer . calculate ( self . input . get ()): # Do something now that the DI is True. pass",
      "content_preview": "Debouncer A debouncer is a filter used to eliminate unwanted quick on/off cycles (termed “bounces,” originally from the physical vibrations of a switch as it is thrown). These cycles are usually due to a sensor error like noise or reflections and not the actual event the sensor is trying to record."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/index.html",
      "title": "Advanced Controls",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Advanced Controls This section covers advanced control features in WPILib, such as various feedback/feedforward control algorithms and trajectory following. A Video Walkthrough of Model Based Validation of Autonomous in FRC Advanced Controls Introduction Control System Basics Picking a Control Strategy Introduction to DC Motor Feedforward Introduction to PID PID Introduction Video by WPI Introduction To Controls Tuning Tutorials Tuning a Flywheel Velocity Controller Tuning a Turret Position Controller Tuning a Vertical Arm Position Controller Tuning a Vertical Elevator with Motion Profiling Common Control Loop Tuning Issues Filters Introduction to Filters Linear Filters Median Filter Slew Rate Limiter Debouncer Geometry Classes Translation, Rotation, and Pose Transformations System Identification Introduction to System Identification Creating an Identification Routine Running the Identification Routine Loading Data Viewing Diagnostics Analyzing Data Additional Utilities and Tools Controllers PID Control in WPILib Feedforward Control in WPILib Combining Feedforward and PID Control Trapezoidal Motion Profiles in WPILib Combining Motion Profiling and PID Control with ProfiledPIDController Bang-Bang Control with BangBangController Trajectory Generation and Following with WPILib Trajectory Generation Trajectory Constraints Manipulating Trajectories Transforming Trajectories LTV Unicycle Controller Ramsete Controller Holonomic Drive Controller Troubleshooting State-Space and Model Based Control with WPILib Introduction to State-Space Control State-Space Controller Walkthrough State Observers and Kalman Filters Pose Estimators Debugging State-Space Models and Controllers Controls Glossary",
      "content_preview": "Advanced Controls This section covers advanced control features in WPILib, such as various feedback/feedforward control algorithms and trajectory following."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/index.html",
      "title": "Advanced Controls Introduction",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Advanced Controls Introduction Control System Basics Picking a Control Strategy Introduction to DC Motor Feedforward Introduction to PID PID Introduction Video by WPI Introduction To Controls Tuning Tutorials Tuning a Flywheel Velocity Controller Tuning a Turret Position Controller Tuning a Vertical Arm Position Controller Tuning a Vertical Elevator with Motion Profiling Common Control Loop Tuning Issues",
      "content_preview": "Advanced Controls Introduction Control System Basics Picking a Control Strategy Introduction to DC Motor Feedforward Introduction to PID PID Introduction Video by WPI Introduction To Controls Tuning Tutorials Tuning a Flywheel Velocity Controller Tuning a Turret Position Controller Tuning a..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/introduction-to-pid.html",
      "title": "Introduction to PID",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction to PID Note For a guide on implementing PID control with WPILib, see PID Control in WPILib . This page explains the conceptual and mathematical workings of a PID controller. A video explanation from WPI is also available . What is a PID Controller? The PID controller is a common feedback controller consisting of proportional, integral, and derivative terms, hence the name. This article will build up the definition of a PID controller term by term while trying to provide some intuition for how each term behaves. First, we’ll get some nomenclature for PID controllers out of the way. In a PID context, we use the term reference or setpoint to mean the desired state of the mechanism, and the term output or process variable to refer to the measured state of the mechanism. Below are some common variable naming conventions for relevant quantities. \\(r(t)\\) setpoint , reference \\(u(t)\\) control effort \\(e(t)\\) error \\(y(t)\\) output , process variable The error \\(e(t)\\) is the difference between the reference and the output , \\(r(t) - y(t)\\) . For those already familiar with PID control, this interpretation may not be consistent with the classical explanation of the P, I, and D terms corresponding to response to “past”, “present”, and “future” errors. While that model has merit, we will instead be approaching PID control from the viewpoint of modern control theory, as proportional controllers applied to different physical quantities we care about. This will provide a more complete explanation of the derivative term’s behavior for constant and moving setpoints . Roughly speaking: the proportional term drives the position error to zero, the derivative term drives the velocity error to zero, and the integral term drives the total accumulated error-over-time to zero. All three terms are added together to produce the control signal . We’ll go into more detail on each of these below. Note Throughout the WPILib documentation, you’ll see two ways of writing the tunable constants of the PID controller. For example, for the proportional gain: \\(K_p\\) is the standard math-equation-focused way to notate the constant. kP is a common way to see it written as a variable in software. Despite the differences in capitalization, the two formats refer to the same concept. Proportional Term The Proportional term attempts to drive the position error to zero by contributing to the control signal proportionally to the current position error. Intuitively, this tries to move the output towards the reference . \\[u(t) = K_p e(t)\\] where \\(K_p\\) is the proportional gain and \\(e(t)\\) is the error at the current time \\(t\\) . The below figure shows a block diagram for a system controlled by a P controller. Proportional gains act like a “software-defined springs” that pull the system toward the desired position. Recall from physics that we model springs as \\(F = - kx\\) where \\(F\\) is the force applied, \\(k\\) is a proportional constant, and \\(x\\) is the displacement from the equilibrium point. This can be written another way as \\(F = k(0-x)\\) where \\(0\\) is the equilibrium point. If we let the equilibrium point be our feedback controller’s setpoint , the equations have a one to one correspondence. \\[\\begin{split}F &= k(r - x) \\\\ u(t) &= K_p e(t) = K_p(r(t) - y(t))\\end{split}\\] so the “force” with which the proportional controller pulls the system’s output toward the setpoint is proportional to the error , just like a spring. Derivative Term The Derivative term attempts to drive the derivative of the error to zero by contributing to the control signal proportionally to the derivative of the error. Intuitively, this tries to make the output move at the same rate as the reference . \\[u(t) = K_p e(t) + K_d \\frac{de}{dt}\\] where \\(K_p\\) is the proportional gain, \\(K_d\\) is the derivative gain, and \\(e(t)\\) is the error at the current time \\(t\\) . The below figure shows a block diagram for a system controlled by a PD controller. A PD controller has a proportional controller for position ( \\(K_p\\) ) and a proportional controller for velocity ( \\(K_d\\) ). The velocity setpoint is implicitly provided by how the position setpoint changes over time. To prove this, we will rearrange the equation for a PD controller. \\[u_k = K_p e_k + K_d \\frac{e_k - e_{k-1}}{dt}\\] where \\(u_k\\) is the control effort at timestep \\(k\\) and \\(e_k\\) is the error at timestep \\(k\\) . \\(e_k\\) is defined as \\(e_k = r_k - x_k\\) where \\(r_k\\) is the setpoint and \\(x_k\\) is the current state at timestep \\(k\\) . \\[\\begin{split}u_k &= K_p (r_k - x_k) + K_d \\frac{(r_k - x_k) - (r_{k-1} - x_{k-1})}{dt} \\\\ u_k &= K_p (r_k - x_k) + K_d \\frac{r_k - x_k - r_{k-1} + x_{k-1}}{dt} \\\\ u_k &= K_p (r_k - x_k) + K_d \\frac{r_k - r_{k-1} - x_k + x_{k-1}}{dt} \\\\ u_k &= K_p (r_k - x_k) + K_d \\frac{(r_k - r_{k-1}) - (x_k - x_{k-1})}{dt} \\\\ u_k &= K_p (r_k - x_k) + K_d \\left(\\frac{r_k - r_{k-1}}{dt} - \\frac{x_k - x_{k-1}}{dt}\\right)\\end{split}\\] Notice how \\(\\frac{r_k - r_{k-1}}{dt}\\) is the velocity of the setpoint . By the same reason, \\(\\frac{x_k - x_{k-1}}{dt}\\) is the system’s velocity at a given timestep. That means the \\(K_d\\) term of the PD controller is driving the estimated velocity to the setpoint velocity. If the setpoint is constant, the implicit velocity setpoint is zero, so the \\(K_d\\) term slows the system down if it’s moving. This acts like a “software-defined damper”. These are commonly seen on door closers, and their damping force increases linearly with velocity. Integral Term Important Integral gain is generally not recommended for FRC® use. It is almost always better to use a feedforward controller to eliminate steady-state error. If you do employ integral gain, it is crucial to provide some protection against integral windup . The Integral term attempts to drive the total accumulated error to zero by contributing to the control signal proportionally to the sum of all past errors. Intuitively, this tries to drive the average of all past output values towards the average of all past reference values. \\[u(t) = K_p e(t) + K_i \\int_0^t e(\\tau) \\,d\\tau\\] where \\(K_p\\) is the proportional gain, \\(K_i\\) is the integral gain, \\(e(t)\\) is the error at the current time \\(t\\) , and \\(\\tau\\) is the integration variable. The Integral integrates from time \\(0\\) to the current time \\(t\\) . we use \\(\\tau\\) for the integration because we need a variable to take on multiple values throughout the integral, but we can’t use \\(t\\) because we already defined that as the current time. The below figure shows a block diagram for a system controlled by a PI controller. When the system is close the setpoint in steady-state, the proportional term may be too small to pull the output all the way to the setpoint , and the derivative term is zero. This can result in steady-state error as shown in figure 2.4 A common way of eliminating steady-state error is to integrate the error and add it to the control effort . This increases the control effort until the system converges. Figure 2.4 shows an example of steady-state error for a flywheel, and figure 2.5 shows how an integrator added to the flywheel controller eliminates it. However, too high of an integral gain can lead to overshoot, as shown in figure 2.6. Putting It All Together Note For information on using the WPILib provided PIDController, see the relevant article . When these terms are combined by summing them all together, one gets the typical definition for a PID controller. \\[u(t) = K_p e(t) + K_i \\int_0^t e(\\tau) \\,d\\tau + K_d \\frac{de}{dt}\\] where \\(K_p\\) is the proportional gain, \\(K_i\\) is the integral gain, \\(K_d\\) is the derivative gain, \\(e(t)\\) is the error at the current time \\(t\\) , and \\(\\tau\\) is the integration variable. The below figure shows a block diagram for a PID controller. Response Types A system driven by a PID controller generally has three types of responses: underdamped, over-damped, and critically damped. These are shown in figure 2.8. For the step responses in figure 2.7, rise time is the time the system takes to initially reach the reference after applying the step input . Settling time is the time the system takes to settle at the reference after the step input is applied. An underdamped response oscillates around the reference before settling. An overdamped response is slow to rise and does not overshoot the reference . A critically damped response has the fastest rise time without overshooting the reference .",
      "content_preview": "Introduction to PID Note For a guide on implementing PID control with WPILib, see PID Control in WPILib . This page explains the conceptual and mathematical workings of a PID controller. A video explanation from WPI is also available ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/index.html",
      "title": "System Identification",
      "section": "Advanced Controls",
      "language": "All",
      "content": "System Identification Introduction to System Identification Creating an Identification Routine Running the Identification Routine Loading Data Viewing Diagnostics Analyzing Data Additional Utilities and Tools",
      "content_preview": "System Identification Introduction to System Identification Creating an Identification Routine Running the Identification Routine Loading Data Viewing Diagnostics Analyzing Data Additional Utilities and Tools"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/manipulating-trajectories.html",
      "title": "Manipulating Trajectories",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Manipulating Trajectories Once a trajectory has been generated, you can retrieve information from it using certain methods. These methods will be useful when writing code to follow these trajectories. Getting the total duration of the trajectory Because all trajectories have timestamps at each point, the amount of time it should take for a robot to traverse the entire trajectory is pre-determined. The TotalTime() (C++) / getTotalTimeSeconds() (Java) / totalTime (Python) method can be used to determine the time it takes to traverse the trajectory. JAVA // Get the total time of the trajectory in seconds double duration = trajectory . getTotalTimeSeconds (); C++ // Get the total time of the trajectory units :: second_t duration = trajectory . TotalTime (); PYTHON # Get the total time of the trajectory duration = trajectory . totalTime () Sampling the trajectory The trajectory can be sampled at various timesteps to get the pose, velocity, and acceleration at that point. The Sample(units::second_t time) (C++) / sample(double timeSeconds) (Java/Python) method can be used to sample the trajectory at any timestep. The parameter refers to the amount of time passed since 0 seconds (the starting point of the trajectory). This method returns a Trajectory::Sample with information about that sample point. JAVA // Sample the trajectory at 1.2 seconds. This represents where the robot // should be after 1.2 seconds of traversal. Trajectory . Sample point = trajectory . sample ( 1.2 ); C++ // Sample the trajectory at 1.2 seconds. This represents where the robot // should be after 1.2 seconds of traversal. Trajectory :: State point = trajectory . Sample ( 1.2 _s ); PYTHON # Sample the trajectory at 1.2 seconds. This represents where the robot # should be after 1.2 seconds of traversal. point = trajectory . sample ( 1.2 ) The Trajectory::Sample struct has several pieces of information about the sample point: t : The time elapsed from the beginning of the trajectory up to the sample point. velocity : The velocity at the sample point. acceleration : The acceleration at the sample point. pose : The pose (x, y, heading) at the sample point. curvature : The curvature (rate of change of heading with respect to distance along the trajectory) at the sample point. Note: The angular velocity at the sample point can be calculated by multiplying the velocity by the curvature. Getting all states of the trajectory (advanced) A more advanced user can get a list of all states of the trajectory by calling the States() (C++) / getStates() (Java) / states (Python) method. Each state represents a point on the trajectory. When the trajectory is created using the TrajectoryGenerator::GenerateTrajectory(...) method, a list of trajectory points / states are created. When the user samples the trajectory at a particular timestep, a new sample point is interpolated between two existing points / states in the list.",
      "content_preview": "Manipulating Trajectories Once a trajectory has been generated, you can retrieve information from it using certain methods. These methods will be useful when writing code to follow these trajectories."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controls-glossary.html",
      "title": "Controls Glossary",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Controls Glossary bang-bang control A very simple, no-tuning-required closed-loop control technique. It simply “turns on” the control effort when the process variable is too small, and “turns off” the control effort when the process variable is too big. It works well in some cases, but not all. See “Bang-bang” control on Wikipedia for more info. Cartesian coordinate system A set of points in space where each point is described by a set of numbers, indicating its coordinates within that space. These coordinates are an expression of the orthogonal distance of each point from a set of fixed, orthogonal axes (IE, a “rectangular” system). 2-dimension and 3-dimension spaces are most common in FRC (and likely what was learned in algebra 1), but any number of dimensions is theoretically possible. See Cartesian coordinate system on Wikipedia for more info. churning losses Complex friction-like forces arising from the fact that when gears and bearings rotate, they must displace liquid lubricant. This reduces the efficiency of rotating mechanisms. control signal The driving signal sent to a plant by a controller , usually quantified as a voltage. control effort Control signal control law A mathematical formula that generates inputs to drive a system to a desired state , given the current state . A common example is the control law \\(\\mathbf{u} = \\mathbf{K(r - x)}\\) controller Used in position or negative feedback with a plant to bring about a desired system state by driving the difference between a reference signal and the output to zero. convolution A mathematical operation that calculates a weighted moving average of one function, with the weights assigned by a second function. A common way to “filter” sensor input is to apply a convolution to it, using a carefully-chosen filtering function. See convolution on Wikipedia for more info. counter-electromotive force A voltage generated in a spinning motor. The voltage is a result of the fact that has a coil of wire rotating near a magnet. See Counter-electromotive_force on Wikipedia for more info. current The flow of electrons through a conductor. Current is described with a unit of “Amps” (or simply “A”), and is measured at a single point in a circuit. One amp is equal to \\(6241509074000000000\\) electrons moving past the measurement point in one second. dynamics A branch of physics concerned with the motion of bodies under the action of forces. In modern control, systems evolve according to their dynamics. derivative A mathematical operation which evaluates the “rate-of-change” of a function at a given point. See derivative on Wikipedia for more info. error Reference minus an output or state . exponential search An iterative process of finding a specific value within a wide search range by applying a multiplicative factor to the search value. See exponential search on Wikipedia for more info. exponential smoothing A very common way to implement a simple low-pass filter, using an exponential window function in a convolution with an input signal. The convolution operation simplifies down to a very simple set of math operations on the current input and previous output. See exponential smoothing on Wikipedia for more info. gain A scalar value that relates the magnitude of an input signal to the magnitude of an output signal. For example, gain in output = gain * input . A gain greater than one would amplify an input signal, while a gain less than one would dampen an input signal. A negative gain would negate the input signal. Gaussian distribution A special mathematical function that describes distributions of averages. The graph of a Gaussian function is a “bell curve” shape. This function is described by its mean (the location of the “peak” of the bell curve) and variance (a measure of how “spread out” the bell curve is). See Gaussian distribution on Wikipedia for more info. gradient The derivative , but applied to a function with multiple inputs. As a result, the output is both the magnitude of the rate of change, and the vector direction along which it occurs. hidden state A state that cannot be directly measured, but whose dynamics can be related to other states. input An input to the plant (hence the name) that can be used to change the plant’s state . Ex. A flywheel will have 1 input: the voltage of the motor driving it. Ex. A drivetrain might have 2 inputs: the voltages of the left and right motors. Inputs are often represented by the variable \\(\\mathbf{u}\\) , a column vector with one entry per input to the system . least-squares regression A curve-fitting technique which picks a curve to minimize the square of the error between the fitted curve and the actual measured data. See ordinary least-squares regression on Wikipedia for more info. LQR Linear-Quadratic Regulator - A feedback control scheme which seeks to operate a system in a “most optimal” or “lowest cost” manner, in the sense of minimizing the square of some “cost function” that represents a combination of system error and control effort. This requires an accurate mathematical model of the system being controlled, and function describing the “cost” of any given system state. See LQR on Wikipedia for more info. measurement Measurements are outputs that are measured from a plant , or physical system, using sensors. model A set of mathematical equations that reflects some aspect of a physical system 's behavior. observer In control theory, a system that provides an estimate of the internal state of a given real system from measurements of the input and output of the real system . WPILib includes a Kalman Filter class for observing linear systems, and ExtendedKalmanFilter and UnscentedKalmanFilter classes for nonlinear systems. orthogonal Having the property of being independent, or lacking mutual influence. For example, two lines are orthogonal if moving any number of units along one line causes zero displacement along the other line. In a cartesian coordinate system , orthogonal lines are often said to have 90-degree angles between each other. output Measurements from sensors. There can be more measurements than states. These outputs are used in the “correct” step of Kalman Filters. Ex. A flywheel might have 1 output from a encoder that measures it’s velocity. Ex. A drivetrain might use solvePNP and V-SLAM to find it’s x/y/heading position on the field. It’s fine that there are 6 measurements (solvePNP x/y/heading and V-SLAM x/y/heading) and 3 states (robot x/y/heading). Outputs of a system are often represented using the variable \\(\\mathbf{y}\\) , a column vector with one entry per output (or thing we can measure). For example, if our system had states for velocity and acceleration but our sensor could only measure velocity, our output vector would only include the system 's velocity. phase portrait A graph of a function’s value and its derivative as they change in time, given some initial starting conditions. They are useful for analyzing system behavior (stable/unstable operating points, limit cycles, etc.) given a certain set of parameters or starting conditions. See phase portrait on Wikipedia for more info. PID Proportional-Integral-Derivative - A feedback controller which calculates a control signal from a weighted sum of the error , the rate of change of the error, and an accumulated sum of previous errors. See PID controller on Wikipedia for more info. plant The system or collection of actuators being controlled. process variable The term used to describe the output of a plant in the context of PID control. r-squared A statistical measurement of how well a model predicts a set of data, representing the fraction of the observed variation in the independent variable that is accurately predicted by the model. The value typically runs from 0.0 (a terrible fit, equivalent to just guessing the average value of your independent variable) to 1.0 (a perfect fit). See Coefficient_of_determination on Wikipedia for more info. reference The desired state. This value is used as the reference point for a controller’s error calculation. rise time The time a system takes to initially reach the reference after applying a step input . RMSE Root Mean Squared Error - Statistical measurement of how well a curve is fit to a set of data. It is calculated as the square root of the average (mean) of the squares of all the errors between the actual sample and the curve fit. It has units of the original input data. See Root Mean Squared Error on Wikipedia for more info. setpoint The term used to describe the reference of a PID controller. settling time The time a system takes to settle at the reference after a step input is applied. signum function A non-continuous function that expresses the “sign” of its input. It is equal to -1 for all negative input numbers, 0 for an input of 0, and 1 for all positive input numbers. See signum function on Wikipedia for more info. state A characteristic of a system (e.g., velocity) that can be used to determine the system 's future behavior. In state-space notation, the state of a system is written as a column vector describing its position in state-space. Ex. A drivetrain system might have the states \\(\\begin{bmatrix}x \\\\ y \\\\ \\theta \\end{bmatrix}\\) to describe its position on the field. Ex. An elevator system might have the states \\(\\begin{bmatrix} \\text{position} \\\\ \\text{velocity} \\end{bmatrix}\\) to describe its current height and velocity. A system 's state is often represented by the variable \\(\\mathbf{x}\\) , a column vector with one entry per state . statistically robust The property of a data processing algorithm which makes it resilient to a noisy or outlier-prone data set. Designing statistically robust algorithms on robots is important because real-world sensor data can often be unpredictable, but unexpected robot behavior is never desirable. See Robust Statistics on Wikipedia for more info. steady-state error Error after system reaches equilibrium. step input A system input that is \\(0\\) for \\(t < 0\\) and a constant greater than \\(0\\) for \\(t \\geq 0\\) . A step input that is \\(1\\) for \\(t \\geq 0\\) is called a unit step input. step response The response of a system to a step input . system A term encompassing a plant and its interaction with a controller and observer , which are treated as a single entity. Mathematically speaking, a system maps inputs to outputs through a linear combination of states . system identification The process of capturing a system 's dynamics in a mathematical model using measured data. The SysId toolsuite uses system identification to find kS, kV, and kA terms. system response The behavior of a system over time for a given input . voltage The measurement of how much an electric field is “pushing” electrons through a circuit. It is sometimes called “Electromotive Force”, or “EMF”. It is measured in units of “Volts”. It always is defined between two points in a circuit. If one electron travels between two points that have one volt of EMF between them, it will have been accelerated to the point of having \\(\\frac{1}{6241509074000000000}\\) joules of energy. viscous drag The force generated from an object moving relatively slowly through non-turbulent fluid. In this region, the force is roughly proportional to the velocity of the object. It describes the most common type of “air resistance” an FRC robot would encounter, as well as losses in a gearbox from displacing grease. See Drag (physics) on Wikipedia for more info. x-dot \\(\\dot{\\mathbf{x}}\\) , or x-dot: the derivative of the state vector \\(\\mathbf{x}\\) . If the system had just a velocity state , then \\(\\dot{\\mathbf{x}}\\) would represent the system 's acceleration. x-hat \\(\\hat{\\mathbf{x}}\\) , or x-hat: the estimated state of a system, as estimated by an observer .",
      "content_preview": "Controls Glossary bang-bang control A very simple, no-tuning-required closed-loop control technique. It simply “turns on” the control effort when the process variable is too small, and “turns off” the control effort when the process variable is too big. It works well in some cases, but not all."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/ramsete.html",
      "title": "Ramsete Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Ramsete Controller Warning Ramsete Controller has been deprecated . Use LTV Unicycle Controller which has more intuitive tuning. The Ramsete Controller is a trajectory tracker that is built in to WPILib. This tracker can be used to accurately track trajectories with correction for minor disturbances for differential drivetrains. Constructing the Ramsete Controller Object The Ramsete controller should be initialized with two gains, namely b and zeta . Larger values of b make convergence more aggressive like a proportional term whereas larger values of zeta provide more damping in the response. These controller gains only dictate how the controller will output adjusted velocities. It does NOT affect the actual velocity tracking of the robot. This means that these controller gains are generally robot-agnostic. Note Gains of 2.0 and 0.7 for b and zeta have been tested repeatedly to produce desirable results when all units were in meters. As such, a zero-argument constructor for RamseteController exists with gains defaulted to these values. JAVA // Using the default constructor of RamseteController. Here // the gains are initialized to 2.0 and 0.7. RamseteController controller1 = new RamseteController (); // Using the secondary constructor of RamseteController where // the user can choose any other gains. RamseteController controller2 = new RamseteController ( 2.1 , 0.8 ); C++ // Using the default constructor of RamseteController. Here // the gains are initialized to 2.0 and 0.7. frc :: RamseteController controller1 ; // Using the secondary constructor of RamseteController where // the user can choose any other gains. frc :: RamseteController controller2 { 2.1 , 0.8 }; PYTHON from wpimath.controller import RamseteController # Using the default constructor of RamseteController. Here # the gains are initialized to 2.0 and 0.7. controller1 = RamseteController () # Using the secondary constructor of RamseteController where # the user can choose any other gains. controller2 = RamseteController ( 2.1 , 0.8 ) Getting Adjusted Velocities The Ramsete controller returns “adjusted velocities” so that the when the robot tracks these velocities, it accurately reaches the goal point. The controller should be updated periodically with the new reference, which is where it should be at the current time. The reference comprises of a desired pose, desired linear velocity, and desired angular velocity. Furthermore, the current position of the robot should also be updated periodically. The controller uses these four arguments to return the adjusted linear and angular velocity. Users should command their robot to these linear and angular velocities to achieve optimal trajectory tracking. Note The “reference pose” represents the position that the robot should be at a particular timestep when tracking the trajectory. It does NOT represent the final endpoint of the trajectory, which is the goal. The controller can be updated using the Calculate (C++) / calculate (Java/Python) method. There are two overloads for this method. Both of these overloads accept the current robot position as the first parameter. For the other parameters, one of these overloads takes in the reference as three separate parameters (pose, linear velocity, and angular velocity) whereas the other overload accepts a Trajectory.State object, which contains information about the reference pose. For its ease, users should use the latter method when tracking trajectories. JAVA Trajectory . State reference = trajectory . sample ( 3.4 ); // sample the trajectory at 3.4 seconds from the beginning ChassisSpeeds adjustedSpeeds = controller . calculate ( currentRobotPose , reference ); C++ const Trajectory :: State reference = trajectory . Sample ( 3.4 _s ); // sample the trajectory at 3.4 seconds from the beginning ChassisSpeeds adjustedSpeeds = controller . Calculate ( currentRobotPose , reference ); PYTHON reference = trajectory . sample ( 3.4 ) # sample the trajectory at 3.4 seconds from the beginning adjustedSpeeds = controller . calculate ( currentRobotPose , reference ) These calculations should be performed at every loop iteration, with an updated robot position and reference. Using the Adjusted Velocities The adjusted velocities are of type ChassisSpeeds , which contains a vx (linear velocity in the forward direction), a vy (linear velocity in the sideways direction), and an omega (angular velocity around the center of the robot frame). Because the Ramsete controller is a controller for non-holonomic robots (robots which cannot move sideways), the adjusted speeds object has a vy of zero. The returned adjusted speeds can be converted to usable speeds using the kinematics classes for your drivetrain type. For example, the adjusted velocities can be converted to left and right velocities for a differential drive using a DifferentialDriveKinematics object. JAVA ChassisSpeeds adjustedSpeeds = controller . calculate ( currentRobotPose , reference ); DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( adjustedSpeeds ); double left = wheelSpeeds . leftMetersPerSecond ; double right = wheelSpeeds . rightMetersPerSecond ; C++ ChassisSpeeds adjustedSpeeds = controller . Calculate ( currentRobotPose , reference ); DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . ToWheelSpeeds ( adjustedSpeeds ); auto [ left , right ] = kinematics . ToWheelSpeeds ( adjustedSpeeds ); PYTHON adjustedSpeeds = controller . calculate ( currentRobotPose , reference ) wheelSpeeds = kinematics . toWheelSpeeds ( adjustedSpeeds ) left = wheelSpeeds . left right = wheelSpeeds . right Because these new left and right velocities are still speeds and not voltages, two PID Controllers, one for each side may be used to track these velocities. Either the WPILib PIDController ( C++ , Java , Python ) can be used, or the Velocity PID feature on smart motor controllers such as the TalonSRX and the SPARK MAX can be used. Ramsete in the Command-Based Framework For the sake of ease for users, a RamseteCommand class is built in to WPILib. For a full tutorial on implementing a path-following autonomous using RamseteCommand, see Trajectory Tutorial .",
      "content_preview": "Ramsete Controller Warning Ramsete Controller has been deprecated . Use LTV Unicycle Controller which has more intuitive tuning. The Ramsete Controller is a trajectory tracker that is built in to WPILib."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/tutorial-intro.html",
      "title": "Introduction To Controls Tuning Tutorials",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction To Controls Tuning Tutorials The WPILib docs include multiple interactive tuning simulations. Their goal is to allow students to learn how tuning parameters impact system behavior, without having to deal with software bugs or other real-world behavior. Even though WPILib tooling can provide you with optimal gains, it is worth going through the manual tuning process to see how the different control strategies interact with the mechanism. Ultimately, students should use the examples to build intuition and make their time on the robot more productive. This page details a few tips while working with the tutorials. Parameter Exponential Search While interacting with the simulations, you will get instructions to “increase” or “decrease” different parameters. When “increasing” a value, multiply it by two until the expected effect is observed. After the first time the value becomes too large (i.e. the behavior is unstable or the mechanism overshoots), reduce the value to halfway between the first too-large value encountered and the previous value tested before that. Continue iterating this “split-half” procedure to zero in on the optimal value (if the response undershoots, pick the halfway point between the new value and the last value immediately above it - if it overshoots, pick the halfway point between the new value and the last value immediately below it). This is called an exponential search , and is a very efficient way to find positive values of unknown scale. System Noise The “system noise” option introduces random, gaussian error into the plant to provide a more realistic situation of system behavior. Leave the setting turned off at first to learn the system’s ideal behavior. Later, turn it on to see how your tuning works in the presence of real-world effects. Be Systematic As seen in the introduction to PID , a PID controller has three tuned constants.Feedforward components will add even more. This means searching for the “correct” constants manually can be quite difficult - it is therefore necessary to approach the tuning procedure systematically. Follow the order of tuning presented in the tutorials - it will maximize your chances of success. Resist checking the tuning solutions until you believe your solution is close to correct. Then check your answer, and try the provided one to compare against your own results. Furthermore, work from easy to difficult. The tutorials progress in complexity in this order: Flywheel Mechanisms Turret Mechanisms Vertical Arm Mechanisms Vertical Elevator Mechanisms (with Motion Profiling)",
      "content_preview": "Introduction To Controls Tuning Tutorials The WPILib docs include multiple interactive tuning simulations. Their goal is to allow students to learn how tuning parameters impact system behavior, without having to deal with software bugs or other real-world behavior."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/holonomic.html",
      "title": "Holonomic Drive Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Holonomic Drive Controller The holonomic drive controller is a trajectory tracker for robots with holonomic drivetrains (e.g. swerve, mecanum, etc.). This can be used to accurately track trajectories with correction for minor disturbances. Constructing a Holonomic Drive Controller The holonomic drive controller should be instantiated with 2 PID controllers and 1 profiled PID controller. Note For more information on PID control, see PID Control in WPILib . The 2 PID controllers are controllers that should correct for error in the field-relative x and y directions respectively. For example, if the first 2 arguments are PIDController(1, 0, 0) and PIDController(1.2, 0, 0) respectively, the holonomic drive controller will add an additional meter per second in the x direction for every meter of error in the x direction and will add an additional 1.2 meters per second in the y direction for every meter of error in the y direction. The final parameter is a ProfiledPIDController for the rotation of the robot. Because the rotation dynamics of a holonomic drivetrain are decoupled from movement in the x and y directions, users can set custom heading references while following a trajectory. These heading references are profiled according to the parameters set in the ProfiledPIDController . JAVA var controller = new HolonomicDriveController ( new PIDController ( 1 , 0 , 0 ), new PIDController ( 1 , 0 , 0 ), new ProfiledPIDController ( 1 , 0 , 0 , new TrapezoidProfile . Constraints ( 6.28 , 3.14 ))); // Here, our rotation profile constraints were a max velocity // of 1 rotation per second and a max acceleration of 180 degrees // per second squared. C++ frc :: HolonomicDriveController controller { frc :: PIDController { 1 , 0 , 0 }, frc :: PIDController { 1 , 0 , 0 }, frc :: ProfiledPIDController < units :: radian > { 1 , 0 , 0 , frc :: TrapezoidProfile < units :: radian >:: Constraints { 6.28 _rad_per_s , 3.14 _rad_per_s / 1 _s }}}; // Here, our rotation profile constraints were a max velocity // of 1 rotation per second and a max acceleration of 180 degrees // per second squared. PYTHON from wpimath.controller import ( HolonomicDriveController , PIDController , ProfiledPIDControllerRadians , ) from wpimath.trajectory import TrapezoidProfileRadians controller = HolonomicDriveController ( PIDController ( 1 , 0 , 0 ), PIDController ( 1 , 0 , 0 ), ProfiledPIDControllerRadians ( 1 , 0 , 0 , TrapezoidProfileRadians . Constraints ( 6.28 , 3.14 ) ), ) # Here, our rotation profile constraints were a max velocity # of 1 rotation per second and a max acceleration of 180 degrees # per second squared. Getting Adjusted Velocities The holonomic drive controller returns “adjusted velocities” such that when the robot tracks these velocities, it accurately reaches the goal point. The controller should be updated periodically with the new goal. The goal is comprised of a desired pose, linear velocity, and heading. Note The “goal pose” represents the position that the robot should be at a particular timestamp when tracking the trajectory. It does NOT represent the trajectory’s endpoint. The controller can be updated using the Calculate (C++) / calculate (Java/Python) method. There are two overloads for this method. Both of these overloads accept the current robot position as the first parameter and the desired heading as the last parameter. For the middle parameters, one overload accepts the desired pose and the linear velocity reference while the other accepts a Trajectory.State object, which contains information about the goal pose. The latter method is preferred for tracking trajectories. JAVA // Sample the trajectory at 3.4 seconds from the beginning. Trajectory . State goal = trajectory . sample ( 3.4 ); // Get the adjusted speeds. Here, we want the robot to be facing // 70 degrees (in the field-relative coordinate system). ChassisSpeeds adjustedSpeeds = controller . calculate ( currentRobotPose , goal , Rotation2d . fromDegrees ( 70.0 )); C++ // Sample the trajectoty at 3.4 seconds from the beginning. const auto goal = trajectory . Sample ( 3.4 _s ); // Get the adjusted speeds. Here, we want the robot to be facing // 70 degrees (in the field-relative coordinate system). const auto adjustedSpeeds = controller . Calculate ( currentRobotPose , goal , 70 _deg ); PYTHON from wpimath.geometry import Rotation2d # Sample the trajectory at 3.4 seconds from the beginning. goal = trajectory . sample ( 3.4 ) # Get the adjusted speeds. Here, we want the robot to be facing # 70 degrees (in the field-relative coordinate system). adjustedSpeeds = controller . calculate ( currentRobotPose , goal , Rotation2d . fromDegrees ( 70.0 ) ) Using the Adjusted Velocities The adjusted velocities are of type ChassisSpeeds , which contains a vx (linear velocity in the forward direction), a vy (linear velocity in the sideways direction), and an omega (angular velocity around the center of the robot frame). The returned adjusted speeds can be converted into usable speeds using the kinematics classes for your drivetrain type. In the example code below, we will assume a swerve drive robot; however, the kinematics code is exactly the same for a mecanum drive robot except using MecanumDriveKinematics . JAVA SwerveModuleState [] moduleStates = kinematics . toSwerveModuleStates ( adjustedSpeeds ); SwerveModuleState frontLeft = moduleStates [ 0 ] ; SwerveModuleState frontRight = moduleStates [ 1 ] ; SwerveModuleState backLeft = moduleStates [ 2 ] ; SwerveModuleState backRight = moduleStates [ 3 ] ; C++ auto [ fl , fr , bl , br ] = kinematics . ToSwerveModuleStates ( adjustedSpeeds ); PYTHON fl , fr , bl , br = kinematics . toSwerveModuleStates ( adjustedSpeeds ) Because these swerve module states are still speeds and angles, you will need to use PID controllers to set these speeds and angles.",
      "content_preview": "Holonomic Drive Controller The holonomic drive controller is a trajectory tracker for robots with holonomic drivetrains (e.g. swerve, mecanum, etc.). This can be used to accurately track trajectories with correction for minor disturbances."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/trapezoidal-profiles.html",
      "title": "Trapezoidal Motion Profiles in WPILib",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Trapezoidal Motion Profiles in WPILib Note This article covers the in-code generation of trapezoidal motion profiles. Documentation describing the involved concepts in more detail is forthcoming. Note For a guide on implementing the TrapezoidProfile class in the command-based framework framework, see Motion Profiling in Command-based . Note The TrapezoidProfile class, used on its own, is most useful when composed with a custom controller (such as a “smart” motor controller with a built-in PID functionality). To integrate it with a WPILib PIDController , see Combining Motion Profiling and PID Control with ProfiledPIDController . While feedforward and feedback control offer convenient ways to achieve a given setpoint, we are often still faced with the problem of generating setpoints for our mechanisms. While the naive approach of immediately commanding a mechanism to its desired state may work, it is often suboptimal. To improve the handling of our mechanisms, we often wish to command mechanisms to a sequence of setpoints that smoothly interpolate between its current state, and its desired goal state. To help users do this, WPILib provides a TrapezoidProfile class ( Java , C++ , Python ). Creating a TrapezoidProfile Note In C++, the TrapezoidProfile class is templated on the unit type used for distance measurements, which may be angular or linear. The passed-in values must have units consistent with the distance units, or a compile-time error will be thrown. For more information on C++ units, see The C++ Units Library . Constraints Note The various feedforward helper classes provide methods for calculating the maximum simultaneously-achievable velocity and acceleration of a mechanism. These can be very useful for calculating appropriate motion constraints for your TrapezoidProfile . In order to create a trapezoidal motion profile, we must first impose some constraints on the desired motion. Namely, we must specify a maximum velocity and acceleration that the mechanism will be expected to achieve during the motion. To do this, we create an instance of the TrapezoidProfile.Constraints class ( Java , C++ , Python ): JAVA // Creates a new set of trapezoidal motion profile constraints // Max velocity of 10 meters per second // Max acceleration of 20 meters per second squared new TrapezoidProfile . Constraints ( 10 , 20 ); C++ // Creates a new set of trapezoidal motion profile constraints // Max velocity of 10 meters per second // Max acceleration of 20 meters per second squared frc :: TrapezoidProfile < units :: meters >:: Constraints { 10 _mps , 20 _mps_sq }; PYTHON from wpimath.trajectory import TrapezoidProfile # Creates a new set of trapezoidal motion profile constraints # Max velocity of 10 meters per second # Max acceleration of 20 meters per second squared TrapezoidProfile . Constraints ( 10 , 20 ) Start and End States Next, we must specify the desired starting and ending states for our mechanisms using the TrapezoidProfile.State class ( Java , C++ , Python ). Each state has a position and a velocity: JAVA // Creates a new state with a position of 5 meters // and a velocity of 0 meters per second new TrapezoidProfile . State ( 5 , 0 ); C++ // Creates a new state with a position of 5 meters // and a velocity of 0 meters per second frc :: TrapezoidProfile < units :: meters >:: State { 5 _m , 0 _mps }; PYTHON from wpimath.trajectory import TrapezoidProfile # Creates a new state with a position of 5 meters # and a velocity of 0 meters per second TrapezoidProfile . State ( 5 , 0 ) Putting It All Together Note C++ is often able to infer the type of the inner classes, and thus a simple initializer list (without the class name) can be sent as a parameter. The full class names are included in the example below for clarity. Now that we know how to create a set of constraints and the desired start/end states, we are ready to create our motion profile. The TrapezoidProfile constructor takes 1 parameter: the constraints. JAVA // Creates a new TrapezoidProfile // Profile will have a max vel of 5 meters per second // Profile will have a max acceleration of 10 meters per second squared TrapezoidProfile profile = new TrapezoidProfile ( new TrapezoidProfile . Constraints ( 5 , 10 )); C++ // Creates a new TrapezoidProfile // Profile will have a max vel of 5 meters per second // Profile will have a max acceleration of 10 meters per second squared frc :: TrapezoidProfile < units :: meters > profile { frc :: TrapezoidProfile < units :: meters >:: Constraints { 5 _mps , 10 _mps_sq }}; PYTHON from wpimath.trajectory import TrapezoidProfile # Creates a new TrapezoidProfile # Profile will have a max vel of 5 meters per second # Profile will have a max acceleration of 10 meters per second squared profile = TrapezoidProfile ( TrapezoidProfile . Constraints ( 5 , 10 )) Using a TrapezoidProfile Sampling the Profile Once we’ve created a TrapezoidProfile , using it is very simple: to get the profile state at the given time after the profile has started, call the calculate() method with the goal state and initial state: JAVA // Profile will start stationary at zero position // Profile will end stationary at 5 meters // Returns the motion profile state after 5 seconds of motion profile . calculate ( 5 , new TrapezoidProfile . State ( 0 , 0 ), new TrapezoidProfile . State ( 5 , 0 )); C++ // Profile will start stationary at zero position // Profile will end stationary at 5 meters // Returns the motion profile state after 5 seconds of motion profile . Calculate ( 5 _s , frc :: TrapezoidProfile < units :: meters >:: State { 0 _m , 0 _mps }, frc :: TrapezoidProfile < units :: meters >:: State { 5 _m , 0 _mps }); PYTHON # Profile will start stationary at zero position # Profile will end stationary at 5 meters # Returns the motion profile state after 5 seconds of motion profile . calculate ( 5 , TrapezoidProfile . State ( 0 , 0 ), TrapezoidProfile . State ( 5 , 0 )) Using the State The calculate method returns a TrapezoidProfile.State class (the same one that was used to specify the initial/end states when calculating the profile state). To use this for actual control, simply pass the contained position and velocity values to whatever controller you wish (for example, a PIDController): JAVA var setpoint = profile . calculate ( elapsedTime , initialState , goalState ); controller . calculate ( encoder . getDistance (), setpoint . position ); C++ auto setpoint = profile . Calculate ( elapsedTime , initialState , goalState ); controller . Calculate ( encoder . GetDistance (), setpoint . position . value ()); PYTHON setpoint = profile . calculate ( elapsedTime , initialState , goalState ) controller . calculate ( encoder . getDistance (), setpoint . position ) Complete Usage Example Note In this example, the initial state is re-computed every timestep. This is a somewhat different usage technique than is detailed above, but works according to the same principles - the profile is sampled at a time corresponding to the loop period to get the setpoint for the next loop iteration. A more complete example of TrapezoidProfile usage is provided in the ElevatorTrapezoidProfile example project ( Java , C++ , Python ): JAVA 5 package edu.wpi.first.wpilibj.examples.elevatortrapezoidprofile ; 6 7 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 8 import edu.wpi.first.math.trajectory.TrapezoidProfile ; 9 import edu.wpi.first.wpilibj.Joystick ; 10 import edu.wpi.first.wpilibj.TimedRobot ; 11 12 public class Robot extends TimedRobot { 13 private static double kDt = 0.02 ; 14 15 private final Joystick m_joystick = new Joystick ( 1 ); 16 private final ExampleSmartMotorController m_motor = new ExampleSmartMotorController ( 1 ); 17 // Note: These gains are fake, and will have to be tuned for your robot. 18 private final SimpleMotorFeedforward m_feedforward = new SimpleMotorFeedforward ( 1 , 1.5 ); 19 20 // Create a motion profile with the given maximum velocity and maximum 21 // acceleration constraints for the next setpoint. 22 private final TrapezoidProfile m_profile = 23 new TrapezoidProfile ( new TrapezoidProfile . Constraints ( 1.75 , 0.75 )); 24 private TrapezoidProfile . State m_goal = new TrapezoidProfile . State (); 25 private TrapezoidProfile . State m_setpoint = new TrapezoidProfile . State (); 26 27 public Robot () { 28 // Note: These gains are fake, and will have to be tuned for your robot. 29 m_motor . setPID ( 1.3 , 0.0 , 0.7 ); 30 } 31 32 @Override 33 public void teleopPeriodic () { 34 if ( m_joystick . getRawButtonPressed ( 2 )) { 35 m_goal = new TrapezoidProfile . State ( 5 , 0 ); 36 } else if ( m_joystick . getRawButtonPressed ( 3 )) { 37 m_goal = new TrapezoidProfile . State (); 38 } 39 40 // Retrieve the profiled setpoint for the next timestep. This setpoint moves 41 // toward the goal while obeying the constraints. 42 m_setpoint = m_profile . calculate ( kDt , m_setpoint , m_goal ); 43 44 // Send setpoint to offboard controller PID 45 m_motor . setSetpoint ( 46 ExampleSmartMotorController . PIDMode . kPosition , 47 m_setpoint . position , 48 m_feedforward . calculate ( m_setpoint . velocity ) / 12.0 ); 49 } 50 } C++ 5 #include <numbers> 6 7 #include <frc/Joystick.h> 8 #include <frc/TimedRobot.h> 9 #include <frc/controller/SimpleMotorFeedforward.h> 10 #include <frc/trajectory/TrapezoidProfile.h> 11 #include <units/acceleration.h> 12 #include <units/length.h> 13 #include <units/time.h> 14 #include <units/velocity.h> 15 #include <units/voltage.h> 16 17 #include \"ExampleSmartMotorController.h\" 18 19 class Robot : public frc :: TimedRobot { 20 public : 21 static constexpr units :: second_t kDt = 20 _ms ; 22 23 Robot () { 24 // Note: These gains are fake, and will have to be tuned for your robot. 25 m_motor . SetPID ( 1.3 , 0.0 , 0.7 ); 26 } 27 28 void TeleopPeriodic () override { 29 if ( m_joystick . GetRawButtonPressed ( 2 )) { 30 m_goal = { 5 _m , 0 _mps }; 31 } else if ( m_joystick . GetRawButtonPressed ( 3 )) { 32 m_goal = { 0 _m , 0 _mps }; 33 } 34 35 // Retrieve the profiled setpoint for the next timestep. This setpoint moves 36 // toward the goal while obeying the constraints. 37 m_setpoint = m_profile . Calculate ( kDt , m_setpoint , m_goal ); 38 39 // Send setpoint to offboard controller PID 40 m_motor . SetSetpoint ( ExampleSmartMotorController :: PIDMode :: kPosition , 41 m_setpoint . position . value (), 42 m_feedforward . Calculate ( m_setpoint . velocity ) / 12 _V ); 43 } 44 45 private : 46 frc :: Joystick m_joystick { 1 }; 47 ExampleSmartMotorController m_motor { 1 }; 48 frc :: SimpleMotorFeedforward < units :: meters > m_feedforward { 49 // Note: These gains are fake, and will have to be tuned for your robot. 50 1 _V , 1.5 _V * 1 _s / 1 _m }; 51 52 // Create a motion profile with the given maximum velocity and maximum 53 // acceleration constraints for the next setpoint. 54 frc :: TrapezoidProfile < units :: meters > m_profile {{ 1.75 _mps , 0.75 _mps_sq }}; 55 frc :: TrapezoidProfile < units :: meters >:: State m_goal ; 56 frc :: TrapezoidProfile < units :: meters >:: State m_setpoint ; 57 }; 58 59 #ifndef RUNNING_FRC_TESTS 60 int main () { 61 return frc :: StartRobot < Robot > (); 62 } 63 #endif PYTHON 8 import wpilib 9 import wpimath.controller 10 from wpimath.trajectory import TrapezoidProfile 11 12 import examplesmartmotorcontroller 13 14 15 class MyRobot ( wpilib . TimedRobot ): 16 kDt = 0.02 17 18 def robotInit ( self ): 19 self . joystick = wpilib . Joystick ( 1 ) 20 self . motor = examplesmartmotorcontroller . ExampleSmartMotorController ( 1 ) 21 # Note: These gains are fake, and will have to be tuned for your robot. 22 self . feedforward = wpimath . controller . SimpleMotorFeedforwardMeters ( 1 , 1.5 ) 23 24 # Create a motion profile with the given maximum velocity and maximum 25 # acceleration constraints for the next setpoint. 26 self . profile = TrapezoidProfile ( TrapezoidProfile . Constraints ( 1.75 , 0.75 )) 27 28 self . goal = TrapezoidProfile . State () 29 self . setpoint = TrapezoidProfile . State () 30 31 # Note: These gains are fake, and will have to be tuned for your robot. 32 self . motor . setPID ( 1.3 , 0.0 , 0.7 ) 33 34 def teleopPeriodic ( self ): 35 if self . joystick . getRawButtonPressed ( 2 ): 36 self . goal = TrapezoidProfile . State ( 5 , 0 ) 37 elif self . joystick . getRawButtonPressed ( 3 ): 38 self . goal = TrapezoidProfile . State ( 0 , 0 ) 39 40 # Retrieve the profiled setpoint for the next timestep. This setpoint moves 41 # toward the goal while obeying the constraints. 42 self . setpoint = self . profile . calculate ( self . kDt , self . setpoint , self . goal ) 43 44 # Send setpoint to offboard controller PID 45 self . motor . setSetPoint ( 46 examplesmartmotorcontroller . ExampleSmartMotorController . PIDMode . kPosition , 47 self . setpoint . position , 48 self . feedforward . calculate ( self . setpoint . velocity ) / 12 , 49 )",
      "content_preview": "Trapezoidal Motion Profiles in WPILib Note This article covers the in-code generation of trapezoidal motion profiles. Documentation describing the involved concepts in more detail is forthcoming."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/linear-filter.html",
      "title": "Linear Filters",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Linear Filters The first (and most commonly-employed) sort of filter that WPILib supports is a linear filter - or, more specifically, a linear time-invariant (LTI) filter. An LTI filter is, put simply, a weighted moving average - the value of the output stream at any given time is a localized, weighted average of the inputs near that time. The difference between different types of LTI filters is thus reducible to the difference in the choice of the weighting function (also known as a “window function” or an “impulse response”) used. The mathematical term for this operation is convolution . There are two broad “sorts” of impulse responses: infinite impulse responses (IIR), and finite impulse responses (FIR). Infinite impulse responses have infinite “support” - that is, they are nonzero over an infinitely-large region. This means, broadly, that they also have infinite “memory” - once a value appears in the input stream, it will influence all subsequent outputs, forever . This is typically undesirable from a strict signal-processing perspective, however filters with infinite impulse responses tend to be very easy to compute as they can be expressed by simple recursion relations. Finite impulse responses have finite “support” - that is, they are nonzero on a bounded region. The “archetypical” FIR filter is a flat moving average - that is, simply setting the output equal to the average of the past n inputs. FIR filters tend to have more-desirable properties than IIR filters, but are more costly to compute. Linear filters are supported in WPILib through the LinearFilter class ( Java , C++ , , Python ). Creating a LinearFilter Note The C++ LinearFilter class is templated on the data type used for the input. Note Because filters have “memory”, each input stream requires its own filter object. Do not attempt to use the same filter object for multiple input streams. While it is possible to directly instantiate LinearFilter class to build a custom filter, it is far more convenient (and common) to use one of the supplied factory methods, instead: singlePoleIIR The singlePoleIIR() factory method creates a single-pole infinite impulse response filter which performs exponential smoothing . This is the “go-to,” “first-try” low-pass filter in most applications; it is computationally trivial and works in most cases. JAVA // Creates a new Single-Pole IIR filter // Time constant is 0.1 seconds // Period is 0.02 seconds - this is the standard FRC main loop period LinearFilter filter = LinearFilter . singlePoleIIR ( 0.1 , 0.02 ); C++ // Creates a new Single-Pole IIR filter // Time constant is 0.1 seconds // Period is 0.02 seconds - this is the standard FRC main loop period frc :: LinearFilter < double > filter = frc :: LinearFilter < double >:: SinglePoleIIR ( 0.1 _s , 0.02 _s ); PYTHON from wpimath.filter import LinearFilter # Creates a new Single-Pole IIR filter # Time constant is 0.1 seconds # Period is 0.02 seconds - this is the standard FRC main loop period filter = LinearFilter . singlePoleIIR ( 0.1 , 0.02 ) The “time constant” parameter determines the “characteristic timescale” of the filter’s impulse response; the filter will cancel out any signal dynamics that occur on timescales significantly shorter than this. Relatedly, it is also the approximate timescale of the introduced phase lag . The reciprocal of this timescale, multiplied by 2 pi, is the “cutoff frequency” of the filter. The “period” parameter is the period at which the filter’s calculate() method will be called. For the vast majority of implementations, this will be the standard main robot loop period of 0.02 seconds. movingAverage The movingAverage factory method creates a simple flat moving average filter. This is the simplest possible low-pass FIR filter, and is useful in many of the same contexts as the single-pole IIR filter. It is somewhat more costly to compute, but generally behaves in a somewhat nicer manner. JAVA // Creates a new flat moving average filter // Average will be taken over the last 5 samples LinearFilter filter = LinearFilter . movingAverage ( 5 ); C++ // Creates a new flat moving average filter // Average will be taken over the last 5 samples frc :: LinearFilter < double > filter = frc :: LinearFilter < double >:: MovingAverage ( 5 ); PYTHON from wpimath.filter import LinearFilter # Creates a new flat moving average filter # Average will be taken over the last 5 samples filter = LinearFilter . movingAverage ( 5 ) The “taps” parameter is the number of samples that will be included in the flat moving average. This behaves similarly to the “time constant” above - the effective time constant is the number of taps times the period at which calculate() is called. highPass The highPass factory method creates a simple first-order infinite impulse response high-pass filter. This is the “counterpart” to the singlePoleIIR . JAVA // Creates a new high-pass IIR filter // Time constant is 0.1 seconds // Period is 0.02 seconds - this is the standard FRC main loop period LinearFilter filter = LinearFilter . highPass ( 0.1 , 0.02 ); C++ // Creates a new high-pass IIR filter // Time constant is 0.1 seconds // Period is 0.02 seconds - this is the standard FRC main loop period frc :: LinearFilter < double > filter = frc :: LinearFilter < double >:: HighPass ( 0.1 _s , 0.02 _s ); PYTHON from wpimath.filter import LinearFilter # Creates a new high-pass IIR filter # Time constant is 0.1 seconds # Period is 0.02 seconds - this is the standard FRC main loop period filter = LinearFilter . highPass ( 0.1 , 0.02 ) The “time constant” parameter determines the “characteristic timescale” of the filter’s impulse response; the filter will cancel out any signal dynamics that occur on timescales significantly longer than this. Relatedly, it is also the approximate timescale of the introduced phase lead . The reciprocal of this timescale, multiplied by 2 pi, is the “cutoff frequency” of the filter. The “period” parameter is the period at which the filter’s calculate() method will be called. For the vast majority of implementations, this will be the standard main robot loop period of 0.02 seconds. Using a LinearFilter Note In order for the created filter to obey the specified timescale parameter, its calculate() function must be called regularly at the specified period. If, for some reason, a significant lapse in calculate() calls must occur, the filter’s reset() method should be called before further use. Once your filter has been created, using it is easy - simply call the calculate() method with the most recent input to obtain the filtered output: JAVA // Calculates the next value of the output filter . calculate ( input ); C++ // Calculates the next value of the output filter . Calculate ( input ); PYTHON # Calculates the next value of the output filter . calculate ( input )",
      "content_preview": "Linear Filters The first (and most commonly-employed) sort of filter that WPILib supports is a linear filter - or, more specifically, a linear time-invariant (LTI) filter."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/constraints.html",
      "title": "Trajectory Constraints",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Trajectory Constraints In the previous article , you might have noticed that no custom constraints were added when generating the trajectories. Custom constraints allow users to impose more restrictions on the velocity and acceleration at points along the trajectory based on location and curvature. For example, a custom constraint can keep the velocity of the trajectory under a certain threshold in a certain region or slow down the robot near turns for stability purposes. WPILib-Provided Constraints WPILib includes a set of predefined constraints that users can utilize when generating trajectories. The list of WPILib-provided constraints is as follows: CentripetalAccelerationConstraint : Limits the centripetal acceleration of the robot as it traverses along the trajectory. This can help slow down the robot around tight turns. DifferentialDriveKinematicsConstraint : Limits the velocity of the robot around turns such that no wheel of a differential-drive robot goes over a specified maximum velocity. DifferentialDriveVoltageConstraint : Limits the acceleration of a differential drive robot such that no commanded voltage goes over a specified maximum. EllipticalRegionConstraint : Imposes a constraint only in an elliptical region on the field. MaxVelocityConstraint : Imposes a max velocity constraint. This can be composed with the EllipticalRegionConstraint or RectangularRegionConstraint to limit the velocity of the robot only in a specific region. MecanumDriveKinematicsConstraint : Limits the velocity of the robot around turns such that no wheel of a mecanum-drive robot goes over a specified maximum velocity. RectangularRegionConstraint : Imposes a constraint only in a rectangular region on the field. SwerveDriveKinematicsConstraint : Limits the velocity of the robot around turns such that no wheel of a swerve-drive robot goes over a specified maximum velocity. Note The DifferentialDriveVoltageConstraint only ensures that theoretical voltage commands do not go over the specified maximum using a feedforward model . If the robot were to deviate from the reference while tracking, the commanded voltage may be higher than the specified maximum. Creating a Custom Constraint Users can create their own constraint by implementing the TrajectoryConstraint interface. JAVA @Override public double getMaxVelocityMetersPerSecond ( Pose2d poseMeters , double curvatureRadPerMeter , double velocityMetersPerSecond ) { // code here } @Override public MinMax getMinMaxAccelerationMetersPerSecondSq ( Pose2d poseMeters , double curvatureRadPerMeter , double velocityMetersPerSecond ) { // code here } C++ units :: meters_per_second_t MaxVelocity ( const Pose2d & pose , units :: curvature_t curvature , units :: meters_per_second_t velocity ) override { // code here } MinMax MinMaxAcceleration ( const Pose2d & pose , units :: curvature_t curvature , units :: meters_per_second_t speed ) override { // code here } PYTHON from wpimath import units from wpimath.geometry import Pose2d from wpimath.trajectory.constraint import TrajectoryConstraint class MyConstraint ( TrajectoryConstraint ): def maxVelocity ( self , pose : Pose2d , curvature : units . radians_per_meter , velocity : units . meters_per_second , ) -> units . meters_per_second : ... def minMaxAcceleration ( self , pose : Pose2d , curvature : units . radians_per_meter , speed : units . meters_per_second , ) -> TrajectoryConstraint . MinMax : ... The MaxVelocity method should return the maximum allowed velocity for the given pose, curvature, and original velocity of the trajectory without any constraints. The MinMaxAcceleration method should return the minimum and maximum allowed acceleration for the given pose, curvature, and constrained velocity. See the source code ( Java , [C++] ( https://github.com/wpilibsuite/allwpilib/tree/main/wpimath/src/main/native/include/frc/trajectory/constraint )) for the WPILib-provided constraints for more examples on how to write your own custom trajectory constraints.",
      "content_preview": "Trajectory Constraints In the previous article , you might have noticed that no custom constraints were added when generating the trajectories. Custom constraints allow users to impose more restrictions on the velocity and acceleration at points along the trajectory based on location and curvature."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/median-filter.html",
      "title": "Median Filter",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Median Filter A statistically robust alternative to the moving-average filter is the median filter . Where a moving average filter takes the arithmetic mean of the input over a moving sample window, a median filter (per the name) takes a median instead. The median filter is most-useful for removing occasional outliers from an input stream. This makes it particularly well-suited to filtering inputs from distance sensors, which are prone to occasional interference. Unlike a moving average, the median filter will remain completely unaffected by small numbers of outliers, no matter how extreme. The median filter is supported in WPILib through the MedianFilter class ( Java , C++ , , Python ). Creating a MedianFilter Note The C++ MedianFilter class is templated on the data type used for the input. Note Because filters have “memory”, each input stream requires its own filter object. Do not attempt to use the same filter object for multiple input streams. Creating a MedianFilter is simple: JAVA // Creates a MedianFilter with a window size of 5 samples MedianFilter filter = new MedianFilter ( 5 ); C++ // Creates a MedianFilter with a window size of 5 samples frc :: MedianFilter < double > filter ( 5 ); PYTHON from wpimath.filter import MedianFilter # Creates a MedianFilter with a window size of 5 samples filter = MedianFilter ( 5 ) Using a MedianFilter Once your filter has been created, using it is easy - simply call the calculate() method with the most recent input to obtain the filtered output: JAVA // Calculates the next value of the output filter . calculate ( input ); C++ // Calculates the next value of the output filter . Calculate ( input ); PYTHON # Calculates the next value of the output filter . calculate ( input )",
      "content_preview": "Median Filter A statistically robust alternative to the moving-average filter is the median filter . Where a moving average filter takes the arithmetic mean of the input over a moving sample window, a median filter (per the name) takes a median instead."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/tuning-flywheel.html",
      "title": "Tuning a Flywheel Velocity Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Tuning a Flywheel Velocity Controller In this section, we will tune a simple velocity controller for a flywheel. The tuning principles explained here will also work for almost any velocity control scenario. Flywheel Model Description Our “Flywheel” consists of: A rotating inertial mass which launches the game piece (the flywheel) A motor (and possibly a gearbox) driving the mass. For the purposes of this tutorial, this plant is modeled with the same equation used by WPILib’s SimpleMotorFeedforward , with additional adjustment for sensor delay and gearbox inefficiency. The simulation assumes the plant is controlled by feedforward and feedback controllers, composed in this fashion: Where: The plant’s output \\(y(t)\\) is the flywheel rotational velocity The controller’s setpoint \\(r(t)\\) is the desired velocity of the flywheel The controller’s control effort , \\(u(t)\\) is the voltage applied to the motor driving the flywheel’s motion Note A more detailed description of the mathematics of the system can be found here . Picking the Control Strategy for a Flywheel Velocity Controller In general: the more voltage that is applied to the motor, the faster the flywheel will spin. Once voltage is removed, friction and back-EMF oppose the motion and bring the flywheel to a stop. Flywheels are commonly used to propel game pieces through the air, toward a target. In this simulation, a gamepiece is injected into the flywheel about halfway through the simulation. [ 1 ] To consistently launch a gamepiece, a good first step is to make sure it is spinning at a particular speed before putting a gamepiece into it. Thus, we want to accurately control the velocity of our flywheel. Note This is fundamentally different from the vertical arm and turret controllers, which both control position . The tutorials below will demonstrate the behavior of the system under bang-bang, pure feedforward, pure feedback (PID), and combined feedforward-feedback control strategies. Follow the instructions to learn how to manually tune these controllers, and expand the “tuning solution” to view an optimal model-based set of tuning parameters. Bang-Bang Control Interact with the simulation below to see how the flywheel system responds when controlled by a bang-bang controller. The “Bang-Bang” controller is a simple controller which applies a binary (present/not-present) force to a mechanism to try to get it closer to a setpoint. A more detailed description (and documentation for the corresponding WPILib implementation) can be found here. There are no tuneable controller parameters for a bang-bang controller - you can only adjust the setpoint. This simplicity is a strength, and also a weakness. Try adjusting the setpoint up and down. You should see that for almost all values, the output converges to be somewhat near the setpoint. Common Issues with Bang-Bang Controllers Note that the system behavior is not perfect, because of delays in the control loop. These can result from the nature of the sensors, measurement filters, loop iteration timers, or even delays in the control hardware itself. Collectively, these cause a cycle of “overshoot” and “undershoot”, as the output repeatedly goes above and below the setpoint. This oscillation is unavoidable with a bang-bang controller. Typically, the steady-state oscillation of a bang-bang controller is small enough that it performs quite well in practice. However, rapid on/off cycling of the control effort can cause mechanical issues - the cycles of rapidly applying and removing forces can loosen bolts and joints, and put a lot of stress on gearboxes. The abrupt changes in control effort can cause abrupt changes in current draw if the system’s inductance is too low. This may stress motor control hardware, and cause eventual damage or failure. Finally, this technique only works for mechanisms that accelerate relatively slowly. A more in-depth discussion of the details can be found here . Bang-bang control sacrifices a lot for simplicity and high performance (in the sense of fast convergence to the setpoint). To achieve “smoother” control, we need to consider a different control strategy. Pure Feedforward Control Interact with the simulation below to see how the flywheel system responds when controlled only by a feedforward controller. To tune the feedforward controller, increase the velocity feedforward gain \\(K_v\\) until the flywheel approaches the correct setpoint over time. If the flywheel overshoots, reduce \\(K_v\\) . Tuning solution The exact gain used by the simulation is \\(K_v = 0.0075\\) . We can see that a pure feedforward control strategy works reasonably well for flywheel velocity control. As we mentioned earlier, this is why it’s possible to control most motors “directly” with joysticks, without any explicit “control loop” at all. However, we can still do better - the pure feedforward strategy cannot reject disturbances, and so takes a while to recover after the ball is introduced. Additionally, the motor may not perfectly obey the feedforward equation (even after accounting for vibration/noise). To account for these, we need a feedback controller. Pure Feedback Control Interact with the simulation below to see how the flywheel system responds when controlled by only a feedback (PID) controller. Perform the following: Set \\(K_p\\) , \\(K_i\\) , \\(K_d\\) , and \\(K_v\\) to zero. Increase \\(K_p\\) until the output starts to oscillate around the setpoint , then decrease it until the oscillations stop. In some cases , increase \\(K_i\\) if output gets “stuck” before converging to the setpoint . Note PID-only control is not a very good control scheme for flywheel velocity! Do not be surprised if/when the simulation below does not behave well, even when the “optimal” constants are used. Tuning solution In this particular example, for a setpoint of 300, values of \\(K_p = 0.1\\) , \\(K_i = 0.0\\) , and \\(K_d = 0.0\\) will produce somewhat reasonable results. Since this control strategy is not very good, it will not work well for all setpoints. You can attempt to improve this behavior by incorporating some \\(K_i\\) , but it is very difficult to achieve good behavior across a wide range of setpoints. Issues with Feedback Control Alone Because a non-zero amount of control effort is required to keep the flywheel spinning, even when the output and setpoint are equal, this feedback-only strategy is flawed. In order to optimally control a flywheel, a combined feedforward-feedback strategy is needed. Combined Feedforward and Feedback Control Interact with the simulation below to see how the flywheel system responds under simultaneous feedforward and feedback (PID) control. Tuning the combined flywheel controller is simple - we first tune the feedforward controller following the same procedure as in the feedforward-only section, and then we tune the PID controller following the same procedure as in the feedback-only section. Notice that PID portion of the controller is much easier to tune “on top of” an accurate feedforward. Tuning solution In this particular example, for a setpoint of 300, values of \\(K_v = 0.0075\\) and \\(K_p = 0.1\\) will produce very good results across all setpoints. Small changes to \\(K_p\\) will change the controller behavior to be more or less aggressive - the optimal choice depends on your problem constraints. Note that the combined feedforward-feedback controller works well across all setpoints, and recovers very quickly after the external disturbance of the ball contacting the flywheel. Tuning Conclusions Applicability of Velocity Control A gamepiece-launching flywheel is one of the most visible applications of velocity control. It is also applicable to drivetrain control - following a pre-defined path in autonomous involves controlling the velocity of the wheels with precision, under a variety of different loads. Choice of Control Strategies Because we are controlling velocity, we can achieve fairly good performance with a pure feedforward controller . This is because a permanent-magnet DC motor’s steady-state velocity is roughly proportional to the voltage applied, and is the reason that you can drive your robot around with joysticks without appearing to use any control loop at all - in that case, you are implicitly using a proportional feedforward model. Because we must apply a constant control voltage to the motor to maintain a velocity at the setpoint, we cannot successfully use a pure feedback (PID) controller (whose output typically disappears when you reach the setpoint) - in order to effectively control velocity, a feedback controller must be combined with a feedforward controller . Bang-bang control can be combined with feedforward control much in the way PID control can - for the sake of brevity we do not include a combined feedforward-bang-bang simulation. Tuning with only feedback can produce reasonable results in cases where no control effort is required to keep the output at the setpoint . This may work for mechanisms like turrets, or swerve drive steering. However, as seen above, it does not work well for a flywheel, where the back-EMF and friction both act to slow the motor even when it is sustaining motion at the setpoint. To control this system, we need to combine the PID controller with a feedforward controller. \\(K_d\\) is not useful for velocity control with a constant setpoint - it is only necessary when the setpoint is changing. Adding an integral gain to the controller is often a sub-optimal way to eliminate steady-state error - you can see how sloppy and “laggy” it is in the simulation above! As we will see soon, a better approach is to combine the PID controller with a feedforward controller. Velocity and Position Control Velocity control also differs from position control in the effect of inertia - in a position controller, inertia tends to cause the mechanism to swing past the setpoint even if the control voltage drops to zero near the setpoint. This makes aggressive control strategies infeasible, as they end up wasting lots of energy fighting self-induced oscillations. In a velocity controller, however, the effect is different - the rotor shaft stops accelerating as soon as you stop applying a control voltage (in fact, it will slow down due to friction and back-EMF), so such overshoots are rare (in fact, overshoot typically occurs in velocity controllers only as a result of loop delay). This enables the use of an extremely simple, extremely aggressive control strategy called bang-bang control . Feedforward Simplifications For the sake of simplicity, the simulations above omit the \\(K_s\\) term from the WPILib SimpleMotorFeedforward equation. On actual mechanisms, however, this can be important - especially if there’s a lot of friction in the mechanism gearing. A flywheel with a lot of static friction will not have a linear control voltage-velocity relationship unless the feedforward controller includes a \\(K_s\\) term to cancel it out. To measure \\(K_s\\) manually, slowly increase the voltage to the mechanism until it starts to move. The value of \\(K_s\\) is the largest voltage applied before the mechanism begins to move. Additionally, there is no need for a \\(K_a\\) term in the feedforward for velocity control unless the setpoint is changing - for a flywheel, this is not a concern, and so the gain is omitted here. Footnotes [ 1 ] For this simulation, we model a ball being injected to the flywheel as a velocity-dependant (frictional) torque fighting the spinning of the wheel for one quarter of a wheel rotation, right around the 5 second mark. This is a very simplistic way to model the ball, but is sufficient to illustrate the controller’s behavior under a sudden load. It would not be sufficient to predict the ball’s trajectory, or the actual “pulldown” in output for the system.",
      "content_preview": "Tuning a Flywheel Velocity Controller In this section, we will tune a simple velocity controller for a flywheel. The tuning principles explained here will also work for almost any velocity control scenario."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/feedforward.html",
      "title": "Feedforward Control in WPILib",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Feedforward Control in WPILib Note This article focuses on in-code implementation of feedforward control in WPILib. For a conceptual explanation of the feedforward equations used by WPILib, see Introduction to DC Motor Feedforward You may have used feedback control (such as PID) for reference tracking (making a system’s output follow a desired reference signal). While this is effective, it’s a reactionary measure; the system won’t start applying control effort until the system is already behind. If we could tell the controller about the desired movement and required input beforehand, the system could react quicker and the feedback controller could do less work. A controller that feeds information forward into the plant like this is called a feedforward controller. A feedforward controller injects information about the system’s dynamics (like a mathematical model does) or the intended movement. Feedforward handles parts of the control actions we already know must be applied to make a system track a reference, then feedback compensates for what we do not or cannot know about the system’s behavior at runtime. The WPILib Feedforward Classes WPILib provides a number of classes to help users implement accurate feedforward control for their mechanisms. In many ways, an accurate feedforward is more important than feedback to effective control of a mechanism. Since most FRC® mechanisms closely obey well-understood system equations, starting with an accurate feedforward is both easy and hugely beneficial to accurate and robust mechanism control. The WPILib feedforward classes closely match the available mechanism characterization tools available in the SysId toolsuite . The system identification toolsuite can be used to quickly and effectively determine the correct gains for each type of feedforward. If you are unable to empirically characterize your mechanism (due to space and/or time constraints), reasonable estimates of kG , kV , and kA can be obtained by fairly simple computation, and are also available from ReCalc . kS is nearly impossible to model, and must be measured empirically. WPILib currently provides the following three helper classes for feedforward control: SimpleMotorFeedforward ( Java , C++ , Python ) ArmFeedforward ( Java , C++ , Python ) ElevatorFeedforward ( Java , C++ , Python ) SimpleMotorFeedforward Note In C++, the SimpleMotorFeedforward class is templated on the unit type used for distance measurements, which may be angular or linear. The passed-in gains must have units consistent with the distance units, or a compile-time error will be thrown. kS should have units of volts , kV should have units of volts * seconds / distance , and kA should have units of volts * seconds^2 / distance . For more information on C++ units, see The C++ Units Library . Note The Java feedforward components will calculate outputs in units determined by the units of the user-provided feedforward gains. Users must take care to keep units consistent, as WPILibJ does not have a type-safe unit system. Note The API documentation for Python feedforward components indicate which unit is being used as wpimath.units.NAME . Users must take care to use correct units, as Python does not have a type-safe unit system. The SimpleMotorFeedforward class calculates feedforwards for mechanisms that consist of permanent-magnet DC motors with no external loading other than friction and inertia, such as flywheels and robot drives. To create a SimpleMotorFeedforward , simply construct it with the required gains: Note The kA gain can be omitted, and if it is, will default to a value of zero. For many mechanisms, especially those with little inertia, it is not necessary. JAVA // Create a new SimpleMotorFeedforward with gains kS, kV, and kA SimpleMotorFeedforward feedforward = new SimpleMotorFeedforward ( kS , kV , kA ); C++ // Create a new SimpleMotorFeedforward with gains kS, kV, and kA // Distance is measured in meters frc :: SimpleMotorFeedforward < units :: meters > feedforward ( kS , kV , kA ); PYTHON from wpimath.controller import SimpleMotorFeedforwardMeters # Create a new SimpleMotorFeedforward with gains kS, kV, and kA # Distance is measured in meters feedforward = SimpleMotorFeedforwardMeters ( kS , kV , kA ) To calculate the feedforward, simply call the calculate() method with the desired motor velocity and acceleration: Note The acceleration argument may be omitted from the calculate() call, and if it is, will default to a value of zero. This should be done whenever there is not a clearly-defined acceleration setpoint. JAVA // Calculates the feedforward for a velocity of 10 units/second and an acceleration of 20 units/second^2 // Units are determined by the units of the gains passed in at construction. feedforward . calculate ( 10 , 20 ); C++ // Calculates the feedforward for a velocity of 10 meters/second and an acceleration of 20 meters/second^2 // Output is in volts feedforward . Calculate ( 10 _mps , 20 _mps_sq ); PYTHON # Calculates the feedforward for a velocity of 10 meters/second and an acceleration of 20 meters/second^2 # Output is in volts feedforward . calculate ( 10 , 20 ) ArmFeedforward Note In C++, the ArmFeedforward class assumes distances are angular, not linear. The passed-in gains must have units consistent with the angular unit, or a compile-time error will be thrown. kS and kG should have units of volts , kV should have units of volts * seconds / radians , and kA should have units of volts * seconds^2 / radians . For more information on C++ units, see The C++ Units Library . Note The Java feedforward components will calculate outputs in units determined by the units of the user-provided feedforward gains. Users must take care to keep units consistent, as WPILibJ does not have a type-safe unit system. Note The API documentation for Python feedforward components indicate which unit is being used as wpimath.units.NAME . Users must take care to use correct units, as Python does not have a type-safe unit system. The ArmFeedforward class calculates feedforwards for arms that are controlled directly by a permanent-magnet DC motor, with external loading of friction, inertia, and mass of the arm. This is an accurate model of most arms in FRC. To create an ArmFeedforward , simply construct it with the required gains: Note The kA gain can be omitted, and if it is, will default to a value of zero. For many mechanisms, especially those with little inertia, it is not necessary. JAVA // Create a new ArmFeedforward with gains kS, kG, kV, and kA ArmFeedforward feedforward = new ArmFeedforward ( kS , kG , kV , kA ); C++ // Create a new ArmFeedforward with gains kS, kG, kV, and kA frc :: ArmFeedforward feedforward ( kS , kG , kV , kA ); PYTHON from wpimath.controller import ArmFeedforward # Create a new ArmFeedforward with gains kS, kG, kV, and kA feedforward = ArmFeedforward ( kS , kG , kV , kA ) To calculate the feedforward, simply call the calculate() method with the desired arm position, velocity, and acceleration: Note The acceleration argument may be omitted from the calculate() call, and if it is, will default to a value of zero. This should be done whenever there is not a clearly-defined acceleration setpoint. JAVA // Calculates the feedforward for a position of 1 units, a velocity of 2 units/second, and // an acceleration of 3 units/second^2 // Units are determined by the units of the gains passed in at construction. feedforward . calculate ( 1 , 2 , 3 ); C++ // Calculates the feedforward for a position of 1 radians, a velocity of 2 radians/second, and // an acceleration of 3 radians/second^2 // Output is in volts feedforward . Calculate ( 1 _rad , 2 _rad_per_s , 3 _rad / ( 1 _s * 1 _s )); PYTHON # Calculates the feedforward for a position of 1 radians, a velocity of 2 radians/second, and # an acceleration of 3 radians/second^2 # Output is in volts feedforward . calculate ( 1 , 2 , 3 ) ElevatorFeedforward Note In C++, the passed-in gains must have units consistent with the distance units, or a compile-time error will be thrown. kS and kG should have units of volts , kV should have units of volts * seconds / distance , and kA should have units of volts * seconds^2 / distance . For more information on C++ units, see The C++ Units Library . Note The Java feedforward components will calculate outputs in units determined by the units of the user-provided feedforward gains. Users must take care to keep units consistent, as WPILibJ does not have a type-safe unit system. Note The API documentation for Python feedforward components indicate which unit is being used as wpimath.units.NAME . Users must take care to use correct units, as Python does not have a type-safe unit system. The ElevatorFeedforward class calculates feedforwards for elevators that consist of permanent-magnet DC motors loaded by friction, inertia, and the mass of the elevator. This is an accurate model of most elevators in FRC. To create a ElevatorFeedforward , simply construct it with the required gains: Note The kA gain can be omitted, and if it is, will default to a value of zero. For many mechanisms, especially those with little inertia, it is not necessary. JAVA // Create a new ElevatorFeedforward with gains kS, kG, kV, and kA ElevatorFeedforward feedforward = new ElevatorFeedforward ( kS , kG , kV , kA ); C++ // Create a new ElevatorFeedforward with gains kS, kV, and kA // Distance is measured in meters frc :: ElevatorFeedforward feedforward ( kS , kG , kV , kA ); PYTHON from wpimath.controller import ElevatorFeedforward # Create a new ElevatorFeedforward with gains kS, kV, and kA # Distance is measured in meters feedforward = ElevatorFeedforward ( kS , kG , kV , kA ) To calculate the feedforward, simply call the calculate() method with the desired motor velocity and acceleration: Note The acceleration argument may be omitted from the calculate() call, and if it is, will default to a value of zero. This should be done whenever there is not a clearly-defined acceleration setpoint. JAVA // Calculates the feedforward for a velocity of 20 units/second // and an acceleration of 30 units/second^2 // Units are determined by the units of the gains passed in at construction. feedforward . calculate ( 20 , 30 ); C++ // Calculates the feedforward for a velocity of 20 meters/second // and an acceleration of 30 meters/second^2 // Output is in volts feedforward . Calculate ( 20 _mps , 30 _mps_sq ); PYTHON # Calculates the feedforward for a velocity of 20 meters/second # and an acceleration of 30 meters/second^2 # Output is in volts feedforward . calculate ( 20 , 30 ) Using Feedforward to Control Mechanisms Note Since feedforward voltages are physically meaningful, it is best to use the setVoltage() ( Java , C++ , Python ) method when applying them to motors to compensate for “voltage sag” from the battery. Feedforward control can be used entirely on its own, without a feedback controller. This is known as “open-loop” control, and for many mechanisms (especially robot drives) can be perfectly satisfactory. A SimpleMotorFeedforward might be employed to control a robot drive as follows: JAVA public void tankDriveWithFeedforward ( double leftVelocity , double rightVelocity ) { leftMotor . setVoltage ( feedforward . calculate ( leftVelocity )); rightMotor . setVoltage ( feedForward . calculate ( rightVelocity )); } C++ void TankDriveWithFeedforward ( units :: meters_per_second_t leftVelocity , units :: meters_per_second_t rightVelocity ) { leftMotor . SetVoltage ( feedforward . Calculate ( leftVelocity )); rightMotor . SetVoltage ( feedforward . Calculate ( rightVelocity )); } PYTHON def tankDriveWithFeedforward ( self , leftVelocity : float , rightVelocity : float ): self . leftMotor . setVoltage ( feedForward . calculate ( leftVelocity )) self . rightMotor . setVoltage ( feedForward . calculate ( rightVelocity ))",
      "content_preview": "Feedforward Control in WPILib Note This article focuses on in-code implementation of feedforward control in WPILib. For a conceptual explanation of the feedforward equations used by WPILib, see Introduction to DC Motor Feedforward You may have used feedback control (such as PID) for reference..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-intro.html",
      "title": "Introduction to State",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction to State-Space Control Note This article is from Controls Engineering in FRC by Tyler Veness with permission. From PID to Model-Based Control When tuning PID controllers, we focus on fiddling with controller parameters relating to the current, past, and future error (P, I, and D terms) rather than the underlying system states. While this approach works in a lot of situations, it is an incomplete view of the world. Model-based control focuses on developing an accurate model of the system (mechanism) we are trying to control. These models help inform gains picked for feedback controllers based on the physical responses of the system, rather than an arbitrary proportional gain derived through testing. This allows us not only to predict ahead of time how a system will react, but also test our controllers without a physical robot and save time debugging simple bugs. Note State-space control makes extensive use of linear algebra. More on linear algebra in modern control theory, including an introduction to linear algebra and resources, can be found in Chapter 5 of Controls Engineering in FRC . If you’ve used WPILib’s feedforward classes for SimpleMotorFeedforward or its sister classes, or used SysId to pick PID gains for you, you’re already familiar with model-based control! The kv and ka gains can be used to describe how a motor (or arm, or drivetrain) will react to voltage. We can put these constants into standard state-space notation using WPILib’s LinearSystem , something we will do in a later article. Vocabulary For the background vocabulary that will be used throughout this article, see the Glossary . Introduction to Linear Algebra For a short and intuitive introduction to the core concepts of Linear Algebra, we recommend chapters 1 through 4 of 3Blue1Brown’s Essence of linear algebra series (Vectors, what even are they?, Linear combinations, span, and basis vectors, Linear transformations and matrices, and Matrix multiplication as composition). What is State-Space? Recall that 2D space has two axes: x and y. We represent locations within this space as a pair of numbers packaged in a vector, and each coordinate is a measure of how far to move along the corresponding axis. State-space is a Cartesian coordinate system with an axis for each state variable, and we represent locations within it the same way we do for 2D space: with a list of numbers in a vector. Each element in the vector corresponds to a state of the system. This example shows two example state vectors in the state-space of an elevator model with the states \\([\\text{position}, \\text{velocity}]\\) : In this image, the vectors representing states in state-space are arrows. From now on these vectors will be represented simply by a point at the vector’s tip, but remember that the rest of the vector is still there. In addition to the state , inputs and outputs are represented as vectors. Since the mapping from the current states and inputs to the change in state is a system of equations, it’s natural to write it in matrix form. This matrix equation can be written in state-space notation. What is State-Space Notation? State-space notation is a set of matrix equations which describe how a system will evolve over time. These equations relate the change in state \\(\\dot{\\mathbf{x}}\\) , and the output \\(\\mathbf{y}\\) , to linear combinations of the current state vector \\(\\mathbf{x}\\) and input vector \\(\\mathbf{u}\\) . State-space control can deal with continuous-time and discrete-time systems. In the continuous-time case, the rate of change of the system’s state \\(\\mathbf{\\dot{x}}\\) is expressed as a linear combination of the current state \\(\\mathbf{x}\\) and input \\(\\mathbf{u}\\) . In contrast, discrete-time systems expresses the state of the system at our next timestep \\(\\mathbf{x}_{k+1}\\) based on the current state \\(\\mathbf{x}_k\\) and input \\(\\mathbf{u}_k\\) , where \\(k\\) is the current timestep and \\(k+1\\) is the next timestep. In both the continuous- and discrete-time forms, the output vector \\(\\mathbf{y}\\) is expressed as a linear combination of the current state and input . In many cases, the output is a subset of the system’s state, and has no contribution from the current input. When modeling systems, we first derive the continuous-time representation because the equations of motion are naturally written as the rate of change of a system’s state as a linear combination of its current state and inputs. We convert this representation to discrete-time on the robot because we update the system in discrete timesteps there instead of continuously. The following two sets of equations are the standard form of continuous-time and discrete-time state-space notation: \\[\\begin{split}\\text{Continuous: } \\dot{\\mathbf{x}} &= \\mathbf{A}\\mathbf{x} + \\mathbf{B}\\mathbf{u} \\\\ \\mathbf{y} &= \\mathbf{C}\\mathbf{x} + \\mathbf{D}\\mathbf{u} \\\\ \\nonumber \\\\ \\text{Discrete: } \\mathbf{x}_{k+1} &= \\mathbf{A}\\mathbf{x}_k + \\mathbf{B}\\mathbf{u}_k \\\\ \\mathbf{y}_k &= \\mathbf{C}\\mathbf{x}_k + \\mathbf{D}\\mathbf{u}_k\\end{split}\\] \\[\\begin{split}\\begin{array}{llll} \\mathbf{A} & \\text{system matrix} & \\mathbf{x} & \\text{state vector} \\\\ \\mathbf{B} & \\text{input matrix} & \\mathbf{u} & \\text{input vector} \\\\ \\mathbf{C} & \\text{output matrix} & \\mathbf{y} & \\text{output vector} \\\\ \\mathbf{D} & \\text{feedthrough matrix} & & \\\\ \\end{array}\\end{split}\\] A continuous-time state-space system can be converted into a discrete-time system through a process called discretization. Note In the discrete-time form, the system’s state is held constant between updates. This means that we can only react to disturbances as quickly as our state estimate is updated. Updating our estimate more quickly can help improve performance, up to a point. WPILib’s Notifier class can be used if updates faster than the main robot loop are desired. Note While a system’s continuous-time and discrete-time matrices A, B, C, and D have the same names, they are not equivalent. The continuous-time matrices describes the rate of change of the state, \\(\\mathbf{x}\\) , while the discrete-time matrices describe the system’s state at the next timestep as a function of the current state and input. Important WPILib’s LinearSystem takes continuous-time system matrices, and converts them internally to the discrete-time form where necessary. State-space Notation Example: Flywheel from Kv and Ka Recall that we can model the motion of a flywheel connected to a brushed DC motor with the equation \\(V = K_v \\cdot v + K_a \\cdot a\\) , where V is voltage output, v is the flywheel’s angular velocity and a is its angular acceleration. This equation can be rewritten as \\(a = \\frac{V - K_v \\cdot v}{K_a}\\) , or \\(a = \\frac{-K_v}{K_a} \\cdot v + \\frac{1}{K_a} \\cdot V\\) . Notice anything familiar? This equation relates the angular acceleration of the flywheel to its angular velocity and the voltage applied. We can convert this equation to state-space notation. We can create a system with one state (velocity), one input (voltage), and one output (velocity). Recalling that the first derivative of velocity is acceleration, we can write our equation as follows, replacing velocity with \\(\\mathbf{x}\\) , acceleration with \\(\\mathbf{\\dot{x}}\\) , and voltage \\(\\mathbf{V}\\) with \\(\\mathbf{u}\\) : \\[\\mathbf{\\dot{x}} = \\begin{bmatrix}\\frac{-K_v}{K_a}\\end{bmatrix} \\mathbf{x} + \\begin{bmatrix}\\frac{1}{K_a}\\end{bmatrix} \\mathbf{u}\\] The output and state are the same, so the output equation is the following: \\[\\mathbf{y} = \\begin{bmatrix}1\\end{bmatrix} \\mathbf{x} + \\begin{bmatrix}0\\end{bmatrix} \\mathbf{u}\\] That’s it! That’s the state-space model of a system for which we have the \\(K_v\\) and \\(K_a\\) constants. This same math is used in system identification to model flywheels and drivetrain velocity systems. Visualizing State-Space Responses: Phase Portrait A phase portrait can help give a visual intuition for the response of a system in state-space. The vectors on the graph have their roots at some point \\(\\mathbf{x}\\) in state-space, and point in the direction of \\(\\mathbf{\\dot{x}}\\) , the direction that the system will evolve over time. This example shows a model of a pendulum with the states of angle and angular velocity. To trace a potential trajectory that a system could take through state-space, choose a point to start at and follow the arrows around. In this example, we might start at \\([-2, 0]\\) . From there, the velocity increases as we swing through vertical and starts to decrease until we reach the opposite extreme of the swing. This cycle of spinning about the origin repeats indefinitely. Note that near the edges of the phase portrait, the X axis wraps around as a rotation of \\(\\pi\\) radians counter clockwise and a rotation of \\(\\pi\\) radians clockwise will end at the same point. For more on differential equations and phase portraits, see 3Blue1Brown’s Differential Equations video – they do a great job of animating the pendulum phase space at around 15:30. Visualizing Feedforward This phase portrait shows the “open loop” responses of the system – that is, how it will react if we were to let the state evolve naturally. If we want to, say, balance the pendulum horizontal (at \\((\\frac{\\pi}{2}, 0)\\) in state space), we would need to somehow apply a control input to counteract the open loop tendency of the pendulum to swing downward. This is what feedforward is trying to do – make it so that our phase portrait will have an equilibrium at the reference position (or setpoint) in state-space. Looking at our phase portrait from before, we can see that at \\((\\frac{\\pi}{2}, 0)\\) in state space, gravity is pulling the pendulum down with some torque T, and producing some downward angular acceleration with magnitude \\(\\frac{\\tau}{I}\\) , where I is angular moment of inertia of the pendulum. If we want to create an equilibrium at our reference of \\((\\frac{\\pi}{2}, 0)\\) , we would need to apply an input can counteract the system’s natural tendency to swing downward. The goal here is to solve the equation \\(\\mathbf{0 = Ax + Bu}\\) for \\(\\mathbf{u}\\) . Below is shown a phase portrait where we apply a constant input that opposes the force of gravity at \\((\\frac{\\pi}{2}, 0)\\) : Feedback Control In the case of a DC motor, with just a mathematical model and knowledge of all current states of the system (i.e., angular velocity), we can predict all future states given the future voltage inputs. But if the system is disturbed in any way that isn’t modeled by our equations, like a load or unexpected friction, the angular velocity of the motor will deviate from the model over time. To combat this, we can give the motor corrective commands using a feedback controller. A PID controller is a form of feedback control. State-space control often uses the following control law , where \\(\\mathbf{K}\\) is some controller gain matrix, \\(\\mathbf{r}\\) is the reference state, and \\(\\mathbf{x}\\) is the current state in state-space. The difference between these two vectors, \\(\\mathbf{r-x}\\) , is the error . \\[\\mathbf{u} = \\mathbf{K(r - x)}\\] This control law is a proportional controller for each state of our system. Proportional controllers create software-defined springs that pull our system’s state toward our reference state in state-space. In the case that the system being controlled has position and velocity states, the control law above will behave as a PD controller, which also tries to drive position and velocity error to zero. Let’s show an example of this control law in action. We’ll use the pendulum system from above, where the swinging pendulum circled the origin in state-space. The case where \\(\\mathbf{K}\\) is the zero matrix (a matrix with all zeros) would be like picking P and D gains of zero – no control input would be applied, and the phase portrait would look identical to the one above. To add some feedback, we arbitrarily pick a \\(\\mathbf{K}\\) of [2, 2], where our input to the pendulum is angular acceleration. This K would mean that for every radian of position error , the angular acceleration would be 2 radians per second squared; similarly, we accelerate by 2 radians per second squared for every radian per second of error . Try following an arrow from somewhere in state-space inwards – no matter the initial conditions, the state will settle at the reference rather than circle endlessly with pure feedforward. But how can we choose an optimal gain matrix K for our system? While we can manually choose gains and simulate the system response or tune it on-robot like a PID controller, modern control theory has a better answer: the Linear-Quadratic Regulator (LQR). The Linear-Quadratic Regulator Because model-based control means that we can predict the future states of a system given an initial condition and future control inputs, we can pick a mathematically optimal gain matrix \\(\\mathbf{K}\\) . To do this, we first have to define what a “good” or “bad” \\(\\mathbf{K}\\) would look like. We do this by summing the square of error and control input over time, which gives us a number representing how “bad” our control law will be. If we minimize this sum, we will have arrived at the optimal control law. LQR: Definition Linear-Quadratic Regulators work by finding a control law that minimizes the following cost function, which weights the sum of error and control effort over time, subject to the linear system dynamics \\(\\mathbf{x_{k+1} = Ax_k + Bu_k}\\) . \\[J = \\sum\\limits_{k=0}^\\infty \\left(\\mathbf{x}_k^T\\mathbf{Q}\\mathbf{x}_k + \\mathbf{u}_k^T\\mathbf{R}\\mathbf{u}_k\\right)\\] The control law that minimizes \\(\\mathbf{J}\\) can be written as \\(\\mathbf{u = K(r_k - x_k)}\\) , where \\(r_k - x_k\\) is the error . Note LQR design’s \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) matrices don’t need discretization, but the \\(\\mathbf{K}\\) calculated for continuous-time and discrete time systems will be different. LQR: tuning Like PID controllers can be tuned by adjusting their gains, we also want to change how our control law balances our error and input. For example, a spaceship might want to minimize the fuel it expends to reach a given reference, while a high-speed robotic arm might need to react quickly to disturbances. We can weight error and control effort in our LQR with \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) matrices. In our cost function (which describes how “bad” our control law will perform), \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) weight our error and control input relative to each other. In the spaceship example from above, we might use a \\(\\mathbf{Q}\\) with relatively small numbers to show that we don’t want to highly penalize error, while our \\(\\mathbf{R}\\) might be large to show that expending fuel is undesirable. With WPILib, the LQR class takes a vector of desired maximum state excursions and control efforts and converts them internally to full Q and R matrices with Bryson’s rule. We often use lowercase \\(\\mathbf{q}\\) and \\(\\mathbf{r}\\) to refer to these vectors, and \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) to refer to the matrices. Increasing the \\(\\mathbf{q}\\) elements would make the LQR less heavily weight large errors, and the resulting control law will behave more conservatively. This has a similar effect to penalizing control effort more heavily by decreasing \\(\\mathbf{r}\\) 's elements. Similarly, decreasing the \\(\\mathbf{q}\\) elements would make the LQR penalize large errors more heavily, and the resulting control law will behave more aggressively. This has a similar effect to penalizing control effort less heavily by increasing \\(\\mathbf{r}\\) elements. For example, we might use the following Q and R for an elevator system with position and velocity states. JAVA // Example system -- must be changed to match your robot. LinearSystem < N2 , N1 , N1 > elevatorSystem = LinearSystemId . identifyPositionSystem ( 5 , 0.5 ); LinearQuadraticRegulator < N2 , N1 , N1 > controller = new LinearQuadraticRegulator ( elevatorSystem , // q's elements VecBuilder . fill ( 0.02 , 0.4 ), // r's elements VecBuilder . fill ( 12.0 ), // our dt 0.020 ); C++ // Example system -- must be changed to match your robot. LinearSystem < 2 , 1 , 1 > elevatorSystem = frc :: LinearSystemId :: IdentifyVelocitySystem ( 5 , 0.5 ); LinearQuadraticRegulator < 2 , 1 > controller { elevatorSystem , // q's elements { 0.02 , 0.4 }, // r's elements { 12.0 }, // our dt 0.020 _s }; PYTHON from wpimath.controller import LinearQuadraticRegulator_2_1 from wpimath.system.plant import LinearSystemId # Example system -- must be changed to match your robot. elevatorSystem = LinearSystemId . identifyPositionSystemMeters ( 5 , 0.5 ) controller = LinearQuadraticRegulator_2_1 ( elevatorSystem , # q's elements ( 0.02 , 0.4 ), # r's elements ( 12.0 ,), # our dt 0.020 , ) LQR: example application Let’s apply a Linear-Quadratic Regulator to a real-world example. Say we have a flywheel velocity system determined through system identification to have \\(K_v = 1 \\frac{\\text{volts}}{\\text{radian per second}}\\) and \\(K_a = 1.5 \\frac{\\text{volts}}{\\text{radian per second squared}}\\) . Using the flywheel example above, we have the following linear system : \\[\\mathbf{\\dot{x}} = \\begin{bmatrix}\\frac{-K_v}{K_a}\\end{bmatrix} v + \\begin{bmatrix}\\frac{1}{K_a}\\end{bmatrix} V\\] We arbitrarily choose a desired state excursion (maximum error) of \\(q = [0.1\\ \\text{rad/sec}]\\) , and an \\(\\mathbf{r}\\) of \\([12\\ \\text{volts}]\\) . After discretization with a timestep of 20ms, we find a gain of \\(\\mathbf{K} = ~81\\) . This K gain acts as the proportional component of a PID loop on flywheel’s velocity. Let’s adjust \\(\\mathbf{q}\\) and \\(\\mathbf{r}\\) . We know that increasing the q elements or decreasing the \\(\\mathbf{r}\\) elements we use to create \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) would make our controller more heavily penalize control effort , analogous to trying to driving a car more conservatively to improve fuel economy. In fact, if we increase our error tolerance q from 0.1 to 1.0, our gain matrix \\(\\mathbf{K}\\) drops from ~81 to ~11. Similarly, decreasing our maximum voltage \\(r\\) from 12.0 to 1.2 decreases \\(\\mathbf{K}\\) . The following graph shows the flywheel’s angular velocity and applied voltage over time with two different gain s. We can see how a higher gain will make the system reach the reference more quickly (at t = 0.8 seconds), while keeping our motor saturated at 12V for longer. This is exactly the same as increasing the P gain of a PID controller by a factor of ~8x. LQR and Measurement Latency Compensation Oftentimes, our sensors have a delay associated with their measurements. For example the SPARK MAX motor controller over CAN can have up to 30ms of delay associated with velocity measurements. This lag means that our feedback controller will be generating voltage commands based on state estimates from the past. This often has the effect of introducing instability and oscillations into our system, as shown in the graph below. However, we can model our controller to control where the system’s state is delayed into the future. This will reduce the LQR’s gain matrix \\(\\mathbf{K}\\) , trading off controller performance for stability. The below formula, which adjusts the gain matrix to account for delay, is also used in system identification. \\[\\mathbf{K_{compensated}} = \\mathbf{K} \\cdot \\left(\\mathbf{A} - \\mathbf{BK}\\right)^{\\text{delay} / dt}\\] Multiplying \\(\\mathbf{K}\\) by \\(\\mathbf{A} - \\mathbf{BK}\\) essentially advances the gains by one timestep. In this case, we multiply by \\(\\left(\\mathbf{A} - \\mathbf{BK}\\right)^{\\text{delay} / dt}\\) to advance the gains by measurement’s delay. Note This can have the effect of reducing \\(\\mathbf{K}\\) to zero, effectively disabling feedback control. Note The SPARK MAX motor controller uses a 40-tap FIR filter with a delay of 19.5ms, and status frames are by default sent every 20ms. The code below shows how to adjust the LQR controller’s K gain for sensor input delays: JAVA // Adjust our LQR's controller for 25 ms of sensor input delay. We // provide the linear system, discretization timestep, and the sensor // input delay as arguments. controller . latencyCompensate ( elevatorSystem , 0.02 , 0.025 ); C++ // Adjust our LQR's controller for 25 ms of sensor input delay. We // provide the linear system, discretization timestep, and the sensor // input delay as arguments. controller . LatencyCompensate ( elevatorSystem , 20 _ms , 25 _ms ); PYTHON # Adjust our LQR's controller for 25 ms of sensor input delay. We # provide the linear system, discretization timestep, and the sensor # input delay as arguments. controller . latencyCompensate ( elevatorSystem , 0.020 , 0.025 ) Linearization Linearization is a tool used to approximate nonlinear functions and state-space systems using linear ones. In two-dimensional space, linear functions are straight lines while nonlinear functions curve. A common example of a nonlinear function and its corresponding linear approximation is \\(y=\\sin{x}\\) . This function can be approximated by \\(y=x\\) near zero. This approximation is accurate while near \\(x=0\\) , but looses accuracy as we stray further from the linearization point. For example, the approximation \\(\\sin{x} \\approx x\\) is accurate to within 0.02 within 0.5 radians of \\(y = 0\\) , but quickly loses accuracy past that. In the following picture, we see \\(y =\\sin{x}\\) , \\(y=x\\) and the difference between the approximation and the true value of \\(\\sin{x}\\) at \\(x\\) . We can also linearize state-space systems with nonlinear dynamics . We do this by picking a point \\(\\mathbf{x}\\) in state-space and using this as the input to our nonlinear functions. Like in the above example, this works well for states near the point about which the system was linearized, but can quickly diverge further from that state.",
      "content_preview": "Introduction to State-Space Control Note This article is from Controls Engineering in FRC by Tyler Veness with permission. From PID to Model-Based Control When tuning PID controllers, we focus on fiddling with controller parameters relating to the current, past, and future error (P, I, and D terms)..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/index.html",
      "title": "Trajectory Generation and Following with WPILib",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Trajectory Generation and Following with WPILib This section describes WPILib support for generating parameterized spline trajectories and following those trajectories with typical FRC® robot drives. Trajectory Generation Trajectory Constraints Manipulating Trajectories Transforming Trajectories LTV Unicycle Controller Ramsete Controller Holonomic Drive Controller Troubleshooting",
      "content_preview": "Trajectory Generation and Following with WPILib This section describes WPILib support for generating parameterized spline trajectories and following those trajectories with typical FRC® robot drives."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/loading-data.html",
      "title": "Loading Data",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Loading Data After downloading the WPILog containing the tests from the roboRIO, go to the Log Loader pane in SysId and click Open data log file... . After the file loads, look for a string type entry with a name containing “state”. Drag this entry into the Data Selector pane’s Test State slot. Note SysIdRoutine will name the entry “sysid-test-state-mechanism”, where “mechanism” is the name passed to the Mechanism constructor or the subsystem name. Now the Data Selector pane will present Position , Velocity , and Voltage slots. In the Log Loader pane, find entries starting with each of those terms and containing the motor name you set in the log callback, and drag those into the Data Selector slots. Ideally, the correct units for the position and velocity entries would have been set in the code before running the tests. If this was not the case, use the Units dropdown in the Data Selector pane to correct it. Additionally, if you did not account for a gear ratio or some other factor that scales the recorded values up or down uniformly, you can compensate for that by setting position and velocity scaling factors in the provided boxes. Ensure the correct analysis type has been selected, then click the Load button and move on to checking the fit diagnostics in the Diagnostics pane.",
      "content_preview": "Loading Data After downloading the WPILog containing the tests from the roboRIO, go to the Log Loader pane in SysId and click Open data log file... . After the file loads, look for a string type entry with a name containing “state”. Drag this entry into the Data Selector pane’s Test State slot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/introduction.html",
      "title": "Introduction to System Identification",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction to System Identification What is “System Identification?” In Control Theory, system identification is the process of determining a mathematical model for the behavior of a system through statistical analysis of its inputs and outputs. This model is a rule describing how input voltage affects the way our measurements (typically encoder data) evolve in time. A “system identification” routine takes such a model and a dataset and attempts to fit parameters which would make your model most closely-match the dataset. Generally, the model is not perfect - the real-world data are polluted by both measurement noise (e.g. timing errors, encoder resolution limitations) and system noise (unmodeled forces acting on the system, like vibrations). However, even an imperfect model is usually “good enough” to give us accurate feedforward control of the mechanism, and even to estimate optimal gains for feedback control . Assumed Behavioral Model If you haven’t yet, read the full explanation of the feedforward equations used by the WPILib toolsuite in The Permanent-Magnet DC Motor Feedforward Equation . The process of System Identification is to determine concrete values for the coefficients in the model that best-reflect the behavior of your particular real-world system. To determine numeric values for each coefficient in our model, a curve-fitting technique (such as least-squares regression ) is applied to measurements taken from the real mechanism. Careful selection of the data-producing experiments helps improve the accuracy of the curve-fitting. Once these coefficients have been determined, we can then take a given desired velocity and acceleration for the motor and calculate the voltage that should be applied to achieve it. This is very useful - not only for, say, following motion profiles, but also for making mechanisms more controllable in open-loop control, because your joystick inputs will more closely match the actual mechanism motion. Some of the tools in this toolsuite introduce additional terms into the above equation to account for known differences from the simple case described above - details for each tool can be found below: The WPILib System Identification Tool (SysId) The WPILib system identification tool consists of the SysId application that runs on the user’s PC and a routine that lives in the code running on the user’s robot. The routine will generate control signals which user-defined callbacks will send to the motors being characterized, while the robot records data into a log file. After the routine completes, the user will retrieve this file from the roboRIO and load it into SysId. SysId then processes the data and determines model parameters for the user’s robot mechanism, as well as producing diagnostic plots. Included Tools Note With a bit of ingenuity, these tools can be used to accurately characterize a surprisingly large variety of robot mechanisms. Even if your mechanism does not seem to obviously match any of the tools, an understanding of the system equations often reveals that one of the included routines will do. The System Identification toolsuite currently supports: Simple Motor Setups Elevators Arms Several of these options use nearly identical robot-side code, and differ only in the analysis used by SysId to interpret the data. Simple Motor Identification The simple motor identification tool determines the best-fit parameters for the equation: \\[V = K_s \\cdot sgn(\\dot{d}) + K_v \\cdot \\dot{d} + K_a \\cdot \\ddot{d}\\] where \\(V\\) is the applied voltage, \\(d\\) is the displacement (position) of the drive, \\(\\dot{d}\\) is its velocity, and \\(\\ddot{d}\\) is its acceleration. This is the model for a permanent-magnet dc motor with no loading other than friction and inertia, as mentioned above, and is an accurate model for flywheels, turrets, and horizontal linear sliders. Elevator Identification The elevator identification tool determines the best-fit parameters for the equation: \\[V = K_g + K_s \\cdot sgn(\\dot{d}) + K_v \\cdot \\dot{d} + K_a \\cdot \\ddot{d}\\] where \\(V\\) is the applied voltage, \\(d\\) is the displacement (position) of the elevator, \\(\\dot{d}\\) is its velocity, and \\(\\ddot{d}\\) is its acceleration. The constant term ( \\(K_g\\) ) is added to correctly account for the effect of gravity. Arm Identification The arm identification tool determines the best-fit parameters for the equation: \\[V = K_g \\cdot cos(\\theta) + K_s \\cdot sgn(\\dot{\\theta}) + K_v \\cdot \\dot{\\theta} + K_a \\cdot \\ddot{\\theta}\\] where \\(V\\) is the applied voltage, \\(\\theta\\) is the angular displacement (position) of the arm, \\(\\dot{\\theta}\\) is its angular velocity, and \\(\\ddot{\\theta}\\) is its angular acceleration. The cosine term ( \\(K_g\\) ) is added to correctly account for the effect of gravity. Installing SysId SysId is included with the WPILib Installer. Note The old Python characterization tool from previous years is no longer supported. Launching the SysId Tool The system identification tool can be opened from the Start Tool option in VS Code or by using the shortcut inside the WPILib Tools desktop folder (Windows).",
      "content_preview": "Introduction to System Identification What is “System Identification?” In Control Theory, system identification is the process of determining a mathematical model for the behavior of a system through statistical analysis of its inputs and outputs."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/introduction-to-feedforward.html",
      "title": "Introduction to DC Motor Feedforward",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction to DC Motor Feedforward Note For a guide on implementing feedforward control in code with WPILib, see Feedforward Control in WPILib . This page explains the conceptual and mathematical workings of WPILib’s SimpleMotorFeedforward (and the other related classes). The Permanent-Magnet DC Motor Feedforward Equation Recall from earlier that the point of a feedforward controller is to use the known dynamics of a mechanism to make a best guess at the control effort required to put the mechanism in the state you want. In order to do this, we need to have some idea of what kind of mechanism we are controlling - that will determine the relationship between control effort and output , and let us guess at what value of the former will give us the desired value of the latter. In FRC, the most common system that we’re interested in controlling is the permanent-magnet DC motor . These motors have a number of convenient properties that make them particularly easy to control, and ideal for FRC tasks. In particular, they obey a particular relationship between applied voltage, rotor velocity, and rotor acceleration known as a “voltage balance equation”. \\[V = K_s \\cdot sgn(\\dot{d}) + K_v \\cdot \\dot{d} + K_a \\cdot \\ddot{d}\\] where \\(V\\) is the applied voltage, \\(d\\) is the displacement (position) of the motor, \\(\\dot{d}\\) is its velocity, and \\(\\ddot{d}\\) is its acceleration (the “overdot” notation traditionally denotes the derivative with respect to time). We can interpret the coefficients in the above equation as follows: \\(K_s\\) is the voltage needed to overcome the motor’s static friction, or in other words to just barely get it moving; it turns out that this static friction (because it’s, well, static) has the same effect regardless of velocity or acceleration. That is, no matter what speed you’re going or how fast you’re accelerating, some constant portion of the voltage you’ve applied to your motor (depending on the specific mechanism assembly) will be going towards overcoming the static friction in your gears, bearings, etc; this value is your kS. Note the presence of the signum function because friction force always opposes the direction-of-motion. \\(K_v\\) describes how much voltage is needed to hold (or “cruise”) at a given constant velocity while overcoming the counter-electromotive force and any additional friction that increases with speed (including viscous drag and some churning losses ). The relationship between speed and voltage (at constant acceleration) is almost entirely linear (for FRC-legal components) because of how permanent-magnet DC motors work. \\(K_a\\) describes the voltage needed to induce a given acceleration in the motor shaft. As with kV , the relationship between voltage and acceleration (at constant velocity) is almost perfectly linear for FRC components. For more information, see this paper . Variants of the Feedforward Equation Some of WPILib’s other feedforward classes introduce additional terms into the above equation to account for known differences from the simple case described above - details for each tool can be found below: Elevator Feedforward An elevator consists of a permanent-magnet DC motor attached to a mass under the force of gravity. Compared to the feedforward equation for an unloaded motor, it differs only in the inclusion of a constant \\(K_g\\) term that accounts for the action of gravity: \\[V = K_g + K_s \\cdot sgn(\\dot{d}) + K_v \\cdot \\dot{d} + K_a \\cdot \\ddot{d}\\] where \\(V\\) is the applied voltage, \\(d\\) is the displacement (position) of the drive, \\(\\dot{d}\\) is its velocity, and \\(\\ddot{d}\\) is its acceleration. Arm Feedforward An arm consists of a permanent-magnet DC motor attached to a mass on a stick held under the force of gravity. Like the elevator feedforward, it includes a \\(K_g\\) term to account for the effect of gravity - unlike the elevator feedforward, however, this term is multiplied by the cosine of the arm angle (since the gravitational force does not act directly on the motor): \\[V = K_g \\cdot cos(\\theta) + K_s \\cdot sgn(\\dot{\\theta}) + K_v \\cdot \\dot{\\theta} + K_a \\cdot \\ddot{\\theta}\\] where \\(V\\) is the applied voltage, \\(\\theta\\) is the angular displacement (position) of the arm, \\(\\dot{\\theta}\\) is its angular velocity, and \\(\\ddot{\\theta}\\) is its angular acceleration. Using the Feedforward In order to use the feedforward, we need to plug in values for each unknown in the above voltage-balance equation other than the voltage . As mentioned earlier , the values of the gains \\(K_g\\) , \\(K_v\\) , \\(K_a\\) can be obtained through theoretical modeling with [ReCalc] ( https://www.reca.lc/ ). Explicit measurement with SysId will yield the aforementioned gains in addition to \\(K_s\\) . That leaves us needing values for velocity, acceleration, and (in the case of the arm feedforward) position. Typically, these come from our setpoints - remember that with feedforward we are making a “guess” as to the output we need based on where we want the system to be. For velocity control, this does not pose a problem - we can take the velocity value from our setpoint directly, and if necessary (it can often be omitted in practice) we can infer the acceleration from the difference between the current and previous velocity setpoints. For position control, however, this can be difficult - except for the arm controller, there’s no direct term in the feedforward equation for position. We often have no choice but to calculate our velocity from the difference between the current and previous setpoint positions, and to ignore acceleration entirely. In order to do better, we need to ensure that our setpoints vary smoothly according to some set of constraints - this is usually accomplished with a motion profile .",
      "content_preview": "Introduction to DC Motor Feedforward Note For a guide on implementing feedforward control in code with WPILib, see Feedforward Control in WPILib . This page explains the conceptual and mathematical workings of WPILib’s SimpleMotorFeedforward (and the other related classes)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/tuning-vertical-arm.html",
      "title": "Tuning a Vertical Arm Position Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Tuning a Vertical Arm Position Controller In this section, we will tune a simple position controller for a vertical arm. The same tuning principles explained below will work also for almost all position-control scenarios under the load of gravity. Arm Model Description Vertical arms are commonly used to lift gamepieces from the ground up to a scoring position. Other similar examples include shooter hoods and elevators. Our “vertical arm” consists of: A mass on a stick, under the force of gravity, pivoting around an axle. A motor and gearbox driving the axle to which the mass-on-a-stick is attached For the purposes of this tutorial, this plant is modeled with the same equation used by WPILib’s ArmFeedforward , with additional adjustment for sensor delay and gearbox inefficiency. The simulation assumes the plant is controlled by feedforward and feedback controllers, composed in this fashion: Where: The plant’s output \\(y(t)\\) is the arm’s rotational position The controller’s setpoint \\(r(t)\\) is the desired angle of the arm The controller’s control effort , \\(u(t)\\) is the voltage applied to the motor driving the arm Picking the Control Strategy for a Vertical Arm Applying voltage to the motor causes a force on the mechanism that drives the arm up or down. If there is no voltage, gravity still acts on the arm to pull it downward. Generally, it is desirable to fight this effect, and keep the arm at a specific angle. The tutorials below will demonstrate the behavior of the system under pure feedforward, pure feedback (PID), and combined feedforward-feedback control strategies. Follow the instructions to learn how to manually tune these controllers, and expand the “tuning solution” to view an optimal model-based set of tuning parameters. Even though WPILib tooling can provide you with optimal gains, it is worth going through the manual tuning process to see how the different control strategies interact with the mechanism. Pure Feedforward Control Interact with the simulation below to examine how the turret system responds when controlled only by a feedforward controller. Note To change the arm setpoint, click on the desired angle along the perimeter of the turret. To command smooth motion, click and drag the setpoint indicator. To tune the feedforward controller, perform the following: Set \\(K_g\\) and \\(K_v\\) to zero. Increase \\(K_g\\) until the arm can hold its position with as little movement as possible. If the arm moves in the opposite direction, decrease \\(K_g\\) until it remains stationary. You will have to zero in on \\(K_g\\) fairly precisely (at least four decimal places). Increase the velocity feedforward gain \\(K_v\\) until the arm tracks the setpoint during smooth, slow motion. If the arm overshoots, reduce the gain. Note that the arm may “lag” the commanded motion - this is normal, and is fine so long as it moves the correct amount in total. Note Feedforward-only control is not a viable control scheme for vertical arms! Do not be surprised if/when the simulation below does not behave well, even when the “correct” constants are used. Tuning solution The exact gains used by the simulation are \\(K_g = 1.75\\) and \\(K_v = 1.95\\) . Issues with Feed-Forward Control Alone As mentioned above, our simulated mechanism almost-perfectly obeys the WPILib ArmFeedforward equation (as long as the “system noise” option is disabled). We might then expect, like in the case of the flywheel velocity controller , that we should be able to achieve perfect convergence-to-setpoint with a feedforward loop alone. However, our feedforward equation relates velocity and acceleration to voltage - it allows us to control the instantaneous motion of our mechanism with high accuracy, but it does not allow us direct control over the position . This is a problem even in our simulation (in which the feedforward equation is the actual equation of motion), because unless we employ a motion profile to generate a sequence of velocity setpoints we can ask the arm to jump immediately from one position to another. This is impossible, even for our simulated arm. The resulting behavior from the feedforward controller is to output a single “voltage spike” when the position setpoint changes (corresponding to a single loop iteration of very high velocity), and then zero voltage (because it is assumed that the system has already reached the setpoint). In practice, we can see in the simulation that this results in an initial “impulse” movement towards the target position, that stops at some indeterminate position in-between. This kind of response is called a “kick,” and is generally seen as undesirable. You will notice that, once properly tuned, the mechanism can track slow/smooth movement with a surprising amount of accuracy - however, there are some obvious problems with this approach. Our feedforward equation corrects for the force of gravity at the setpoint - this results in poor behavior if our arm is far from the setpoint. With the “system noise” option enabled, we can also see that even smooth, slow motion eventually results in compounding position errors when only feedforward control is used. To accurately converge to and remain at the setpoint, we need to use a feedback (PID) controller. Pure Feedback Control Interact with the simulation below to examine how the vertical arm system responds when controlled only by a feedback (PID) controller. Perform the following: Set \\(K_p\\) , \\(K_i\\) , \\(K_d\\) , and \\(K_g\\) to zero. Increase \\(K_p\\) until the mechanism responds to a sudden change in setpoint by moving sharply to the new position. If the controller oscillates too much around the setpoint, reduce K_p until it stops. Increase \\(K_i\\) when the output gets “stuck” before converging to the setpoint . Increase \\(K_d\\) to help the system track smoothly-moving setpoints and further reduce oscillation. Note Feedback-only control is not a viable control scheme for vertical arms! Do not be surprised if/when the simulation below does not behave well, even when the “correct” constants are used. Tuning solution There is no good tuning solution for this control strategy. Values of \\(K_p = 5\\) and \\(K_d = 1\\) yield a reasonable approach to a stable equilibrium, but that equilibrium is not actually at the setpoint! Issues with Feedback Control Alone A set of gains that works well for one setpoint will act poorly for a different setpoint. Adding some integral gain can push us to the setpoint over time, but it’s unstable and laggy. Because a non-zero amount of control effort is required to keep the arm at a constant height, even when the output and setpoint are equal, this feedback-only strategy is flawed. In order to optimally control a vertical arm, a combined feedforward-feedback strategy is needed. Combined Feedforward and Feedback Control Interact with the simulation below to examine how the vertical arm system responds under simultaneous feedforward and feedback control. Tuning the combined arm controller is simple - we first tune the feedforward controller following the same procedure as in the feedforward-only section, and then we tune the PID controller following the same procedure as in the feedback-only section. Notice that PID portion of the controller is much easier to tune “on top of” an accurate feedforward. Tuning solution Combining the feedforward coefficients from our first simulation ( \\(K_g = 1.75\\) and \\(K_v = 1.95\\) ) and the feedback coefficients from our second simulation ( \\(K_p = 5\\) and \\(K_d = 1\\) ) yields a good controller behavior. Once tuned properly, the combined controller accurately tracks a smoothly moving setpoint, and also accurately converge to the setpoint over time after a “jump” command. Tuning Conclusions Choice of Control Strategies Like in the case of the turret , and unlike the case of the flywheel , we are trying to control the position rather than the velocity of our mechanism. In the case of the flywheel velocity controller we could achieve good control performance with feedforward alone. However, it is very hard to predict how much voltage will cause a certain total change in position (time can turn even small errors in velocity into very big errors in position). In this case, we cannot rely on feedforward control alone - as with the vertical arm, we will need a feedback controller. Unlike in the case of the turret, though, there is a voltage required to keep the mechanism steady at the setpoint (because the arm is affected by the force of gravity). As a consequence, a pure feedback controller will not work acceptably for this system, and a combined feedforward-feedback strategy is needed. The core reason the feedback-only control strategy fails for the vertical arm is gravity. The external force of gravity requires a constant control effort to counteract even when at rest at the setpoint, but a feedback controller does not typically output any control effort when at rest at the setpoint (unless integral gain is used, which we can see clearly in the simulation is laggy and introduces oscillations). We saw in the feedforward-only example above that an accurate feedforward can track slow, smooth velocity setpoints quite well. Combining a feedforward controller with the feedback controller gives the smooth velocity-following of a feedforward controller with the stable long-term error elimination of a feedback controller. Reasons for Non-Ideal Performance This simulation does not include any motion profile generation, so acceleration setpoints are not very well-defined. Accordingly, the kA term of the feedforward equation is not used by the controller. This means there will be some amount of delay/lag inherent to the feedforward-only response. The control law is good, but not perfect. There is usually some overshoot even for smoothly-moving setpoints - this is combination of the lack of \\(K_a\\) in the feedforward (see the note above for why it is omitted here), and some discretization error in the simulation. Attempting to move the setpoint too quickly can also cause the setpoint and mechanism to diverge, which (as mentioned earlier) will result in poor behavior due to the :math:’K_g’ term correcting for the wrong force, as it is calculated from the setpoint, not the measurement. Using the measurement to correct for gravity is called “feedback linearization” (as opposed to “feedforward linearization” when the setpoint is used), and can be a better control strategy if your measurements are sufficiently fast and accurate. A Note on Feedforward and Static Friction For the sake of simplicity, the simulations above omit the \\(K_s\\) term from the WPILib SimpleMotorFeedforward equation. On actual mechanisms, however, this can be important - especially if there’s a lot of friction in the mechanism gearing. In the case of a vertical arm or elevator, \\(K_s\\) can be somewhat tedious to estimate separately from \\(K_g\\) . If your arm or elevator has enough friction for \\(K_s\\) to be important, it is recommended that you use the WPILib system identification tool to determine your system gains.",
      "content_preview": "Tuning a Vertical Arm Position Controller In this section, we will tune a simple position controller for a vertical arm. The same tuning principles explained below will work also for almost all position-control scenarios under the load of gravity."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/additional-utils.html",
      "title": "Additional Utilities and Tools",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Additional Utilities and Tools This page mainly covers useful information about additional functionality that this tool provides. ImGui Tips The following are essentially handy features that come with the ImGui framework that SysId uses: Showing and Hiding Plot Data To add or remove certain data from the plots, click on the color of the data that you would like to hide or remove. For example, if we want to hide sim data, we can click the green color box. Auto Sizing Plots If you zoom in to plots and want to revert back to the normally sized plots, just double click on the plot and it will automatically resize it. Here is a plot that is zoomed in: After double clicking, it is automatically resized: Setting Slider Values To set the value of a slider as a number rather than sliding the widget, you can CTRL + Click the slider and it will allow you to input a number. Here is a regular slider: Here is the input after double clicking the slider:",
      "content_preview": "Additional Utilities and Tools This page mainly covers useful information about additional functionality that this tool provides. ImGui Tips The following are essentially handy features that come with the ImGui framework that SysId uses: Showing and Hiding Plot Data To add or remove certain data..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/tuning-elevator.html",
      "title": "Tuning a Vertical Elevator with Motion Profiling",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Tuning a Vertical Elevator with Motion Profiling In this section, we will tune a simple position controller for a vertical elevator. In addition, we will discuss the advantages of using motion profiling for this situation. About the Profiler A Motion Profiler is the software logic which, given a goal, commands a changing position, velocity, acceleration which are physically realistic for how a mechanism can move. These position/velocity/acceleration commands can be passed to feedforward and feedback controllers to cause the mechanism to actually achieve the commands. In this specific example: We assume there are one or more fixed positions that our elevator needs to move to. The operator commands which position is desired. In one periodic loop, the operator’s commanded position might instantly snap from one value to a different one. Naturally, we don’t expect the elevator to physically move that fast. Since it is not physically plausible for the elevator to move in that manner, using a motion profiler is useful. Constraining to realistic motion is a generally good principle for robust controls: don’t ask the physical system to do something it physically can’t. Having desired velocity and acceleration signals are also useful for supporting a more complex feedforward model. The result is now two setpoint concepts: An “unprofiled” input setpoint which is allowed to change freely, and a “profiled” intermediate setpoint which is constrained to move in a more physically realistic manner. Elevator Model Description Vertical elevators are commonly used to lift gamepieces from the ground up to a scoring position. Other similar examples include shooter hoods and vertical arms. Our “vertical elevator” consists of: A mass on a carriage, under the force of gravity, traveling up and down in a constrained vertical path A motor and gearbox driving a linear chain, to which the mass-on-a-carriage is attached The simulation assumes the plant (the elevator itself) is controlled by motion profiling, feedforward and feedback controllers, composed in this fashion: Where: The plant’s output \\(y(t)\\) is the elevator’s height The controller’s setpoint \\(r_f(t)\\) is the unprofiled, final desired height of the elevator The Motion Profiler’s position setpoint \\(r(t)\\) is where the elevator should currently be positioned The Motion Profiler’s velocity setpoint \\(r'(t)\\) is how fast the elevator should currently be moving The Motion Profiler’s accelerator setpoint \\(r''(t)\\) is how fast the elevator should currently be accelerating The controller’s control effort , \\(u(t)\\) is the voltage applied to the motor driving the elevator Picking the Control Strategy for a Vertical Elevator Applying voltage to the motor causes a force on the mechanism that drives the elevator up or down. If there is no voltage, gravity still acts on the elevator to pull it downward. Generally, it is desirable to fight this effect, and keep the elevator at a specific height. The tutorials below will demonstrate the behavior of the system under just feedback (PID), and then combined feedforward-feedback with motion profiling control strategies. Follow the instructions to learn how to manually tune these controllers, and expand the “tuning solution” to view an optimal model-based set of tuning parameters. Even though WPILib tooling can provide you with optimal gains, it is worth going through the manual tuning process to see how the different control strategies interact with the mechanism. Feedback Only Control Interact with the simulation below to examine how the vertical elevator system responds when controlled only by a feedback (PID) controller. Note To change the elevator setpoint, click on the desired height along the vertical support. Perform the following: Set \\(K_p\\) , \\(K_i\\) , and \\(K_d\\) to zero. Increase \\(K_p\\) until the mechanism responds to a sudden change in setpoint by moving sharply to the new position. If the controller oscillates too much around the setpoint, reduce \\(K_p\\) until it stops. Increase \\(K_i\\) when the output gets “stuck” before converging to the setpoint . Increase \\(K_d\\) to help the system track smoothly-moving setpoints and further reduce oscillation. Note Feedback-only control is not a good control scheme for vertical elevators! Do not be surprised if/when the simulation below does not behave consistently, even when the “correct” constants are used. Tuning solution There is no perfect tuning solution for this control strategy. Values of \\(K_p = 10.0\\) , \\(K_i = 2.5\\) and and \\(K_d = 0.0\\) yield a possible solution, but with overshoot and large settling times. Additionally, it will act very differently depending on the setpoint - aggressively overshooting at the top and undershooting at the bottom. Motion Profiled, Feedforward, and Feedback Control Interact with the simulation below to initially examine how the elevator system responds when controlled only by a feedforward controller and then transition to using a little bit of feedback to correct any leftover error. Note To change the elevator setpoint, click on the desired height along the vertical support. To tune the feedforward controller, perform the following: Start with fairly slow maximum velocity and maximum acceleration. 0.3 for both is a good guess. Set \\(K_g\\) , \\(K_v\\) , \\(K_a\\) , \\(K_p\\) , \\(K_i\\) , and \\(K_d\\) to zero. Increase \\(K_g\\) as much as you can without the elevator moving upward. You will have to zero in on \\(K_g\\) fairly precisely (at least two decimal places). Increase the velocity feedforward gain \\(K_v\\) until the straight segments of the elevator actual motion have the same slope as the desired motion. Increase the acceleration feedforward gain \\(K_a\\) until the curved segments of the elevator actual motion have the same curvature as the desired motion. At this point, note how with no sensors involved , the elevator motion is fairly consistent. With the exception of a small amount of error, we are almost controlling the mechanism without issue. Only as a last step, add in a bit of feedback gain. Increase \\(K_p\\) until the actual position starts to overshoot the target, then back it off by 20%. Finally, start to increase the maximum velocity and acceleration. Tweak your feed forward gains if needed. Tuning solution \\(K_g = 2.28\\) , \\(K_v = 3.07\\) , \\(K_a = 0.41\\) , \\(K_p = 2.0\\) will behave quite well for a range of acceleration, velocities, and setpoints, even in the presence of system noise. A Note on Feedforward and Static Friction For the sake of simplicity, the simulations above omit the \\(K_s\\) term from the WPILib SimpleMotorFeedforward equation. On actual mechanisms, however, this can be important - especially if there’s a lot of friction in the mechanism gearing. In the case of a vertical arm or elevator, \\(K_s\\) can be somewhat tedious to estimate separately from \\(K_g\\) . If your arm or elevator has enough friction for \\(K_s\\) to be important, it is recommended that you use the WPILib system identification tool to determine your system gains.",
      "content_preview": "Tuning a Vertical Elevator with Motion Profiling In this section, we will tune a simple position controller for a vertical elevator. In addition, we will discuss the advantages of using motion profiling for this situation."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/trajectory-generation.html",
      "title": "Trajectory Generation",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Trajectory Generation WPILib contains classes that help generating trajectories. A trajectory is a smooth curve, with velocities and accelerations at each point along the curve, connecting two endpoints on the field. Generation and following of trajectories is incredibly useful for performing autonomous tasks. Instead of a simple autonomous routine – which involves moving forward, stopping, turning 90 degrees to the right, then moving forward – using trajectories allows for motion along a smooth curve. This has the advantage of speeding up autonomous routines, creating more time for other tasks; and when implemented well, makes autonomous navigation more accurate and precise. This article goes over how to generate a trajectory. The next few articles in this series will go over how to actually follow the generated trajectory. There are a few things that your robot must have before you dive into the world of trajectories: A way to measure the position and velocity of each side of the robot. An encoder is the best way to do this; however, other options may include optical flow sensors, etc. A way to measure the angle or angular rate of the robot chassis. A gyroscope is the best way to do this. Although the angular rate can be calculated using encoder velocities, this method is NOT recommended because of wheel scrubbing. If you are looking for a simpler way to perform autonomous navigation, see the section on driving to a distance . Splines A spline refers to a set of curves that interpolate between points. Think of it as connecting dots, except with curves. WPILib supports two types of splines: hermite clamped cubic and hermite quintic. Hermite clamped cubic: This is the recommended option for most users. Generation of trajectories using these splines involves specifying the (x, y) coordinates of all points, and the headings at the start and end waypoints. The headings at the interior waypoints are automatically determined to ensure continuous curvature (rate of change of the heading) throughout. Hermite quintic: This is a more advanced option which requires the user to specify (x, y) coordinates and headings for all waypoints. This should be used if you are unhappy with the trajectories that are being generated by the clamped cubic splines or if you want finer control of headings at the interior points. Splines are used as a tool to generate trajectories; however, the spline itself does not have any information about velocities and accelerations. Therefore, it is not recommended that you use the spline classes directly. In order to generate a smooth path with velocities and accelerations, a trajectory must be generated. Creating the trajectory config A configuration must be created in order to generate a trajectory. The config contains information about special constraints, the max velocity, the max acceleration in addition to the start velocity and end velocity. The config also contains information about whether the trajectory should be reversed (robot travels backward along the waypoints). The TrajectoryConfig class should be used to construct a config. The constructor for this class takes two arguments, the max velocity and max acceleration. The other fields ( startVelocity , endVelocity , reversed , constraints ) are defaulted to reasonable values ( 0 , 0 , false , {} ) when the object is created. If you wish to modify the values of any of these fields, you can call the following methods: setStartVelocity(double startVelocityMetersPerSecond) (Java/Python) / SetStartVelocity(units::meters_per_second_t startVelocity) (C++) setEndVelocity(double endVelocityMetersPerSecond) (Java/Python) / SetEndVelocity(units::meters_per_second_t endVelocity) (C++) setReversed(boolean reversed) (Java/Python) / SetReversed(bool reversed) (C++) addConstraint(TrajectoryConstraint constraint) (Java/Python) / AddConstraint(TrajectoryConstraint constraint) (C++) Note The reversed property simply represents whether the robot is traveling backward. If you specify four waypoints, a, b, c, and d, the robot will still travel in the same order through the waypoints when the reversed flag is set to true . This also means that you must account for the direction of the robot when providing the waypoints. For example, if your robot is facing your alliance station wall and travels backwards to some field element, the starting waypoint should have a rotation of 180 degrees. Generating the trajectory The method used to generate a trajectory is generateTrajectory(...) . There are four overloads for this method. Two that use clamped cubic splines and the two others that use quintic splines. For each type of spline, there are two ways to construct a trajectory. The easiest methods are the overloads that accept Pose2d objects. For clamped cubic splines, this method accepts two Pose2d objects, one for the starting waypoint and one for the ending waypoint. The method takes in a vector of Translation2d objects which represent the interior waypoints. The headings at these interior waypoints are determined automatically to ensure continuous curvature. For quintic splines, the method simply takes in a list of Pose2d objects, with each Pose2d representing a point and heading on the field. The more complex overload accepts “control vectors” for splines. This method is used when generating trajectories with Pathweaver, where you are able to control the magnitude of the tangent vector at each point. The ControlVector class consists of two double arrays. Each array represents one dimension (x or y), and its elements represent the derivatives at that point. For example, the value at element 0 of the x array represents the x coordinate (0th derivative), the value at element 1 represents the 1st derivative in the x dimension and so on. When using clamped cubic splines, the length of the array must be 2 (0th and 1st derivatives), whereas when using quintic splines, the length of the array should be 3 (0th, 1st, and 2nd derivative). Unless you know exactly what you are doing, the first and simpler method is HIGHLY recommended for manually generating trajectories. (i.e. when not using Pathweaver JSON files). Here is an example of generating a trajectory using clamped cubic splines for the 2018 game, FIRST Power Up: Java class ExampleTrajectory { public void generateTrajectory () { // 2018 cross scale auto waypoints. var sideStart = new Pose2d ( Units . feetToMeters ( 1.54 ), Units . feetToMeters ( 23.23 ), Rotation2d . fromDegrees ( - 180 )); var crossScale = new Pose2d ( Units . feetToMeters ( 23.7 ), Units . feetToMeters ( 6.8 ), Rotation2d . fromDegrees ( - 160 )); var interiorWaypoints = new ArrayList < Translation2d > (); interiorWaypoints . add ( new Translation2d ( Units . feetToMeters ( 14.54 ), Units . feetToMeters ( 23.23 ))); interiorWaypoints . add ( new Translation2d ( Units . feetToMeters ( 21.04 ), Units . feetToMeters ( 18.23 ))); TrajectoryConfig config = new TrajectoryConfig ( Units . feetToMeters ( 12 ), Units . feetToMeters ( 12 )); config . setReversed ( true ); var trajectory = TrajectoryGenerator . generateTrajectory ( sideStart , interiorWaypoints , crossScale , config ); } } C++ void GenerateTrajectory () { // 2018 cross scale auto waypoints const frc :: Pose2d sideStart { 1.54 _ft , 23.23 _ft , frc :: Rotation2d ( 180 _deg )}; const frc :: Pose2d crossScale { 23.7 _ft , 6.8 _ft , frc :: Rotation2d ( -160 _deg )}; std :: vector < frc :: Translation2d > interiorWaypoints { frc :: Translation2d { 14.54 _ft , 23.23 _ft }, frc :: Translation2d { 21.04 _ft , 18.23 _ft }}; frc :: TrajectoryConfig config { 12 _fps , 12 _fps_sq }; config . SetReversed ( true ); auto trajectory = frc :: TrajectoryGenerator :: GenerateTrajectory ( sideStart , interiorWaypoints , crossScale , config ); } Python def generateTrajectory (): # 2018 cross scale auto waypoints. sideStart = Pose2d . fromFeet ( 1.54 , 23.23 , Rotation2d . fromDegrees ( - 180 )) crossScale = Pose2d . fromFeet ( 23.7 , 6.8 , Rotation2d . fromDegrees ( - 160 )) interiorWaypoints = [ Translation2d . fromFeet ( 14.54 , 23.23 ), Translation2d . fromFeet ( 21.04 , 18.23 ), ] config = TrajectoryConfig . fromFps ( 12 , 12 ) config . setReversed ( True ) trajectory = TrajectoryGenerator . generateTrajectory ( sideStart , interiorWaypoints , crossScale , config ) Note The Java code utilizes the Units utility, for easy unit conversions. Note Generating a typical trajectory takes about 10 ms to 25 ms. This isn’t long, but it’s still highly recommended to generate all trajectories on startup in the Robot constructor. Concatenating Trajectories Trajectories in Java can be combined into a single trajectory using the concatenate(trajectory) function. C++/Python users can simply add ( + ) the two trajectories together. Warning It is up to the user to ensure that the end of the initial and start of the appended trajectory match. It is also the user’s responsibility to ensure that the start and end velocities of their trajectories match. JAVA var trajectoryOne = TrajectoryGenerator . generateTrajectory ( new Pose2d ( 0 , 0 , Rotation2d . fromDegrees ( 0 )), List . of ( new Translation2d ( 1 , 1 ), new Translation2d ( 2 , - 1 )), new Pose2d ( 3 , 0 , Rotation2d . fromDegrees ( 0 )), new TrajectoryConfig ( Units . feetToMeters ( 3.0 ), Units . feetToMeters ( 3.0 ))); var trajectoryTwo = TrajectoryGenerator . generateTrajectory ( new Pose2d ( 3 , 0 , Rotation2d . fromDegrees ( 0 )), List . of ( new Translation2d ( 4 , 4 ), new Translation2d ( 6 , 3 )), new Pose2d ( 6 , 0 , Rotation2d . fromDegrees ( 0 )), new TrajectoryConfig ( Units . feetToMeters ( 3.0 ), Units . feetToMeters ( 3.0 ))); var concatTraj = trajectoryOne . concatenate ( trajectoryTwo ); C++ auto trajectoryOne = frc :: TrajectoryGenerator :: GenerateTrajectory ( frc :: Pose2d ( 0 _m , 0 _m , 0 _rad ), { frc :: Translation2d ( 1 _m , 1 _m ), frc :: Translation2d ( 2 _m , -1 _m )}, frc :: Pose2d ( 3 _m , 0 _m , 0 _rad ), frc :: TrajectoryConfig ( 3 _fps , 3 _fps_sq )); auto trajectoryTwo = frc :: TrajectoryGenerator :: GenerateTrajectory ( frc :: Pose2d ( 3 _m , 0 _m , 0 _rad ), { frc :: Translation2d ( 4 _m , 4 _m ), frc :: Translation2d ( 5 _m , 3 _m )}, frc :: Pose2d ( 6 _m , 0 _m , 0 _rad ), frc :: TrajectoryConfig ( 3 _fps , 3 _fps_sq )); auto concatTraj = m_trajectoryOne + m_trajectoryTwo ; PYTHON from wpimath.geometry import Pose2d , Rotation2d , Translation2d from wpimath.trajectory import TrajectoryGenerator , TrajectoryConfig trajectoryOne = TrajectoryGenerator . generateTrajectory ( Pose2d ( 0 , 0 , Rotation2d . fromDegrees ( 0 )), [ Translation2d ( 1 , 1 ), Translation2d ( 2 , - 1 )], Pose2d ( 3 , 0 , Rotation2d . fromDegrees ( 0 )), TrajectoryConfig . fromFps ( 3.0 , 3.0 ), ) trajectoryTwo = TrajectoryGenerator . generateTrajectory ( Pose2d ( 3 , 0 , Rotation2d . fromDegrees ( 0 )), [ Translation2d ( 4 , 4 ), Translation2d ( 6 , 3 )], Pose2d ( 6 , 0 , Rotation2d . fromDegrees ( 0 )), TrajectoryConfig . fromFps ( 3.0 , 3.0 ), ) concatTraj = trajectoryOne + trajectoryTwo",
      "content_preview": "Trajectory Generation WPILib contains classes that help generating trajectories. A trajectory is a smooth curve, with velocities and accelerations at each point along the curve, connecting two endpoints on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-flywheel-walkthrough.html",
      "title": "State",
      "section": "Advanced Controls",
      "language": "All",
      "content": "State-Space Controller Walkthrough Note Before following this tutorial, readers are recommended to have read an Introduction to State-Space Control . The goal of this tutorial is to provide “end-to-end” instructions on implementing a state-space controller for a flywheel. By following this tutorial, readers will learn how to: Create an accurate state-space model of a flywheel using system identification or CAD software. Implement a Kalman Filter to filter encoder velocity measurements without lag. Implement a LQR feedback controller which, when combined with model-based feedforward, will generate voltage inputs to drive the flywheel to a reference . This tutorial is intended to be approachable for teams without a great deal of programming expertise. While the WPILib library offers significant flexibility in the manner in which its state-space control features are implemented, closely following the implementation outlined in this tutorial should provide teams with a basic structure which can be reused for a variety of state-space systems. The full example is available in the state-space flywheel ( Java / C++ / Python ) and state-space flywheel system identification ( Java / C++ / Python ) example projects. Why Use State-Space Control? Because state-space control focuses on creating an accurate model of our system, we can accurately predict how our model will respond to control inputs . This allows us to simulate our mechanisms without access to a physical robot, as well as easily choose gains that we know will work well. Having a model also allows us to create lagless filters, such as Kalman Filters, to optimally filter sensor readings. Modeling Our Flywheel Recall that continuous state-space systems are modeled using the following system of equations: \\[\\begin{split}\\dot{\\mathbf{x}} &= \\mathbf{A}\\mathbf{x} + \\mathbf{B}\\mathbf{u} \\\\ \\mathbf{y} &= \\mathbf{C}\\mathbf{x} + \\mathbf{D}\\mathbf{u}\\end{split}\\] Where x-dot is the rate of change of the system ’s state , \\(\\mathbf{x}\\) is the system’s current state, \\(\\mathbf{u}\\) is the input to the system, and \\(\\mathbf{y}\\) is the system’s output . Let’s use this system of equations to model our flywheel in two different ways. We’ll first model it using system identification using the SysId toolsuite, and then model it based on the motor and flywheel’s moment of inertia . The first step of building up our state-space system is picking our system’s states. We can pick anything we want as a state – we could pick completely unrelated states if we wanted – but it helps to pick states that are important. We can include hidden states in our state (such as elevator velocity if we were only able to measure its position) and let our Kalman Filter estimate their values. Remember that the states we choose will be driven towards their respective references by the feedback controller (typically the Linear-Quadratic Regulator since it’s optimal). For our flywheel, we care only about one state: its velocity. While we could chose to also model its acceleration, the inclusion of this state isn’t necessary for our system. Next, we identify the inputs to our system. Inputs can be thought of as things we can put “into” our system to change its state. In the case of the flywheel (and many other single-jointed mechanisms in FRC®), we have just one input: voltage applied to the motor. By choosing voltage as our input (over something like motor duty cycle), we can compensate for battery voltage sag as battery load increases. A continuous-time state-space system writes x-dot , or the instantaneous rate of change of the system’s system 's state, as proportional to the current state and inputs . Because our state is angular velocity, \\(\\mathbf{\\dot{x}}\\) will be the flywheel’s angular acceleration. Next, we will model our flywheel as a continuous-time state-space system. WPILib’s LinearSystem will convert this to discrete-time internally. Review state-space notation for more on continuous-time and discrete-time systems. Modeling with System Identification To rewrite this in state-space notation using system identification , we recall from the flywheel state-space notation example , where we rewrote the following equation in terms of \\(\\mathbf{a}\\) . \\[\\begin{split}V = kV \\cdot \\mathbf{v} + kA \\cdot \\mathbf{a}\\\\ \\mathbf{a} = \\mathbf{\\dot{v}} = \\begin{bmatrix}\\frac{-kV}{kA}\\end{bmatrix} v + \\begin{bmatrix}\\frac{1}{kA}\\end{bmatrix} V\\end{split}\\] Where \\(\\mathbf{v}\\) is flywheel velocity, \\(\\mathbf{a}\\) and \\(\\mathbf{\\dot{v}}\\) are flywheel acceleration, and \\(V\\) is voltage. Rewriting this with the standard convention of \\(\\mathbf{x}\\) for the state vector and \\(\\mathbf{u}\\) for the input vector, we find: \\[\\mathbf{\\dot{x}} = \\begin{bmatrix}\\frac{-kV}{kA} \\end{bmatrix} \\mathbf{x} + \\begin{bmatrix}\\frac{1}{kA} \\end{bmatrix} \\mathbf{u}\\] The second part of state-space notation relates the system’s current state and inputs to the output . In the case of a flywheel, our output vector \\(\\mathbf{y}\\) (or things that our sensors can measure) is our flywheel’s velocity, which also happens to be an element of our state vector \\(\\mathbf{x}\\) . Therefore, our output matrix is \\(\\mathbf{C} = \\begin{bmatrix}1 \\end{bmatrix}\\) , and our system feedthrough matrix is \\(\\mathbf{D} = \\begin{bmatrix}0 \\end{bmatrix}\\) . Writing this out in continuous-time state-space notation yields the following. \\[\\begin{split}\\mathbf{\\dot{x}} &= \\begin{bmatrix}\\frac{-kV}{kA} \\end{bmatrix} \\mathbf{x} + \\begin{bmatrix}\\frac{1}{kA} \\end{bmatrix} \\mathbf{u} \\\\ \\mathbf{y} &= \\begin{bmatrix}1\\end{bmatrix} \\mathbf{x} + \\begin{bmatrix}0\\end{bmatrix} \\mathbf{u}\\end{split}\\] The LinearSystem class contains methods for easily creating state-space systems identified using system identification . This example shows a flywheel model with a kV of 0.023 and a kA of 0.001: Java 32 // Volts per (radian per second) 33 private static final double kFlywheelKv = 0.023 ; 34 35 // Volts per (radian per second squared) 36 private static final double kFlywheelKa = 0.001 ; 37 38 // The plant holds a state-space model of our flywheel. This system has the following properties: 39 // 40 // States: [velocity], in radians per second. 41 // Inputs (what we can \"put in\"): [voltage], in volts. 42 // Outputs (what we can measure): [velocity], in radians per second. 43 // 44 // The Kv and Ka constants are found using the FRC Characterization toolsuite. 45 private final LinearSystem < N1 , N1 , N1 > m_flywheelPlant = 46 LinearSystemId . identifyVelocitySystem ( kFlywheelKv , kFlywheelKa ); C++ 17 #include <frc/system/plant/LinearSystemId.h> 30 // Volts per (radian per second) 31 static constexpr auto kFlywheelKv = 0.023 _V / 1 _rad_per_s ; 32 33 // Volts per (radian per second squared) 34 static constexpr auto kFlywheelKa = 0.001 _V / 1 _rad_per_s_sq ; 35 36 // The plant holds a state-space model of our flywheel. This system has the 37 // following properties: 38 // 39 // States: [velocity], in radians per second. 40 // Inputs (what we can \"put in\"): [voltage], in volts. 41 // Outputs (what we can measure): [velocity], in radians per second. 42 // 43 // The Kv and Ka constants are found using the FRC Characterization toolsuite. 44 frc :: LinearSystem < 1 , 1 , 1 > m_flywheelPlant = 45 frc :: LinearSystemId :: IdentifyVelocitySystem < units :: radian > ( kFlywheelKv , 46 kFlywheelKa ); Python 23 # Volts per (radian per second) 24 kFlywheelKv = 0.023 25 26 # Volts per (radian per second squared) 27 kFlywheelKa = 0.001 37 # The plant holds a state-space model of our flywheel. This system has the following properties: 38 # 39 # States: [velocity], in radians per second. 40 # Inputs (what we can \"put in\"): [voltage], in volts. 41 # Outputs (what we can measure): [velocity], in radians per second. 42 # 43 # The Kv and Ka constants are found using the FRC Characterization toolsuite. 44 self . flywheelPlant = ( 45 wpimath . system . plant . LinearSystemId . identifyVelocitySystemRadians ( 46 kFlywheelKv , kFlywheelKa 47 ) 48 ) Modeling Using Flywheel Moment of Inertia and Gearing A flywheel can also be modeled without access to a physical robot, using information about the motors, gearing, and flywheel’s moment of inertia . A full derivation of this model is presented in Section 12.3 of Controls Engineering in FRC . The LinearSystem class contains methods to easily create a model of a flywheel from the flywheel’s motors, gearing and moment of inertia . The moment of inertia can be calculated using CAD software or using physics. The examples used here are detailed in the flywheel example project ( Java / C++ / Python ). Note For WPILib’s state-space classes, gearing is written as output over input – that is, if the flywheel spins slower than the motors, this number should be greater than one. Note The C++ LinearSystem class uses the C++ Units Library to prevent unit mixups and assert dimensionality. Java 33 private static final double kFlywheelMomentOfInertia = 0.00032 ; // kg * m^2 34 35 // Reduction between motors and encoder, as output over input. If the flywheel spins slower than 36 // the motors, this number should be greater than one. 37 private static final double kFlywheelGearing = 1.0 ; 38 39 // The plant holds a state-space model of our flywheel. This system has the following properties: 40 // 41 // States: [velocity], in radians per second. 42 // Inputs (what we can \"put in\"): [voltage], in volts. 43 // Outputs (what we can measure): [velocity], in radians per second. 44 private final LinearSystem < N1 , N1 , N1 > m_flywheelPlant = 45 LinearSystemId . createFlywheelSystem ( 46 DCMotor . getNEO ( 2 ), kFlywheelMomentOfInertia , kFlywheelGearing ); C++ 17 #include <frc/system/plant/LinearSystemId.h> 31 static constexpr units :: kilogram_square_meter_t kFlywheelMomentOfInertia = 32 0.00032 _kg_sq_m ; 33 34 // Reduction between motors and encoder, as output over input. If the flywheel 35 // spins slower than the motors, this number should be greater than one. 36 static constexpr double kFlywheelGearing = 1.0 ; 37 38 // The plant holds a state-space model of our flywheel. This system has the 39 // following properties: 40 // 41 // States: [velocity], in radians per second. 42 // Inputs (what we can \"put in\"): [voltage], in volts. 43 // Outputs (what we can measure): [velocity], in radians per second. 44 frc :: LinearSystem < 1 , 1 , 1 > m_flywheelPlant = 45 frc :: LinearSystemId :: FlywheelSystem ( 46 frc :: DCMotor :: NEO ( 2 ), kFlywheelMomentOfInertia , kFlywheelGearing ); Python 22 kFlywheelMomentOfInertia = 0.00032 # kg/m^2 23 24 # Reduction between motors and encoder, as output over input. If the flywheel spins slower than 25 # the motors, this number should be greater than one. 26 kFlywheelGearing = 1 38 # The plant holds a state-space model of our flywheel. This system has the following properties: 39 # 40 # States: [velocity], in radians per second. 41 # Inputs (what we can \"put in\"): [voltage], in volts. 42 # Outputs (what we can measure): [velocity], in radians per second. 43 self . flywheelPlant = wpimath . system . plant . LinearSystemId . flywheelSystem ( 44 wpimath . system . plant . DCMotor . NEO ( 2 ), 45 kFlywheelMomentOfInertia , 46 kFlywheelGearing , 47 ) Kalman Filters: Observing Flywheel State Kalman filters are used to filter our velocity measurements using our state-space model to generate a state estimate \\(\\mathbf{\\hat{x}}\\) . As our flywheel model is linear, we can use a Kalman filter to estimate the flywheel’s velocity. WPILib’s Kalman filter takes a LinearSystem (which we found above), along with standard deviations of model and sensor measurements. We can adjust how “smooth” our state estimate is by adjusting these weights. Larger state standard deviations will cause the filter to “distrust” our state estimate and favor new measurements more highly, while larger measurement standard deviations will do the opposite. In the case of a flywheel we start with a state standard deviation of 3 rad/s and a measurement standard deviation of 0.01 rad/s. These values are up to the user to choose – these weights produced a filter that was tolerant to some noise but whose state estimate quickly reacted to external disturbances for a flywheel – and should be tuned to create a filter that behaves well for your specific flywheel. Graphing states, measurements, inputs, references, and outputs over time is a great visual way to tune Kalman filters. The above graph shows two differently tuned Kalman filters, as well as a single-pole IIR filter and a Median Filter . This data was collected with a shooter over ~5 seconds, and four balls were run through the shooter (as seen in the four dips in velocity). While there are no hard rules on choosing good state and measurement standard deviations, they should in general be tuned to trust the model enough to reject noise while reacting quickly to external disturbances. Because the feedback controller computes error using the x-hat estimated by the Kalman filter, the controller will react to disturbances only as quickly the filter’s state estimate changes. In the above chart, the upper left plot (with a state standard deviation of 3.0 and measurement standard deviation of 0.2) produced a filter that reacted quickly to disturbances while rejecting noise, while the upper right plot shows a filter that was barely affected by the velocity dips. Java 48 // The observer fuses our encoder data and voltage inputs to reject noise. 49 private final KalmanFilter < N1 , N1 , N1 > m_observer = 50 new KalmanFilter <> ( 51 Nat . N1 (), 52 Nat . N1 (), 53 m_flywheelPlant , 54 VecBuilder . fill ( 3.0 ), // How accurate we think our model is 55 VecBuilder . fill ( 0.01 ), // How accurate we think our encoder 56 // data is 57 0.020 ); C++ 13 #include <frc/estimator/KalmanFilter.h> 48 // The observer fuses our encoder data and voltage inputs to reject noise. 49 frc :: KalmanFilter < 1 , 1 , 1 > m_observer { 50 m_flywheelPlant , 51 { 3.0 }, // How accurate we think our model is 52 { 0.01 }, // How accurate we think our encoder data is 53 20 _ms }; Python 49 # The observer fuses our encoder data and voltage inputs to reject noise. 50 self . observer = wpimath . estimator . KalmanFilter_1_1_1 ( 51 self . flywheelPlant , 52 ( 3 ,), # How accurate we think our model is 53 ( 0.01 ,), # How accurate we think our encoder data is 54 0.020 , 55 ) Because Kalman filters use our state-space model in the Predict step , it is important that our model is as accurate as possible. One way to verify this is to record a flywheel’s input voltage and velocity over time, and replay this data by calling only predict on the Kalman filter. Then, the kV and kA gains (or moment of inertia and other constants) can be adjusted until the model closely matches the recorded data. Linear-Quadratic Regulators and Plant Inversion Feedforward The Linear-Quadratic Regulator finds a feedback controller to drive our flywheel system to its reference . Because our flywheel has just one state, the control law picked by our LQR will be in the form \\(\\mathbf{u = K (r - x)}\\) where \\(\\mathbf{K}\\) is a 1x1 matrix; in other words, the control law picked by LQR is simply a proportional controller, or a PID controller with only a P gain. This gain is chosen by our LQR based on the state excursion and control efforts we pass it. More on tuning LQR controllers can be found in the LQR application example . Much like SimpleMotorFeedforward can be used to generate feedforward voltage inputs given kS, kV, and kA constants, the Plant Inversion Feedforward class generate feedforward voltage inputs given a state-space system. The voltage commands generated by the LinearSystemLoop class are the sum of the feedforward and feedback inputs. Java 59 // A LQR uses feedback to create voltage commands. 60 private final LinearQuadraticRegulator < N1 , N1 , N1 > m_controller = 61 new LinearQuadraticRegulator <> ( 62 m_flywheelPlant , 63 VecBuilder . fill ( 8.0 ), // qelms. Velocity error tolerance, in radians per second. Decrease 64 // this to more heavily penalize state excursion, or make the controller behave more 65 // aggressively. 66 VecBuilder . fill ( 12.0 ), // relms. Control effort (voltage) tolerance. Decrease this to more 67 // heavily penalize control effort, or make the controller less aggressive. 12 is a good 68 // starting point because that is the (approximate) maximum voltage of a battery. 69 0.020 ); // Nominal time between loops. 0.020 for TimedRobot, but can be 70 // lower if using notifiers. C++ 11 #include <frc/controller/LinearQuadraticRegulator.h> 55 // A LQR uses feedback to create voltage commands. 56 frc :: LinearQuadraticRegulator < 1 , 1 > m_controller { 57 m_flywheelPlant , 58 // qelms. Velocity error tolerance, in radians per second. Decrease this 59 // to more heavily penalize state excursion, or make the controller behave 60 // more aggressively. 61 { 8.0 }, 62 // relms. Control effort (voltage) tolerance. Decrease this to more 63 // heavily penalize control effort, or make the controller less 64 // aggressive. 12 is a good starting point because that is the 65 // (approximate) maximum voltage of a battery. 66 { 12.0 }, 67 // Nominal time between loops. 20ms for TimedRobot, but can be lower if 68 // using notifiers. 69 20 _ms }; 70 71 // The state-space loop combines a controller, observer, feedforward and plant 72 // for easy control. 73 frc :: LinearSystemLoop < 1 , 1 , 1 > m_loop { m_flywheelPlant , m_controller , 74 m_observer , 12 _V , 20 _ms }; Python 57 # A LQR uses feedback to create voltage commands. 58 self . controller = wpimath . controller . LinearQuadraticRegulator_1_1 ( 59 self . flywheelPlant , 60 ( 8 ,), # qelms. Velocity error tolerance, in radians per second. Decrease 61 # this to more heavily penalize state excursion, or make the controller behave more 62 # aggressively. 63 ( 12 ,), # relms. Control effort (voltage) tolerance. Decrease this to more 64 # heavily penalize control effort, or make the controller less aggressive. 12 is a good 65 # starting point because that is the (approximate) maximum voltage of a battery. 66 0.020 , # Nominal time between loops. 0.020 for TimedRobot, but can be lower if using notifiers. 67 ) Bringing it All Together: LinearSystemLoop LinearSystemLoop combines our system, controller, and observer that we created earlier. The constructor shown will also instantiate a PlantInversionFeedforward . Java 72 // The state-space loop combines a controller, observer, feedforward and plant for easy control. 73 private final LinearSystemLoop < N1 , N1 , N1 > m_loop = 74 new LinearSystemLoop <> ( m_flywheelPlant , m_controller , m_observer , 12.0 , 0.020 ); C++ 15 #include <frc/system/LinearSystemLoop.h> 71 // The state-space loop combines a controller, observer, feedforward and plant 72 // for easy control. 73 frc :: LinearSystemLoop < 1 , 1 , 1 > m_loop { m_flywheelPlant , m_controller , 74 m_observer , 12 _V , 20 _ms }; Python 69 # The state-space loop combines a controller, observer, feedforward and plant for easy control. 70 self . loop = wpimath . system . LinearSystemLoop_1_1_1 ( 71 self . flywheelPlant , self . controller , self . observer , 12.0 , 0.020 72 ) Once we have our LinearSystemLoop , the only thing left to do is actually run it. To do that, we’ll periodically update our Kalman filter with our new encoder velocity measurements and apply new voltage commands to it. To do that, we first set the reference , then correct with the current flywheel speed, predict the Kalman filter into the next timestep, and apply the inputs generated using getU . Java 94 @Override 95 public void teleopPeriodic () { 96 // Sets the target speed of our flywheel. This is similar to setting the setpoint of a 97 // PID controller. 98 if ( m_joystick . getTriggerPressed ()) { 99 // We just pressed the trigger, so let's set our next reference 100 m_loop . setNextR ( VecBuilder . fill ( kSpinupRadPerSec )); 101 } else if ( m_joystick . getTriggerReleased ()) { 102 // We just released the trigger, so let's spin down 103 m_loop . setNextR ( VecBuilder . fill ( 0.0 )); 104 } 105 106 // Correct our Kalman filter's state vector estimate with encoder data. 107 m_loop . correct ( VecBuilder . fill ( m_encoder . getRate ())); 108 109 // Update our LQR to generate new voltage commands and use the voltages to predict the next 110 // state with out Kalman filter. 111 m_loop . predict ( 0.020 ); 112 113 // Send the new calculated voltage to the motors. 114 // voltage = duty cycle * battery voltage, so 115 // duty cycle = voltage / battery voltage 116 double nextVoltage = m_loop . getU ( 0 ); 117 m_motor . setVoltage ( nextVoltage ); 118 } 119 } C++ 5 #include <numbers> 6 7 #include <frc/DriverStation.h> 8 #include <frc/Encoder.h> 9 #include <frc/TimedRobot.h> 10 #include <frc/XboxController.h> 11 #include <frc/controller/LinearQuadraticRegulator.h> 12 #include <frc/drive/DifferentialDrive.h> 13 #include <frc/estimator/KalmanFilter.h> 14 #include <frc/motorcontrol/PWMSparkMax.h> 15 #include <frc/system/LinearSystemLoop.h> 16 #include <frc/system/plant/DCMotor.h> 17 #include <frc/system/plant/LinearSystemId.h> 92 void TeleopPeriodic () override { 93 // Sets the target speed of our flywheel. This is similar to setting the 94 // setpoint of a PID controller. 95 if ( m_joystick . GetRightBumperButton ()) { 96 // We pressed the bumper, so let's set our next reference 97 m_loop . SetNextR ( frc :: Vectord < 1 > { kSpinup . value ()}); 98 } else { 99 // We released the bumper, so let's spin down 100 m_loop . SetNextR ( frc :: Vectord < 1 > { 0.0 }); 101 } 102 103 // Correct our Kalman filter's state vector estimate with encoder data. 104 m_loop . Correct ( frc :: Vectord < 1 > { m_encoder . GetRate ()}); 105 106 // Update our LQR to generate new voltage commands and use the voltages to 107 // predict the next state with out Kalman filter. 108 m_loop . Predict ( 20 _ms ); 109 110 // Send the new calculated voltage to the motors. 111 // voltage = duty cycle * battery voltage, so 112 // duty cycle = voltage / battery voltage 113 m_motor . SetVoltage ( units :: volt_t { m_loop . U ( 0 )}); 114 } Python 88 def teleopPeriodic ( self ) -> None : 89 # Sets the target speed of our flywheel. This is similar to setting the setpoint of a 90 # PID controller. 91 if self . joystick . getTriggerPressed (): 92 # We just pressed the trigger, so let's set our next reference 93 self . loop . setNextR ([ kSpinUpRadPerSec ]) 94 95 elif self . joystick . getTriggerReleased (): 96 # We just released the trigger, so let's spin down 97 self . loop . setNextR ([ 0.0 ]) 98 99 # Correct our Kalman filter's state vector estimate with encoder data. 100 self . loop . correct ([ self . encoder . getRate ()]) 101 102 # Update our LQR to generate new voltage commands and use the voltages to predict the next 103 # state with out Kalman filter. 104 self . loop . predict ( 0.020 ) 105 106 # Send the new calculated voltage to the motors. 107 # voltage = duty cycle * battery voltage, so 108 # duty cycle = voltage / battery voltage 109 nextVoltage = self . loop . U ( 0 ) 110 self . motor . setVoltage ( nextVoltage ) Angle Wrap with LQR Mechanisms with a continuous angle can have that angle wrapped by calling the code below instead of lqr.Calculate(x, r) . JAVA var error = lqr . getR (). minus ( x ); error . set ( 0 , 0 , MathUtil . angleModulus ( error . get ( 0 , 0 ))); var u = lqr . getK (). times ( error ); C++ Eigen :: Vector < double , 2 > error = lqr . R () - x ; error ( 0 ) = frc :: AngleModulus ( units :: radian_t { error ( 0 )}). value (); Eigen :: Vector < double , 2 > u = lqr . K () * error ; PYTHON error = lqr . R () - x error [ 0 ] = wpimath . angleModulus ( error [ 0 ]) u = lqr . K () * error",
      "content_preview": "State-Space Controller Walkthrough Note Before following this tutorial, readers are recommended to have read an Introduction to State-Space Control . The goal of this tutorial is to provide “end-to-end” instructions on implementing a state-space controller for a flywheel."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/viewing-diagnostics.html",
      "title": "Viewing Diagnostics",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Viewing Diagnostics Goodness-of-Fit Metrics There are three numerical accuracy metrics that are computed with this tool: acceleration r-squared , simulated velocity r-squared, and the simulated velocity RMSE . The acceleration r-squared is the fraction of the variance in measured acceleration (used as the independent variable in the SysId regression) explained by the linear model. This can be quite variable, because acceleration is very susceptible to system noise. Mechanisms tend to vibrate quite a bit, so this value rarely goes above 0.5 , even on very good datasets. If the acceleration r-squared goes below around 0.2 , the kA gain will be of dubious quality and the mechanism vibration should be reduced if possible. Even if your r-squared is outside this range it may still be valid, but it is recommended to improve the data if practical. The simulated velocity r-squared is the fraction of the variance in measured velocity explained by a noiseless simulation of the motor movement stepped forward with the constants determined from the regression. A value north of .9 indicates a good fit. The simulated velocity RMSE is the standard deviation of the velocity error from the simulated model. This is a good estimation of the amount of process noise present during the test routine, and can be used as a low-end estimate for the model noise term in state-space control . Diagnostic Plots SysId also produces several diagnostic plots to help users evaluate the quality of their model fit. Time-Domain Plots Note To improve plot quality, the diagnostic plots are separated by direction. Be sure to view both the forward and backward plots when troubleshooting! The Time-Domain Diagnostics plots display velocity versus time over the course of the analyzed tests. These should look something like this: The velocity time domain plots contain three sets of data: Raw Data, Filtered Data, and Simulation. The Raw Data is the recorded data from your robot, the Filtered Data is the data after a median filter has been applied to the data, and the Simulation represents the velocity predictions of a model based off of the feedforward gains from the tool (these are used to calculate the “sim” error metrics mentioned above). A successful quasistatic graph will be very nearly linear, while a successful dynamic graph will be an approximately exponential approach of the steady-speed. Deviation from this behavior is a sign of an error , either in your robot setup, analysis settings, or your test procedure. Acceleration-Velocity Plot The acceleration-versus-velocity plot displays the mechanism velocity versus the portion of acceleration corresponding to factors other than friction (ideally, this would leave only back-EMF) and applied voltage across all of the tests. This plot should be quite linear, with patches of relatively noiseless quasistatic data intermixed with quite-noisy dynamic data. The noise on the dynamic sections of the plot may be reduced by increasing the Window Size setting. However, if your robot or mechanism has low mass compared to the motor power, this may “eat” what little meaningful acceleration data you have. In these cases kA will tend towards zero and can be ignored for feedforward purposes. However, if kA cannot be accurately measured, the calculated feedback gains are likely to be inaccurate, and manual tuning may be required. Common Failure Modes When something has gone wrong with the identification, diagnostic plots, and console output provide crucial clues as to what has gone wrong. This section describes some common failures encountered while running the system identification tool, the identifying features of their diagnostic plots, and the steps that can be taken to fix them. Improperly Set Motion Threshold One of the most-common errors is an inappropriate value for the motion threshold. Velocity Threshold Too Low The presence of a “leading tail” (emphasized by added red circle) in the quasistatic time-domain plot indicates that the Velocity Threshold setting is too low, and thus data points from before the robot begins to move are being included. To solve this, increase the velocity threshold and re-analyze the data. Motion Threshold Too High While not nearly as problematic as a too-low threshold, a velocity threshold that is too high will result in a large “gap” in the acceleration-versus-velocity plot. To solve this, decrease the velocity threshold and re-analyze the data. Noisy Velocity Signals Note There are two types of noise that affect mechanical systems - signal noise and system noise. Signal noise corresponds to measurement error, while system noise corresponds to actual physical motion that is unaccounted-for by your model (e.g. vibration). If SysId suggests that your system is noisy, you must figure out which of the two types of noise is at play - signal noise is often easier to eliminate than system noise. Many FRC setups suffer from poorly-installed encoders - errors in shaft concentricity (for optical encoders) and magnet location (For magnetic encoders) can both contribute to noisy velocity signals, as can inappropriate filtering settings. Encoder noise will be immediately visible in your diagnostic plots, as can be seen above. Encoder noise is especially common on the toughbox mini gearboxes provided in the kit of parts. System parameters can sometimes be accurately determined even from data polluted by encoder noise by increasing the window size setting. However, this sort of encoder noise is problematic for robot code much the same way it is problematic for the system identification tool. As the root cause of the noise is not known, it is recommended to try a different encoder setup if this is observed, either by moving the encoders to a different shaft, replacing them with a different type of encoder, or increasing the sample per average in project generation (adds an additional layer of filtering).",
      "content_preview": "Viewing Diagnostics Goodness-of-Fit Metrics There are three numerical accuracy metrics that are computed with this tool: acceleration r-squared , simulated velocity r-squared, and the simulated velocity RMSE ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/slew-rate-limiter.html",
      "title": "Slew Rate Limiter",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Slew Rate Limiter A common use for filters in FRC® is to soften the behavior of control inputs (for example, the joystick inputs from your driver controls). Unfortunately, a simple low-pass filter is poorly-suited for this job; while a low-pass filter will soften the response of an input stream to sudden changes, it will also wash out fine control detail and introduce phase lag. A better solution is to limit the rate-of-change of the control input directly. This is performed with a slew rate limiter - a filter that caps the maximum rate-of-change of the signal. A slew rate limiter can be thought of as a sort of primitive motion profile. In fact, the slew rate limiter is the first-order equivalent of the Trapezoidal Motion Profile supported by WPILib - it is precisely the limiting case of trapezoidal motion when the acceleration constraint is allowed to tend to infinity. Accordingly, the slew rate limiter is a good choice for applying a de-facto motion profile to a stream of velocity setpoints (or voltages, which are usually approximately proportional to velocity). For input streams that control positions, it is usually better to use a proper trapezoidal profile. Slew rate limiting is supported in WPILib through the SlewRateLimiter class ( Java , C++ , Python ). Creating a SlewRateLimiter Note The C++ SlewRateLimiter class is templated on the unit type of the input. For more information on C++ units, see The C++ Units Library . Note Because filters have “memory”, each input stream requires its own filter object. Do not attempt to use the same filter object for multiple input streams. Creating a SlewRateLimiter is simple: JAVA // Creates a SlewRateLimiter that limits the rate of change of the signal to 0.5 units per second SlewRateLimiter filter = new SlewRateLimiter ( 0.5 ); C++ // Creates a SlewRateLimiter that limits the rate of change of the signal to 0.5 volts per second frc :: SlewRateLimiter < units :: volts > filter { 0.5 _V / 1 _s }; PYTHON from wpimath.filter import SlewRateLimiter # Creates a SlewRateLimiter that limits the rate of change of the signal to 0.5 units per second filter = SlewRateLimiter ( 0.5 ) Using a SlewRateLimiter Once your filter has been created, using it is easy - simply call the calculate() method with the most recent input to obtain the filtered output: JAVA // Calculates the next value of the output filter . calculate ( input ); C++ // Calculates the next value of the output filter . Calculate ( input ); PYTHON # Calculates the next value of the output filter . calculate ( input ) Using a SlewRateLimiter with DifferentialDrive Note The C++ example below templates the filter on units::scalar for use with doubles, since joystick values are typically dimensionless. A typical use of a SlewRateLimiter is to limit the acceleration of a robot’s drive. This can be especially handy for robots that are very top-heavy, or that have very powerful drives. To do this, apply a SlewRateLimiter to a value passed into your robot drive function: JAVA // Ordinary call with no ramping applied drivetrain . arcadeDrive ( forward , turn ); // Slew-rate limits the forward/backward input, limiting forward/backward acceleration drivetrain . arcadeDrive ( filter . calculate ( forward ), turn ); C++ // Ordinary call with no ramping applied drivetrain . ArcadeDrive ( forward , turn ); // Slew-rate limits the forward/backward input, limiting forward/backward acceleration drivetrain . ArcadeDrive ( filter . Calculate ( forward ), turn ); PYTHON # Ordinary call with no ramping applied drivetrain . arcadeDrive ( forward , turn ) # Slew-rate limits the forward/backward input, limiting forward/backward acceleration drivetrain . arcadeDrive ( filter . calculate ( forward ), turn )",
      "content_preview": "Slew Rate Limiter A common use for filters in FRC® is to soften the behavior of control inputs (for example, the joystick inputs from your driver controls)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/index.html",
      "title": "Controllers",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Controllers This section describes various WPILib feedback and feedforward controller classes that are useful for controlling the motion of robot mechanisms, as well as motion-profiling classes that can automatically generate setpoints for use with these controllers. PID Control in WPILib Feedforward Control in WPILib Combining Feedforward and PID Control Trapezoidal Motion Profiles in WPILib Combining Motion Profiling and PID Control with ProfiledPIDController Bang-Bang Control with BangBangController",
      "content_preview": "Controllers This section describes various WPILib feedback and feedforward controller classes that are useful for controlling the motion of robot mechanisms, as well as motion-profiling classes that can automatically generate setpoints for use with these controllers."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/index.html?present",
      "title": "Advanced Controls",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Advanced Controls This section covers advanced control features in WPILib, such as various feedback/feedforward control algorithms and trajectory following. A Video Walkthrough of Model Based Validation of Autonomous in FRC Advanced Controls Introduction Control System Basics Picking a Control Strategy Introduction to DC Motor Feedforward Introduction to PID PID Introduction Video by WPI Introduction To Controls Tuning Tutorials Tuning a Flywheel Velocity Controller Tuning a Turret Position Controller Tuning a Vertical Arm Position Controller Tuning a Vertical Elevator with Motion Profiling Common Control Loop Tuning Issues Filters Introduction to Filters Linear Filters Median Filter Slew Rate Limiter Debouncer Geometry Classes Translation, Rotation, and Pose Transformations System Identification Introduction to System Identification Creating an Identification Routine Running the Identification Routine Loading Data Viewing Diagnostics Analyzing Data Additional Utilities and Tools Controllers PID Control in WPILib Feedforward Control in WPILib Combining Feedforward and PID Control Trapezoidal Motion Profiles in WPILib Combining Motion Profiling and PID Control with ProfiledPIDController Bang-Bang Control with BangBangController Trajectory Generation and Following with WPILib Trajectory Generation Trajectory Constraints Manipulating Trajectories Transforming Trajectories LTV Unicycle Controller Ramsete Controller Holonomic Drive Controller Troubleshooting State-Space and Model Based Control with WPILib Introduction to State-Space Control State-Space Controller Walkthrough State Observers and Kalman Filters Pose Estimators Debugging State-Space Models and Controllers Controls Glossary",
      "content_preview": "Advanced Controls This section covers advanced control features in WPILib, such as various feedback/feedforward control algorithms and trajectory following."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/index.html",
      "title": "State",
      "section": "Advanced Controls",
      "language": "All",
      "content": "State-Space and Model Based Control with WPILib This section provides an introduction to and describes WPILib support for state-space control. Introduction to State-Space Control State-Space Controller Walkthrough State Observers and Kalman Filters Pose Estimators Debugging State-Space Models and Controllers",
      "content_preview": "State-Space and Model Based Control with WPILib This section provides an introduction to and describes WPILib support for state-space control. Introduction to State-Space Control State-Space Controller Walkthrough State Observers and Kalman Filters Pose Estimators Debugging State-Space Models and..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/ltv.html",
      "title": "LTV Unicycle Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "LTV Unicycle Controller The LTV Unicycle Controller ( C++ , Java , Python ) is a trajectory tracker that is built in to WPILib. This tracker can be used to accurately track trajectories with correction for minor disturbances for differential drivetrains. Note LTV has replaced RAMSETE, because it has more intuitive tuning. Constructing the LTV Unicycle Controller Object The LTV Unicycle controller should be initialized with four parameters. qelems is a vector of the maximum desired error tolerance in the X and Y directions and heading. relems is a vector of the desired control effort in linear velocity and angular velocity. dt represents the timestep used in calculations (the default loop rate of 20 ms is a reasonable value) and maxVelocity should be the max velocity your robot can achieve. See The State Space control LQR Tuning for more information on the effect of qelems and relems on the controller. The code example below initializes the LTV Unicycle Controller with qelems of 0.0625 m in X, 0.125 m in Y, and 2 radians in heading; relems of 1 m/s of linear velocity, and 2 rad/sec angular velocity; dt of 20 ms; and maxVelocity of 9 m/s. Note The maximum desired error of the heading is much larger then X and Y to ensure that the heading controller doesn’t overpower the Y controller. JAVA LTVUnicycleController controller = new LTVUnicycleController ( VecBuilder . fill ( 0.0625 , 0.125 , 2.0 ), VecBuilder . fill ( 1.0 , 2.0 ), 0.02 , 9 ); C++ frc :: LTVUnicycleController controller {{ 0.0625 , 0.125 , 2.0 }, { 1.0 , 2.0 }, 0.02 _s , 9 _mps }; PYTHON controller = LTVUnicycleController ([ 0.0625 , 0.125 , 2.0 ], [ 1.0 , 2.0 ], 0.02 , 9 ) Getting Velocity Commands The LTV Unicycle controller returns linear and angular velocity commands which, if followed, will make the robot accurately reach a goal state consisting of a desired pose, desired linear velocity, and desired angular velocity. Note The “reference pose” represents the position that the robot should be at a particular timestep when tracking the trajectory. It does NOT represent the final endpoint of the trajectory, which is the goal. The controller can be updated using the Calculate (C++) / calculate (Java/Python) method. The first overload of this method accepts the current robot pose, desired robot pose, desired linear velocity, and desired angular velocity. The second overload accepts the current robot pose and desired pose, linear velocity, and angular velocity as a Trajectory.State object. This overload is ideal for those using the WPILib trajectory API. JAVA Trajectory . State reference = trajectory . sample ( 3.4 ); // sample the trajectory at 3.4 seconds from the beginning ChassisSpeeds adjustedSpeeds = controller . calculate ( currentRobotPose , reference ); C++ const Trajectory :: State reference = trajectory . Sample ( 3.4 _s ); // sample the trajectory at 3.4 seconds from the beginning ChassisSpeeds adjustedSpeeds = controller . Calculate ( currentRobotPose , reference ); PYTHON reference = trajectory . sample ( 3.4 ) # sample the trajectory at 3.4 seconds from the beginning adjustedSpeeds = controller . calculate ( currentRobotPose , reference ) These calculations should be performed at every loop iteration, with an updated robot position and reference. Using the Velocity Commands The velocity commands are of type ChassisSpeeds , which contains a vx (linear velocity in the forward direction), a vy (linear velocity in the sideways direction), and an omega (angular velocity around the center of the robot frame). The returned adjusted speeds can be converted to usable speeds using the kinematics classes for your drivetrain type. For example, the adjusted velocities can be converted to left and right velocities for a differential drive using a DifferentialDriveKinematics object. JAVA ChassisSpeeds adjustedSpeeds = controller . calculate ( currentRobotPose , reference ); DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( adjustedSpeeds ); double left = wheelSpeeds . leftMetersPerSecond ; double right = wheelSpeeds . rightMetersPerSecond ; C++ ChassisSpeeds adjustedSpeeds = controller . Calculate ( currentRobotPose , reference ); DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . ToWheelSpeeds ( adjustedSpeeds ); auto [ left , right ] = kinematics . ToWheelSpeeds ( adjustedSpeeds ); PYTHON adjustedSpeeds = controller . calculate ( currentRobotPose , reference ) wheelSpeeds = kinematics . toWheelSpeeds ( adjustedSpeeds ) left = wheelSpeeds . left right = wheelSpeeds . right These new left and right velocities are still speeds and not voltages, so two PID Controllers, one for each side, should be used to track them. You can use either the WPILib PIDController ( C++ , Java , Python ) or the Velocity PID feature on smart motor controllers such as the TalonSRX and the SPARK MAX.",
      "content_preview": "LTV Unicycle Controller The LTV Unicycle Controller ( C++ , Java , Python ) is a trajectory tracker that is built in to WPILib. This tracker can be used to accurately track trajectories with correction for minor disturbances for differential drivetrains."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/bang-bang.html",
      "title": "Bang",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Bang-Bang Control with BangBangController The bang-bang control algorithm is a control strategy that employs only two states: on (when the measurement is below the setpoint) and off (otherwise). This is roughly equivalent to a proportional loop with infinite gain. This may initially seem like a poor control strategy, as PID loops are known to become unstable as the gains become large - and indeed, it is a very bad idea to use a bang-bang controller on anything other than velocity control of a high-inertia mechanism . However, when controlling the velocity of high-inertia mechanisms under varying loads (like a shooter flywheel), a bang-bang controller can yield faster recovery time and thus better/more consistent performance than a proportional controller. Unlike an ordinary P loop, a bang-bang controller is asymmetric - that is, the controller turns on when the process variable is below the setpoint, and does nothing otherwise. This allows the control effort in the forward direction to be made as large as possible without risking destructive oscillations as the control loop tries to correct a resulting overshoot. Asymmetric bang-bang control is provided in WPILib by the BangBangController class ( Java , C++ , Python ). Constructing a BangBangController Since a bang-bang controller does not have any gains, it does not need any constructor arguments (one can optionally specify the controller tolerance used by atSetpoint , but it is not required). JAVA // Creates a BangBangController BangBangController controller = new BangBangController (); C++ // Creates a BangBangController frc :: BangBangController controller ; PYTHON from wpimath.controller import BangBangController # Creates a BangBangController controller = BangBangController () Using a BangBangController Warning Bang-bang control is an extremely aggressive algorithm that relies on response asymmetry to remain stable. Be absolutely certain that your motor controllers have been set to “coast mode” before attempting to control them with a bang-bang controller, or else the braking action will fight the controller and cause potentially destructive oscillation. Using a bang-bang controller is easy: JAVA // Controls a motor with the output of the BangBang controller motor . set ( controller . calculate ( encoder . getRate (), setpoint )); C++ // Controls a motor with the output of the BangBang controller motor . Set ( controller . Calculate ( encoder . GetRate (), setpoint )); PYTHON # Controls a motor with the output of the BangBang controller motor . set ( controller . calculate ( encoder . getRate (), setpoint )) Combining Bang Bang Control with Feedforward Like a PID controller, best results are obtained in conjunction with a feedforward controller that provides the necessary voltage to sustain the system output at the desired speed, so that the bang-bang controller is only responsible for rejecting disturbances. Since the bang-bang controller can only correct in the forward direction, however, it may be preferable to use a slightly conservative feedforward estimate to ensure that the shooter does not over-speed. JAVA // Controls a motor with the output of the BangBang controller and a feedforward // Shrinks the feedforward slightly to avoid overspeeding the shooter motor . setVoltage ( controller . calculate ( encoder . getRate (), setpoint ) * 12.0 + 0.9 * feedforward . calculate ( setpoint )); C++ // Controls a motor with the output of the BangBang controller and a feedforward // Shrinks the feedforward slightly to avoid overspeeding the shooter motor . SetVoltage ( controller . Calculate ( encoder . GetRate (), setpoint ) * 12.0 + 0.9 * feedforward . Calculate ( setpoint )); PYTHON # Controls a motor with the output of the BangBang controller and a feedforward motor . setVoltage ( controller . calculate ( encoder . getRate (), setpoint ) * 12.0 + 0.9 * feedforward . calculate ( setpoint ))",
      "content_preview": "Bang-Bang Control with BangBangController The bang-bang control algorithm is a control strategy that employs only two states: on (when the measurement is below the setpoint) and off (otherwise). This is roughly equivalent to a proportional loop with infinite gain."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/creating-routine.html",
      "title": "Creating an Identification Routine",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Creating an Identification Routine Types of Tests A standard motor identification routine consists of two types of tests: Quasistatic: In this test, the mechanism is gradually sped-up such that the voltage corresponding to acceleration is negligible (hence, “as if static”). Dynamic: In this test, a constant ‘step voltage’ is given to the mechanism, so that the behavior while accelerating can be determined. Each test type is run both forwards and backwards, for four tests in total. The tests can be run in any order, but running a “backwards” test directly after a “forwards” test is generally advisable (as it will more or less reset the mechanism to its original position). SysIdRoutine provides command factories that may be used to run the tests, for example as part of an autonomous routine. Previous versions of SysId used a project generator to create and deploy robot code to run these tests, but it proved to be very fragile and difficult to maintain. The user code-based workflow enables teams to use mechanism code they already know works, including soft and hard limits. User Code Setup Note Some familiarity with your language’s units library is recommended and knowing how to use Consumers is required. This page assumes you are using the Commands framework. To assist in creating SysId-compatible identification routines, WPILib provides the SysIdRoutine class. Users should create a SysIdRoutine object, which take both a Config object describing the test settings and a Mechanism object describing how the routine will control the relevant motors and log the measurements needed to perform the fit. Routine Config The Config object takes in a a voltage ramp rate for use in Quasistatic tests, a steady state step voltage for use in Dynamic tests, a time to use as the maximum test duration for safety reasons, and a callback method that accepts the current test state (such as “dynamic-forward”) for use by a 3rd party logging solution. The constructor may be left blank to default the ramp rate to 1 volt per second and the step voltage to 7 volts. Note Not all 3rd party loggers will interact with SysIdRoutine directly. CTRE users who do not wish to use SysIdRoutine directly for logging should use the SignalLogger API and use Tuner X to convert to wpilog. REV users may use Team 6328’s Unofficial REV-Compatible Logger (URCL) . In both cases the log callback should be set to null . Once the log file is in hand, it may be used with SysId just like any other. The timeout and state callback are optional and defaulted to 10 seconds and null (which will log the data to a normal WPILog file) respectively. Declaring the Mechanism The Mechanism object takes a voltage consumer, a log consumer, the subsystem being characterized, and the name of the mechanism (to record in the log). The drive callback takes in the routine-generated voltage command and passes it to the relevant motors. The log callback reads the motor voltage, position, and velocity for each relevant motor and adds it to the running log. The subsystem is required so that it may be added to the requirements of the routine commands. The name is optional and will be defaulted to the string returned by getName(). The callbacks can either be created in-place via Lambda expressions or can be their own standalone functions and be passed in via method references. Best practice is to create the routine and callbacks inside the subsystem, to prevent leakage. JAVA // Creates a SysIdRoutine SysIdRoutine routine = new SysIdRoutine ( new SysIdRoutine . Config (), new SysIdRoutine . Mechanism ( this :: voltageDrive , this :: logMotors , this ) ); PYTHON routine = commands2 . sysid . SysIdRoutine ( commands2 . sysid . SysIdRoutine . Config (), commands2 . sysid . SysIdRoutine . Mechanism ( self . voltageDrive , self . logMotors , self ), ) Mechanism Callbacks The Mechanism callbacks are essentially just plumbing between the routine and your motors and sensors. The drive callback exists so that you can pass the requested voltage directly to your motor controller(s). The log callback reads sensors so that the routine can log the voltage, position, and velocity at each timestep. See the SysIdRoutine ( Java , C++ ) example project for example callbacks. Test Factories To be able to run the tests, SysIdRoutine exposes test “factories”, or functions that each return a command that will execute a given test. JAVA public Command sysIdQuasistatic ( SysIdRoutine . Direction direction ) { return routine . quasistatic ( direction ); } public Command sysIdDynamic ( SysIdRoutine . Direction direction ) { return routine . dynamic ( direction ); } PYTHON def sysIdQuasistatic ( self , direction : commands2 . sysid . SysIdRoutine . Direction ) -> commands2 . Command : return commands2 . sysid . SysIdRoutine . quasistatic ( direction ) def sysIdDynamic ( self , direction : commands2 . sysid . SysIdRoutine . Direction ) -> commands2 . Command : return commands2 . sysid . SysIdRoutine . dynamic ( direction ) Either bind the factory methods to either controller buttons or create an autonomous routine with them. It is recommended to bind them to buttons that the user must hold down for the duration of the test so that the user can stop the routine quickly if it exceeds safe limits.",
      "content_preview": "Creating an Identification Routine Types of Tests A standard motor identification routine consists of two types of tests: Quasistatic: In this test, the mechanism is gradually sped-up such that the voltage corresponding to acceleration is negligible (hence, “as if static”)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/analyzing-gains.html",
      "title": "Analyzing Data",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Analyzing Data Feedforward Analysis Note For information on what the calculated feedback gains mean, see The Permanent-Magnet DC Motor Feedforward Equation . For information on using the calculated feedback gains in code, see feedforward control . Click the dropdown arrow on the Feedforward Section. Note If you would like to change units, you will have to press the Override Units button and fill out the information on the popup. The computed mechanism system parameters will then be displayed. Feedback Analysis Important These gains are, in effect, “educated guesses” - they are not guaranteed to be perfect, and should be viewed as a “starting point” for further tuning. To view the feedback constants, click on the dropdown arrow on the Feedback section. This view can be used to calculate optimal feedback gains for a PD or P controller for your mechanism (via LQR ). Enter Controller Parameters Note The “Spark Max” preset assumes that the user has configured the controller to operate in the units of analysis with the SPARK MAX API’s position/velocity scaling factor feature. The calculated feedforward gains are dimensioned quantities . Unfortunately, not much attention is often paid to the units of PID gains in FRC® controls, and so the various typical options for PID controller implementations differ in their unit conventions (which are often not made clear to the user). To specify the correct settings for your PID controller, use the following options. Gain Settings Preset This drop-down menu will auto-populate the remaining fields with likely settings for one of a number of common FRC controller setups. Note that some settings, such as post-encoder gearing, PPR, and the presence of a follower motor must still be manually specified (as the analyzer has no way of knowing these without user input), and that others may vary from the given defaults depending on user setup. Controller Period This is the execution period of the control loop, in seconds. The default RIO loop rate is 50Hz, corresponding to a period of 0.02s. The onboard controllers on most “smart controllers” run at 1Khz, or a period of 0.001s. Max Controller Output This is the maximum value of the controller output, with respect to the PID calculation. Most controllers calculate outputs with a maximum value of 1, but Talon controllers have a maximum output of 1023. Time-Normalized Controller This specifies whether the PID calculation is normalized to the period of execution, which affects the scaling of the D gain. Controller Type This specifies whether the controller is an onboard RIO loop, or is running on a smart motor controller such as a Talon or a SPARK MAX. Post-Encoder Gearing This specifies the gearing between the encoder and the mechanism itself. This is necessary for control loops that do not allow user-specified unit scaling in their PID computations (e.g. those running on Talons). This will be disabled if not relevant. Encoder EPR This specifies the edges-per-revolution (not cycles per revolution) of the encoder used, which is needed in the same cases as Post-Encoder Gearing. Has Follower Whether there is a motor controller following the controller running the control loop, if the control loop is being run on a peripheral device. This changes the effective loop period. Follower Update Period The rate at which the follower (if present) is updated. By default, this is 100Hz (every 0.01s) for the Talon SRX, Talon FX, and the SPARK MAX, but can be changed. Note If you select a smart motor controller as the preset (e.g. TalonSRX, SPARK MAX, etc.) the Convert Gains checkbox will be automatically checked. This means the tool will convert your gains so that they can be used through the smart motor controller’s PID methods. Therefore, if you would like to use WPILib’s PID Loops, you must uncheck that box. Measurement Delays Note If you are using default smart motor controller settings or WPILib PID Control without additional filtering, SysId handles this for you. Many “smart motor controllers” (such as the Talon SRX , Venom , Talon FX , and SPARK MAX ) apply substantial low-pass filtering to their encoder velocity measurements, which can introduce a significant amount of phase lag. This can cause the calculated gains for velocity loops to be unstable. This can be accounted for with the Measurement Delay box. However, the measurement delays have already been calculated for the default settings of the previously mentioned motor controllers so for most users this is handled by selecting the right preset in Gain Settings Preset . The following only applies if the user decides to implement their own custom filtering settings (e.g. adding a moving average filter to a WPILib PID loop or changing smart motorcontroller measurement period and/or measurement window size) as the measurement delay must be recalculated. Here is the general formula that can be used for filters with moving windows (e.g. median filter + moving average filter): \\[d = \\frac{T(n - 1)}{2}\\] Where T is the period at which measurements are sampled (RIO default is 20 ms) and n is the size of the moving window used. Specify Optimality Criteria Finally, the user must specify what will be considered an “optimal” controller. This takes the form of desired tolerances for the system error and control effort - note that it is not guaranteed that the system will obey these tolerances at all times. As a rule, smaller values for the Max Acceptable Error and larger values for the Max Acceptable Control Effort will result in larger gains - this will result in larger control efforts, which can grant better setpoint-tracking but may cause more violent behavior and greater wear on components. The Max Acceptable Control Effort should never exceed 12V, as that corresponds to full battery voltage, and ideally should be somewhat lower than this. Select Loop Type It is typical to control mechanisms with both position and velocity PIDs, depending on application. Either can be selected using the drop-down Loop Type menu.",
      "content_preview": "Analyzing Data Feedforward Analysis Note For information on what the calculated feedback gains mean, see The Permanent-Magnet DC Motor Feedforward Equation . For information on using the calculated feedback gains in code, see feedforward control ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/profiled-pidcontroller.html",
      "title": "Combining Motion Profiling and PID Control with ProfiledPIDController",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Combining Motion Profiling and PID Control with ProfiledPIDController Note For a guide on implementing the ProfiledPIDController class in the command-based framework framework, see Combining Motion Profiling and PID in Command-Based . In the previous article, we saw how to use the TrapezoidProfile class to create and use a trapezoidal motion profile. The example code from that article demonstrates manually composing the TrapezoidProfile class with the external PID control feature of a “smart” motor controller. This combination of functionality (a motion profile for generating setpoints combined with a PID controller for following them) is extremely common. To facilitate this, WPILib comes with a ProfiledPIDController class ( Java , C++ , Python ) that does most of the work of combining these two functionalities. The API of the ProfiledPIDController is very similar to that of the PIDController , allowing users to add motion profiling to a PID-controlled mechanism with very few changes to their code. Using the ProfiledPIDController class Note In C++, the ProfiledPIDController class is templated on the unit type used for distance measurements, which may be angular or linear. The passed-in values must have units consistent with the distance units, or a compile-time error will be thrown. For more information on C++ units, see The C++ Units Library . Note Much of the functionality of ProfiledPIDController is effectively identical to that of PIDController . Accordingly, this article will only cover features that are substantially-changed to accommodate the motion profiling functionality. For information on standard PIDController features, see PID Control in WPILib . Constructing a ProfiledPIDController Note C++ is often able to infer the type of the inner classes, and thus a simple initializer list (without the class name) can be sent as a parameter. The full class name is included in the example below for clarity. Creating a ProfiledPIDController is nearly identical to creating a PIDController . The only difference is the need to supply a set of trapezoidal profile constraints , which will be automatically forwarded to the internally-generated TrapezoidProfile instances: JAVA // Creates a ProfiledPIDController // Max velocity is 5 meters per second // Max acceleration is 10 meters per second ProfiledPIDController controller = new ProfiledPIDController ( kP , kI , kD , new TrapezoidProfile . Constraints ( 5 , 10 )); C++ // Creates a ProfiledPIDController // Max velocity is 5 meters per second // Max acceleration is 10 meters per second frc :: ProfiledPIDController < units :: meters > controller ( kP , kI , kD , frc :: TrapezoidProfile < units :: meters >:: Constraints { 5 _mps , 10 _mps_sq }); PYTHON from wpimath.controller import ProfiledPIDController from wpimath.trajectory import TrapezoidProfile # Creates a ProfiledPIDController # Max velocity is 5 meters per second # Max acceleration is 10 meters per second controller = ProfiledPIDController ( kP , kI , kD , TrapezoidProfile . Constraints ( 5 , 10 )) Goal vs Setpoint A major difference between a standard PIDController and a ProfiledPIDController is that the actual setpoint of the control loop is not directly specified by the user. Rather, the user specifies a goal position or state, and the setpoint for the controller is computed automatically from the generated motion profile between the current state and the goal. So, while the user-side call looks mostly identical: JAVA // Calculates the output of the PID algorithm based on the sensor reading // and sends it to a motor motor . set ( controller . calculate ( encoder . getDistance (), goal )); C++ // Calculates the output of the PID algorithm based on the sensor reading // and sends it to a motor motor . Set ( controller . Calculate ( encoder . GetDistance (), goal )); PYTHON # Calculates the output of the PID algorithm based on the sensor reading # and sends it to a motor motor . set ( controller . calculate ( encoder . getDistance (), goal )) The specified goal value (which can be either a position value or a TrapezoidProfile.State , if nonzero velocity is desired) is not necessarily the current setpoint of the loop - rather, it is the eventual setpoint once the generated profile terminates. Getting/Using the Setpoint Since the ProfiledPIDController goal differs from the setpoint, is if often desirable to poll the current setpoint of the controller (for instance, to get values to use with feedforward ). This can be done with the getSetpoint() method. The returned setpoint might then be used as in the following example: JAVA double lastSpeed = 0 ; double lastTime = Timer . getFPGATimestamp (); // Controls a simple motor's position using a SimpleMotorFeedforward // and a ProfiledPIDController public void goToPosition ( double goalPosition ) { double pidVal = controller . calculate ( encoder . getDistance (), goalPosition ); double acceleration = ( controller . getSetpoint (). velocity - lastSpeed ) / ( Timer . getFPGATimestamp () - lastTime ); motor . setVoltage ( pidVal + feedforward . calculate ( controller . getSetpoint (). velocity , acceleration )); lastSpeed = controller . getSetpoint (). velocity ; lastTime = Timer . getFPGATimestamp (); } C++ units :: meters_per_second_t lastSpeed = 0 _mps ; units :: second_t lastTime = frc2 :: Timer :: GetFPGATimestamp (); // Controls a simple motor's position using a SimpleMotorFeedforward // and a ProfiledPIDController void GoToPosition ( units :: meter_t goalPosition ) { auto pidVal = controller . Calculate ( units :: meter_t { encoder . GetDistance ()}, goalPosition ); auto acceleration = ( controller . GetSetpoint (). velocity - lastSpeed ) / ( frc2 :: Timer :: GetFPGATimestamp () - lastTime ); motor . SetVoltage ( pidVal + feedforward . Calculate ( controller . GetSetpoint (). velocity , acceleration )); lastSpeed = controller . GetSetpoint (). velocity ; lastTime = frc2 :: Timer :: GetFPGATimestamp (); } PYTHON from wpilib import Timer from wpilib.controller import ProfiledPIDController from wpilib.controller import SimpleMotorFeedforward def __init__ ( self ): # Assuming encoder, motor, controller are already defined self . lastSpeed = 0 self . lastTime = Timer . getFPGATimestamp () # Assuming feedforward is a SimpleMotorFeedforward object self . feedforward = SimpleMotorFeedforward ( ks = 0.0 , kv = 0.0 , ka = 0.0 ) def goToPosition ( self , goalPosition : float ): pidVal = self . controller . calculate ( self . encoder . getDistance (), goalPosition ) acceleration = ( self . controller . getSetpoint () . velocity - self . lastSpeed ) / ( Timer . getFPGATimestamp () - self . lastTime ) self . motor . setVoltage ( pidVal + self . feedforward . calculate ( self . controller . getSetpoint () . velocity , acceleration )) self . lastSpeed = controller . getSetpoint () . velocity self . lastTime = Timer . getFPGATimestamp () Complete Usage Example A more complete example of ProfiledPIDController usage is provided in the ElevatorProfilePID example project ( Java , C++ , Python ): JAVA 5 package edu.wpi.first.wpilibj.examples.elevatorprofiledpid ; 6 7 import edu.wpi.first.math.controller.ElevatorFeedforward ; 8 import edu.wpi.first.math.controller.ProfiledPIDController ; 9 import edu.wpi.first.math.trajectory.TrapezoidProfile ; 10 import edu.wpi.first.wpilibj.Encoder ; 11 import edu.wpi.first.wpilibj.Joystick ; 12 import edu.wpi.first.wpilibj.TimedRobot ; 13 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 14 15 @SuppressWarnings ( \"PMD.RedundantFieldInitializer\" ) 16 public class Robot extends TimedRobot { 17 private static double kDt = 0.02 ; 18 private static double kMaxVelocity = 1.75 ; 19 private static double kMaxAcceleration = 0.75 ; 20 private static double kP = 1.3 ; 21 private static double kI = 0.0 ; 22 private static double kD = 0.7 ; 23 private static double kS = 1.1 ; 24 private static double kG = 1.2 ; 25 private static double kV = 1.3 ; 26 27 private final Joystick m_joystick = new Joystick ( 1 ); 28 private final Encoder m_encoder = new Encoder ( 1 , 2 ); 29 private final PWMSparkMax m_motor = new PWMSparkMax ( 1 ); 30 31 // Create a PID controller whose setpoint's change is subject to maximum 32 // velocity and acceleration constraints. 33 private final TrapezoidProfile . Constraints m_constraints = 34 new TrapezoidProfile . Constraints ( kMaxVelocity , kMaxAcceleration ); 35 private final ProfiledPIDController m_controller = 36 new ProfiledPIDController ( kP , kI , kD , m_constraints , kDt ); 37 private final ElevatorFeedforward m_feedforward = new ElevatorFeedforward ( kS , kG , kV ); 38 39 public Robot () { 40 m_encoder . setDistancePerPulse ( 1.0 / 360.0 * 2.0 * Math . PI * 1.5 ); 41 } 42 43 @Override 44 public void teleopPeriodic () { 45 if ( m_joystick . getRawButtonPressed ( 2 )) { 46 m_controller . setGoal ( 5 ); 47 } else if ( m_joystick . getRawButtonPressed ( 3 )) { 48 m_controller . setGoal ( 0 ); 49 } 50 51 // Run controller and update motor output 52 m_motor . setVoltage ( 53 m_controller . calculate ( m_encoder . getDistance ()) 54 + m_feedforward . calculate ( m_controller . getSetpoint (). velocity )); 55 } 56 } C++ 5 #include <numbers> 6 7 #include <frc/Encoder.h> 8 #include <frc/Joystick.h> 9 #include <frc/TimedRobot.h> 10 #include <frc/controller/ElevatorFeedforward.h> 11 #include <frc/controller/ProfiledPIDController.h> 12 #include <frc/motorcontrol/PWMSparkMax.h> 13 #include <frc/trajectory/TrapezoidProfile.h> 14 #include <units/acceleration.h> 15 #include <units/length.h> 16 #include <units/time.h> 17 #include <units/velocity.h> 18 #include <units/voltage.h> 19 20 class Robot : public frc :: TimedRobot { 21 public : 22 static constexpr units :: second_t kDt = 20 _ms ; 23 24 Robot () { 25 m_encoder . SetDistancePerPulse ( 1.0 / 360.0 * 2.0 * std :: numbers :: pi * 1.5 ); 26 } 27 28 void TeleopPeriodic () override { 29 if ( m_joystick . GetRawButtonPressed ( 2 )) { 30 m_controller . SetGoal ( 5 _m ); 31 } else if ( m_joystick . GetRawButtonPressed ( 3 )) { 32 m_controller . SetGoal ( 0 _m ); 33 } 34 35 // Run controller and update motor output 36 m_motor . SetVoltage ( 37 units :: volt_t { 38 m_controller . Calculate ( units :: meter_t { m_encoder . GetDistance ()})} + 39 m_feedforward . Calculate ( m_controller . GetSetpoint (). velocity )); 40 } 41 42 private : 43 static constexpr units :: meters_per_second_t kMaxVelocity = 1.75 _mps ; 44 static constexpr units :: meters_per_second_squared_t kMaxAcceleration = 45 0.75 _mps_sq ; 46 static constexpr double kP = 1.3 ; 47 static constexpr double kI = 0.0 ; 48 static constexpr double kD = 0.7 ; 49 static constexpr units :: volt_t kS = 1.1 _V ; 50 static constexpr units :: volt_t kG = 1.2 _V ; 51 static constexpr auto kV = 1.3 _V / 1 _mps ; 52 53 frc :: Joystick m_joystick { 1 }; 54 frc :: Encoder m_encoder { 1 , 2 }; 55 frc :: PWMSparkMax m_motor { 1 }; 56 57 // Create a PID controller whose setpoint's change is subject to maximum 58 // velocity and acceleration constraints. 59 frc :: TrapezoidProfile < units :: meters >:: Constraints m_constraints { 60 kMaxVelocity , kMaxAcceleration }; 61 frc :: ProfiledPIDController < units :: meters > m_controller { kP , kI , kD , 62 m_constraints , kDt }; 63 frc :: ElevatorFeedforward m_feedforward { kS , kG , kV }; 64 }; 65 66 #ifndef RUNNING_FRC_TESTS 67 int main () { 68 return frc :: StartRobot < Robot > (); 69 } 70 #endif PYTHON 8 import wpilib 9 import wpimath.controller 10 import wpimath.trajectory 11 import math 12 13 14 class MyRobot ( wpilib . TimedRobot ): 15 kDt = 0.02 16 17 def robotInit ( self ) -> None : 18 self . joystick = wpilib . Joystick ( 1 ) 19 self . encoder = wpilib . Encoder ( 1 , 2 ) 20 self . motor = wpilib . PWMSparkMax ( 1 ) 21 22 # Create a PID controller whose setpoint's change is subject to maximum 23 # velocity and acceleration constraints. 24 self . constraints = wpimath . trajectory . TrapezoidProfile . Constraints ( 1.75 , 0.75 ) 25 self . controller = wpimath . controller . ProfiledPIDController ( 26 1.3 , 0 , 0.7 , self . constraints , self . kDt 27 ) 28 29 self . encoder . setDistancePerPulse ( 1 / 360 * 2 * math . pi * 1.5 ) 30 31 def teleopPeriodic ( self ) -> None : 32 if self . joystick . getRawButtonPressed ( 2 ): 33 self . controller . setGoal ( 5 ) 34 elif self . joystick . getRawButtonPressed ( 3 ): 35 self . controller . setGoal ( 0 ) 36 37 # Run controller and update motor output 38 self . motor . set ( self . controller . calculate ( self . encoder . getDistance ()))",
      "content_preview": "Combining Motion Profiling and PID Control with ProfiledPIDController Note For a guide on implementing the ProfiledPIDController class in the command-based framework framework, see Combining Motion Profiling and PID in Command-Based ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/pidcontroller.html",
      "title": "PID Control in WPILib",
      "section": "Advanced Controls",
      "language": "All",
      "content": "PID Control in WPILib Note This article focuses on in-code implementation of PID control in WPILib. For a conceptual explanation of the working of a PIDController, see Introduction to PID Note For a guide on implementing PID control through the command-based framework , see PID Control in Command-based . WPILib supports PID control of mechanisms through the PIDController class ( Java , C++ , Python ). This class handles the feedback loop calculation for the user, as well as offering methods for returning the error, setting tolerances, and checking if the control loop has reached its setpoint within the specified tolerances. Using the PIDController Class Constructing a PIDController Note While PIDController may be used asynchronously, it does not provide any thread safety features - ensuring threadsafe operation is left entirely to the user, and thus asynchronous usage is recommended only for advanced teams. In order to use WPILib’s PID control functionality, users must first construct a PIDController object with the desired gains: JAVA // Creates a PIDController with gains kP, kI, and kD PIDController pid = new PIDController ( kP , kI , kD ); C++ // Creates a PIDController with gains kP, kI, and kD frc :: PIDController pid { kP , kI , kD }; PYTHON from wpimath.controller import PIDController # Creates a PIDController with gains kP, kI, and kD pid = PIDController ( kP , kI , kD ) An optional fourth parameter can be provided to the constructor, specifying the period at which the controller will be run. The PIDController object is intended primarily for synchronous use from the main robot loop, and so this value is defaulted to 20ms. Using the Feedback Loop Output Note The PIDController assumes that the calculate() method is being called regularly at an interval consistent with the configured period. Failure to do this will result in unintended loop behavior. Using the constructed PIDController is simple: simply call the calculate() method from the robot’s main loop (e.g. the robot’s autonomousPeriodic() method): JAVA // Calculates the output of the PID algorithm based on the sensor reading // and sends it to a motor motor . set ( pid . calculate ( encoder . getDistance (), setpoint )); C++ // Calculates the output of the PID algorithm based on the sensor reading // and sends it to a motor motor . Set ( pid . Calculate ( encoder . GetDistance (), setpoint )); PYTHON # Calculates the output of the PID algorithm based on the sensor reading # and sends it to a motor motor . set ( pid . calculate ( encoder . getDistance (), setpoint )) Checking Errors Note getPositionError() and getVelocityError() are named assuming that the loop is controlling a position - for a loop that is controlling a velocity, these return the velocity error and the acceleration error, respectively. The current error of the measured process variable is returned by the getPositionError() function, while its derivative is returned by the getVelocityError() function: Specifying and Checking Tolerances Note If only a position tolerance is specified, the velocity tolerance defaults to infinity. Note As above, “position” refers to the process variable measurement, and “velocity” to its derivative - thus, for a velocity loop, these are actually velocity and acceleration, respectively. Occasionally, it is useful to know if a controller has tracked the setpoint to within a given tolerance - for example, to determine if a command should be ended, or (while following a motion profile) if motion is being impeded and needs to be re-planned. To do this, we first must specify the tolerances with the setTolerance() method; then, we can check it with the atSetpoint() method. JAVA // Sets the error tolerance to 5, and the error derivative tolerance to 10 per second pid . setTolerance ( 5 , 10 ); // Returns true if the error is less than 5 units, and the // error derivative is less than 10 units pid . atSetpoint (); C++ // Sets the error tolerance to 5, and the error derivative tolerance to 10 per second pid . SetTolerance ( 5 , 10 ); // Returns true if the error is less than 5 units, and the // error derivative is less than 10 units pid . AtSetpoint (); PYTHON # Sets the error tolerance to 5, and the error derivative tolerance to 10 per second pid . setTolerance ( 5 , 10 ) # Returns true if the error is less than 5 units, and the # error derivative is less than 10 units pid . atSetpoint () Resetting the Controller It is sometimes desirable to clear the internal state (most importantly, the integral accumulator) of a PIDController , as it may be no longer valid (e.g. when the PIDController has been disabled and then re-enabled). This can be accomplished by calling the reset() method. Setting a Max Integrator Value Note Integrators introduce instability and hysteresis into feedback loop systems. It is strongly recommended that teams avoid using integral gain unless absolutely no other solution will do - very often, problems that can be solved with an integrator can be better solved through use of a more-accurate feedforward . A typical problem encountered when using integral feedback is excessive “wind-up” causing the system to wildly overshoot the setpoint. This can be alleviated in a number of ways - the WPILib PIDController class enforces an integrator range limiter to help teams overcome this issue. By default, the total output contribution from the integral gain is limited to be between -1.0 and 1.0. The range limits may be increased or decreased using the setIntegratorRange() method. JAVA // The integral gain term will never add or subtract more than 0.5 from // the total loop output pid . setIntegratorRange ( - 0.5 , 0.5 ); C++ // The integral gain term will never add or subtract more than 0.5 from // the total loop output pid . SetIntegratorRange ( -0.5 , 0.5 ); PYTHON # The integral gain term will never add or subtract more than 0.5 from # the total loop output pid . setIntegratorRange ( - 0.5 , 0.5 ) Disabling Integral Gain if the Error is Too High Another way integral “wind-up” can be alleviated is by limiting the error range where integral gain is active. This can be achieved by setting IZone . If the error is more than IZone , the total accumulated error is reset, disabling integral gain. When the error is equal to or less than IZone, integral gain is enabled. By default, IZone is disabled. IZone may be set using the setIZone() method. To disable it, set it to infinity. JAVA // Disable IZone pid . setIZone ( Double . POSITIVE_INFINITY ); // Integral gain will not be applied if the absolute value of the error is // more than 2 pid . setIZone ( 2 ); C++ // Disable IZone pid . SetIZone ( std :: numeric_limits < double >:: infinity ()); // Integral gain will not be applied if the absolute value of the error is // more than 2 pid . SetIZone ( 2 ); PYTHON # Disable IZone pid . setIZone ( math . inf ) # Integral gain will not be applied if the absolute value of the error is # more than 2 pid . setIZone ( 2 ) Setting Continuous Input Warning If your mechanism is not capable of fully continuous rotational motion (e.g. a turret without a slip ring, whose wires twist as it rotates), do not enable continuous input unless you have implemented an additional safety feature to prevent the mechanism from moving past its limit! Some process variables (such as the angle of a turret) are measured on a circular scale, rather than a linear one - that is, each “end” of the process variable range corresponds to the same point in reality (e.g. 360 degrees and 0 degrees). In such a configuration, there are two possible values for any given error, corresponding to which way around the circle the error is measured. It is usually best to use the smaller of these errors. To configure a PIDController to automatically do this, use the enableContinuousInput() method: JAVA // Enables continuous input on a range from -180 to 180 pid . enableContinuousInput ( - 180 , 180 ); C++ // Enables continuous input on a range from -180 to 180 pid . EnableContinuousInput ( -180 , 180 ); PYTHON # Enables continuous input on a range from -180 to 180 pid . enableContinuousInput ( - 180 , 180 ) Clamping Controller Output JAVA // Clamps the controller output to between -0.5 and 0.5 MathUtil . clamp ( pid . calculate ( encoder . getDistance (), setpoint ), - 0.5 , 0.5 ); C++ // Clamps the controller output to between -0.5 and 0.5 std :: clamp ( pid . Calculate ( encoder . GetDistance (), setpoint ), -0.5 , 0.5 ); PYTHON # Python doesn't have a builtin clamp function def clamp ( v , minval , maxval ): return max ( min ( v , maxval ), minval ) # Clamps the controller output to between -0.5 and 0.5 clamp ( pid . calculate ( encoder . getDistance (), setpoint ), - 0.5 , 0.5 )",
      "content_preview": "PID Control in WPILib Note This article focuses on in-code implementation of PID control in WPILib. For a conceptual explanation of the working of a PIDController, see Introduction to PID Note For a guide on implementing PID control through the command-based framework , see PID Control in..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-observers.html",
      "title": "State Observers and Kalman Filters",
      "section": "Advanced Controls",
      "language": "All",
      "content": "State Observers and Kalman Filters State observers combine information about a system’s behavior and external measurements to estimate the true state of the system. A common observer used for linear systems is the Kalman Filter. Kalman filters are advantageous over other filters as they fuse measurements from one or more sensors with a state-space model of the system to optimally estimate a system’s state. This image shows flywheel velocity measurements over time, run through a variety of different filters. Note that a well-tuned Kalman filter shows no measurement lag during flywheel spinup while still rejecting noisy data and reacting quickly to disturbances as balls pass through it. More on filters can be found in the filters section . Gaussian Functions Kalman filters utilize a Gaussian distribution to model the noise in a process [ 1 ] . In the case of a Kalman filter, the estimated state of the system is the mean, while the variance is a measure of how certain (or uncertain) the filter is about the true state . The idea of variance and covariance is central to the function of a Kalman filter. Covariance is a measurement of how two random variables are correlated. In a system with a single state, the covariance matrix is simply \\(\\mathbf{\\text{cov}(x_1, x_1)}\\) , or a matrix containing the variance \\(\\mathbf{\\text{var}(x_1)}\\) of the state \\(x_1\\) . The magnitude of this variance is the square of the standard deviation of the Gaussian function describing the current state estimate. Relatively large values for covariance might indicate noisy data, while small covariances might indicate that the filter is more confident about it’s estimate. Remember that “large” and “small” values for variance or covariance are relative to the base unit being used – for example, if \\(\\mathbf{x_1}\\) was measured in meters, \\(\\mathbf{\\text{cov}(x_1, x_1)}\\) would be in meters squared. Covariance matrices are written in the following form: \\[\\begin{split}\\mathbf{\\Sigma} &= \\begin{bmatrix} \\text{cov}(x_1, x_1) & \\text{cov}(x_1, x_2) & \\ldots & \\text{cov}(x_1, x_n) \\\\ \\text{cov}(x_2, x_1) & \\text{cov}(x_2, x_2) & \\ldots & \\text{cov}(x_1, x_n) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\text{cov}(x_n, x_1) & \\text{cov}(x_n, x_2) & \\ldots & \\text{cov}(x_n, x_n) \\\\ \\end{bmatrix}\\end{split}\\] Kalman Filters Important It is important to develop an intuition for what a Kalman filter is actually doing. The book Kalman and Bayesian Filters in Python by Roger Labbe provides a great visual and interactive introduction to Bayesian filters. The Kalman filters in WPILib use linear algebra to gentrify the math, but the ideas are similar to the single-dimensional case. We suggest reading through Chapter 4 to gain an intuition for what these filters are doing. To summarize, Kalman filters (and all Bayesian filters) have two parts: prediction and correction. Prediction projects our state estimate forward in time according to our system’s dynamics, and correct steers the estimated state towards the measured state. While filters often perform both in the same timestep, it’s not strictly necessary – For example, WPILib’s pose estimators call predict frequently, and correct only when new measurement data is available (for example, from a low-framerate vision system). The following shows the equations of a discrete-time Kalman filter: \\[\\begin{split}\\text{Predict step} \\nonumber \\\\ \\hat{\\mathbf{x}}_{k+1}^- &= \\mathbf{A}\\hat{\\mathbf{x}}_k^+ + \\mathbf{B} \\mathbf{u}_k \\\\ \\mathbf{P}_{k+1}^- &= \\mathbf{A} \\mathbf{P}_k^- \\mathbf{A}^T + \\mathbf{\\Gamma}\\mathbf{Q}\\mathbf{\\Gamma}^T \\\\ \\text{Update step} \\nonumber \\\\ \\mathbf{K}_{k+1} &= \\mathbf{P}_{k+1}^- \\mathbf{C}^T (\\mathbf{C}\\mathbf{P}_{k+1}^- \\mathbf{C}^T + \\mathbf{R})^{-1} \\\\ \\hat{\\mathbf{x}}_{k+1}^+ &= \\hat{\\mathbf{x}}_{k+1}^- + \\mathbf{K}_{k+1}(\\mathbf{y}_{k+1} - \\mathbf{C} \\hat{\\mathbf{x}}_{k+1}^- - \\mathbf{D}\\mathbf{u}_{k+1}) \\\\ \\mathbf{P}_{k+1}^+ &= (\\mathbf{I} - \\mathbf{K}_{k+1}\\mathbf{C})\\mathbf{P}_{k+1}^-\\end{split}\\] \\[\\begin{split}\\begin{array}{llll} \\mathbf{A} & \\text{system matrix} & \\hat{\\mathbf{x}} & \\text{state estimate vector} \\\\ \\mathbf{B} & \\text{input matrix} & \\mathbf{u} & \\text{input vector} \\\\ \\mathbf{C} & \\text{output matrix} & \\mathbf{y} & \\text{output vector} \\\\ \\mathbf{D} & \\text{feedthrough matrix} & \\mathbf{\\Gamma} & \\text{process noise intensity vector} \\\\ \\mathbf{P} & \\text{error covariance matrix} & \\mathbf{Q} & \\text{process noise covariance matrix} \\\\ \\mathbf{K} & \\text{Kalman gain matrix} & \\mathbf{R} & \\text{measurement noise covariance matrix} \\end{array}\\end{split}\\] The state estimate \\(\\mathbf{x}\\) , together with \\(\\mathbf{P}\\) , describe the mean and covariance of the Gaussian function that describes our filter’s estimate of the system’s true state. Process and Measurement Noise Covariance Matrices The process and measurement noise covariance matrices \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) describe the variance of each of our states and measurements. Remember that for a Gaussian function, variance is the square of the function’s standard deviation. In a WPILib, Q, and R are diagonal matrices whose diagonals contain their respective variances. For example, a Kalman filter with states \\(\\begin{bmatrix}\\text{position} \\\\ \\text{velocity} \\end{bmatrix}\\) and measurements \\(\\begin{bmatrix}\\text{position} \\end{bmatrix}\\) with state standard deviations \\(\\begin{bmatrix}0.1 \\\\ 1.0\\end{bmatrix}\\) and measurement standard deviation \\(\\begin{bmatrix}0.01\\end{bmatrix}\\) would have the following \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) matrices: \\[\\begin{split}Q = \\begin{bmatrix}0.01 & 0 \\\\ 0 & 1.0\\end{bmatrix}, R = \\begin{bmatrix}0.0001\\end{bmatrix}\\end{split}\\] Error Covariance Matrix The error covariance matrix \\(\\mathbf{P}\\) describes the covariance of the state estimate \\(\\mathbf{\\hat{x}}\\) . Informally, \\(\\mathbf{P}\\) describes our certainty about the estimated state . If \\(\\mathbf{P}\\) is large, our uncertainty about the true state is large. Conversely, a \\(\\mathbf{P}\\) with smaller elements would imply less uncertainty about our true state. As we project the model forward, \\(\\mathbf{P}\\) increases as our certainty about the system’s true state decreases. Predict step In prediction, our state estimate is updated according to the linear system dynamics \\(\\mathbf{\\dot{x} = Ax + Bu}\\) . Furthermore, our error covariance \\(\\mathbf{P}\\) increases by the process noise covariance matrix \\(\\mathbf{Q}\\) . Larger values of \\(\\mathbf{Q}\\) will make our error covariance \\(\\mathbf{P}\\) grow more quickly. This \\(\\mathbf{P}\\) is used in the correction step to weight the model and measurements. Correct step In the correct step, our state estimate is updated to include new measurement information. This new information is weighted against the state estimate \\(\\mathbf{\\hat{x}}\\) by the Kalman gain \\(\\mathbf{K}\\) . Large values of \\(\\mathbf{K}\\) more highly weight incoming measurements, while smaller values of \\(\\mathbf{K}\\) more highly weight our state prediction. Because \\(\\mathbf{K}\\) is related to \\(\\mathbf{P}\\) , larger values of \\(\\mathbf{P}\\) will increase \\(\\mathbf{K}\\) and more heavily weight measurements. If, for example, a filter is predicted for a long duration, the large \\(\\mathbf{P}\\) would heavily weight the new information. Finally, the error covariance \\(\\mathbf{P}\\) decreases to increase our confidence in the state estimate. Tuning Kalman Filters WPILib’s Kalman Filter classes’ constructors take a linear system, a vector of process noise standard deviations and measurement noise standard deviations. These are converted to \\(\\mathbf{Q}\\) and \\(\\mathbf{R}\\) matrices by filling the diagonals with the square of the standard deviations, or variances, of each state or measurement. By decreasing a state’s standard deviation (and therefore its corresponding entry in \\(\\mathbf{Q}\\) ), the filter will distrust incoming measurements more. Similarly, increasing a state’s standard deviation will trust incoming measurements more. The same holds for the measurement standard deviations – decreasing an entry will make the filter more highly trust the incoming measurement for the corresponding state, while increasing it will decrease trust in the measurement. Java 48 // The observer fuses our encoder data and voltage inputs to reject noise. 49 private final KalmanFilter < N1 , N1 , N1 > m_observer = 50 new KalmanFilter <> ( 51 Nat . N1 (), 52 Nat . N1 (), 53 m_flywheelPlant , 54 VecBuilder . fill ( 3.0 ), // How accurate we think our model is 55 VecBuilder . fill ( 0.01 ), // How accurate we think our encoder 56 // data is 57 0.020 ); C++ 5 #include <numbers> 6 7 #include <frc/DriverStation.h> 8 #include <frc/Encoder.h> 9 #include <frc/TimedRobot.h> 10 #include <frc/XboxController.h> 11 #include <frc/controller/LinearQuadraticRegulator.h> 12 #include <frc/drive/DifferentialDrive.h> 13 #include <frc/estimator/KalmanFilter.h> 14 #include <frc/motorcontrol/PWMSparkMax.h> 15 #include <frc/system/LinearSystemLoop.h> 16 #include <frc/system/plant/DCMotor.h> 17 #include <frc/system/plant/LinearSystemId.h> 18 #include <units/angular_velocity.h> 48 // The observer fuses our encoder data and voltage inputs to reject noise. 49 frc :: KalmanFilter < 1 , 1 , 1 > m_observer { 50 m_flywheelPlant , 51 { 3.0 }, // How accurate we think our model is 52 { 0.01 }, // How accurate we think our encoder data is 53 20 _ms }; Python 49 # The observer fuses our encoder data and voltage inputs to reject noise. 50 self . observer = wpimath . estimator . KalmanFilter_1_1_1 ( 51 self . flywheelPlant , 52 ( 3 ,), # How accurate we think our model is 53 ( 0.01 ,), # How accurate we think our encoder data is 54 0.020 , 55 ) Footnotes [ 1 ] In a real robot, noise comes from all sorts of sources. Stray electromagnetic radiation adds extra voltages to sensor readings, vibrations, and temperature variations throw off inertial measurement units, gear lash causes encoders to have inaccuracies when directions change… all sorts of things. It’s important to realize that, by themselves, each of these sources of “noise” aren’t guaranteed to follow any pattern. Some of them might be the “white noise” random vibrations you’ve probably heard on the radio. Others might be “pops” or single-loop errors. Others might be nominally zero, but strongly correlated with events on the robot. However, the Central Limit Theorem shows mathematically that regardless of how the individual sources of noise are distributed, as we add more and more of them up their combined effect eventually is distributed like a Gaussian. Since we do not know the exact individual sources of noise, the best choice of a model we can make is indeed that Gaussian function.",
      "content_preview": "State Observers and Kalman Filters State observers combine information about a system’s behavior and external measurements to estimate the true state of the system. A common observer used for linear systems is the Kalman Filter."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/geometry/index.html",
      "title": "Geometry Classes",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Geometry Classes This section covers the geometry classes of WPILib. Translation, Rotation, and Pose Transformations",
      "content_preview": "Geometry Classes This section covers the geometry classes of WPILib. Translation, Rotation, and Pose Transformations"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/pid-video.html",
      "title": "PID Introduction Video by WPI",
      "section": "Advanced Controls",
      "language": "All",
      "content": "PID Introduction Video by WPI Have you ever had trouble designing a robot system to move quickly and then stop at exactly a desired position? Challenges like this can arise when driving fixed distances or speeds, operating an arm or elevator, or any other motor controlled system that requires specific motion. In this video, WPI Professor Dmitry Berenson talks about robot controls and how PID controls work.",
      "content_preview": "PID Introduction Video by WPI Have you ever had trouble designing a robot system to move quickly and then stop at exactly a desired position? Challenges like this can arise when driving fixed distances or speeds, operating an arm or elevator, or any other motor controlled system that requires..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/running-routine.html",
      "title": "Running the Identification Routine",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Running the Identification Routine Once the code has been deployed, we can now run the system identification routine, and record the resulting data for analysis. Note Ensure you have sufficient space around the robot before running any identification routine! The drive identification requires at least 10’ of space, ideally closer to 20’. The robot drive can not be accurately characterized while on blocks. Warning Only log files with a single routine in them are usable for analysis. Multiple motors can be run in one routine, but they must be run at the same time. If you run a routine on one motor and then run a routine on another motor without extracting the log or power-cycling the roboRIO in between, analysis will fail. Running Tests Perform the tests using the bindings you created in the previous section. Warning Watch out for your mechanism and stop the test early if it exceeds safe limits! The routine only creates voltage commands for you to connect to your motors, it is up to you to set up hard or soft limits to prevent injury or damage. The entire routine should look something like this: Note A drivetrain routine is shown below, but the same motions will occur on any mechanism. After all four tests have been completed, use the DataLogTool to retrieve the log file from the roboRIO.",
      "content_preview": "Running the Identification Routine Once the code has been deployed, we can now run the system identification routine, and record the resulting data for analysis."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/common-control-issues.html",
      "title": "Common Control Loop Tuning Issues",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Common Control Loop Tuning Issues There are a number of common issues which can arise while tuning feedforward and feedback controllers. Integral Term Windup Beware that if \\(K_i\\) is too large, integral windup can occur. Following a large change in setpoint , the integral term can accumulate an error larger than the maximal control effort . As a result, the system overshoots and continues to increase until this accumulated error is unwound. There are a few ways to mitigate this: Decrease the value of \\(K_i\\) , down to zero if possible. Add logic to reset the integrator term to zero if the output is too far from the setpoint . Some smart motor controllers and WPILib’s PIDController implement this with a setIZone() method. Cap the integrator at some maximum value. WPILib’s PIDController implements this with the setIntegratorRange() method. Important Most mechanisms in FRC do not require any integral control, and systems that seem to require integral control to respond well probably have an inaccurate feedforward model. Voltage Sag When we operate mechanisms on our robot, we draw current from its battery. This causes the available “bus voltage” that all the robot mechanisms operate off of to drop. This means that the performance of our mechanisms will vary depending on the loading and action of the robot - this is not ideal. To fix this, most voltage controllers offer a “voltage compensation” setting for their internal control loops that keep the output voltage of the control loops constant despite changes in the bus voltage. The WPILib MotorController class offers a setVoltage method can do the same thing if the control loops are being run on the RIO (provided you call it every robot loop iteration). Keep in mind that voltage compensation cannot increase the voltage applied to the motor beyond what is available on the bus - if your actuator is saturating (described below), you’ll have to account for that separately. Actuator Saturation A controller calculates its output based on the error between the setpoint and the current state . Plant in the real world don’t have unlimited control authority available for the controller to apply - that is to say, real mechanisms have some maximum achievable torque/acceleration and velocity. If our control gains are too aggressive, our control algorithm might try to move the mechanism faster than it is capable of actually going. In this case, the mechanism will “saturate”, and behave as if the control gains were smaller than they are. This might adversely affect control response (i.e., result in errors and instability). If you are encountering problems with actuator saturation, consider modifying your mechanism gearing or powering it with a bigger motor.",
      "content_preview": "Common Control Loop Tuning Issues There are a number of common issues which can arise while tuning feedforward and feedback controllers. Integral Term Windup Beware that if \\(K_i\\) is too large, integral windup can occur."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/transforming-trajectories.html",
      "title": "Transforming Trajectories",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Transforming Trajectories Trajectories can be transformed from one coordinate system to another and moved within a coordinate system using the relativeTo and the transformBy methods. These methods are useful for moving trajectories within space, or redefining an already existing trajectory in another frame of reference. Note Neither of these methods changes the shape of the original trajectory. The relativeTo Method The relativeTo method is used to redefine an already existing trajectory in another frame of reference. This method takes one argument: a pose, (via a Pose2d object) that is defined with respect to the current coordinate system, that represents the origin of the new coordinate system. For example, a trajectory defined in coordinate system A can be redefined in coordinate system B, whose origin is at (3, 3, 30 degrees) in coordinate system A, using the relativeTo method. JAVA Pose2d bOrigin = new Pose2d ( 3 , 3 , Rotation2d . fromDegrees ( 30 )); Trajectory bTrajectory = aTrajectory . relativeTo ( bOrigin ); C++ frc :: Pose2d bOrigin { 3 _m , 3 _m , frc :: Rotation2d ( 30 _deg )}; frc :: Trajectory bTrajectory = aTrajectory . RelativeTo ( bOrigin ); PYTHON from wpimath.geometry import Pose2d , Rotation2d bOrigin = Pose2d ( 3 , 3 , Rotation2d . fromDegrees ( 30 )) bTrajectory = aTrajectory . relativeTo ( bOrigin ) In the diagram above, the original trajectory ( aTrajectory in the code above) has been defined in coordinate system A, represented by the black axes. The red axes, located at (3, 3) and 30° with respect to the original coordinate system, represent coordinate system B. Calling relativeTo on aTrajectory will redefine all poses in the trajectory to be relative to coordinate system B (red axes). The transformBy Method The transformBy method can be used to move (i.e. translate and rotate) a trajectory within a coordinate system. This method takes one argument: a transform (via a Transform2d object) that maps the current initial position of the trajectory to a desired initial position of the same trajectory. For example, one may want to transform a trajectory that begins at (2, 2, 30 degrees) to make it begin at (4, 4, 50 degrees) using the transformBy method. JAVA Transform2d transform = new Pose2d ( 4 , 4 , Rotation2d . fromDegrees ( 50 )). minus ( trajectory . getInitialPose ()); Trajectory newTrajectory = trajectory . transformBy ( transform ); C++ frc :: Transform2d transform = Pose2d ( 4 _m , 4 _m , Rotation2d ( 50 _deg )) - trajectory . InitialPose (); frc :: Trajectory newTrajectory = trajectory . TransformBy ( transform ); PYTHON from wpimath.geometry import Pose2d , Rotation2d transform = Pose2d ( 4 , 4 , Rotation2d . fromDegrees ( 50 )) - trajectory . initialPose () newTrajectory = trajectory . transformBy ( transform ) In the diagram above, the original trajectory, which starts at (2, 2) and at 30° is visible in blue. After applying the transform above, the resultant trajectory’s starting location is changed to (4, 4) at 50°. The resultant trajectory is visible in orange.",
      "content_preview": "Transforming Trajectories Trajectories can be transformed from one coordinate system to another and moved within a coordinate system using the relativeTo and the transformBy methods."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-pose-estimators.html",
      "title": "Pose Estimators",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Pose Estimators WPILib includes pose estimators for differential, swerve, and mecanum drivetrains. These estimators are designed to be drop-in replacements for the existing odometry classes that also support fusing latency-compensated robot pose estimates with encoder and gyro measurements. These estimators can account for encoder drift and noisy vision data. These estimators can behave identically to their corresponding odometry classes if only update is called on these estimators. Pose estimators estimate robot position using a state-space system with the states \\(\\begin{bmatrix}x & y & \\theta \\end{bmatrix}^T\\) , which can represent robot position as a Pose2d . WPILib includes DifferentialDrivePoseEstimator , SwerveDrivePoseEstimator and MecanumDrivePoseEstimator to estimate robot position. In these, users call update periodically with encoder and gyro measurements (same as the odometry classes) to update the robot’s estimated position. When the robot receives measurements of its field-relative position (encoded as a Pose2d ) from sensors such as computer vision or V-SLAM, the pose estimator latency-compensates the measurement to accurately estimate robot position. Here’s how to initialize a DifferentialDrivePoseEstimator : JAVA 86 private final DifferentialDrivePoseEstimator m_poseEstimator = 87 new DifferentialDrivePoseEstimator ( 88 m_kinematics , 89 m_gyro . getRotation2d (), 90 m_leftEncoder . getDistance (), 91 m_rightEncoder . getDistance (), 92 new Pose2d (), 93 VecBuilder . fill ( 0.05 , 0.05 , Units . degreesToRadians ( 5 )), 94 VecBuilder . fill ( 0.5 , 0.5 , Units . degreesToRadians ( 30 ))); C++ 158 frc :: DifferentialDrivePoseEstimator m_poseEstimator { 159 m_kinematics , 160 m_gyro . GetRotation2d (), 161 units :: meter_t { m_leftEncoder . GetDistance ()}, 162 units :: meter_t { m_rightEncoder . GetDistance ()}, 163 frc :: Pose2d {}, 164 { 0.01 , 0.01 , 0.01 }, 165 { 0.1 , 0.1 , 0.1 }}; Add odometry measurements every loop by calling Update() . JAVA 227 m_poseEstimator . update ( 228 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); C++ 84 m_poseEstimator . Update ( m_gyro . GetRotation2d (), 85 units :: meter_t { m_leftEncoder . GetDistance ()}, 86 units :: meter_t { m_rightEncoder . GetDistance ()}); Add vision pose measurements occasionally by calling AddVisionMeasurement() . JAVA 236 // Compute the robot's field-relative position exclusively from vision measurements. 237 Pose3d visionMeasurement3d = 238 objectToRobotPose ( m_objectInField , m_robotToCamera , m_cameraToObjectEntry ); 239 240 // Convert robot pose from Pose3d to Pose2d needed to apply vision measurements. 241 Pose2d visionMeasurement2d = visionMeasurement3d . toPose2d (); 242 243 // Apply vision measurements. For simulation purposes only, we don't input a latency delay -- on 244 // a real robot, this must be calculated based either on known latency or timestamps. 245 m_poseEstimator . addVisionMeasurement ( visionMeasurement2d , Timer . getFPGATimestamp ()); C++ 93 // Compute the robot's field-relative position exclusively from vision 94 // measurements. 95 frc :: Pose3d visionMeasurement3d = ObjectToRobotPose ( 96 m_objectInField , m_robotToCamera , m_cameraToObjectEntryRef ); 97 98 // Convert robot's pose from Pose3d to Pose2d needed to apply vision 99 // measurements. 100 frc :: Pose2d visionMeasurement2d = visionMeasurement3d . ToPose2d (); 101 102 // Apply vision measurements. For simulation purposes only, we don't input a 103 // latency delay -- on a real robot, this must be calculated based either on 104 // known latency or timestamps. 105 m_poseEstimator . AddVisionMeasurement ( visionMeasurement2d , 106 frc :: Timer :: GetFPGATimestamp ()); Tuning Pose Estimators All pose estimators offer user-customizable standard deviations for model and measurements (defaults are used if you don’t provide them). Standard deviation is a measure of how spread out the noise is for a random signal. Giving a state a smaller standard deviation means it will be trusted more during data fusion. For example, increasing the standard deviation for measurements (as one might do for a noisy signal) would lead to the estimator trusting its state estimate more than the incoming measurements. On the field, this might mean that the filter can reject noisy vision data well, at the cost of being slow to correct for model deviations. While these values can be estimated beforehand, they very much depend on the unique setup of each robot and global measurement method. When incorporating AprilTag poses, make the vision heading standard deviation very large, make the gyro heading standard deviation small, and scale the vision x and y standard deviation by distance from the tag.",
      "content_preview": "Pose Estimators WPILib includes pose estimators for differential, swerve, and mecanum drivetrains. These estimators are designed to be drop-in replacements for the existing odometry classes that also support fusing latency-compensated robot pose estimates with encoder and gyro measurements."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/controllers/combining-feedforward-feedback.html",
      "title": "Combining Feedforward and PID Control",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Combining Feedforward and PID Control Note This article covers the in-code implementation of combined feedforward/PID control with WPILib’s provided library classes. Documentation describing the involved concepts in more detail is forthcoming. Feedforward and feedback controllers can each be used in isolation, but are most effective when combined together. Thankfully, combining these two control methods is exceedingly straightforward - one simply adds their outputs together. Using Feedforward with a PIDController Users may add any feedforward they like to the output of the controller before sending it to their motors: JAVA // Adds a feedforward to the loop output before sending it to the motor motor . setVoltage ( pid . calculate ( encoder . getDistance (), setpoint ) + feedforward ); C++ // Adds a feedforward to the loop output before sending it to the motor motor . SetVoltage ( pid . Calculate ( encoder . GetDistance (), setpoint ) + feedforward ); PYTHON # Adds a feedforward to the loop output before sending it to the motor motor . setVoltage ( pid . calculate ( encoder . getDistance (), setpoint ) + feedforward ) Moreover, feedforward is a separate feature entirely from feedback, and thus has no reason to be handled in the same controller object, as this violates separation of concerns. WPILib comes with several helper classes to compute accurate feedforward voltages for common FRC® mechanisms - for more information, see Feedforward Control in WPILib . Using Feedforward Components with PID Note Since feedforward voltages are physically meaningful, it is best to use the setVoltage() ( Java , C++ , Python ) method when applying them to motors to compensate for “voltage sag” from the battery. What might a more complete example of combined feedforward/PID control look like? Consider the drive example from the feedforward page. We can easily modify this to include feedback control (with a SimpleMotorFeedforward component): JAVA public void tankDriveWithFeedforwardPID ( double leftVelocitySetpoint , double rightVelocitySetpoint ) { leftMotor . setVoltage ( feedforward . calculate ( leftVelocitySetpoint ) + leftPID . calculate ( leftEncoder . getRate (), leftVelocitySetpoint )); rightMotor . setVoltage ( feedForward . calculate ( rightVelocitySetpoint ) + rightPID . calculate ( rightEncoder . getRate (), rightVelocitySetpoint )); } C++ void TankDriveWithFeedforwardPID ( units :: meters_per_second_t leftVelocitySetpoint , units :: meters_per_second_t rightVelocitySetpoint ) { leftMotor . SetVoltage ( feedforward . Calculate ( leftVelocitySetpoint ) + leftPID . Calculate ( leftEncoder . getRate (), leftVelocitySetpoint . value ())); rightMotor . SetVoltage ( feedforward . Calculate ( rightVelocitySetpoint ) + rightPID . Calculate ( rightEncoder . getRate (), rightVelocitySetpoint . value ())); } PYTHON def tank_drive_with_feedforward_PID ( left_velocity_setpoint : float , right_velocity_setpoint : float , ) -> None : leftMotor . setVoltage ( feedforward . calculate ( left_velocity_setpoint ) + leftPID . calculate ( leftEncoder . getRate (), left_velocity_setpoint ) ) rightMotor . setVoltage ( feedforward . calculate ( right_velocity_setpoint ) + rightPID . calculate ( rightEncoder . getRate (), right_velocity_setpoint ) ) Other mechanism types can be handled similarly.",
      "content_preview": "Combining Feedforward and PID Control Note This article covers the in-code implementation of combined feedforward/PID control with WPILib’s provided library classes. Documentation describing the involved concepts in more detail is forthcoming."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/trajectories/troubleshooting.html",
      "title": "Troubleshooting",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Troubleshooting Troubleshooting Complete Failures There are a number of things that can cause your robot to do completely the wrong thing. The below checklist covers some common mistakes. My robot doesn’t move. Are you actually outputting to your motors? Is a MalformedSplineException getting printed to the driver station? If yes, go to the MalformedSplineException section below. Is your trajectory very short or in the wrong units? My robot swings around to drive the trajectory facing the other direction. Are the start and end headings of your trajectory wrong? Is your robot’s gyro getting reset to the wrong heading? Do you have the reverse flag set incorrectly? Are your gyro angles clockwise positive? If so, you should negate them. My robot just drives in a straight line even though it should turn. Is your gyro set up correctly and returning good data? Are you passing your gyro heading to your odometry object with the correct units? Is your track width correct? Is it in the correct units? I get a MalformedSplineException printout on the driver station and the robot doesn’t move. Do you have the reverse flag set incorrectly? Do you have two waypoints very close together with approximately opposite headings? Do you have two waypoints with the same (or nearly the same) coordinates? My robot drives way too far. Are your encoder unit conversions set up correctly? Are your encoders connected? My robot mostly does the right thing, but it’s a little inaccurate. Go to the next section. Troubleshooting Poor Performance Note This section is mostly concerned with troubleshooting poor trajectory tracking performance like a meter of error, not catastrophic failures like compilation errors, robots turning around and going in the wrong direction, or MalformedSplineException s. Note This section is designed for differential drive robots, but most of the ideas can be adapted to swerve drive or mecanum. Poor trajectory tracking performance can be difficult to troubleshoot. Although the trajectory generator and follower are intended to be easy-to-use and performant out of the box, there are situations where your robot doesn’t quite end up where it should. The trajectory generator and followers have many knobs to tune and many moving parts, so it can be difficult to know where to start, especially because it is difficult to locate the source of trajectory problems from the robot’s general behavior. Because it can be so hard to locate the layer of the trajectory generator and followers that is misbehaving, a systematic, layer-by-layer approach is recommended for general poor tracking performance (e.g. the robot is off by few feet or more than twenty degrees). The below steps are listed in the order that you should do them in; it is important to follow this order so that you can isolate the effects of different steps from each other. Note The below examples put diagnostic values onto NetworkTables . The easiest way to graph these values is to use Shuffleboard’s graphing capabilities . Verify Odometry If your odometry is bad, then your Ramsete controller may misbehave, because it modifies your robot’s target velocities based on where your odometry thinks the robot is. Note Sending your robot pose and trajectory to field2d can help verify that your robot is driving correctly relative to the robot trajectory. Set up your code to record your robot’s position after each odometry update: JAVA NetworkTableEntry m_xEntry = NetworkTableInstance . getDefault (). getTable ( \"troubleshooting\" ). getEntry ( \"X\" ); NetworkTableEntry m_yEntry = NetworkTableInstance . getDefault (). getTable ( \"troubleshooting\" ). getEntry ( \"Y\" ); @Override public void periodic () { // Update the odometry in the periodic block m_odometry . update ( Rotation2d . fromDegrees ( getHeading ()), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); var translation = m_odometry . getPoseMeters (). getTranslation (); m_xEntry . setNumber ( translation . getX ()); m_yEntry . setNumber ( translation . getY ()); } C++ NetworkTableEntry m_xEntry = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"troubleshooting\" ) -> GetEntry ( \"X\" ); NetworkTableEntry m_yEntry = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"troubleshooting\" ) -> GetEntry ( \"Y\" ); void DriveSubsystem::Periodic () { // Implementation of subsystem periodic method goes here. m_odometry . Update ( frc :: Rotation2d ( units :: degree_t ( GetHeading ())), units :: meter_t ( m_leftEncoder . GetDistance ()), units :: meter_t ( m_rightEncoder . GetDistance ())); auto translation = m_odometry . GetPose (). Translation (); m_xEntry . SetDouble ( translation . X (). value ()); m_yEntry . SetDouble ( translation . Y (). value ()); } Lay out a tape measure parallel to your robot and push your robot out about one meter along the tape measure. Lay out a tape measure along the Y axis and start over, pushing your robot one meter along the X axis and one meter along the Y axis in a rough arc. Compare X and Y reported by the robot to actual X and Y. If X is off by more than 5 centimeters in the first test then you should check that you measured your wheel diameter correctly, and that your wheels are not worn down. If the second test is off by more than 5 centimeters in either X or Y then your track width (distance from the center of the left wheel to the center of the right wheel) may be incorrect; if you’re sure that you measured the track width correctly with a tape measure then your robot’s wheels may be slipping in a way that is not accounted for by track width, so try increasing the track width number or measuring it programmatically. Verify Feedforward If your feedforwards are bad then the P controllers for each side of the robot will not track as well, and your DifferentialDriveVoltageConstraint will not limit your robot’s acceleration accurately. We mostly want to turn off the wheel P controllers so that we can isolate and test the feedforwards. First, we must set disable the P controller for each wheel. Set the P gain to 0 for every controller. In the RamseteCommand example, you would set kPDriveVel to 0: JAVA 123 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), 124 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), C++ 79 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, 80 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, Next, we want to disable the Ramsete controller to make it easier to isolate our problematic behavior. To do so, simply call setEnabled(false) on the RamseteController passed into your RamseteCommand : JAVA RamseteController m_disabledRamsete = new RamseteController (); m_disabledRamsete . setEnabled ( false ); // Be sure to pass your new disabledRamsete variable RamseteCommand ramseteCommand = new RamseteCommand ( exampleTrajectory , m_robotDrive :: getPose , m_disabledRamsete , ... ); C++ frc :: RamseteController m_disabledRamsete ; m_disabledRamsete . SetEnabled ( false ); // Be sure to pass your new disabledRamsete variable frc2 :: RamseteCommand ramseteCommand ( exampleTrajectory , [ this ]() { return m_drive . GetPose (); }, m_disabledRamsete , ... ); Finally, we need to log desired wheel velocity and actual wheel velocity (you should put actual and desired velocities on the same graph if you’re using Shuffleboard, or if your graphing software has that capability): JAVA var table = NetworkTableInstance . getDefault (). getTable ( \"troubleshooting\" ); var leftReference = table . getEntry ( \"left_reference\" ); var leftMeasurement = table . getEntry ( \"left_measurement\" ); var rightReference = table . getEntry ( \"right_reference\" ); var rightMeasurement = table . getEntry ( \"right_measurement\" ); var leftController = new PIDController ( kPDriveVel , 0 , 0 ); var rightController = new PIDController ( kPDriveVel , 0 , 0 ); RamseteCommand ramseteCommand = new RamseteCommand ( exampleTrajectory , m_robotDrive :: getPose , disabledRamsete , // Pass in disabledRamsete here new SimpleMotorFeedforward ( ksVolts , kvVoltSecondsPerMeter , kaVoltSecondsSquaredPerMeter ), kDriveKinematics , m_robotDrive :: getWheelSpeeds , leftController , rightController , // RamseteCommand passes volts to the callback ( leftVolts , rightVolts ) -> { m_robotDrive . tankDriveVolts ( leftVolts , rightVolts ); leftMeasurement . setNumber ( m_robotDrive . getWheelSpeeds (). leftMetersPerSecond ); leftReference . setNumber ( leftController . getSetpoint ()); rightMeasurement . setNumber ( m_robotDrive . getWheelSpeeds (). rightMetersPerSecond ); rightReference . setNumber ( rightController . getSetpoint ()); }, m_robotDrive ); C++ auto table = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"troubleshooting\" ); auto leftRef = table -> GetEntry ( \"left_reference\" ); auto leftMeas = table -> GetEntry ( \"left_measurement\" ); auto rightRef = table -> GetEntry ( \"right_reference\" ); auto rightMeas = table -> GetEntry ( \"right_measurement\" ); frc :: PIDController leftController ( DriveConstants :: kPDriveVel , 0 , 0 ); frc :: PIDController rightController ( DriveConstants :: kPDriveVel , 0 , 0 ); frc2 :: RamseteCommand ramseteCommand ( exampleTrajectory , [ this ]() { return m_drive . GetPose (); }, frc :: RamseteController ( AutoConstants :: kRamseteB , AutoConstants :: kRamseteZeta ), frc :: SimpleMotorFeedforward < units :: meters > ( DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka ), DriveConstants :: kDriveKinematics , [ this ] { return m_drive . GetWheelSpeeds (); }, leftController , rightController , [ = ]( auto left , auto right ) { auto leftReference = leftRef ; auto leftMeasurement = leftMeas ; auto rightReference = rightRef ; auto rightMeasurement = rightMeas ; m_drive . TankDriveVolts ( left , right ); leftMeasurement . SetDouble ( m_drive . GetWheelSpeeds (). left . value ()); leftReference . SetDouble ( leftController . GetSetpoint ()); rightMeasurement . SetDouble ( m_drive . GetWheelSpeeds (). right . value ()); rightReference . SetDouble ( rightController . GetSetpoint ()); }, { & m_drive }); Run the robot on a variety of trajectories (curved and straight line), and check to see if the actual velocity tracks the desired velocity by looking at graphs from NetworkTables. If the desired and actual are off by a lot then you should check if the wheel diameter and encoderEPR you used for system identification were correct. If you’ve verified that your units and conversions are correct, then you should try recharacterizing on the same floor that you’re testing on to see if you can get better data. Verify P Gain If you completed the previous step and the problem went away then your problem can probably be found in one of the next steps. In this step we’re going to verify that your wheel P controllers are well-tuned. If you’re using Java then we want to turn off Ramsete so that we can just view our PF controllers on their own. You must reuse all the code from the previous step that logs actual vs. desired velocity (and the code that disables Ramsete, if you’re using Java), except that the P gain must be set back to its previous nonzero value. Run the robot again on a variety of trajectories, and check that your actual vs. desired graphs look good. If the graphs do not look good (i.e. the actual velocity is very different from the desired) then you should try tuning your P gain and rerunning your test trajectories. Check Constraints Note Make sure that your P gain is nonzero for this step and that you still have the logging code added in the previous steps. If you’re using Java then you should remove the code to disable Ramsete. If your accuracy issue persisted through all of the previous steps then you might have an issue with your constraints. Below are a list of symptoms that the different available constraints will exhibit when poorly tuned. Test one constraint at a time! Remove the other constraints, tune your one remaining constraint, and repeat that process for each constraint you want to use. The below checklist assumes that you only use one constraint at a time. DifferentialDriveVoltageConstraint : If your robot accelerates very slowly then it’s possible that the max voltage for this constraint is too low. If your robot doesn’t reach the end of the path then your system identification data may problematic. DifferentialDriveKinematicsConstraint : If your robot ends up at the wrong heading then it’s possible that the max drivetrain side speed is too low, or that it’s too high. The only way to tell is to tune the max speed and to see what happens. CentripetalAccelerationConstraint : If your robot ends up at the wrong heading then this could be the culprit. If your robot doesn’t seem to turn enough then you should increase the max centripetal acceleration, but if it seems to go around tight turns to quickly then you should decrease the maximum centripetal acceleration. Check Trajectory Waypoints It is possible that your trajectory itself is not very driveable. Try moving waypoints (and headings at the waypoints, if applicable) to reduce sharp turns.",
      "content_preview": "Troubleshooting Troubleshooting Complete Failures There are a number of things that can cause your robot to do completely the wrong thing. The below checklist covers some common mistakes. My robot doesn’t move."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/geometry/transformations.html",
      "title": "Transformations",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Transformations Translation2d Operations on a Translation2d perform operations to the vector represented by the Translation2d . Addition: Addition between two Translation2d a and b can be performed using plus in Java, or the + operator in C++/Python. Addition adds the two vectors. Subtraction: Subtraction between two Translation2d can be performed using minus in Java, or the binary - operator in C++/Python. Subtraction subtracts the two vectors. Multiplication: Multiplication of a Translation2d and a scalar can be performed using times in Java, or the * operator in C++/Python. This multiplies the vector by the scalar. Division: Division of a Translation2d and a scalar can be performed using div in Java, or the / operator in C++/Python. This divides the vector by the scalar. Rotation: Rotation of a Translation2d by a counter-clockwise rotation \\(\\theta\\) about the origin can be performed by using rotateBy . This is equivalent to multiplying the vector by the matrix \\(\\begin{bmatrix} cos\\theta & -sin\\theta \\\\ sin\\theta & cos\\theta \\end{bmatrix}\\) Additionally, you can rotate a Translation2d by 180 degrees by using unaryMinus in Java, or the unary - operator in C++/Python. Rotation2d Transformations for Rotation2d are just arithmetic operations on the angle measure represented by the Rotation2d . plus (Java) or + (C++/Python): Adds the rotation component of other to this Rotation2d ’s rotation component minus (Java) or binary - (C++/Python): Subtracts the rotation component of other to this Rotation2d ’s rotation component unaryMinus (Java) or unary - (C++/Python): Multiplies the rotation component by a scalar of -1. times (Java) or * (C++/Python) : Multiplies the rotation component by a scalar. Transform2d and Twist2d WPILib provides 2 classes, Transform2d ( Java , C++ , Python ), which represents a transformation to a pose, and Twist2d ( Java , C++ , Python ) which represents a movement along an arc. Transform2d and Twist2d all have x, y and \\(\\theta\\) components. Transform2d represents a relative transformation. It has an translation and a rotation component. Transforming a Pose2d by a Transform2d rotates the translation component of the transform by the rotation of the pose, and then adds the rotated translation component and the rotation component to the pose. In other words, Pose2d.plus(Transform2d) returns \\(\\begin{bmatrix} x_p \\\\ y_p \\\\ \\theta_p \\end{bmatrix}+\\begin{bmatrix} cos\\theta_p & -sin\\theta_p & 0 \\\\ sin\\theta_p & cos\\theta_p & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\begin{bmatrix}x_t \\\\ y_t \\\\ \\theta_t \\end{bmatrix}\\) Twist2d represents a change in distance along an arc. Usually, this class is used to represent the movement of a drivetrain, where the x component is the forward distance driven, the y component is the distance driven to the side (left positive), and the \\(\\theta\\) component is the change in heading. The underlying math behind finding the pose exponential (new pose after moving the pose forward along the curvature of the twist) can be found here in chapter 10. Note For nonholonomic drivetrains, the y component of a Twist2d should always be 0. Both classes can be used to estimate robot location. Twist2d is used in WPILib’s odometry classes to update the robot’s pose based on movement, while Transform2d can be used to estimate the robot’s global position from vision data.",
      "content_preview": "Transformations Translation2d Operations on a Translation2d perform operations to the vector represented by the Translation2d . Addition: Addition between two Translation2d a and b can be performed using plus in Java, or the + operator in C++/Python. Addition adds the two vectors."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/state-space/state-space-debugging.html",
      "title": "Debugging State",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Debugging State-Space Models and Controllers Checking Signs One of the most common causes of bugs with state-space controllers is signs being flipped. For example, models included in WPILib expect positive voltage to result in a positive acceleration, and vice versa. If applying a positive voltage does not make the mechanism accelerate forwards, or if moving “forwards” makes encoder (or other sensor readings) decrease, they should be inverted so that positive voltage input results in a positive encoder reading. For example, if I apply an input of \\([12, 12]^T\\) (full forwards for the left and right motors) to my differential drivetrain, my wheels should propel my robot “forwards” (along the +X axis locally), and for my encoders to read a positive velocity. Important The WPILib DifferentialDrive , by default, does not invert any motors. You may need to call the setInverted(true) method on the motor controller object to invert so that positive input creates forward motion. The Importance of Graphs Reliable data of the system’s state s, input s and output s over time is important when debugging state-space controllers and observers. One common approach is to send this data over NetworkTables and use tools such as Shuffleboard , which allow us to both graph the data in real-time as well as save it to a CSV file for plotting later with tools such as Google Sheets, Excel, or Python. Note By default, NetworkTables is limited to a 10hz update rate. For testing, this can be bypassed with the following code snippet to submit data at up to 100hz. This code should be run periodically to forcibly publish new data. Danger This will send extra data (at up to 100hz) over NetworkTables, which can cause lag with both user code and robot dashboards. This will also increase network utilization. It is often a good idea to disable this during competitions. JAVA @Override public void robotPeriodic () { NetworkTableInstance . getDefault (). flush (); } C++ void RobotPeriodic () { NetworkTableInstance :: GetDefault (). Flush (); } PYTHON from ntcore import NetworkTableInstance def robotPeriodic ( self ): NetworkTableInstance . getDefault () . flush () Compensating for Input Lag Often times, some sensor input data (i.e. velocity readings) may be delayed due to onboard filtering that smart motor controllers tend to perform. By default, LQR’s K gain assumes no input delay, so introducing significant delay on the order of tens of milliseconds can cause instability. To combat this, the LQR’s K gain can be reduced, trading off performance for stability. A code example for how to compensate for this latency in a mathematically rigorous manner is available here .",
      "content_preview": "Debugging State-Space Models and Controllers Checking Signs One of the most common causes of bugs with state-space controllers is signs being flipped. For example, models included in WPILib expect positive voltage to result in a positive acceleration, and vice versa."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/control-system-basics.html",
      "title": "Control System Basics",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Control System Basics Note This article includes sections of Controls Engineering in FRC by Tyler Veness with permission. The Need for Control Systems Control systems are all around us and we interact with them daily. A small list of ones you may have seen includes heaters and air conditioners with thermostats, cruise control, and the anti-lock braking system (ABS) on automobiles, and fan speed modulation on modern laptops. Control systems monitor or control the behavior of systems like these and may consist of humans controlling them directly (manual control), or of only machines (automatic control). All of these examples have a mechanism which does useful work, but cannot be directly commanded to the state that is desired. For example, an air conditioner’s fans and compressor have no mechanical or electrical input where the user specifies a temperature. Rather, some additional mechanism must compare the current air temperature to some setpoint, and choose how to cycle the compressor and fans on and off to achieve that temperature. Similarly, an automobile’s engine and transmission have no mechanical lever which directly sets a particular speed. Rather, some additional mechanism must measure the current speed of the vehicle, and adjust the transmission gear and fuel injected into the cylinders to achieve the desired vehicle speed. Controls Engineering is the study of how to design those additional mechanisms to bridge the gap from what the user wants a mechanism to do, to how the mechanism is actually manipulated. How can we prove closed-loop controllers on an autonomous car, for example, will behave safely and meet the desired performance specifications in the presence of uncertainty? Control theory is an application of algebra and geometry used to analyze and predict the behavior of systems, make them respond how we want them to, and make them robust to disturbances and uncertainty. Controls engineering is, put simply, the engineering process applied to control theory. As such, it’s more than just applied math. While control theory has some beautiful math behind it, controls engineering is an engineering discipline like any other that is filled with trade-offs. The solutions control theory gives should always be sanity checked and informed by our performance specifications. We don’t need to be perfect; we just need to be good enough to meet our specifications. Nomenclature Most resources for advanced engineering topics assume a level of knowledge well above that which is necessary. Part of the problem is the use of jargon. While it efficiently communicates ideas to those within the field, new people who aren’t familiar with it are lost. The system or collection of actuators being controlled by a control system is called the plant . A controller is used to drive the plant from its current state to some desired state (the reference). Controllers which don’t include information measured from the plant’s output are called open-loop controllers. Controllers which incorporate information fed back from the plant’s output are called closed-loop controllers or feedback controllers. Note The input and output of a system are defined from the plant’s point of view. The negative feedback controller shown is driving the difference between the reference and output, also known as the error, to zero. What is Gain? Gain is a proportional value that shows the relationship between the magnitude of an input signal to the magnitude of an output signal at steady-state. Many systems contain a method by which the gain can be altered, providing more or less “power” to the system. The figure below shows a system with a hypothetical input and output. Since the output is twice the amplitude of the input, the system has a gain of two. What is a Model? A model of your mechanism is a mathematical description of its behavior. Specifically, this mathematical description must define the mechanism’s inputs and outputs, and how the output values change over time as a function of its input values. The mathematical description is often just simple algebra equations. It can also include some linear algebra, matrices, and differential equations. WPILib provides a number of classes to help simplify the more complex math. Classical Mechanics defines many of the equations used to build up models of system behavior. Many of the values inside those equations can be determined by doing experiments on the mechanism. Block Diagrams When designing or analyzing a control system, it is useful to model it graphically. Block diagrams are used for this purpose. They can be manipulated and simplified systematically. The open-loop gain is the total gain from the sum node at the input (the circle) to the output branch. this would be the system’s gain if the feedback loop was disconnected. The feedback gain is the total gain from the output back to the input sum node. A sum node’s output is the sum of its inputs. The below figure is a block diagram with more formal notation in a feedback configuration. \\(\\mp\\) means “minus or plus” where a minus represents negative feedback. A Note on Dimensionality For the purposes of the introductory section, all systems and controllers (except feedforward controllers) are assumed to be “single-in, single-out” (SISO) - this means they only map single values to single values. For example, a DC motor is considered to take an input of a single scalar value (voltage) and yield an output of only a single scalar value in return (either position or velocity). This forces us to consider position controllers and velocity controllers as separate entities - this is sometimes source of confusion in situations when we want to control both (such as when following a motion profiles). Limiting ourselves to SISO systems also means that we are unable to analyze more-complex “multiple-in, multiple-out” (MIMO) systems like drivetrains that cannot be represented with a single state (there are at least two independent sets of wheels in a drive). Nonetheless, we restrict ourselves to SISO systems here to be able to present the following tutorials in terms of the PID Controller formalism, which is commonly featured in introductory course material and has extensive documentation and many available implementations. The state-space formalism is an alternate way to conceptualize these systems which allows us to easily capture interactions between different quantities (as well as simultaneously represent multiple aspects of the same quantity, such as position and velocity of a motor). It does this, roughly, by replacing the single-dimensional scalars (e.g. the gain , input , and output ) with multi-dimensional vectors. In the state-space formalism, the equivalent of a “PID” controller is a vector-proportional controller on a single vector-valued mechanism state, with a single gain vector (instead of three different gain scalars). If you remember that a state-space controller is really just a PID controller written with dense notation, many of the principles covered in this set of introductory articles will transfer seamlessly to the case of state-space control.",
      "content_preview": "Control System Basics Note This article includes sections of Controls Engineering in FRC by Tyler Veness with permission. The Need for Control Systems Control systems are all around us and we interact with them daily."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/picking-control-strategy.html",
      "title": "Picking a Control Strategy",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Picking a Control Strategy Note This article includes sections of Controls Engineering in FRC by Tyler Veness with permission. When designing a control algorithm for a robot mechanism, there are a number of different approaches to take. These range from very simple approaches, to advanced and complex ones. Each has tradeoffs . Some will work better than others in different situations, some require more mathematical analysis than others. Teams should prioritize picking the easiest strategy which enables success on the field. However, as you do experiments, keep in mind there is almost always a “next-step” to take to improve your field performance. There are two fundamental types of mechanism controller that we will cover here: Note These are not strict definitions - some control strategies are not easily classifiable and incorporate elements of both feedforward and feedback controllers. However, it is still a useful distinction in most FRC applications. Feedforward control (or “open-loop control”) refers to the class of algorithms which incorporate knowledge of how the mechanism under control is expected to operate. Using this “model” of operation, the control input is chosen to make the mechanism get close to where it should be. Feedback control (or “closed-loop control”) refers to the class of algorithms which use sensors to measure what a mechanism is doing, and issue corrective commands to move a mechanism from where it actually is, to where you want it to be. These are not mutually exclusive, and in fact it is usually best to use both. The tutorial pages that follow will cover three types of mechanism (turret, flywheel, and vertical arm), and allow you to experiment with how each type of system responds to each type of control strategy, both individually and combined. Feedforward Control: Making a Best Guess “Feedforward control” means providing the mechanism with the control signal you think it needs to make the mechanism do what you want, without any knowledge of where the mechanism currently is. A feedforward controller feeds information we already know about the system forward into an estimate of the required control effort . The feedforward controller does not adjust this in response to the measured behavior of the system to try to correct for errors from the guess. Feedforward control is also sometimes referred to as “open-loop control”, because if you draw out a block diagram of the controlled system it consists of only a line from the controller to the plant, with no connection from the measured plant output back into the controller (hence an “open” loop, which really isn’t a loop at all). This is the type of control you are implicitly using whenever you use a joystick to “directly” control the speed of a motor through the applied voltage. It is the simplest and most straightforward type of control, and is probably the one you encountered first when programming a FRC motor, though it may not have been referred to by name. When Do We Need Feedforward Control? In general, feedforward control is required whenever the system requires some constant control signal to remain at the desired setpoint (such as position control of a vertical arm where gravity will cause the arm to fall, or velocity control where internal motor dynamics and friction will cause the motor to slow down over time). Feedback controllers naturally fall to zero output when they achieve their setpoint, and so a feedforward controller is needed to provide the signal to keep the mechanism where we want it. Some control strategies instead account for this in the feedback controller with integral gain - however, this is slow and prone to oscillation. It is almost always better to use a feedforward controller to account for the output needed to maintain the setpoint. Feedforward and Position Control The WPILib feedforward classes require velocity and acceleration setpoints to generate an estimated control voltage. This is because the equations-of-motion of a permanent-magnet DC motor relate the applied voltage to velocity and acceleration; it is a fact of physics that we cannot change. But what if we want to control position? When controlling a DC motor, there’s no immediate relation between position and control signal. In order to use feedforward effectively for position control, we need to come up with a sequence of velocities that will take the robot mechanism to the desired position. This is called a motion profile . Many teams do not wish to incur the extra technical cost of using a motion profile when doing position control, and instead omit the feedforward controller entirely and opt to use only feedback control. As we will discuss later, this may work in some situations, but has some important caveats. Most FRC mechanisms are well-described by WPILib’s feedforward classes, though pure feedforward control typically only yields acceptable results for velocity control of mechanisms with little external load. In other cases, errors from the system model will be unavoidable and a feedback controller will be necessary to correct for them. Feedback Control: Correcting for Errors and Disturbances Even with unlimited study, it is impossible to know every force that will be exerted on a robot’s mechanism in perfect detail. For example, in a flywheel shooter, the timing and exact forces associated with a ball being put through the mechanism are extremely difficult to measure accurately. For another example, consider the fact that gearboxes gradually throw off grease as they operate, increasing their internal friction over time. This is a very complex process to model well. In practice, this means that the “guess” made by our feedforward controller will never be perfect. There will always be some error - that is, some lingering difference between the state we want our mechanism to be in, and the state the feedforward controller leaves it in. In many situations, this error is large enough that we need to adjust our output to correct it; this is the job of the feedback controller. Feedback controllers are also called “closed-loop” controllers, because the flow of information about the current state back through the system “closes” the loop in the system’s block diagram. The simplest feedback controller possible is a “proportional controller”, which responds proportionally to the current error (i.e. difference between the desired state and measured state). More advanced controllers (such as the PID controller) add response to the rate-of-change of the error and to the total accumulated error. All of these operate on the principle that the system response is roughly linear, in order to “nudge” the system towards the setpoint based on local measurements of the error. When Do We Need Feedback Control? In general, there are two scenarios in which we need feedback control: We are controlling the position of the system, so errors accumulate over time There are a lot of difficult-to-dynamic external forces interacting with the mechanism that the feedforward loop cannot account for (e.g. a flywheel that is launching game pieces). In each of these situations, the best solution is to combine a feedforward controller and a feedback controller by adding their outputs together. However, in the case of a simple position controller with no external loading, a pure feedback controller can work acceptably. Feedback-Only Control Feedforward controllers are extremely helpful and quite simple, but they require explicit knowledge of the system behavior in order to generate a guess at the required control signal. In many controls textbooks, you may see a set of techniques which rely on feedback control only. These are very common in industry, and works well in many cases, especially when the underlying system behavior is not easy to explicitly model, or when you want to quickly reach a “good enough” solution without spending the time to thoroughly investigate your system behavior. Feedback-only control typically only works well in situations where: The motors are fairly overpowered relative to loading. The mechanism’s position (not velocity) is being controlled. There are no substantial or varying external forces on the mechanism. When these criteria are met (such as in the turret tuning tutorial), feedback-only control can yield acceptable results. In other situations, it is necessary to use a feedforward model to reduce the amount of work done by the feedback controller. In FRC, our systems are almost all modeled by well-understood equations with working code support, so it is almost always a good idea to include a feedforward controller. Modeling: How do you expect your system to behave? It’s easiest to control a system if we have some prior knowledge of how the system responds to inputs. Even the “pure feedback” strategy described above implicitly assumes things about the system response (e.g. that it is approximately linear), and consequently won’t work in cases where the system does not respond in the expected way. To control our system optimally , we need some way to reliably predict how it will respond to inputs. This can be done by combining several concepts you may be familiar with from physics: drawing free body diagrams of the forces that act on the mechanism, taking measurements of mass and moment of inertia from your CAD models, applying standard equations of how DC motors or pneumatic cylinders convert energy into mechanical force and motion, etc. The act of creating a consistent mathematical description of your system is called modeling your system’s behavior. The resulting set of equations are called a model of how you expect the system to behave. Not every system requires an explicit model to be controlled (we will see in the turret tutorial that a pure, manually-tuned feedback controller is satisfactory in some cases ), but an explicit model is always helpful. Note that models do not have to be perfectly accurate to be useful. As we will see in later tuning exercises, even using a simple model of a mechanism can make the tuning effort much simpler. Obtaining Models for Your Mechanisms If modeling your mechanism seems daunting, don’t worry! Most mechanisms in FRC are modeled by well-studied equations and code for interacting with those models is included in WPILib. Usually, all that is needed is to determine a set of physical parameters (sometimes called “tuning constants” or “gains”) that depend on the specific details of your mechanism/robot. These can be estimated theoretically from other known parameters of your system (such as mass, length, and choice of motor/gearbox), or measured from your mechanism’s actual behavior through a system identification routine. When in doubt, ask a mentor or support resource ! Theoretical Modeling ReCalc is an online calculator which estimates physical parameters for a number of common FRC mechanisms. Importantly, it can generate estimate the kV , kA , and kG gains for the WPILib feedforward classes. The WPILib system identification tool supports a “theoretical mode” that can be used to determine PID gains for feedback control from the kV and kA gains from ReCalc, enabling (in theory) full tuning of a control loop without running any test routines. Remember, however, that theory is not reality and purely theoretical gains are not guaranteed to work well. There is never a substitute for testing. System Identification A good way to improve the accuracy of a simple physics model is to perform experiments on the real mechanism, record data, and use the data to derive the constants associated with different parts of the model. This is very useful for physical quantities which are difficult or impossible to predict, but easy to measure (ex: friction in a gearbox). WPILib’s system identification tool supports some common FRC mechanisms, including drivetrain. It deploys its own code to the robot to exercise the mechanism, record data, and derive gains for both feedforward and feedback control schemes. Manual Tuning: What to Do with No Explicit Model Sometimes, you have to tune a system without at an explicit model. Maybe the system is uniquely complicated, or maybe you’re under time constraints and need something that works quickly, even if it doesn’t work optimally. Model-based control requires a correct mathematical model of the system, and for better or for worse, we do not always have one. In such cases, the physical parameters of the control algorithm can be tuned manually . This is generally done by systematically “sweeping” the controller gains by hand until the mechanism behaves as expected. Manual tuning can work quickly in cases where only one or two parameters (such as kV and kP ) need to be adjusted - however, in more-complicated scenarios it can become a very involved and difficult process. One common problem with manual tuning is that it can be hard to distinguish a well-founded controller architecture that is not yet tuned properly, from an inappropriate controller architecture that cannot work (for example, it is generally not possible to tune a velocity controller or vertical arm position controller that functions well without a feedforward). In such a case, we can waste a lot of time searching for correct gains, when no such correct gains exist. There is no substitute for understanding the mechanics of the systems being controlled well enough to determine a correct controller architecture for the mechanism, even if we do not explicitly use any model-based control methodologies. The tutorials that follow include simulations that will allow you to perform the manual tuning process on several typical FRC mechanisms. The fundamental concepts that govern which control strategies are valid for each mechanism are covered on the individual mechanism pages; pay close attention to this as you work through the tutorials!",
      "content_preview": "Picking a Control Strategy Note This article includes sections of Controls Engineering in FRC by Tyler Veness with permission. When designing a control algorithm for a robot mechanism, there are a number of different approaches to take."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/introduction.html",
      "title": "Introduction to Filters",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Introduction to Filters Filters are some of the most common tools used in modern technology, and find numerous applications in robotics in both signal processing and controls. Understanding the notion of a filter is crucial to understanding the utility of the various types of filters provided by WPILib. What Is a Filter? Note For the sake of this article, we will assume all data are single-dimensional time-series data. Obviously, the concepts involved are more general than this - but a full/rigorous discussion of signals and filtering is out of the scope of this documentation. So, what exactly is a filter, then? Simply put, a filter is a mapping from a stream of inputs to a stream of outputs. That is to say, the value output by a filter (in principle) can depend not only on the current value of the input, but on the entire set of past and future values (of course, in practice, the filters provided by WPILib are implementable in real-time on streaming data; accordingly, they can only depend on the past values of the input, and not on future values). This is an important concept, because generally we use filters to remove/mitigate unwanted dynamics from a signal. When we filter a signal, we’re interested in modifying how the signal changes over time . Effects of Using a Filter Noise Reduction One of the most typical uses of a filter is for noise reduction. A filter that reduces noise is called a low-pass filter (because it allows low frequencies to “pass through,” while blocking high-frequencies). Most of the filters currently included in WPILib are effectively low-pass filters. Rate Limiting Filters are also commonly used to reduce the rate at which a signal can change. This is closely related to noise reduction, and filters that reduce noise also tend to limit the rate of change of their output. Edge Detection The counterpart to the low-pass filter is the high-pass filter, which only permits high frequencies to pass through to the output. High-pass filters can be somewhat tricky to build intuition for, but a common usage for a high-pass filter is edge-detection - since high-pass filters will reflect sudden changes in the input while ignoring slower changes, they are useful for determining the location of sharp discontinuities in the signal. Phase Lag An unavoidable negative effect of a real-time low-pass filter is the introduction of “phase lag.” Since, as mentioned earlier, a real-time filter can only depend on past values of the signal (we cannot time-travel to obtain the future values), the filtered value takes some time to “catch up” when the input starts changing. The greater the noise-reduction, the greater the introduced delay. This is, in many ways, the fundamental trade-off of real-time filtering, and should be the primary driving factor of your filter design. Interestingly, high-pass filters introduce a phase lead , as opposed to a phase lag, as they exacerbate local changes to the value of the input.",
      "content_preview": "Introduction to Filters Filters are some of the most common tools used in modern technology, and find numerous applications in robotics in both signal processing and controls."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/index.html",
      "title": "Filters",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Filters Note The data used to generate the various demonstration plots in this section can be found here . This section describes a number of filters included with WPILib that are useful for noise reduction and/or input smoothing. Introduction to Filters Linear Filters Median Filter Slew Rate Limiter Debouncer",
      "content_preview": "Filters Note The data used to generate the various demonstration plots in this section can be found here . This section describes a number of filters included with WPILib that are useful for noise reduction and/or input smoothing."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/introduction/tuning-turret.html",
      "title": "Tuning a Turret Position Controller",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Tuning a Turret Position Controller In this section, we will tune a simple position controller for a turret. The tuning principles explained here will also work for almost any position-control scenarios under no external loading. Turret Model Description A turret rotates some mechanism side-to-side to position it for scoring gamepieces. Our “turret” consists of: A rotating inertial mass (the turret) A motor and gearbox driving the mass For the purposes of this tutorial, this plant is modeled with the same equation used by WPILib’s SimpleMotorFeedforward , with additional adjustment for sensor delay and gearbox inefficiency. The simulation assumes the plant is controlled by feedforward and feedback controllers, composed in this fashion: Where: The plant’s output \\(y(t)\\) is the turret’s position The controller’s setpoint \\(r(t)\\) is the desired position of the turret The controller’s control effort , \\(u(t)\\) is the voltage applied to the motor driving the turret Picking the Control Strategy for a Turret Position Controller In general: the more voltage that is applied to the motor, the faster the motor (and turret) will spin. Once voltage is removed, friction and back-EMF slowly decrease the spinning until the turret stops. We want to make the turret rotate to a given position. The tutorials below will demonstrate the behavior of the system under pure feedforward, pure feedback (PID), and combined feedforward-feedback control strategies. Follow the instructions to learn how to manually tune these controllers, and expand the “tuning solution” to view an optimal model-based set of tuning parameters. Even though WPILib tooling can provide you with optimal gains, it is worth going through the manual tuning process to see how the different control strategies interact with the mechanism. This simulation does not include any motion profile generation, so acceleration setpoints are not very well-defined. Accordingly, the kA term of the feedforward equation is not used by the controller. This means there will be some amount of delay/lag inherent to the feedforward-only response. Pure Feedforward Control Interact with the simulation below to examine how the turret system responds when controlled only by a feedforward controller. Note To change the turret setpoint, click on the desired angle along the perimeter of the turret. To command smooth motion, click and drag the setpoint indicator. To tune the feedforward controller, perform the following: Set \\(K_v\\) to zero. Increase the velocity feedforward gain \\(K_v\\) until the turret tracks the setpoint during smooth, slow motion. If the turret overshoots, reduce the gain. Note that the turret may “lag” the commanded motion - this is normal, and is fine so long as it moves the correct amount in total. Note Feedforward-only control is not a viable control scheme for turrets! Do not be surprised if/when the simulation below does not behave well, even when the “correct” constants are used. Tuning solution The exact gain used by the plant is \\(K_v = 0.2\\) . Note that due to timing inaccuracy in browser simulations, the \\(K_v\\) that works best in the simulation may be somewhat smaller than this. Issues with Feed-Forward Control Alone As mentioned above, our simulated mechanism perfectly obeys the WPILib SimpleMotorFeedforward equation (as long as the “system noise” option is disabled). We might then expect, like in the case of the flywheel velocity controller , that we should be able to achieve perfect convergence-to-setpoint with a feedforward loop alone. However, our feedforward equation relates velocity and acceleration to voltage - it allows us to control the instantaneous motion of our mechanism with high accuracy, but it does not allow us direct control over the position . This is a problem even in our simulation (in which the feedforward equation is the actual equation of motion), because unless we employ a motion profile to generate a sequence of velocity setpoints we can ask the turret to jump immediately from one position to another. This is impossible, even for our simulated turret. The resulting behavior from the feedforward controller is to output a single “voltage spike” when the position setpoint changes (corresponding to a single loop iteration of very high velocity), and then zero voltage (because it is assumed that the system has already reached the setpoint). In practice, we can see in the simulation that this results in an initial “impulse” movement towards the target position, that stops at some indeterminate position in-between. This kind of response is called a “kick,” and is generally seen as undesirable. You may notice that smooth motion below the turret’s maximum achievable speed can be followed accurately in the simulation with feedforward alone. This is misleading, however, because no real mechanism perfectly obeys its feedforward equation. With the “system noise” option enabled, we can see that even smooth, slow motion eventually results in compounding position errors when only feedforward control is used. To accurately converge to the setpoint, we need to use a feedback (PID) controller. Pure Feedback Control Interact with the simulation below to examine how the turret system responds when controlled only by a feedback (PID) controller. Perform the following: Set \\(K_p\\) , \\(K_i\\) , \\(K_d\\) , and \\(K_v\\) to zero. Increase \\(K_p\\) until the mechanism responds to a sudden change in setpoint by moving sharply to the new position. If the controller oscillates too much around the setpoint, reduce K_p until it stops. Increase \\(K_d\\) to reduce the amount of “lag” when the controller tries to track a smoothly moving setpoint (reminder: click and drag the turret’s directional indicator to move it smoothly). If the controller starts to oscillate, reduce K_d until it stops. Tuning solution Gains of \\(K_p = 0.3\\) and \\(K_d = 0.05\\) yield rapid and stable convergence to the setpoint. Other, similar gains will work nearly as well. Issues with Feedback Control Alone Note that even with system noise enabled, the feedback controller is able to drive the turret to the setpoint in a stable manner over time. However, it may not be possible to smoothly track a moving setpoint without lag using feedback alone, as the feedback controller can only respond to errors once they have built up. To get the best of both worlds, we need to combine our feedback controller with a feedforward controller. Combined Feedforward and Feedback Control Interact with the simulation below to examine how the turret system responds under simultaneous feedforward and feedback control. Tuning the combined turret controller is simple - we first tune the feedforward controller following the same procedure as in the feedforward-only section, and then we tune the PID controller following the same procedure as in the feedback-only section. Notice that PID portion of the controller is much easier to tune “on top of” an accurate feedforward. Tuning solution The optimal gains for the combined controller are just the optimal gains for the individual controllers: gains of \\(K_v = 0.15\\) , \\(K_p = 0.3\\) , and \\(K_d = 0.05\\) yield rapid and stable convergence to the setpoint and relatively accurate tracking of smooth motion. Other, similar gains will work nearly as well. Once tuned properly, the combined controller should accurately track a smoothly moving setpoint, and also accurately converge to the setpoint over time after a “jump” command. Tuning Conclusions Choice of Control Strategies Like in the case of the vertical arm , and unlike the case of the flywheel , we are trying to control the position rather than the velocity of our mechanism. In the case of the flywheel velocity controller we could achieve good control performance with feedforward alone. However, it is very hard to predict how much voltage will cause a certain total change in position (time can turn even small errors in velocity into very big errors in position). In this case, we cannot rely on feedforward control alone - as with the vertical arm, we will need a feedback controller. Unlike in the case of the vertical arm, though, there is no voltage required to keep the mechanism at the setpoint once it’s there. As a consequence, it is often possible to effectively control a turret without any feedforward controller at all, relying only on the output of the feedback controller (if the mechanism has a lot of friction, this may not work well and both a feedforward and feedback controller may be needed). Simple position control in the absence of external forces is one of the only cases in which pure feedback control works well. Controlling a mechanism with only feedback can produce reasonable results in cases where no control effort is required to keep the output at the setpoint . On a turret, this can work acceptably - however, it may still run into problems when trying to follow a moving setpoint, as it relies entirely on the controller transients to control the mechanism’s intermediate motion between position setpoints. We saw in the feedforward-only example above that an accurate feedforward can track slow, smooth velocity setpoints quite well. Combining a feedforward controller with the feedback controller gives the smooth velocity-following of a feedforward controller with the stable long-term error elimination of a feedback controller. Reasons for Non-Ideal Performance This simulation does not include any motion profile generation, so acceleration setpoints are not very well-defined. Accordingly, the kA term of the feedforward equation is not used by the controller. This means there will be some amount of delay/lag inherent to the feedforward-only response. A Note on Feedforward and Static Friction For the sake of simplicity, the simulations above omit the \\(K_s\\) term from the WPILib SimpleMotorFeedforward equation. On actual mechanisms, however, this can be important - especially if there’s a lot of friction in the mechanism gearing. A turret with a lot of static friction will be very hard to control accurately with feedback alone - it will get “stuck” near (but not at) the setpoint when the loop output falls below \\(K_s\\) . To measure \\(K_s\\) manually, slowly increase the voltage to the mechanism until it starts to move. The value of \\(K_s\\) is the largest voltage applied before the mechanism begins to move. It can be mildly difficult to apply the measured \\(K_s\\) to a position controller without motion profiling, as the WPILib SimpleMotorFeedforward class uses the velocity setpoint to determine the direction in which the \\(K_s\\) term should point. To overcome this, either use a motion profile, or else add \\(K_s\\) manually to the output of the controller depending on which direction the mechanism needs to move to get to the setpoint.",
      "content_preview": "Tuning a Turret Position Controller In this section, we will tune a simple position controller for a turret. The tuning principles explained here will also work for almost any position-control scenarios under no external loading."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/geometry/pose.html",
      "title": "Translation, Rotation, and Pose",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Translation, Rotation, and Pose Translation Translation in 2 dimensions is represented by WPILib’s Translation2d class ( Java , C++ , Python ). This class has an x and y component, representing the point \\((x, y)\\) or the vector \\(\\begin{bmatrix}x \\\\ y \\end{bmatrix}\\) on a 2-dimensional coordinate system. You can get the distance to another Translation2d object by using the getDistance(Translation2d other) , which returns the distance to another Translation2d by using the Pythagorean theorem. Note Translation2d uses the C++ Units library. If you’re planning on using other WPILib classes that use Translation2d in Java/Python, such as the trajectory generator, make sure to use meters. Rotation Rotation in 2 dimensions is represented by WPILib’s Rotation2d class ( Java , C++ , Python ). This class has an angle component, which represents the robot’s rotation relative to an axis on a 2-dimensional coordinate system. Positive rotations are counterclockwise. Note Rotation2d uses the C++ Units library. The constructor in Java/Python accepts either the angle in radians, or the sine and cosine of the angle, but the fromDegrees method will construct a Rotation2d object from degrees. Note Rotation2d does not wrap the value of the angle, so if a value of 400 degrees is passed into the constructor, then 400 degrees will be returned in subsequent value calls. Pose Pose is a combination of both translation and rotation and is represented by the Pose2d class ( Java , C++ , Python ). It can be used to describe the pose of your robot in the field coordinate system, or the pose of objects, such as vision targets, relative to your robot in the robot coordinate system. Pose2d can also represent the vector \\(\\begin{bmatrix}x \\\\ y \\\\ \\theta\\end{bmatrix}\\) .",
      "content_preview": "Translation, Rotation, and Pose Translation Translation in 2 dimensions is represented by WPILib’s Translation2d class ( Java , C++ , Python ). This class has an x and y component, representing the point \\((x, y)\\) or the vector \\(\\begin{bmatrix}x \\\\ y \\end{bmatrix}\\) on a 2-dimensional coordinate..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/video-walkthrough.html",
      "title": "A Video Walkthrough of Model Based Validation of Autonomous in FRC",
      "section": "Advanced Controls",
      "language": "All",
      "content": "A Video Walkthrough of Model Based Validation of Autonomous in FRC At the “RSN Spring Conference, Presented by WPI” in 2020, Tyler Veness from the WPILib team gave a presentation on Model Based Validation of Autonomous in FRC®. The link to the presentation is available here .",
      "content_preview": "A Video Walkthrough of Model Based Validation of Autonomous in FRC At the “RSN Spring Conference, Presented by WPI” in 2020, Tyler Veness from the WPILib team gave a presentation on Model Based Validation of Autonomous in FRC®. The link to the presentation is available here ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/advanced-controls/filters/debouncer.html?present",
      "title": "Debouncer",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Debouncer A debouncer is a filter used to eliminate unwanted quick on/off cycles (termed “bounces,” originally from the physical vibrations of a switch as it is thrown). These cycles are usually due to a sensor error like noise or reflections and not the actual event the sensor is trying to record. Debouncing is implemented in WPILib by the Debouncer class ( Java , C++ , Python ), which filters a boolean stream so that the output only changes if the input sustains a change for some nominal time period. Modes The WPILib Debouncer can be configured in three different modes: Rising (default): Debounces rising edges (transitions from false to true ) only. Falling: Debounces falling edges (transitions from true to false ) only. Both: Debounces all transitions. Usage JAVA // Initializes a DigitalInput on DIO 0 DigitalInput input = new DigitalInput ( 0 ); // Creates a Debouncer in \"both\" mode. Debouncer m_debouncer = new Debouncer ( 0.1 , Debouncer . DebounceType . kBoth ); // So if currently false the signal must go true for at least .1 seconds before being read as a True signal. if ( m_debouncer . calculate ( input . get ())) { // Do something now that the DI is True. } C++ // Initializes a DigitalInput on DIO 0 frc :: DigitalInput input { 0 }; // Creates a Debouncer in \"both\" mode. frc :: Debouncer m_debouncer { 100 _ms , frc :: Debouncer :: DebounceType :: kBoth }; // So if currently false the signal must go true for at least .1 seconds before being read as a True signal. if ( m_debouncer . calculate ( input . Get ())) { // Do something now that the DI is True. } PYTHON from wpilib import DigitalInput from wpimath.filter import Debouncer # Initializes a DigitalInput on DIO 0 self . input = DigitalInput ( 0 ) # Creates a Debouncer in \"both\" mode with a debounce time of 0.1 seconds self . debouncer = Debouncer ( 0.1 , Debouncer . DebounceType . kBoth ) # If currently false, the signal must go true for at least 0.1 seconds before being read as a True signal. if self . debouncer . calculate ( self . input . get ()): # Do something now that the DI is True. pass",
      "content_preview": "Debouncer A debouncer is a filter used to eliminate unwanted quick on/off cycles (termed “bounces,” originally from the physical vibrations of a switch as it is thrown). These cycles are usually due to a sensor error like noise or reflections and not the actual event the sensor is trying to record."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/frc-glossary.html",
      "title": "FRC Glossary",
      "section": "General",
      "language": "All",
      "content": "FRC Glossary accelerometer A common sensor used to measure acceleration in one or more axis. AM AndyMark, Inc - strives to develop innovative products and outstanding service while inspiring our customers and making a positive impact in our community. AprilTags Visual tags that provide low overhead, high accuracy localization. AprilTags are useful for helping your robot know where it is at on the field, so it can align itself to some goal position. auto The first phase of each match is called Autonomous (auto) and consists of the robot’s running pre-programmed instructions. back-EMF In electric motors, the force generated by the interaction of spinning magnets in a coil of wire which opposes spinning motion. boolean A form of data with only two possible values (true or false), intended to represent the two truth values of logic and Boolean algebra. call stack A specially-organized region of memory which helps the program keep track of what function it is in. As each function calls another, the call point is recorded and added to the top of the structure, forming a “stack” of references. Additionally, local variables will also be stored in this stack. See call stack on Wikipedia for more info. CAD Computer-Aided Design - software used to design an accurate model of an object. For FRC this is often used to design the robot to get accurate measurements and aid construction. CAM Computer-Aided Manufacturing - the use of software to control machine tools in the manufacturing of work pieces. CAN Controller Area Network - message-based protocol designed to allow microcontrollers and devices to communicate with each other’s applications without a host computer. CD Chief Delphi - FRC team 47 inspired a popular community driven forum that today serves as an unofficial discussion hub for all things FRC. central limit theorem A core concept in probability which states that when many independent variables are added up, the result tends to look like a “normal” (or Gaussian) distribution, regardless of whether the independent variables themselves are normally distributed. See Central Limit Theorem on Wikipedia for more info. CIM CCL Industrial Motor, Limited - Chiaphua Components Limited is the company that made the commonly used, relatively powerful, brushed motor. Classical Mechanics The branch of physics which studies and describes the motion of relatively large, relatively slow objects. See Classical Mechanics on Wikipedia for more info. COTS Commercial off the shelf - a standard (i.e. not custom order) part commonly available from a vendor to all teams for purchase. composition A formal software term for building (or “composing”) software entities out of smaller component entities. See object composition on Wikipedia for more info. CRTP Continuously Recurring Template Pattern - A software idiom in which a class X` derives from a class template instantiation using X` itself as a template argument. See CRTP on Wikipedia for more info. CSA Control Systems Advisor - FRC volunteer position that assists teams with Robot Control System-related issues. CTRE Cross the Road Electronics LLC - is an engineering design, software development, and electronics manufacturer based outside of Detroit in Macomb, MI. They primarily focus on high-performing, high-quality electronics communication, motor control, and control system products for FIRST teams and the EV industry. CTR Electronics was founded in 2006 by two FRC mentors who met through their robotics team: Mike Copioli and Omar Zrien and is staffed largely by FRC alumni, and active volunteers & mentors. C++ One of the four officially supported programming languages. declarative programming A style of software which focuses on describing what a program should do, rather than how it gets done. See declarative programming on Wikipedia for more info. dependency injection A software design pattern where each class receives all objects it depends upon. Sometimes these are passed through the constructor, but not always. See dependency injection on Wikipedia for more info. deprecated Software that has been replaced and will no longer receive new features. Deprecated software will be maintained for at least 1 year, but may be removed after that. For example, if a method is deprecated prior to the 2022 season, it will be usable in the 2022 season, but may be removed prior to the 2023 season. Teams are encouraged to not use deprecated methods in new code. WPILib always deprecates features at least one year prior to removing them from the codebase. design pattern A particular, intentionally-chosen style of organizing code. A design pattern intentionally excludes using certain features of a programming language to constrain developers into solutions that are well-suited to a particular problem-space. See design pattern. on Wikipedia for more info. DHCP Dynamic Host Configuration Protocol - the protocol that allows a central device to assign unique IP addresses to all other devices. encapsulation A software design pattern which uses a class to hide the implementation details of other classes. See encapsulation on Wikipedia for more info. entry In NetworkTables , a combined publisher and subscriber . The subscriber is always active, but the publisher is not created until a publish operation is performed (e.g. a value is “set”, aka published, on the entry). This may be more convenient than maintaining a separate publisher and subscriber. enumeration A list of all elements of a set, typically used to refer to a set of pre-defined values. EPA Expected Points Added - builds upon the Elo rating system, but transforms ratings to point units and makes several modifications. event-driven programming A style of programming where certain parts of code generate “events” as a result of some input (sensors, user interaction, etc). Then, other parts of code listen for and respond to “handle” these events. See event-based on Wikipedia for more info. FIRST For Inspiration and Recognition of Science and Technology - a global nonprofit organization that prepares young people for the future through a suite of life-changing youth robotics programs that build skills, confidence, and resilience. FLL FIRST Lego League - Introduces science, technology, engineering, and math (STEM) to children ages 4-16 through fun, exciting hands-on learning. floating point A method for approximating real numbers in computer-based arithmetic, using a fixed precision integer scaled by an integer exponent. Typically computer systems support both “single” precision (32-bit storage) and “double” precision (64-bit storage) floating point values, as defined by IEEE 754. FMS Field Management System - the electronics core responsible for sensing and controlling the FIRST Robotics Competition field. FPGA Field-programmable gate array - a specialized integrated circuit consisting of many digital logic elements, which can be configured to act in different patterns. This allows its behavior to be changed after manufacturing. In the context of FRC, National Instruments provides a specific configuration for the RIO’s FPGA which allows it to process the electrical inputs and outputs at a very high rate. See FPGA on Wikipedia for more info. FRC FIRST Robotics Competition - Combining the excitement of sport with the rigors of science and technology. The ultimate Sport for the Mind inspiring High-school students. FTA FIRST Technical Advisor - FRC volunteer position that is responsible for ensuring FIRST Robotics Competition events run smoothly, safely, and in accordance with FIRST requirements, and ensuring a high-quality experience for all event participants and teams. FTC FIRST Tech Challenge - Grades 7-12 are challenged to design, build, program, and operate robots to compete in a head-to-head challenge in an alliance format. GDC Game Design Committee - designs the game for each year and develops the rules and field setup for each competition. GP Gracious Professionalism - part of the ethos of FIRST. It’s a way of doing things that encourages high-quality work, emphasizes the value of others, and respects individuals and the community. GradleRIO The mechanism that powers the deployment of robot code to the roboRIO. gyroscope A device that measures rate of rotation. It can add up the rotation measurements to determine heading of the robot. (“gyro”, for short) heading The direction the robot is pointed, usually expressed as an angle in degrees. imperative programming A style of programming that focuses on what the code should be doing, step by step, every loop. See imperative programming on Wikipedia for more info. IMU Inertial Measurement Unit - a sensor that combines both an accelerometer and a gyroscope into a single sensor. I2C Inter-Integrated Circuit - a synchronous, multi-master/multi-slave (controller/target), single-ended, serial communication bus. Java One of the four officially supported programming languages. JSON JavaScript Object Notation - A standardized way of organizing data into named values. The organized data can be easily serialized . While the original usage was in Javascript, it can be used and interested by most modern programming languages. See JSON on Wikipedia for more info. KOP Kit of Parts - the collection of items listed on the Kickoff Kit checklists, distributed to the team via FIRST Choice, or paid for completely (except shipping) with a Product Donation Voucher (PDV). KOP chassis The KOP contains a drive base (chassis) distributed to every team (that did not opt out) as part of the KOP . For the 2025 season, the KOP chassis is the AM14U6 . LabVIEW One of the four officially supported programming languages. LED Light-Emitting Diode - a semiconductor device that emits light when current flows through it. Used on multiple robot parts to convey the status of the device. mass the amount of matter in a physical object. Objects with more mass will resist changes in motion more than objects with less mass. See mass on Wikipedia for more info. moment of inertia The property of an object that describes both how much mass it has, and how that mass is distributed relative to a certain axis of rotation. Objects with higher moments of inertia resist changes in rotational motion more than objects with lower moments of inertia. Increasing the moment of inertia is accomplished by adding more mass, or moving the mass further away from the axis of rotation. See moment of inertia on Wikipedia for more info. mutable An object that can be modified after it is created. MXP myRIO Expansion Port - Port in the center of the roboRIO designed to expand the traditional IO count by offering multiple different IO types through one connector. NetworkTables A publish-subscribe messaging system to communicate data between programs. no-op No-op is a computer instruction which means no operation. When the computer processor encounters a no-op instruction, it simply moves to the next sequential instruction. Read more about no-op on Wikipedia . odometry Using sensors on the robot to create an estimate of the pose of the robot on the field. OPR Offensive Power Rating - a system to attempt to deduce the average point contribution of a team to an alliance PCM Pneumatic Control Module - provides an easy all-in-one interface for pneumatic components. PDH REV Power Distribution Hub - latest evolution in power distribution for FRC. With 20 high-current (40A max) channels, 3 low-current (15A max), and 1 switchable low-current channel, the PDH gives teams more flexibility for overall power delivery. PDP CTRE Power Distribution Panel - power distribution module with 8 high-current (40A max), 8 lower current (20A / 30A), 1 20A protected channel (for PCM and VRM ), and 1 10A protected channel (for the roboRIO). permanent-magnet DC motor The classification of all legal motors for the FIRST robotics competition. This type of motor takes direct current as input, and uses it to create a magnetic field. In turn, this magnetic field interacts with a physical magnet to create a force that turns the output shaft. Electrical (“brushless”) or mechanical (“brushed”) means are used to ensure the electrically-generated magnetic field always points in a direction that creates forces when it interacts with the physical magnet, even as the motor’s shaft rotates. See permanent-magnet motor on Wikipedia for more info. persistent In NetworkTables , a topic that is saved to a file by the server and restored at startup. PH Pneumatic Hub - is a standalone module that is capable of switching both 12V and 24V pneumatic solenoid valves. The Pneumatic Hub features 16 solenoid channels which allow for up to 16 single-acting solenoids, 8 double-acting solenoids, or a combination of the two types. PoE Power Over Ethernet - method of powering a device by an Ethernet cord that also carries power. FRC uses passive PoE usually 12-24V that is always being supplied, this can damage a device not expecting the provided voltage. The most common industry standard is active PoE which uses 48V but first verifies that the device is expecting the power. property In NetworkTables , named information (metadata) about a topic stored and updated separately from the topic’s data. A topic may have any number of properties. A property’s value can be any data type that can be represented in JSON. publisher In NetworkTables , an object that defines a topic and creates and sends timestamped data values. pose The collection of position and rotation information that describes how a rigid body is oriented in space, relative to some fixed reference point. pose estimation The process of estimating the robot’s pose, commonly with odometry and/or AprilTags . Also known as on-field localization . PWM Pulse-width modulation - a method of controlling the average power or amplitude delivered by an electrical signal. Used in FRC to control the output of motors not using the CAN bus. Python One of the four officially supported programming languages. RAII Resource Acquisition Is Initialization - a language behavior (in C++, but not in Java) where holding a resource is tied to object lifetime. retro-reflection The property of reflecting incoming light back at the same angle it came in at, rather than an incident angle (like a mirror), absorbing it, or scattering it. Most FRC vision processing targets are retro-reflective. See retroreflector on Wikipedia for more information. recursive composition A type of composition in which the composite object may contain components of the same type as itself. For example, a command group may contain one or more command groups. See recursive composition on Wikipedia for more info. See also recursive composition . retained In NetworkTables , a topic that is kept alive by the server even after all publishers stop publishing. REV REV Robotics - inspires innovation and creativity within the educational robotics community by offering comprehensive product lines, extensive educational resources, world-class customer service, and specialized sponsorship programs. With a global presence spanning over 190 countries, we empower the next generation of STEM professionals by providing cutting-edge solutions and essential tools for success. Founded in 2014 by robotics enthusiasts Greg Needel and David Yanoshak, REV Robotics is driven by the mission to inspire and support students as they explore the exciting world of robotics and unlock their full robotic design potential. A majority of our employees are FIRST Alumni who remain actively involved, serving as volunteers and mentors for the local FIRST Community. This deep engagement reflects our commitment to supporting and inspiring the next generation of STEM enthusiasts. RPM Radio Power Module - is designed to keep one of the most critical system components, the OpenMesh OM5P-AC WiFi radio, powered in the toughest moments of the competition. Revolutions Per Minute - a unit of rotational speed often used when describing motors. RSL Robot Signal Light - safety light on every FRC robot used to indicate its operational status. serialized The property of a data organization scheme that allows the description of the data to be sent in order, byte by byte, over some communication channel. Reading or writing a file on disk is done in this serial fashion (IE, the data is read or written byte by byte, not all at once). Sending data over a SPI or I2C bus is also done byte by byte, again requiring the data can be serialized. simulation A way for teams to test their code without having an actual robot available. software library A collection of code that can be imported into and used by other software. See software library on Wikipedia for more info. solenoid valve A airflow-controlling valve which is actuated by a small electromagnet. Strictly speaking, the solenoid is the coil of wire which forms the electromagnet, and the valve is the mechanism which actually redirects airflow. However, the set of solenoid and valve together is often simply called “a solenoid”. See solenoid valve . on Wikipedia for more info. SPI Serial Peripheral Interface - protocol for synchronous serial communication, used primarily in embedded systems for short-distance wired communication between integrated circuits. state machine A programming construct that divides a problem into many discrete, well-defined, mutually-exclusive “states”, then defines how the problem is solved by moving between different states. See state machine on Wikipedia for more more info. subscriber In NetworkTables , an object that receives timestamped data value updates to one or more topic s. TBA The Blue Alliance - Website for looking up FRC team statistics and event information. telemetry The process of recording and sending real-time data about the performance of your robot to a real-time readout or log file. For the linguists among us, the word’s roots are “tele” (remote) and “metry” (measurement). See telemetry on Wikipedia for more info. teleop The second phase of each match is called the Teleoperated Period (teleop) and consists of drivers controlling their robots. topic In NetworkTables , a named data channel. torque A force applied at a distance from some axis of rotation trajectory A trajectory is a smooth curve, with velocities, and accelerations at each point along the curve, connecting two endpoints on the field. transitory In NetworkTables , a topic that will disappear after the last publisher stops publishing. VRM Voltage Regulator Module - provides access to different constant voltages for custom sensors, cameras, or other unique applications. 12V DC Input Directly fed power from the Power Distribution Panel Designed to work with the roboRIO FRC control system. WCP WestCoast Products & Design LLC - was founded in Fall of 2011 by Ranjit Chahal (R.C.) and Harvey Rico. WCP aims to provide FIRST Teams, Hobbyists, and educators top notch quality products and designs for their projects. WFA Woodie Flowers Award - This award recognizes an individual who has done an outstanding job of motivation through communication while also challenging the students to be clear and succinct in their communications.",
      "content_preview": "FRC Glossary accelerometer A common sensor used to measure acceleration in one or more axis. AM AndyMark, Inc - strives to develop innovative products and outstanding service while inspiring our customers and making a positive impact in our community."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/frc-glossary.html?present",
      "title": "FRC Glossary",
      "section": "General",
      "language": "All",
      "content": "FRC Glossary accelerometer A common sensor used to measure acceleration in one or more axis. AM AndyMark, Inc - strives to develop innovative products and outstanding service while inspiring our customers and making a positive impact in our community. AprilTags Visual tags that provide low overhead, high accuracy localization. AprilTags are useful for helping your robot know where it is at on the field, so it can align itself to some goal position. auto The first phase of each match is called Autonomous (auto) and consists of the robot’s running pre-programmed instructions. back-EMF In electric motors, the force generated by the interaction of spinning magnets in a coil of wire which opposes spinning motion. boolean A form of data with only two possible values (true or false), intended to represent the two truth values of logic and Boolean algebra. call stack A specially-organized region of memory which helps the program keep track of what function it is in. As each function calls another, the call point is recorded and added to the top of the structure, forming a “stack” of references. Additionally, local variables will also be stored in this stack. See call stack on Wikipedia for more info. CAD Computer-Aided Design - software used to design an accurate model of an object. For FRC this is often used to design the robot to get accurate measurements and aid construction. CAM Computer-Aided Manufacturing - the use of software to control machine tools in the manufacturing of work pieces. CAN Controller Area Network - message-based protocol designed to allow microcontrollers and devices to communicate with each other’s applications without a host computer. CD Chief Delphi - FRC team 47 inspired a popular community driven forum that today serves as an unofficial discussion hub for all things FRC. central limit theorem A core concept in probability which states that when many independent variables are added up, the result tends to look like a “normal” (or Gaussian) distribution, regardless of whether the independent variables themselves are normally distributed. See Central Limit Theorem on Wikipedia for more info. CIM CCL Industrial Motor, Limited - Chiaphua Components Limited is the company that made the commonly used, relatively powerful, brushed motor. Classical Mechanics The branch of physics which studies and describes the motion of relatively large, relatively slow objects. See Classical Mechanics on Wikipedia for more info. COTS Commercial off the shelf - a standard (i.e. not custom order) part commonly available from a vendor to all teams for purchase. composition A formal software term for building (or “composing”) software entities out of smaller component entities. See object composition on Wikipedia for more info. CRTP Continuously Recurring Template Pattern - A software idiom in which a class X` derives from a class template instantiation using X` itself as a template argument. See CRTP on Wikipedia for more info. CSA Control Systems Advisor - FRC volunteer position that assists teams with Robot Control System-related issues. CTRE Cross the Road Electronics LLC - is an engineering design, software development, and electronics manufacturer based outside of Detroit in Macomb, MI. They primarily focus on high-performing, high-quality electronics communication, motor control, and control system products for FIRST teams and the EV industry. CTR Electronics was founded in 2006 by two FRC mentors who met through their robotics team: Mike Copioli and Omar Zrien and is staffed largely by FRC alumni, and active volunteers & mentors. C++ One of the four officially supported programming languages. declarative programming A style of software which focuses on describing what a program should do, rather than how it gets done. See declarative programming on Wikipedia for more info. dependency injection A software design pattern where each class receives all objects it depends upon. Sometimes these are passed through the constructor, but not always. See dependency injection on Wikipedia for more info. deprecated Software that has been replaced and will no longer receive new features. Deprecated software will be maintained for at least 1 year, but may be removed after that. For example, if a method is deprecated prior to the 2022 season, it will be usable in the 2022 season, but may be removed prior to the 2023 season. Teams are encouraged to not use deprecated methods in new code. WPILib always deprecates features at least one year prior to removing them from the codebase. design pattern A particular, intentionally-chosen style of organizing code. A design pattern intentionally excludes using certain features of a programming language to constrain developers into solutions that are well-suited to a particular problem-space. See design pattern. on Wikipedia for more info. DHCP Dynamic Host Configuration Protocol - the protocol that allows a central device to assign unique IP addresses to all other devices. encapsulation A software design pattern which uses a class to hide the implementation details of other classes. See encapsulation on Wikipedia for more info. entry In NetworkTables , a combined publisher and subscriber . The subscriber is always active, but the publisher is not created until a publish operation is performed (e.g. a value is “set”, aka published, on the entry). This may be more convenient than maintaining a separate publisher and subscriber. enumeration A list of all elements of a set, typically used to refer to a set of pre-defined values. EPA Expected Points Added - builds upon the Elo rating system, but transforms ratings to point units and makes several modifications. event-driven programming A style of programming where certain parts of code generate “events” as a result of some input (sensors, user interaction, etc). Then, other parts of code listen for and respond to “handle” these events. See event-based on Wikipedia for more info. FIRST For Inspiration and Recognition of Science and Technology - a global nonprofit organization that prepares young people for the future through a suite of life-changing youth robotics programs that build skills, confidence, and resilience. FLL FIRST Lego League - Introduces science, technology, engineering, and math (STEM) to children ages 4-16 through fun, exciting hands-on learning. floating point A method for approximating real numbers in computer-based arithmetic, using a fixed precision integer scaled by an integer exponent. Typically computer systems support both “single” precision (32-bit storage) and “double” precision (64-bit storage) floating point values, as defined by IEEE 754. FMS Field Management System - the electronics core responsible for sensing and controlling the FIRST Robotics Competition field. FPGA Field-programmable gate array - a specialized integrated circuit consisting of many digital logic elements, which can be configured to act in different patterns. This allows its behavior to be changed after manufacturing. In the context of FRC, National Instruments provides a specific configuration for the RIO’s FPGA which allows it to process the electrical inputs and outputs at a very high rate. See FPGA on Wikipedia for more info. FRC FIRST Robotics Competition - Combining the excitement of sport with the rigors of science and technology. The ultimate Sport for the Mind inspiring High-school students. FTA FIRST Technical Advisor - FRC volunteer position that is responsible for ensuring FIRST Robotics Competition events run smoothly, safely, and in accordance with FIRST requirements, and ensuring a high-quality experience for all event participants and teams. FTC FIRST Tech Challenge - Grades 7-12 are challenged to design, build, program, and operate robots to compete in a head-to-head challenge in an alliance format. GDC Game Design Committee - designs the game for each year and develops the rules and field setup for each competition. GP Gracious Professionalism - part of the ethos of FIRST. It’s a way of doing things that encourages high-quality work, emphasizes the value of others, and respects individuals and the community. GradleRIO The mechanism that powers the deployment of robot code to the roboRIO. gyroscope A device that measures rate of rotation. It can add up the rotation measurements to determine heading of the robot. (“gyro”, for short) heading The direction the robot is pointed, usually expressed as an angle in degrees. imperative programming A style of programming that focuses on what the code should be doing, step by step, every loop. See imperative programming on Wikipedia for more info. IMU Inertial Measurement Unit - a sensor that combines both an accelerometer and a gyroscope into a single sensor. I2C Inter-Integrated Circuit - a synchronous, multi-master/multi-slave (controller/target), single-ended, serial communication bus. Java One of the four officially supported programming languages. JSON JavaScript Object Notation - A standardized way of organizing data into named values. The organized data can be easily serialized . While the original usage was in Javascript, it can be used and interested by most modern programming languages. See JSON on Wikipedia for more info. KOP Kit of Parts - the collection of items listed on the Kickoff Kit checklists, distributed to the team via FIRST Choice, or paid for completely (except shipping) with a Product Donation Voucher (PDV). KOP chassis The KOP contains a drive base (chassis) distributed to every team (that did not opt out) as part of the KOP . For the 2025 season, the KOP chassis is the AM14U6 . LabVIEW One of the four officially supported programming languages. LED Light-Emitting Diode - a semiconductor device that emits light when current flows through it. Used on multiple robot parts to convey the status of the device. mass the amount of matter in a physical object. Objects with more mass will resist changes in motion more than objects with less mass. See mass on Wikipedia for more info. moment of inertia The property of an object that describes both how much mass it has, and how that mass is distributed relative to a certain axis of rotation. Objects with higher moments of inertia resist changes in rotational motion more than objects with lower moments of inertia. Increasing the moment of inertia is accomplished by adding more mass, or moving the mass further away from the axis of rotation. See moment of inertia on Wikipedia for more info. mutable An object that can be modified after it is created. MXP myRIO Expansion Port - Port in the center of the roboRIO designed to expand the traditional IO count by offering multiple different IO types through one connector. NetworkTables A publish-subscribe messaging system to communicate data between programs. no-op No-op is a computer instruction which means no operation. When the computer processor encounters a no-op instruction, it simply moves to the next sequential instruction. Read more about no-op on Wikipedia . odometry Using sensors on the robot to create an estimate of the pose of the robot on the field. OPR Offensive Power Rating - a system to attempt to deduce the average point contribution of a team to an alliance PCM Pneumatic Control Module - provides an easy all-in-one interface for pneumatic components. PDH REV Power Distribution Hub - latest evolution in power distribution for FRC. With 20 high-current (40A max) channels, 3 low-current (15A max), and 1 switchable low-current channel, the PDH gives teams more flexibility for overall power delivery. PDP CTRE Power Distribution Panel - power distribution module with 8 high-current (40A max), 8 lower current (20A / 30A), 1 20A protected channel (for PCM and VRM ), and 1 10A protected channel (for the roboRIO). permanent-magnet DC motor The classification of all legal motors for the FIRST robotics competition. This type of motor takes direct current as input, and uses it to create a magnetic field. In turn, this magnetic field interacts with a physical magnet to create a force that turns the output shaft. Electrical (“brushless”) or mechanical (“brushed”) means are used to ensure the electrically-generated magnetic field always points in a direction that creates forces when it interacts with the physical magnet, even as the motor’s shaft rotates. See permanent-magnet motor on Wikipedia for more info. persistent In NetworkTables , a topic that is saved to a file by the server and restored at startup. PH Pneumatic Hub - is a standalone module that is capable of switching both 12V and 24V pneumatic solenoid valves. The Pneumatic Hub features 16 solenoid channels which allow for up to 16 single-acting solenoids, 8 double-acting solenoids, or a combination of the two types. PoE Power Over Ethernet - method of powering a device by an Ethernet cord that also carries power. FRC uses passive PoE usually 12-24V that is always being supplied, this can damage a device not expecting the provided voltage. The most common industry standard is active PoE which uses 48V but first verifies that the device is expecting the power. property In NetworkTables , named information (metadata) about a topic stored and updated separately from the topic’s data. A topic may have any number of properties. A property’s value can be any data type that can be represented in JSON. publisher In NetworkTables , an object that defines a topic and creates and sends timestamped data values. pose The collection of position and rotation information that describes how a rigid body is oriented in space, relative to some fixed reference point. pose estimation The process of estimating the robot’s pose, commonly with odometry and/or AprilTags . Also known as on-field localization . PWM Pulse-width modulation - a method of controlling the average power or amplitude delivered by an electrical signal. Used in FRC to control the output of motors not using the CAN bus. Python One of the four officially supported programming languages. RAII Resource Acquisition Is Initialization - a language behavior (in C++, but not in Java) where holding a resource is tied to object lifetime. retro-reflection The property of reflecting incoming light back at the same angle it came in at, rather than an incident angle (like a mirror), absorbing it, or scattering it. Most FRC vision processing targets are retro-reflective. See retroreflector on Wikipedia for more information. recursive composition A type of composition in which the composite object may contain components of the same type as itself. For example, a command group may contain one or more command groups. See recursive composition on Wikipedia for more info. See also recursive composition . retained In NetworkTables , a topic that is kept alive by the server even after all publishers stop publishing. REV REV Robotics - inspires innovation and creativity within the educational robotics community by offering comprehensive product lines, extensive educational resources, world-class customer service, and specialized sponsorship programs. With a global presence spanning over 190 countries, we empower the next generation of STEM professionals by providing cutting-edge solutions and essential tools for success. Founded in 2014 by robotics enthusiasts Greg Needel and David Yanoshak, REV Robotics is driven by the mission to inspire and support students as they explore the exciting world of robotics and unlock their full robotic design potential. A majority of our employees are FIRST Alumni who remain actively involved, serving as volunteers and mentors for the local FIRST Community. This deep engagement reflects our commitment to supporting and inspiring the next generation of STEM enthusiasts. RPM Radio Power Module - is designed to keep one of the most critical system components, the OpenMesh OM5P-AC WiFi radio, powered in the toughest moments of the competition. Revolutions Per Minute - a unit of rotational speed often used when describing motors. RSL Robot Signal Light - safety light on every FRC robot used to indicate its operational status. serialized The property of a data organization scheme that allows the description of the data to be sent in order, byte by byte, over some communication channel. Reading or writing a file on disk is done in this serial fashion (IE, the data is read or written byte by byte, not all at once). Sending data over a SPI or I2C bus is also done byte by byte, again requiring the data can be serialized. simulation A way for teams to test their code without having an actual robot available. software library A collection of code that can be imported into and used by other software. See software library on Wikipedia for more info. solenoid valve A airflow-controlling valve which is actuated by a small electromagnet. Strictly speaking, the solenoid is the coil of wire which forms the electromagnet, and the valve is the mechanism which actually redirects airflow. However, the set of solenoid and valve together is often simply called “a solenoid”. See solenoid valve . on Wikipedia for more info. SPI Serial Peripheral Interface - protocol for synchronous serial communication, used primarily in embedded systems for short-distance wired communication between integrated circuits. state machine A programming construct that divides a problem into many discrete, well-defined, mutually-exclusive “states”, then defines how the problem is solved by moving between different states. See state machine on Wikipedia for more more info. subscriber In NetworkTables , an object that receives timestamped data value updates to one or more topic s. TBA The Blue Alliance - Website for looking up FRC team statistics and event information. telemetry The process of recording and sending real-time data about the performance of your robot to a real-time readout or log file. For the linguists among us, the word’s roots are “tele” (remote) and “metry” (measurement). See telemetry on Wikipedia for more info. teleop The second phase of each match is called the Teleoperated Period (teleop) and consists of drivers controlling their robots. topic In NetworkTables , a named data channel. torque A force applied at a distance from some axis of rotation trajectory A trajectory is a smooth curve, with velocities, and accelerations at each point along the curve, connecting two endpoints on the field. transitory In NetworkTables , a topic that will disappear after the last publisher stops publishing. VRM Voltage Regulator Module - provides access to different constant voltages for custom sensors, cameras, or other unique applications. 12V DC Input Directly fed power from the Power Distribution Panel Designed to work with the roboRIO FRC control system. WCP WestCoast Products & Design LLC - was founded in Fall of 2011 by Ranjit Chahal (R.C.) and Harvey Rico. WCP aims to provide FIRST Teams, Hobbyists, and educators top notch quality products and designs for their projects. WFA Woodie Flowers Award - This award recognizes an individual who has done an outstanding job of motivation through communication while also challenging the students to be clear and succinct in their communications.",
      "content_preview": "FRC Glossary accelerometer A common sensor used to measure acceleration in one or more axis. AM AndyMark, Inc - strives to develop innovative products and outstanding service while inspiring our customers and making a positive impact in our community."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/binding-commands-to-triggers.html?present",
      "title": "Binding Commands to Triggers",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Binding Commands to Triggers Apart from autonomous commands, which are scheduled at the start of the autonomous period, and default commands, which are automatically scheduled whenever their subsystem is not currently in-use, the most common way to run a command is by binding it to a triggering event, such as a button being pressed by a human operator. The command-based paradigm makes this extremely easy to do. As mentioned earlier, command-based is a declarative programming paradigm. Accordingly, binding buttons to commands is done declaratively; the association of a button and a command is “declared” once, during robot initialization. The library then does all the hard work of checking the button state and scheduling (or canceling) the command as needed, behind-the-scenes. Users only need to worry about designing their desired UI setup - not about implementing it! Command binding is done through the Trigger class ( Java , C++ ). Getting a Trigger Instance To bind commands to conditions, we need a Trigger object. There are three ways to get a Trigger object: HID Factories The command-based HID classes contain factory methods returning a Trigger for a given button. CommandGenericHID has an index-based button(int) factory ( Java , C++ ), and its subclasses CommandXboxController ( Java , C++ ), CommandPS4Controller ( Java , C++ ), and CommandJoystick ( Java , C++ ) have named factory methods for each button. JAVA CommandXboxController exampleCommandController = new CommandXboxController ( 1 ); // Creates a CommandXboxController on port 1. Trigger xButton = exampleCommandController . x (); // Creates a new Trigger object for the `X` button on exampleCommandController C++ frc2 :: CommandXboxController exampleCommandController { 1 } // Creates a CommandXboxController on port 1 frc2 :: Trigger xButton = exampleCommandController . X () // Creates a new Trigger object for the `X` button on exampleCommandController JoystickButton Alternatively, the regular HID classes can be used and passed to create an instance of JoystickButton Java , C++ ), a constructor-only subclass of Trigger : JAVA XboxController exampleController = new XboxController ( 2 ); // Creates an XboxController on port 2. Trigger yButton = new JoystickButton ( exampleController , XboxController . Button . kY . value ); // Creates a new JoystickButton object for the `Y` button on exampleController C++ frc :: XboxController exampleController { 2 } // Creates an XboxController on port 2 frc2 :: JoystickButton yButton ( & exampleStick , frc :: XboxController :: Button :: kY ); // Creates a new JoystickButton object for the `Y` button on exampleController Arbitrary Triggers While binding to HID buttons is by far the most common use case, users may want to bind commands to arbitrary triggering events. This can be done inline by passing a lambda to the constructor of Trigger : JAVA DigitalInput limitSwitch = new DigitalInput ( 3 ); // Limit switch on DIO 3 Trigger exampleTrigger = new Trigger ( limitSwitch :: get ); C++ frc :: DigitalInput limitSwitch { 3 }; // Limit switch on DIO 3 frc2 :: Trigger exampleTrigger ([ & limitSwitch ] { return limitSwitch . Get (); }); Trigger Bindings Note The C++ command-based library offers two overloads of each button binding method - one that takes an rvalue reference ( CommandPtr&& ), and one that takes a raw pointer ( Command* ). The rvalue overload moves ownership to the scheduler, while the raw pointer overload leaves the user responsible for the lifespan of the command object. It is recommended that users preferentially use the rvalue reference overload unless there is a specific need to retain a handle to the command in the calling code. There are a number of bindings available for the Trigger class. All of these bindings will automatically schedule a command when a certain trigger activation event occurs - however, each binding has different specific behavior. Trigger objects do not need to survive past the call to a binding method , so the binding methods may be simply called on a temp. Remember that button binding is declarative : bindings only need to be declared once, ideally some time during robot initialization. The library handles everything else. Note The Button subclass is deprecated, and usage of its binding methods should be replaced according to the respective deprecation messages in the API docs. onTrue This binding schedules a command when a trigger changes from false to true (or, accordingly, when a button changes is initially pressed). The command will be scheduled on the iteration when the state changes, and will not be scheduled again unless the trigger becomes false and then true again (or the button is released and then re-pressed). JAVA 65 // Retract the intake with the Y button 66 m_driverController . y (). onTrue ( m_intake . retractCommand ()); C++ 28 // Deploy the intake with the X button 29 m_driverController . X (). OnTrue ( m_intake . IntakeCommand ()); The onFalse binding is identical, only that it schedules on false instead of on true . whileTrue This binding schedules a command when a trigger changes from false to true (or, accordingly, when a button is initially pressed) and cancels it when the trigger becomes false again (or the button is released). The command will not be re-scheduled if it finishes while the trigger is still true . For the command to restart if it finishes while the trigger is true , wrap the command in a RepeatCommand , or use a RunCommand instead of an InstantCommand . JAVA 49 // Schedule `exampleMethodCommand` when the Xbox controller's B button is pressed, 50 // cancelling on release. 51 m_driverController . b (). whileTrue ( m_exampleSubsystem . exampleMethodCommand ()); C++ 27 // Schedule `ExampleMethodCommand` when the Xbox controller's B button is 28 // pressed, cancelling on release. 29 m_driverController . B (). WhileTrue ( m_subsystem . ExampleMethodCommand ()); The whileFalse binding is identical, only that it schedules on false and cancels on true . toggleOnTrue This binding toggles a command, scheduling it when a trigger changes from false to true (or a button is initially pressed), and canceling it under the same condition if the command is currently running. Note that while this functionality is supported, toggles are not a highly-recommended option for user control, as they require the driver to keep track of the robot state. The preferred method is to use two buttons; one to turn on and another to turn off. Using a StartEndCommand or a ConditionalCommand is a good way to specify the commands that you want to be want to be toggled between. JAVA 78 // Toggle compressor with the Start button 79 m_driverController . start (). toggleOnTrue ( m_pneumatics . disableCompressorCommand ()); C++ 41 // Toggle compressor with the Start button 42 m_driverController . Start (). ToggleOnTrue ( 43 m_pneumatics . DisableCompressorCommand ()); The toggleOnFalse binding is identical, only that it toggles on false instead of on true . Chaining Calls It is useful to note that the command binding methods all return the trigger that they were called on, and thus can be chained to bind multiple commands to different states of the same trigger. For example: JAVA exampleButton // Binds a FooCommand to be scheduled when the button is pressed . onTrue ( new FooCommand ()) // Binds a BarCommand to be scheduled when that same button is released . onFalse ( new BarCommand ()); C++ exampleButton // Binds a FooCommand to be scheduled when the button is pressed . OnTrue ( FooCommand (). ToPtr ()) // Binds a BarCommand to be scheduled when that same button is released . OnFalse ( BarCommand (). ToPtr ()); Composing Triggers The Trigger class can be composed to create composite triggers through the and() , or() , and negate() methods (or, in C++, the && , || , and ! operators). For example: JAVA // Binds an ExampleCommand to be scheduled when both the 'X' and 'Y' buttons of the driver gamepad are pressed exampleCommandController . x () . and ( exampleCommandController . y ()) . onTrue ( new ExampleCommand ()); C++ // Binds an ExampleCommand to be scheduled when both the 'X' and 'Y' buttons of the driver gamepad are pressed ( exampleCommandController . X () && exampleCommandController . Y ()) . OnTrue ( ExampleCommand (). ToPtr ()); Debouncing Triggers To avoid rapid repeated activation, triggers (especially those originating from digital inputs) can be debounced with the WPILib Debouncer class using the debounce method: JAVA // debounces exampleButton with a 0.1s debounce time, rising edges only exampleButton . debounce ( 0.1 ). onTrue ( new ExampleCommand ()); // debounces exampleButton with a 0.1s debounce time, both rising and falling edges exampleButton . debounce ( 0.1 , Debouncer . DebounceType . kBoth ). onTrue ( new ExampleCommand ()); C++ // debounces exampleButton with a 100ms debounce time, rising edges only exampleButton . Debounce ( 100 _ms ). OnTrue ( ExampleCommand (). ToPtr ()); // debounces exampleButton with a 100ms debounce time, both rising and falling edges exampleButton . Debounce ( 100 _ms , Debouncer :: DebounceType :: Both ). OnTrue ( ExampleCommand (). ToPtr ());",
      "content_preview": "Binding Commands to Triggers Apart from autonomous commands, which are scheduled at the start of the autonomous period, and default commands, which are automatically scheduled whenever their subsystem is not currently in-use, the most common way to run a command is by binding it to a triggering..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/joystick.html",
      "title": "Joysticks",
      "section": "Basic Programming",
      "language": "All",
      "content": "Joysticks A joystick can be used with the Driver Station program to control the robot. Almost any “controller” that can be recognized by Windows can be used as a joystick. Joysticks are accessed using the GenericHID class. This class has three relevant subclasses for preconfigured joysticks. You may also implement your own for other controllers by extending GenericHID . The first is Joystick which is useful for standard flight joysticks. The second is XboxController which works for the Xbox 360, Xbox One, or Logitech F310 (in XInput mode). Finally, the PS4Controller class is ideal for using that controller. Each axis of the controller ranges from -1 to 1. The command based way to use the these classes is detailed in the section: Binding Commands to Triggers . Driver Station Joysticks The USB Devices Tab of the Driver Station is used to setup and configure the joystick for use with the robot. Pressing a button on a joystick will cause its entry in the table to light up green. Selecting the joystick will show the values of axes, buttons, and the POV that can be used to determine the mapping between physical joystick features and axis or button numbers. The USB Devices Tab also assigns a joystick index to each joystick. To reorder the joysticks simply click and drag. The Driver Station software will try to preserve the ordering of devices between runs. It is a good idea to note what order your devices should be in and check each time you start the Driver Station software that they are correct. When the Driver Station is in disabled mode, it is routinely looking for status changes on the joystick devices. Unplugged devices are removed from the list and new devices are opened and added. When not connected to the FMS, unplugging a joystick will force the Driver Station into disabled mode. To start using the joystick again: plug the joystick in, check that it shows up in the right spot, then re-enable the robot. While the Driver Station is in enabled mode, it will not scan for new devices. This is a time consuming operation and timely update of signals from attached devices takes priority. Note For some joysticks the startup routine will read whatever position the joysticks are in as the center position, therefore, when the computer is turned on (or when the joystick is plugged in) the joysticks should be at their center position. When the robot is connected to the Field Management System at competition, the Driver Station mode is dictated by the FMS . This means that you cannot disable your robot and the DS cannot disable itself in order to detect joystick changes. A manual complete refresh of the joysticks can be initiated by pressing the F1 key on the keyboard. Note that this will close and re-open all devices, so all devices should be in their center position as noted above. Joystick Class JAVA Joystick exampleJoystick = new Joystick ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ Joystick exampleJoystick { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON exampleJoystick = wpilib . Joystick ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The Joystick class is designed to make using a flight joystick to operate the robot significantly easier. Depending on the flight joystick, the user may need to set the specific X, Y, Z, and Throttle channels that your flight joystick uses. This class offers special methods for accessing the angle and magnitude of the flight joystick. Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. XboxController Class JAVA XboxController exampleXbox = new XboxController ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ XboxController exampleXbox { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON exampleXbox = wpilib . XboxController ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The XboxController class provides named methods (e.g. getXButton , getXButtonPressed , getXButtonReleased ) for each of the buttons, and the indices can be accessed with XboxController.Button.kX.value . The rumble feature of the controller can be controlled by using XboxController.setRumble(GenericHID.RumbleType.kRightRumble, value) . Many users do a split stick arcade drive that uses the left stick for just forwards / backwards and the right stick for left / right turning. Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. PS4Controller Class JAVA PS4Controller examplePS4 = new PS4Controller ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ PS4Controller examplePS4 { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON examplePS4 = wpilib . PS4Controller ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The PS4Controller class provides named methods (e.g. getSquareButton , getSquareButtonPressed , getSquareButtonReleased ) for each of the buttons, and the indices can be accessed with PS4Controller.Button.kSquare.value . The rumble feature of the controller can be controlled by using PS4Controller.setRumble(GenericHID.RumbleType.kRightRumble, value) . Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. POV On joysticks, the POV is a directional hat that can select one of 8 different angles or read -1 for unpressed. The XboxController/PS4Controller D-pad works the same as a POV. Be careful when using a POV with exact angle requirements as it is hard for the user to ensure they select exactly the angle desired. GenericHID Usage An axis can be used with .getRawAxis(int index) (if not using any of the classes above) that returns the current value. Zero and one in this example are each the index of an axis as found in the Driver Station mentioned above. JAVA private final PWMSparkMax m_leftMotor = new PWMSparkMax ( Constants . kLeftMotorPort ); private final PWMSparkMax m_rightMotor = new PWMSparkMax ( Constants . kRightMotorPort ); private final DifferentialDrive m_robotDrive = new DifferentialDrive ( m_leftMotor :: set , m_rightMotor :: set ); private final GenericHID m_stick = new GenericHID ( Constants . kJoystickPort ); m_robotDrive . arcadeDrive ( - m_stick . getRawAxis ( 0 ), m_stick . getRawAxis ( 1 )); C++ frc :: PWMVictorSPX m_leftMotor { Constants :: kLeftMotorPort }; frc :: PWMVictorSPX m_rightMotor { Constants :: kRightMotorPort }; frc :: DifferentialDrive m_robotDrive {[ & ]( double output ) { m_leftMotor . Set ( output ); }, [ & ]( double output ) { m_rightMotor . Set ( output ); }}; frc :: GenericHID m_stick { Constants :: kJoystickPort }; m_robotDrive . ArcadeDrive ( - m_stick . GetRawAxis ( 0 ), m_stick . GetRawAxis ( 1 )); PYTHON leftMotor = wpilib . PWMVictorSPX ( LEFT_MOTOR_PORT ) rightMotor = wpilib . PWMVictorSPX ( RIGHT_MOTOR_PORT ) self . robotDrive = wpilib . drive . DifferentialDrive ( leftMotor , rightMotor ) self . stick = wpilib . GenericHID ( JOYSTICK_PORT ) self . robotDrive . arcadeDrive ( - self . stick . getRawAxis ( 0 ), self . stick . getRawAxis ( 1 )) Button Usage Note Usage such as the following is for code not using the command-based framework. For button usage in the command-based framework, see Binding Commands to Triggers . Unlike an axis, you will usually want to use the pressed and released methods to respond to button input. These will return true if the button has been activated since the last check. This is helpful for taking an action once when the event occurs but not having to continuously do it while the button is held down. JAVA if ( joystick . getRawButtonPressed ( 0 )) { turnIntakeOn (); // When pressed the intake turns on } if ( joystick . getRawButtonReleased ( 0 )) { turnIntakeOff (); // When released the intake turns off } // OR if ( joystick . getRawButton ( 0 )) { turnIntakeOn (); } else { turnIntakeOff (); } C++ if ( joystick . GetRawButtonPressed ( 0 )) { turnIntakeOn (); // When pressed the intake turns on } if ( joystick . GetRawButtonReleased ( 0 )) { turnIntakeOff (); // When released the intake turns off } // OR if ( joystick . GetRawButton ( 0 )) { turnIntakeOn (); } else { turnIntakeOff (); } PYTHON if joystick . getRawButtonPressed ( 0 ): turnIntakeOn () # When pressed the intake turns on if joystick . getRawButtonReleased ( 0 ): turnIntakeOff () # When released the intake turns off # OR if joystick . getRawButton ( 0 ): turnIntakeOn () else : turnIntakeOff () A common request is to toggle something on and off with the press of a button. Toggles should be used with caution, as they require the user to keep track of the robot state. JAVA boolean toggle = false ; if ( joystick . getRawButtonPressed ( 0 )) { if ( toggle ) { // Current state is true so turn off retractIntake (); toggle = false ; } else { // Current state is false so turn on deployIntake (); toggle = true ; } } C++ bool toggle { false }; if ( joystick . GetRawButtonPressed ( 0 )) { if ( toggle ) { // Current state is true so turn off retractIntake (); toggle = false ; } else { // Current state is false so turn on deployIntake (); toggle = true ; } } PYTHON toggle = False if joystick . getRawButtonPressed ( 0 ): if toggle : # current state is True so turn off retractIntake () toggle = False else : # Current state is False so turn on deployIntake () toggle = True",
      "content_preview": "Joysticks A joystick can be used with the Driver Station program to control the robot. Almost any “controller” that can be recognized by Windows can be used as a joystick. Joysticks are accessed using the GenericHID class. This class has three relevant subclasses for preconfigured joysticks."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/index.html",
      "title": "Basic Programming",
      "section": "Basic Programming",
      "language": "Java",
      "content": "Basic Programming Git Version Control Introduction The C++ Units Library The Java Units Library Joysticks Coordinate System Setting Robot Preferences Robot Project Deploy Directory Using Test Mode Reading Stacktraces Treating Functions as Data Get Alliance Color Java Garbage Collection",
      "content_preview": "Basic Programming Git Version Control Introduction The C++ Units Library The Java Units Library Joysticks Coordinate System Setting Robot Preferences Robot Project Deploy Directory Using Test Mode Reading Stacktraces Treating Functions as Data Get Alliance Color Java Garbage Collection"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/coordinate-system.html",
      "title": "Coordinate System",
      "section": "Basic Programming",
      "language": "All",
      "content": "Coordinate System Coordinate systems are used in FRC programming in several places. A few of the common places are: robot movement, joystick input, pose estimation, AprilTags, and path planning. It is important to understand the basics of the coordinate system used throughout WPILib and other common tools for programming an FRC robot, such as PathPlanner. Many teams intuitively think of a coordinate system that is different from what is used in WPILib, and this leads to problems that need to be tracked down throughout the season. It is worthwhile to take a few minutes to understand the coordinate system, and come back here as a reference when programming. It’s not very difficult to get robot movement with a joystick working without getting the coordinate system right, but it will be much more difficult to build on code using a different coordinate system to add pose estimation with AprilTags and path planning for autonomous. WPILib coordinate system In most cases, WPILib uses the NWU axes convention (North-West-Up as external reference in the world frame.) In the NWU axes convention, where the positive X axis points ahead, the positive Y axis points left, and the positive Z axis points up referenced from the floor. When viewed with each positive axis pointing toward you, counter-clockwise (CCW) is a positive value and clockwise (CW) is a negative value. Robot coordinate system in three dimensions The figure above shows the coordinate system in relation to an FRC robot. The figure below shows this same coordinate system when viewed from the top (with the Z axis pointing toward you.) This is how you can think of the robot’s coordinates in 2D. Robot coordinate system in two dimensions Rotation conventions In most cases in WPILib programming, 0° is aligned with the positive X axis, and 180° is aligned with the negative X axis. CCW rotation is positive, so 90° is aligned with the positive Y axis, and -90° is aligned with the negative Y axis. Unit circle with common angles The figure above shows the unit circle with common angles labeled in degrees (°) and radians (rad). Notice that rotation to the right is negative, and the range for the whole unit circle is -180° to 180° (-Pi radians to Pi radians). Note The range is (-180, 180], meaning it is exclusive of -180° and inclusive of 180°. There are some places you may choose to use a different range, such as 0° to 360° or 0 to 1 rotation, but be aware that many core WPILib classes and FRC tools are built with the unit circle above. Warning Some gyroscope and IMU models use CW positive rotation, such as the NavX IMU. Care must be taken to handle rotation properly, sensor values may need to be inverted. Read the documentation and verify that rotation is CCW positive. Warning Many sensors that read rotation around an axis, such as encoders and IMU’s, read continuously. This means they read more than one rotation, so when rotating past 180° they read 181°, not -179°. Some sensors have configuration settings where you can choose their wrapping behavior and range, while others need to be handled in your code. Careful attention should be paid to make sure sensor readings are consistent and your control loop handles wrapping in the same way as your sensor. Joystick and controller coordinate system Joysticks, including the sticks on controllers, don’t use the same NWU coordinate system. They use the NED (North-East-Down) convention, where the positive X axis points ahead, the positive Y axis points right, and the positive Z axis points down. When viewed with each positive axis pointing toward you, counter-clockwise (CCW) is a positive value and clockwise (CW) is a negative value. Joystick coordinate system It’s important to note that joystick input values are rotations around an axis, not translations. In practical terms, this means: pushing forward on the joystick (toward the positive X axis) is a CW rotation around the Y axis, so you get a negative Y value. pushing to the right (toward the positive Y axis) is a CCW rotation around the X axis, so you get a positive X value. twisting the joystick CW (toward the positive Y axis) is a CCW rotation around the Z axis, so you get a positive Z value. Using Joystick and controller input to drive a robot You may have noticed, the coordinate system used by WPILib for the robot is not the same as the coordinate system used for joysticks and controllers. Care needs to be taken to understand the difference, and properly pass driver input to the drive subsystem. Differential drivetrain example Differential drivetrains are non-holonomic, which means the robot drivetrain cannot move side-to-side (strafe). This type of drivetrain can move forward and backward along the X axis, and rotate around the Z axis. Consider a common arcade drive scheme using a single joystick where the driver pushes the joystick forward/backward for forward/backward robot movement, and push the joystick left/right to rotate the robot left/right. The code snippet below uses the DifferentialDrive and Joystick classes to drive the robot with the arcade scheme described above. DifferentialDrive uses the robot coordinate system defined above, and Joystick uses the joystick coordinate system. JAVA public void teleopPeriodic () { // Arcade drive with a given forward and turn rate myDrive . arcadeDrive ( - driveStick . getY (), - driveStick . getX ()); } C++ void TeleopPeriodic () override { // Arcade drive with a given forward and turn rate myDrive . ArcadeDrive ( - driveStick . GetY (), - driveStick . GetX ()); } PYTHON def teleopPeriodic ( self ): # Arcade drive with a given forward and turn rate self . myDrive . arcadeDrive ( - self . driveStick . getY (), - self . driveStick . getX ()) The code calls the DifferentialDrive.arcadeDrive(xSpeed, zRotation) method, with values it gets from the Joystick class: The first argument is xSpeed Robot: xSpeed is the speed along the robot’s X axis, which is forward/backward. Joystick: The driver sets forward/backward speed by rotating the joystick along its Y axis, which is pushing the joystick forward/backward. Code: Moving the joystick forward is negative Y rotation, whereas moving the robot forward is along the positive X axis. This means the joystick value needs to be inverted by placing a - (minus sign) in front of the value. The second argument is zRotation Robot: zRotation is the speed of rotation along the robot’s Z axis, which is rotating left/right. Joystick: The driver sets rotation speed by rotating the joystick along its X axis, which is pushing the joystick left/right. Code: Moving the joystick to the right is positive X rotation, whereas robot rotation is CCW positive. This means the joystick value needs to be inverted by placing a - (minus sign) in front of the value. Mecanum drivetrain example Mecanum drivetrains are holonomic, meaning they have the ability to move side-to-side. This type of drivetrain can move forward/backward and rotate around the Z axis like differential drivetrains, but it can also move side-to-side along the robot’s Y axis. Consider a common arcade drive scheme using a single joystick where the driver pushes the joystick forward/backward for forward/backward robot movement, pushes the joystick left/right to move side-to-side, and twists the joystick to rotate the robot. JAVA public void teleopPeriodic () { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . getY (), - m_stick . getX (), - m_stick . getZ ()); } C++ void TeleopPeriodic () override { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . GetY (), - m_stick . GetX (), - m_stick . GetZ ()); } PYTHON def teleopPeriodic ( self ): // Drive using the X , Y , and Z axes of the joystick . self . robotDrive . driveCartesian ( - self . stick . getY (), - self . stick . getX (), - self . stick . getZ ()) The code calls the MecanumDrive.driveCartesian(xSpeed, ySpeed, zRotation) method, with values it gets from the Joystick class: The first argument is xSpeed Robot: xSpeed is the speed along the robot’s X axis, which is forward/backward. Joystick: The driver sets forward/backward speed by rotating the joystick along its Y axis, which is pushing the joystick forward/backward. Code: Moving the joystick forward is negative Y rotation, whereas robot forward is along the positive X axis. This means the joystick value needs to be inverted by placing a - (minus sign) in front of the value. The second argument is ySpeed Robot: ySpeed is the speed along the robot’s Y axis, which is left/right. Joystick: The driver sets left/right speed by rotating the joystick along its X axis, which is pushing the joystick left/right. Code: Moving the joystick to the right is positive X rotation, whereas robot right is along the negative Y axis. This means the joystick value needs to be inverted by placing a - (minus sign) in front of the value. The third argument is zRotation Robot: zRotation is the speed of rotation along the robot’s Z axis, which is rotating left/right. Joystick: The driver sets rotation speed by twisting the joystick along its Z axis, which is twisting the joystick left/right. Code: Twisting the joystick to the right is positive Z rotation, whereas robot rotation is CCW positive. This means the joystick value needs to be inverted by placing a - (minus sign) in front of the value. Swerve drivetrain example Like mecanum drivetrains, swerve drivetrains are holonomic and have the ability to move side-to-side. Joystick control can be handled the same way for all holonomic drivetrains, but WPILib doesn’t have a built-in robot drive class for swerve. Swerve coding is described in other sections of this documentation, but an example of using joystick input to set ChassisSpeeds values is included below. Consider the same common arcade drive scheme described in the mecanum section above. The scheme uses a single joystick where the driver pushes the joystick forward/backward for forward/backward robot movement, pushes the joystick left/right to move side-to-side, and twists the joystick to rotate the robot. JAVA // Drive using the X, Y, and Z axes of the joystick. var speeds = new ChassisSpeeds ( - m_stick . getY (), - m_stick . getX (), - m_stick . getZ ()); C++ // Drive using the X, Y, and Z axes of the joystick. frc :: ChassisSpeeds speeds { - m_stick . GetY (), - m_stick . GetX (), - m_stick . GetZ ()}; PYTHON # Drive using the X, Y, and Z axes of the joystick. speeds = ChassisSpeeds ( - self . stick . getY (), - self . stick . getX (), - self . stick . getZ ()) The three arguments to the ChassisSpeeds constructor are the same as driveCartesian in the mecanum section above; xSpeed , ySpeed , and zRotation . See the description of the arguments, and their joystick input in the section above. Robot drive kinematics Kinematics is a topic that is covered in a different section , but it’s worth discussing here in relation to the coordinate system. It is critically important that kinematics is configured using the coordinate system described above. Kinematics is a common starting point for coordinate system errors that then cascade to basic drivetrain control, field oriented driving, pose estimation, and path planning. When you construct a SwerveDriveKinematics or MecanumDriveKinematics object, you specify a translation from the center of your robot to each wheel. These translations use the coordinate system above, with the origin in the center of your robot. Kinematics with translation signs For the robot in the diagram above, let’s assume the distance between the front and rear wheels (wheelbase) is 2’. Let’s also assume the distance between the left and right wheels (trackwidth) is also 2’. Our translations (x, y) would be like this: Front left: (1’, 1’) Front right: (1’, -1’) Rear left: (-1’, 1’) Rear right: (-1’, -1’) Warning A common error is to use an incorrect coordinate system where the positive Y axis points forward on the robot. The correct coordinate system has the positive X axis pointing forward. Field coordinate systems The field coordinate system (or global coordinate system) is an absolute coordinate system where a point on the field is designated as the origin. Two common uses of the field coordinate system will be explored in this document: Field oriented driving is a drive scheme for holonomic drivetrains, where the driver moves the controls relative to their perspective of the field, and the robot moves in that direction regardless of where the front of the robot is facing. For example, a driver on the red alliance pushes the joystick forward, the robot will move downfield toward the blue alliance wall, even if the robot’s front is facing the driver. Pose estimation with odometry and/or AprilTags are used to estimate the robot’s pose on the field. Mirrored field vs. rotated field Historically, FRC has used two types of field layouts in relation to the red and blue alliance. Games such as Rapid React in 2022 used a rotated layout. A rotated layout means that, from your perspective from behind your alliance wall, your field elements and your opponent’s elements are in the same location. Notice in the Rapid React field layout diagram below, whether you are on the red or blue alliance, your human player station is on your right and your hanger is on your left. Rotated field from RAPID REACT in 2022 [ 1 ] Games such as CHARGED UP in 2023 and CRESCENDO in 2024 used a mirrored layout. A mirrored layout means that the red and blue alliance layout are mirrored across the centerpoint of the field. Refer to the CHARGED UP field diagram below. When you are standing behind the blue alliance wall, the charge station is on the right side of the field from your perspective. However, standing behind the red alliance wall, the charge station is on the left side of the field from your perspective. Mirrored field from CHARGED UP in 2023 [ 2 ] Dealing with red or blue alliance There are two primary ways many teams choose to define the field coordinate system. In both methods, positive rotation (theta) is in the counter-clockwise (CCW) direction. Warning There are cases where your alliance may change (or appear to change) after the code is initialized. When you are not connected to the FMS at a competition, you can change your alliance station in the Driver Station application at any time. Even when you are at a competition, your robot will usually initialize before connecting to the FMS so you will not have alliance information. Note At competition events, the FMS will automatically report your Team Station and alliance color. When you are not connected to an FMS, you can choose your Team Station and alliance color on the Driver Station Operation Tab . Always blue origin You may choose to define the origin of the field on the blue side, and keep it there regardless of your alliance color. With this solution, positive x-axis points away from the blue alliance wall. CHARGED UP with blue origin Some advantages to this approach are: Pose estimation with AprilTags is simplified. AprilTags throughout the field are unique. If you keep the coordinate system the same regardless of alliance, there is no need for special logic to deal with the location of AprilTags on the field relative to your alliance. Many of the tools and libraries used in FRC follow this convention. Some of the tools include: PathPlanner, Choreo, and the ShuffleBoard and Glass Field2d widget. In order to use this approach for field oriented driving, driver input needs to consider the alliance color. When your alliance is red and the driver is standing behind the red alliance wall, they will want the robot to move downfield toward the blue alliance wall. However, when your alliance is blue, the driver will want the robot to go downfield toward the red alliance wall. A simple way to deal with field oriented driving is to check the alliance color reported by the DriverStation class, and invert the driver’s controls based on the alliance. As noted above, your alliance color can change so it needs to be checked on every robot iteration. JAVA // The origin is always blue. When our alliance is red, X and Y need to be inverted var alliance = DriverStation . getAlliance (); var invert = 1 ; if ( alliance . isPresent () && alliance . get () == Alliance . Red ) { invert = - 1 ; } // Create field relative ChassisSpeeds for controlling Swerve var chassisSpeeds = ChassisSpeeds . fromFieldRelativeSpeeds ( xSpeed * invert , ySpeed * invert , zRotation , imu . getRotation2d ()); // Control a mecanum drivetrain m_robotDrive . driveCartesian ( xSpeed * invert , ySpeed * invert , zRotation , imu . getRotation2d ()); C++ // The origin is always blue. When our alliance is red, X and Y need to be inverted int invert = 1 ; if ( frc :: DriverStation :: GetAlliance () == frc :: DriverStation :: Alliance :: kRed ) { invert = -1 ; } // Create field relative ChassisSpeeds for controlling Swerve frc :: ChassisSpeeds chassisSpeeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( xSpeed * invert , ySpeed * invert , zRotation , imu . GetRotation2d ()); // Control a mecanum drivetrain m_robotDrive . driveCartesian ( xSpeed * invert , ySpeed * invert , zRotation , imu . GetRotation2d ()); PYTHON # The origin is always blue. When our alliance is red, X and Y need to be inverted invert = 1 if wpilib . DriverStation . getAlliance () == wpilib . DriverStation . Alliance . kRed : invert = - 1 # Create field relative ChassisSpeeds for controlling Swerve chassis_speeds = wpilib . ChassisSpeeds . FromFieldRelativeSpeeds ( xSpeed * invert , ySpeed * invert , zRotation , self . imu . GetAngle () ) # Control a mecanum drivetrain self . robotDrive . driveCartesian ( xSpeed * invert , ySpeed * invert , zRotation , self . imu . GetAngle ()) Origin follows your alliance You may choose to define the origin of the field based on the alliance you are one. With this approach, the positive x-axis always points away from your alliance wall. When you are on the blue alliance, your origin looks like this: CHARGED UP field with blue alliance as origin When you are on the red alliance, your origin looks like this: CHARGED UP field with red alliance as origin This approach has a few more complications than the previous approach, especially in years when the field layout is mirrored between alliances. In years when the field layout is rotated, this is a simple approach if you are not using AprilTags for pose estimation or doing other advanced techniques. When the field layout is rotated, the field elements appear at the same coordinates regardless of your alliance. Some things you need to consider when using this approach are: As warned above, your alliance color can change after initialization. If you are not using AprilTags, you may not have anything to adjust when the alliance changes. However, if you are using AprilTags and your robot has seen a tag and used it for pose estimation, you will need to adjust your origin and reset your estimated pose. The field image in the ShuffleBoard and Glass Field2d widget follows the Always blue origin approach. Special handling is needed to display your robot pose correctly when your alliance is red. You will need to change the origin for your estimated pose to the blue alliance coordinate system before sending it to the dashboard. [ 1 ] Rapid React field image from MikLast on Chiefdelphi https://www.chiefdelphi.com/t/2022-top-down-field-renders/399031 [ 2 ] CHARGED UP field image from MikLast on Chiefdelphi https://www.chiefdelphi.com/t/2023-top-down-field-renders/421365",
      "content_preview": "Coordinate System Coordinate systems are used in FRC programming in several places. A few of the common places are: robot movement, joystick input, pose estimation, AprilTags, and path planning."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/joystick.html?present",
      "title": "Joysticks",
      "section": "Basic Programming",
      "language": "All",
      "content": "Joysticks A joystick can be used with the Driver Station program to control the robot. Almost any “controller” that can be recognized by Windows can be used as a joystick. Joysticks are accessed using the GenericHID class. This class has three relevant subclasses for preconfigured joysticks. You may also implement your own for other controllers by extending GenericHID . The first is Joystick which is useful for standard flight joysticks. The second is XboxController which works for the Xbox 360, Xbox One, or Logitech F310 (in XInput mode). Finally, the PS4Controller class is ideal for using that controller. Each axis of the controller ranges from -1 to 1. The command based way to use the these classes is detailed in the section: Binding Commands to Triggers . Driver Station Joysticks The USB Devices Tab of the Driver Station is used to setup and configure the joystick for use with the robot. Pressing a button on a joystick will cause its entry in the table to light up green. Selecting the joystick will show the values of axes, buttons, and the POV that can be used to determine the mapping between physical joystick features and axis or button numbers. The USB Devices Tab also assigns a joystick index to each joystick. To reorder the joysticks simply click and drag. The Driver Station software will try to preserve the ordering of devices between runs. It is a good idea to note what order your devices should be in and check each time you start the Driver Station software that they are correct. When the Driver Station is in disabled mode, it is routinely looking for status changes on the joystick devices. Unplugged devices are removed from the list and new devices are opened and added. When not connected to the FMS, unplugging a joystick will force the Driver Station into disabled mode. To start using the joystick again: plug the joystick in, check that it shows up in the right spot, then re-enable the robot. While the Driver Station is in enabled mode, it will not scan for new devices. This is a time consuming operation and timely update of signals from attached devices takes priority. Note For some joysticks the startup routine will read whatever position the joysticks are in as the center position, therefore, when the computer is turned on (or when the joystick is plugged in) the joysticks should be at their center position. When the robot is connected to the Field Management System at competition, the Driver Station mode is dictated by the FMS . This means that you cannot disable your robot and the DS cannot disable itself in order to detect joystick changes. A manual complete refresh of the joysticks can be initiated by pressing the F1 key on the keyboard. Note that this will close and re-open all devices, so all devices should be in their center position as noted above. Joystick Class JAVA Joystick exampleJoystick = new Joystick ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ Joystick exampleJoystick { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON exampleJoystick = wpilib . Joystick ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The Joystick class is designed to make using a flight joystick to operate the robot significantly easier. Depending on the flight joystick, the user may need to set the specific X, Y, Z, and Throttle channels that your flight joystick uses. This class offers special methods for accessing the angle and magnitude of the flight joystick. Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. XboxController Class JAVA XboxController exampleXbox = new XboxController ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ XboxController exampleXbox { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON exampleXbox = wpilib . XboxController ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The XboxController class provides named methods (e.g. getXButton , getXButtonPressed , getXButtonReleased ) for each of the buttons, and the indices can be accessed with XboxController.Button.kX.value . The rumble feature of the controller can be controlled by using XboxController.setRumble(GenericHID.RumbleType.kRightRumble, value) . Many users do a split stick arcade drive that uses the left stick for just forwards / backwards and the right stick for left / right turning. Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. PS4Controller Class JAVA PS4Controller examplePS4 = new PS4Controller ( 0 ); // 0 is the USB Port to be used as indicated on the Driver Station C++ PS4Controller examplePS4 { 0 }; // 0 is the USB Port to be used as indicated on the Driver Station PYTHON examplePS4 = wpilib . PS4Controller ( 0 ) # 0 is the USB Port to be used as indicated on the Driver Station The PS4Controller class provides named methods (e.g. getSquareButton , getSquareButtonPressed , getSquareButtonReleased ) for each of the buttons, and the indices can be accessed with PS4Controller.Button.kSquare.value . The rumble feature of the controller can be controlled by using PS4Controller.setRumble(GenericHID.RumbleType.kRightRumble, value) . Important Due to differences in coordinate systems, teams usually negate the values when reading joystick axes. See the Joystick and controller coordinate system section for more detail. POV On joysticks, the POV is a directional hat that can select one of 8 different angles or read -1 for unpressed. The XboxController/PS4Controller D-pad works the same as a POV. Be careful when using a POV with exact angle requirements as it is hard for the user to ensure they select exactly the angle desired. GenericHID Usage An axis can be used with .getRawAxis(int index) (if not using any of the classes above) that returns the current value. Zero and one in this example are each the index of an axis as found in the Driver Station mentioned above. JAVA private final PWMSparkMax m_leftMotor = new PWMSparkMax ( Constants . kLeftMotorPort ); private final PWMSparkMax m_rightMotor = new PWMSparkMax ( Constants . kRightMotorPort ); private final DifferentialDrive m_robotDrive = new DifferentialDrive ( m_leftMotor :: set , m_rightMotor :: set ); private final GenericHID m_stick = new GenericHID ( Constants . kJoystickPort ); m_robotDrive . arcadeDrive ( - m_stick . getRawAxis ( 0 ), m_stick . getRawAxis ( 1 )); C++ frc :: PWMVictorSPX m_leftMotor { Constants :: kLeftMotorPort }; frc :: PWMVictorSPX m_rightMotor { Constants :: kRightMotorPort }; frc :: DifferentialDrive m_robotDrive {[ & ]( double output ) { m_leftMotor . Set ( output ); }, [ & ]( double output ) { m_rightMotor . Set ( output ); }}; frc :: GenericHID m_stick { Constants :: kJoystickPort }; m_robotDrive . ArcadeDrive ( - m_stick . GetRawAxis ( 0 ), m_stick . GetRawAxis ( 1 )); PYTHON leftMotor = wpilib . PWMVictorSPX ( LEFT_MOTOR_PORT ) rightMotor = wpilib . PWMVictorSPX ( RIGHT_MOTOR_PORT ) self . robotDrive = wpilib . drive . DifferentialDrive ( leftMotor , rightMotor ) self . stick = wpilib . GenericHID ( JOYSTICK_PORT ) self . robotDrive . arcadeDrive ( - self . stick . getRawAxis ( 0 ), self . stick . getRawAxis ( 1 )) Button Usage Note Usage such as the following is for code not using the command-based framework. For button usage in the command-based framework, see Binding Commands to Triggers . Unlike an axis, you will usually want to use the pressed and released methods to respond to button input. These will return true if the button has been activated since the last check. This is helpful for taking an action once when the event occurs but not having to continuously do it while the button is held down. JAVA if ( joystick . getRawButtonPressed ( 0 )) { turnIntakeOn (); // When pressed the intake turns on } if ( joystick . getRawButtonReleased ( 0 )) { turnIntakeOff (); // When released the intake turns off } // OR if ( joystick . getRawButton ( 0 )) { turnIntakeOn (); } else { turnIntakeOff (); } C++ if ( joystick . GetRawButtonPressed ( 0 )) { turnIntakeOn (); // When pressed the intake turns on } if ( joystick . GetRawButtonReleased ( 0 )) { turnIntakeOff (); // When released the intake turns off } // OR if ( joystick . GetRawButton ( 0 )) { turnIntakeOn (); } else { turnIntakeOff (); } PYTHON if joystick . getRawButtonPressed ( 0 ): turnIntakeOn () # When pressed the intake turns on if joystick . getRawButtonReleased ( 0 ): turnIntakeOff () # When released the intake turns off # OR if joystick . getRawButton ( 0 ): turnIntakeOn () else : turnIntakeOff () A common request is to toggle something on and off with the press of a button. Toggles should be used with caution, as they require the user to keep track of the robot state. JAVA boolean toggle = false ; if ( joystick . getRawButtonPressed ( 0 )) { if ( toggle ) { // Current state is true so turn off retractIntake (); toggle = false ; } else { // Current state is false so turn on deployIntake (); toggle = true ; } } C++ bool toggle { false }; if ( joystick . GetRawButtonPressed ( 0 )) { if ( toggle ) { // Current state is true so turn off retractIntake (); toggle = false ; } else { // Current state is false so turn on deployIntake (); toggle = true ; } } PYTHON toggle = False if joystick . getRawButtonPressed ( 0 ): if toggle : # current state is True so turn off retractIntake () toggle = False else : # Current state is False so turn on deployIntake () toggle = True",
      "content_preview": "Joysticks A joystick can be used with the Driver Station program to control the robot. Almost any “controller” that can be recognized by Windows can be used as a joystick. Joysticks are accessed using the GenericHID class. This class has three relevant subclasses for preconfigured joysticks."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/driverstation/driver-station.html",
      "title": "FRC Driver Station Powered by NI LabVIEW",
      "section": "General",
      "language": "All",
      "content": "FRC Driver Station Powered by NI LabVIEW This article describes the use and features of the FRC® Driver Station Powered by NI LabVIEW. For information on installing the Driver Station software see this document . Starting the FRC Driver Station The FRC Driver Station can be launched by double-clicking the icon on the Desktop or by selecting Start->All Apps->FRC Driver Station. Note By default the FRC Driver Station launches the LabVIEW Dashboard . It can also be configured on Setup Tab to launch the other Dashboards: SmartDashboard and Shuffleboard . WPILib must be installed to use SmartDashboard and Shuffleboard. Driver Station Key Shortcuts F1 - Force a Joystick refresh. [ + ] + \\ - Enable the robot (the 3 keys above Enter on most keyboards) Enter - Disable the Robot Space - Emergency Stop the robot. After an emergency stop is triggered the roboRIO will need to be rebooted before the robot can be enabled again. Backspace - “A-Stop” the robot when in Practice Mode - Autonomous Enabled. The robot will be disabled until the Practice Mode reaches Teleop then will be automatically re-enabled. While disabled, the application background will flash orange indicating the robot will re-enable automatically. Driver Station flashing orange in A-Stop mode Note Space bar will E-Stop the robot regardless of if the Driver Station window has focus or not Warning When connected to FMS in a match, teams must press the Team Station E-Stop button to emergency stop their robot as the DS enable/disable and E-Stop key shortcuts are ignored. Setting Up the Driver Station The DS should be set to your team number in order to connect to your robot. In order to do this click the Setup tab then enter your team number in the team number box. Press return or click outside the box for the setting to take effect. PCs will typically have the correct network settings for the DS to connect to the robot already, but if not, make sure your Network adapter is set to DHCP . Status Pane The Status Pane of the Driver Station is located in the center of the display and is always visible regardless of the tab selected. It displays a selection of critical information about the state of the DS and robot: Team # - The Team number the DS is currently configured for. This should match your FRC team number. To change the team number see the Setup Tab. Battery Voltage - If the DS is connected and communicating with the roboRIO this displays current battery voltage as a number and with a small chart of voltage over time in the battery icon. The background of the numeric indicator will turn red when the roboRIO brownout is triggered. See roboRIO Brownout and Understanding Current Draw for more information. Major Status Indicators - These three indicators display major status items for the DS. The “Communications” indicates whether the DS is currently communicating with the FRC Network Communications Task on the roboRIO (it is split in half for the TCP and UDP communication). The “Robot Code” indicator shows whether the team Robot Code is currently running (determined by whether or not the Driver Station Task in the robot code is updating the battery voltage), The “Joysticks” indicator shows if at least one joystick is plugged in and recognized by the DS. Status String - The Status String provides an overall status message indicating the state of the robot. Some examples are “No Robot Communication”, “No Robot Code”, “Emergency Stopped”, and “Teleoperated Enabled”. When the roboRIO brownout is triggered this will display “Voltage Brownout”. Operation Tab The Operations Tab is used to control the mode of the robot and provide additional key status indicators while the robot is running. Robot Mode - This section controls the Robot Mode. Teleoperated Mode causes the robot to run the code in the Teleoperated portion of the match. Autonomous Mode causes the robot to run the code in the Autonomous portion of the match. Practice Mode causes the robot to cycle through the same transitions as an FRC match after the Enable button is pressed (timing for practice mode can be found on the setup tab). When Practice Mode is in use, the DS will flash the background orange to indicate a pending enable (either the start of Autonomous or the start of Teleop after an A-Stop). Test Mode is an additional mode where test code that doesn’t run in a regular match can be tested. Enable/Disable - These controls enable and disable the robot. See also Driver Station Key Shortcuts . Elapsed Time - Indicates the amount of time the robot has been enabled. PC Battery - Indicates current state of DS PC battery and whether the PC is plugged in. PC CPU% - Indicates the CPU Utilization of the DS PC. Window Mode - When not on the Driver account on the Classmate allows the user to toggle between floating (arrow) and docked (rectangle). Team Station - When not connected to FMS, sets the team station to transmit to the robot. Note When connected to the Field Management System the controls in sections 1 and 2 will be replaced by the words FMS Connected and the control in Section 7 will be greyed out. Diagnostics Tab The Diagnostics Tab contains additional status indicators that teams can use to diagnose issues with their robot: DS Version - Indicates the Driver Station Version number. roboRIO Image Version - String indicating the version of the roboRIO Image. WPILib Version - String indicating the version of WPILib in use. CAN Device Versions - String indicating the firmware version of devices connected to the CAN bus. These items may not be present if the CTRE Phoenix Framework has not been loaded. Memory Stats - This section shows stats about the roboRIO memory. Connection Indicators - The top half of these indicators show connection status to various components. “Enet Link” indicates the computer has something connected to the ethernet port. “Robot Radio” indicates the ping status to the robot wireless bridge at 10.XX.YY.1. “Robot” indicates the ping status to the roboRIO using mDNS (with a fallback of a static 10.TE.AM.2 address). “FMS” indicates if the DS is receiving packets from FMS (this is NOT a ping indicator). Network Indicators - The second section of indicators indicates status of network adapters and firewalls. These are provided for informational purposes; communication may be established even with one or more unlit indicators in this section. “Enet” indicates the IP address of the detected Ethernet adapter “WiFi” indicates if a wireless adapter has been detected as enabled “USB” indicates if a roboRIO USB connection has been detected “Firewall” indicates if any firewalls are detected as enabled. Enabled firewalls will show in orange (Dom = Domain, Pub = Public, Prv = Private) Reboot roboRIO - This button attempts to perform a remote reboot of the roboRIO (after clicking through a confirmation dialog). Restart Robot Code - This button attempts to restart the code running on the robot (but not restart the OS). Setup Tab The Setup Tab contains a number of buttons teams can use to control the operation of the Driver Station: Team Number - Should contain your FRC Team Number. This controls the mDNS name that the DS expects the robot to be at. Shift clicking on the dropdown arrow will show all roboRIO names detected on the network for troubleshooting purposes. Dashboard Type - Controls what Dashboard is launched by the Driver Station. Default launches the file pointed to by the “FRC DS Data Storage.ini” (for more information about setting a custom dashboard ). By default this is Dashboard.exe in the Program Files (x86)\\FRC Dashboard folder. LabVIEW attempts to launch a dashboard at the default location for a custom built LabVIEW dashboard, but will fall back to the default if no dashboard is found. SmartDashboard and Shuffleboard launch the respective dashboards included with the C++ and Java WPILib installation. Remote forwards LabVIEW dashboard data to the IP specified in Dashboard IP field. Game Data - This box can be used for at home testing of the Game Data API. Text entered into this box will appear in the Game Data API on the Robot Side. When connected to FMS, this data will be populated by the field automatically. Practice Mode Timing - These boxes control the timing of each portion of the practice mode sequence. When the robot is enabled in practice mode the DS automatically proceeds through the modes indicated from top to bottom. Audio Control - This button controls whether audio tones are sounded when the Practice Mode is used. USB Devices Tab The USB Devices tab includes the information about the USB Devices connected to the DS USB Setup List - This contains a list of all compatible USB devices connected to the DS. Pressing a button on a device will highlight the name in green and put 2 *s before the device name Rescan - This button will force a Rescan of the USB devices. While the robot is disabled, the DS will automatically scan for new devices and add them to the list. To force a complete re-scan or to re-scan while the robot is Enabled (such as when connected to FMS during a match) press F1 or use this button. Device indicators - These indicators show the current status of the Axes, buttons, and POV of the joystick. Rumble - For XInput devices (such as X-Box controllers) the Rumble control will appear. This can be used to test the rumble functionality of the device. The top bar is “Right Rumble” and the bottom bar is “Left Rumble”. Clicking and holding anywhere along the bar will activate the rumble proportionally (left is no rumble = 0, right is full rumble = 1). This is a control only and will not indicate the Rumble value set in robot code. Re-Arranging and Locking Devices The Driver Station has the capability of “locking” a USB device into a specific slot. This is done automatically if the device is dragged to a new position and can also be triggered by double clicking on the device. “Locked” devices will show up with an underline under the device. A locked device will reserve its slot even when the device is not connected to the computer (shown as grayed out and underlined). Devices can be unlocked (and unconnected devices removed) by double clicking on the entry. Note If you have two or more of the same device, they should maintain their position as long as all devices remain plugged into the computer in the same ports they were locked in. If you switch the ports of two identical devices the lock should follow the port, not the device. If you re-arrange the ports (take one device and plug it into a new port instead of swapping) the behavior is not determinate (the devices may swap slots). If you unplug one or more of the set of devices, the positions of the others may move; they should return to the proper locked slots when all devices are reconnected. Example: The image above shows 4 devices: A Locked “Logitech Attack 3” joystick. This device will stay in this position unless dragged somewhere else or unlocked An unlocked “Logitech Extreme 3D” joystick An unlocked “Gamepad F310 (Controller)” which is a Logitech F310 gamepad A Locked, but disconnected “MadCatz GamePad (Controller)” which is a MadCatz Xbox 360 Controller In this example, unplugging the Logitech Extreme 3D joystick will result in the F310 Gamepad moving up to slot 1. Plugging in the MadCatz Gamepad (even if the devices in Slots 1 and 2 are removed and those slots are empty) will result in it occupying Slot 3. CAN/Power Tab The last tab on the left side of the DS is the CAN/Robot Power Tab. This tab contains information about the power status of the roboRIO and the status of the CAN bus: Comms Faults - Indicates the number of Comms faults that have occurred since the DS has been connected 12V Faults - Indicates the number of input power faults (Brownouts) that have occurred since the DS has been connected 6V/5V/3.3V Faults - Indicates the number of faults (typically caused by short circuits) that have occurred on the User Voltage Rails since the DS has been connected CAN Bus Utilization - Indicates the percentage utilization of the CAN bus CAN faults - Indicates the counts of each of the 4 types of CAN faults since the DS has been connected If a fault is detected, the indicator for this tab (shown in blue in the image above) will turn red. Messages Tab The Messages tab displays diagnostic messages from the DS, WPILib, User Code, and/or the roboRIO. To access settings for the Messages tab, click the Gear icon. This will display a menu that will allow you to clear the box, launch a larger Console window for viewing messages, launch the DS Log Viewer, launch a viewer for program timing, or download log files from the robot. Charts Tab The Charts tab plots and displays advanced indicators of robot status to help teams diagnose robot issues: The top graph charts trip time in milliseconds in green (against the axis on the right) and lost packets per second in orange (against the axis on the left). The bottom graph plots battery voltage in yellow (against the axis on the left), roboRIO CPU in red (against the axis on the right), DS Requested mode as a continuous line on the bottom of the chart and robot mode as a discontinuous line above it. This key shows the colors used for the DS Requested and Robot Reported modes in the bottom chart. Chart scale - These controls change the time scale of the DS Charts. This button launches the DS Log File Viewer . The DS Requested mode is the mode that the Driver Station is commanding the robot to be in. The Robot Reported mode is what code is actually running based on reporting methods contained in the coding frameworks for each language. Both Tab The last tab on the right side is the Both tab which displays Messages and Charts side by side.",
      "content_preview": "FRC Driver Station Powered by NI LabVIEW This article describes the use and features of the FRC® Driver Station Powered by NI LabVIEW. For information on installing the Driver Station software see this document ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/index.html?present",
      "title": "Command",
      "section": "Command-Based Programming",
      "language": "Java",
      "content": "Command-Based Programming This sequence of articles serves as an introduction to and reference for the WPILib command-based framework. For a collection of example projects using the command-based framework, see Command-Based Examples . What Is “Command-Based” Programming? Commands Command Compositions Subsystems Binding Commands to Triggers Structuring a Command-Based Robot Project Organizing Command-Based Robot Projects The Command Scheduler A Technical Discussion on C++ Commands PID Control in Command-based Motion Profiling in Command-based Combining Motion Profiling and PID in Command-Based Passing Functions As Parameters In order to provide a concise inline syntax, the command-based library often accepts functions as parameters of constructors, factories, and decorators. Fortunately, both Java and C++ offer users the ability to pass functions as objects : Method References (Java) In Java, a reference to a function that can be passed as a parameter is called a method reference. The general syntax for a method reference is object::method or Class::staticMethod . Note that no method parameters are included, since the method itself is passed. The method is not being called - it is being passed to another piece of code (in this case, a command) so that that code can call it when needed. For further information on method references, see Method References . Lambda Expressions (Java) While method references work well for passing a function that has already been written, often it is inconvenient/wasteful to write a function solely for the purpose of sending as a method reference, if that function will never be used elsewhere. To avoid this, Java also supports a feature called “lambda expressions.” A lambda expression is an inline method definition - it allows a function to be defined inside of a parameter list . For specifics on how to write Java lambda expressions, see Lambda Expressions in Java . Lambda Expressions (C++) Warning Due to complications in C++ semantics, capturing this in a C++ lambda can cause a null pointer exception if done from a component command of a command composition. Whenever possible, C++ users should capture relevant command members explicitly and by value. For more details, see here . C++ lacks a close equivalent to Java method references - pointers to member functions are generally not directly usable as parameters due to the presence of the implicit this parameter. However, C++ does offer lambda expressions - in addition, the lambda expressions offered by C++ are in many ways more powerful than those in Java. For specifics on how to write C++ lambda expressions, see Lambda Expressions in C++ .",
      "content_preview": "Command-Based Programming This sequence of articles serves as an introduction to and reference for the WPILib command-based framework. For a collection of example projects using the command-based framework, see Command-Based Examples ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/cpp-command-discussion.html",
      "title": "A Technical Discussion on C++ Commands",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "A Technical Discussion on C++ Commands Note This article assumes that you have a fair understanding of advanced C++ concepts, including templates, smart pointers, inheritance, rvalue references, copy semantics, move semantics, and CRTP. You do not need to understand the information within this article to use the command-based framework in your robot code. This article will help you understand the reasoning behind some of the decisions made in the 2020 command-based framework (such as the use of std::unique_ptr , CRTP in the form of CommandHelper<Base, Derived> , etc.). You do not need to understand the information within this article to use the command-based framework in your robot code. Note The model was further changed in 2023, as described below . Ownership Model The old command-based framework employed the use of raw pointers, meaning that users had to use new (resulting in manual heap allocations) in their robot code. Since there was no clear indication on who owned the commands (the scheduler, the command groups, or the user themselves), it was not apparent who was supposed to take care of freeing the memory. Several examples in the old command-based framework involved code like this: #include \"PlaceSoda.h\" #include \"Elevator.h\" #include \"Wrist.h\" PlaceSoda :: PlaceSoda () { AddSequential ( new SetElevatorSetpoint ( Elevator :: TABLE_HEIGHT )); AddSequential ( new SetWristSetpoint ( Wrist :: PICKUP )); AddSequential ( new OpenClaw ()); } In the command-group above, the component commands of the command group were being heap allocated and passed into AddSequential all in the same line. This meant that user had no reference to that object in memory and therefore had no means of freeing the allocated memory once the command group ended. The command group itself never freed the memory and neither did the command scheduler. This led to memory leaks in robot programs (i.e. memory was allocated on the heap but never freed). This glaring problem was one of the reasons for the rewrite of the framework. A comprehensive ownership model was introduced with this rewrite, along with the usage of smart pointers which will automatically free memory when they go out of scope. Default commands are owned by the command scheduler whereas component commands of command compositions are owned by the command composition. Other commands are owned by whatever the user decides they should be owned by (e.g. a subsystem instance or a RobotContainer instance). This means that the ownership of the memory allocated by any commands or command compositions is clearly defined. std::unique_ptr vs. std::shared_ptr Using std::unique_ptr allows us to clearly determine who owns the object. Because an std::unique_ptr cannot be copied, there will never be more than one instance of a std::unique_ptr that points to the same block of memory on the heap. For example, a constructor for SequentialCommandGroup takes in a std::vector<std::unique_ptr<Command>>&& . This means that it requires an rvalue reference to a vector of std::unique_ptr<Command> . Let’s go through some example code step-by-step to understand this better: // Let's create a vector to store our commands that we want to run sequentially. std :: vector < std :: unique_ptr < Command >> commands ; // Add an instant command that prints to the console. commands . emplace_back ( std :: make_unique < InstantCommand > ([]{ std :: cout << \"Hello\" ; }, requirements )); // Add some other command: this can be something that a user has created. commands . emplace_back ( std :: make_unique < MyCommand > ( args , needed , for , this , command )); // Now the vector \"owns\" all of these commands. In its current state, when the vector is destroyed (i.e. // it goes out of scope), it will destroy all of the commands we just added. // Let's create a SequentialCommandGroup that will run these two commands sequentially. auto group = SequentialCommandGroup ( std :: move ( commands )); // Note that we MOVED the vector of commands into the sequential command group, meaning that the // command group now has ownership of our commands. When we call std::move on the vector, all of its // contents (i.e. the unique_ptr instances) are moved into the command group. // Even if the vector were to be destroyed while the command group was running, everything would be OK // since the vector does not own our commands anymore. With std::shared_ptr , there is no clear ownership model because there can be multiple instances of a std::shared_ptr that point to the same block of memory. If commands were in std::shared_ptr instances, a command group or the command scheduler cannot take ownership and free the memory once the command has finished executing because the user might still unknowingly still have a std::shared_ptr instance pointing to that block of memory somewhere in scope. Use of CRTP You may have noticed that in order to create a new command, you must extend CommandHelper , providing the base class (usually frc2::Command ) and the class that you just created. Let’s take a look at the reasoning behind this: Command Decorators The new command-based framework includes a feature known as “command decorators”, which allows the user to something like this: auto task = MyCommand (). AndThen ([] { std :: cout << \"This printed after my command ended.\" ; }, requirements ); When task is scheduled, it will first execute MyCommand() and once that command has finished executing, it will print the message to the console. The way this is achieved internally is by using a sequential command group. Recall from the previous section that in order to construct a sequential command group, we need a vector of unique pointers to each command. Creating the unique pointer for the print function is pretty trivial: temp . emplace_back ( std :: make_unique < InstantCommand > ( std :: move ( toRun ), requirements )); Here temp is storing the vector of commands that we need to pass into the SequentialCommandGroup constructor. But before we add that InstantCommand , we need to add MyCommand() to the SequentialCommandGroup . How do we do that? temp . emplace_back ( std :: make_unique < MyCommand > ( std :: move ( * this )); You might think it would be this straightforward, but that is not the case. Because this decorator code is in the Command class, *this refers to the Command in the subclass that you are calling the decorator from and has the type of Command . Effectively, you will be trying to move a Command instead of MyCommand . We could cast the this pointer to a MyCommand* and then dereference it but we have no information about the subclass to cast to at compile-time. Solutions to the Problem Our initial solution to this was to create a virtual method in Command called TransferOwnership() that every subclass of Command had to override. Such an override would have looked like this: std :: unique_ptr < Command > TransferOwnership () && override { return std :: make_unique < MyCommand > ( std :: move ( * this )); } Because the code would be in the derived subclass, *this would actually point to the desired subclass instance and the user has the type info of the derived class to make the unique pointer. After a few days of deliberation, a CRTP method was proposed. Here, an intermediary derived class of Command called CommandHelper would exist. CommandHelper would have two template arguments, the original base class and the desired derived subclass. Let’s take a look at a basic implementation of CommandHelper to understand this: // In the real implementation, we use SFINAE to check that Base is actually a // Command or a subclass of Command. template < typename Base , typename Derived > class CommandHelper : public Base { // Here, we are just inheriting all of the superclass (base class) constructors. using Base :: Base ; // Here, we will override the TransferOwnership() method mentioned above. std :: unique_ptr < Command > TransferOwnership () && override { // Previously, we mentioned that we had no information about the derived class // to cast to at compile-time, but because of CRTP we do! It's one of our template // arguments! return std :: make_unique < Derived > ( std :: move ( * static_cast < Derived *> ( this ))); } }; Thus, making your custom commands extend CommandHelper instead of Command will automatically implement this boilerplate for you and this is the reasoning behind asking teams to use what may seem to be a rather obscure way of doing things. Going back to our AndThen() example, we can now do the following: // Because of how inheritance works, we will call the TransferOwnership() // of the subclass. We are moving *this because TransferOwnership() can only // be called on rvalue references. temp . emplace_back ( std :: move ( * this ). TransferOwnership ()); Lack of Advanced Decorators Most of the C++ decorators take in std::function<void()> instead of actual commands themselves. The idea of taking in actual commands in decorators such as AndThen() , BeforeStarting() , etc. was considered but then abandoned due to a variety of reasons. Templating Decorators Because we need to know the types of the commands that we are adding to a command group at compile-time, we will need to use templates (variadic for multiple commands). However, this might not seem like a big deal. The constructors for command groups do this anyway: template < class ... Types , typename = std :: enable_if_t < std :: conjunction_v < std :: is_base_of < Command , std :: remove_reference_t < Types >> ... >>> explicit SequentialCommandGroup ( Types && ... commands ) { AddCommands ( std :: forward < Types > ( commands )...); } template < class ... Types , typename = std :: enable_if_t < std :: conjunction_v < std :: is_base_of < Command , std :: remove_reference_t < Types >> ... >>> void AddCommands ( Types && ... commands ) { std :: vector < std :: unique_ptr < Command >> foo ; (( void ) foo . emplace_back ( std :: make_unique < std :: remove_reference_t < Types >> ( std :: forward < Types > ( commands ))), ...); AddCommands ( std :: move ( foo )); } Note This is a secondary constructor for SequentialCommandGroup in addition to the vector constructor that we described above. However, when we make a templated function, its definition must be declared inline. This means that we will need to instantiate the SequentialCommandGroup in the Command.h header, which poses a problem. SequentialCommandGroup.h includes Command.h . If we include SequentialCommandGroup.h inside of Command.h , we have a circular dependency. How do we do it now then? We use a forward declaration at the top of Command.h : class SequentialCommandGroup ; class Command { ... }; And then we include SequentialCommandGroup.h in Command.cpp . If these decorator functions were templated however, we cannot write definitions in the .cpp files, resulting in a circular dependency. Java vs C++ Syntax These decorators usually save more verbosity in Java (because Java requires raw new calls) than in C++, so in general, it does not make much of a syntanctic difference in C++ if you create the command group manually in user code. 2023 Updates After a few years in the new command-based framework, the recommended way to create commands increasingly shifted towards inline commands, decorators, and factory methods. With this paradigm shift, it became evident that the C++ commands model introduced in 2020 and described above has some pain points when used according to the new recommendations. A significant root cause of most pain points was commands being passed by value in a non-polymorphic way. This made object slicing mistakes rather easy, and changes in composition structure could propagate type changes throughout the codebase: for example, if a ParallelRaceGroup were changed to a ParallelDeadlineGroup , those type changes would propagate through the codebase. Passing around the object as a Command (as done in Java) would result in object slicing. Additionally, various decorators weren’t supported in C++ due to reasons described above . As long as decorators were rarely used and were mainly to reduce verbosity (where Java was more verbose than C++), this was less of a problem. Once heavy usage of decorators was recommended, this became more of an issue. CommandPtr Let’s recall the mention of std::unique_ptr far above: a value type with only move semantics. This is the ownership model we want! However, plainly using std::unique_ptr<Command> had some drawbacks. Primarily, implementing decorators would be impossible: unique_ptr is defined in the standard library so we can’t define methods on it, and any methods defined on Command wouldn’t have access to the owning unique_ptr . The solution is CommandPtr : a move-only value class wrapping unique_ptr , that we can define methods on. Commands should be passed around as CommandPtr , using std::move . All decorators, including those not supported in C++ before, are defined on CommandPtr with rvalue-this. The use of rvalues, move-only semantics, and clear ownership makes it very easy to avoid mistakes such as adding the same command instance to more than one command composition . In addition to decorators, CommandPtr instances also define utility methods such as Schedule() , IsScheduled() . CommandPtr instances can be used in nearly almost every way command objects can be used in Java: they can be moved into trigger bindings, default commands, and so on. For the few things that require a Command* (such as non-owning trigger bindings), a raw pointer to the owned command can be retrieved using get() . There are multiple ways to get a CommandPtr instance: CommandPtr -returning factories are present in the frc2::cmd namespace in the Commands.h header for almost all command types. For multi-command compositions, there is a vector-taking overload as well as a variadic-templated overload for multiple CommandPtr instances. All decorators, including those defined on Command , return CommandPtr . This has allowed defining almost all decorators on Command , so a decorator chain can start from a Command . A ToPtr() method has been added to the CRTP, akin to TransferOwnership . This is useful especially for user-defined command classes, as well as other command classes that don’t have factories. For instance, consider the following from the HatchbotInlined example project : 33 frc2 :: CommandPtr autos::ComplexAuto ( DriveSubsystem * drive , 34 HatchSubsystem * hatch ) { 35 return frc2 :: cmd :: Sequence ( 36 // Drive forward the specified distance 37 frc2 :: FunctionalCommand ( 38 // Reset encoders on command start 39 [ drive ] { drive -> ResetEncoders (); }, 40 // Drive forward while the command is executing 41 [ drive ] { drive -> ArcadeDrive ( kAutoDriveSpeed , 0 ); }, 42 // Stop driving at the end of the command 43 [ drive ]( bool interrupted ) { drive -> ArcadeDrive ( 0 , 0 ); }, 44 // End the command when the robot's driven distance exceeds the 45 // desired value 46 [ drive ] { 47 return drive -> GetAverageEncoderDistance () >= 48 kAutoDriveDistanceInches ; 49 }, 50 // Requires the drive subsystem 51 { drive }) 52 . ToPtr (), 53 // Release the hatch 54 hatch -> ReleaseHatchCommand (), 55 // Drive backward the specified distance 56 // Drive forward the specified distance 57 frc2 :: FunctionalCommand ( 58 // Reset encoders on command start 59 [ drive ] { drive -> ResetEncoders (); }, 60 // Drive backward while the command is executing 61 [ drive ] { drive -> ArcadeDrive ( - kAutoDriveSpeed , 0 ); }, 62 // Stop driving at the end of the command 63 [ drive ]( bool interrupted ) { drive -> ArcadeDrive ( 0 , 0 ); }, 64 // End the command when the robot's driven distance exceeds the 65 // desired value 66 [ drive ] { 67 return drive -> GetAverageEncoderDistance () <= 68 kAutoBackupDistanceInches ; 69 }, 70 // Requires the drive subsystem 71 { drive }) 72 . ToPtr ()); 73 } To avoid breakage, command compositions still use unique_ptr<Command> , so CommandPtr instances can be destructured into a unique_ptr<Command> using the Unwrap() rvalue-this method. For vectors, the static CommandPtr::UnwrapVector(vector<CommandPtr>) function exists.",
      "content_preview": "A Technical Discussion on C++ Commands Note This article assumes that you have a fair understanding of advanced C++ concepts, including templates, smart pointers, inheritance, rvalue references, copy semantics, move semantics, and CRTP."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/command-compositions.html",
      "title": "Command Compositions",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Command Compositions Individual commands are capable of accomplishing a large variety of robot tasks, but the simple three-state format can quickly become cumbersome when more advanced functionality requiring extended sequences of robot tasks or coordination of multiple robot subsystems is required. In order to accomplish this, users are encouraged to use the powerful command composition functionality included in the command-based library. As the name suggests, a command composition is a composition of one or more commands. This allows code to be kept much cleaner and simpler, as the individual component commands may be written independently of the code that combines them, greatly reducing the amount of complexity at any given step of the process. Most importantly, however, command compositions are themselves commands - they extend the Command class. This allows command compositions to be further composed as a recursive composition - that is, a command composition may contain other command compositions as components. This allows very powerful and concise inline expressions: JAVA // Will run fooCommand, and then a race between barCommand and bazCommand button . onTrue ( fooCommand . andThen ( barCommand . raceWith ( bazCommand ))); C++ // Will run fooCommand, and then a race between barCommand and bazCommand button . OnTrue ( std :: move ( fooCommand ). AndThen ( std :: move ( barCommand ). RaceWith ( std :: move ( bazCommand )))); PYTHON # Will run fooCommand, and then a race between barCommand and bazCommand button . onTrue ( fooCommand . andThen ( barCommand . raceWith ( bazCommand ))) As a rule, command compositions require all subsystems their components require, may run when disabled if all their component set runsWhenDisabled as true , and are kCancelIncoming if all their components are kCancelIncoming as well. Command instances that have been passed to a command composition cannot be independently scheduled or passed to a second command composition. Attempting to do so will throw an exception and crash the user program. This is because composition members are run through their encapsulating command composition, and errors could occur if those same command instances were independently scheduled at the same time as the composition - the command would be being run from multiple places at once, and thus could end up with inconsistent internal state, causing unexpected and hard-to-diagnose behavior. The C++ command-based library uses CommandPtr , a class with move-only semantics, so this type of mistake is easier to avoid. Composition Types The command-based library includes various composition types. All of them can be constructed using factories that accept the member commands, and some can also be constructed using decorators: methods that can be called on a command object, which is transformed into a new object that is returned. Important After calling a decorator or being passed to a composition, the command object cannot be reused! Use only the command object returned from the decorator. Repeating The repeatedly() decorator ( Java , C++ , Python ), backed by the RepeatCommand class ( Java , C++ , Python ) restarts the command each time it ends, so that it runs until interrupted. JAVA // Will run forever unless externally interrupted, restarting every time command.isFinished() returns true Command repeats = command . repeatedly (); C++ // Will run forever unless externally interrupted, restarting every time command.IsFinished() returns true frc2 :: CommandPtr repeats = std :: move ( command ). Repeatedly (); PYTHON # Will run forever unless externally interrupted, restarting every time command.IsFinished() returns true repeats = command . repeatedly () Sequence The Sequence factory ( Java , C++ , Python ), backed by the SequentialCommandGroup class ( Java , C++ , Python ), runs a list of commands in sequence: the first command will be executed, then the second, then the third, and so on until the list finishes. The sequential group finishes after the last command in the sequence finishes. It is therefore usually important to ensure that each command in the sequence does actually finish (if a given command does not finish, the next command will never start!). The andThen() ( Java , C++ , Python ) and beforeStarting() ( Java , C++ , Python ) decorators can be used to construct a sequence composition with infix syntax. JAVA fooCommand . andThen ( barCommand ) C++ std :: move ( fooCommand ). AndThen ( std :: move ( barCommand )) PYTHON fooCommand . andThen ( barCommand ) Repeating Sequence As it’s a fairly common combination, the RepeatingSequence factory ( Java , C++ , Python ) creates a Repeating Sequence that runs until interrupted, restarting from the first command each time the last command finishes. Parallel There are three types of parallel compositions, differing based on when the composition finishes: The Parallel factory ( Java , C++ , Python ), backed by the ParallelCommandGroup class ( Java , C++ , Python ), constructs a parallel composition that finishes when all members finish. The alongWith decorator ( Java , C++ , Python ) does the same in infix notation. The Race factory ( Java , C++ , Python ), backed by the ParallelRaceGroup class ( Java , C++ , Python ), constructs a parallel composition that finishes as soon as any member finishes; all other members are interrupted at that point. The raceWith decorator ( Java , C++ , Python ) does the same in infix notation. The Deadline factory ( Java , C++ , Python ), ParallelDeadlineGroup ( Java , C++ , Python ) finishes when a specific command (the “deadline”) ends; all other members still running at that point are interrupted. The deadlineWith decorator ( Java , C++ , Python ) does the same in infix notation; the command the decorator was called on is the deadline. JAVA // Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . onTrue ( Commands . parallel ( twoSecCommand , oneSecCommand , threeSecCommand )); // Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . onTrue ( Commands . race ( twoSecCommand , oneSecCommand , threeSecCommand )); // Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . onTrue ( Commands . deadline ( twoSecCommand , oneSecCommand , threeSecCommand )); C++ // Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . OnTrue ( frc2 :: cmd :: Parallel ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); // Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . OnTrue ( frc2 :: cmd :: Race ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); // Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . OnTrue ( frc2 :: cmd :: Deadline ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); PYTHON # Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . onTrue ( commands2 . cmd . parallel ( twoSecCommand , oneSecCommand , threeSecCommand )) # Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . onTrue ( commands2 . cmd . race ( twoSecCommand , oneSecCommand , threeSecCommand )) # Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . onTrue ( commands2 . cmd . deadline ( twoSecCommand , oneSecCommand , threeSecCommand )) Adding Command End Conditions The until() ( Java , C++ , Python ) decorator composes the command with an additional end condition. Note that the command the decorator was called on will see this end condition as an interruption. JAVA // Will be interrupted if m_limitSwitch.get() returns true button . onTrue ( command . until ( m_limitSwitch :: get )); C++ // Will be interrupted if m_limitSwitch.get() returns true button . OnTrue ( command . Until ([ & m_limitSwitch ] { return m_limitSwitch . Get (); })); PYTHON # Will be interrupted if limitSwitch.get() returns true button . onTrue ( commands2 . cmd . until ( limitSwitch . get )) The withTimeout() decorator ( Java , C++ , Python ) is a specialization of until that uses a timeout as the additional end condition. JAVA // Will time out 5 seconds after being scheduled, and be interrupted button . onTrue ( command . withTimeout ( 5 )); C++ // Will time out 5 seconds after being scheduled, and be interrupted button . OnTrue ( command . WithTimeout ( 5.0 _s )); PYTHON # Will time out 5 seconds after being scheduled, and be interrupted button . onTrue ( commands2 . cmd . withTimeout ( 5.0 )) Adding End Behavior The finallyDo() ( Java , C++ , Python ) decorator composes the command with an a lambda that will be called after the command’s end() method, with the same boolean parameter indicating whether the command finished or was interrupted. The handleInterrupt() ( Java , C++ , Python ) decorator composes the command with an a lambda that will be called only when the command is interrupted. Selecting Compositions Sometimes it’s desired to run a command out of a few options based on sensor feedback or other data known only at runtime. This can be useful for determining an auto routine, or running a different command based on whether a game piece is present or not, and so on. The Select factory ( Java , C++ , Python ), backed by the SelectCommand class ( Java , C++ , Python ), executes one command from a map, based on a selector function called when scheduled. Java 20 public class RobotContainer { 21 // The enum used as keys for selecting the command to run. 22 private enum CommandSelector { 23 ONE , 24 TWO , 25 THREE 26 } 27 28 // An example selector method for the selectcommand. Returns the selector that will select 29 // which command to run. Can base this choice on logical conditions evaluated at runtime. 30 private CommandSelector select () { 31 return CommandSelector . ONE ; 32 } 33 34 // An example selectcommand. Will select from the three commands based on the value returned 35 // by the selector method at runtime. Note that selectcommand works on Object(), so the 36 // selector does not have to be an enum; it could be any desired type (string, integer, 37 // boolean, double...) 38 private final Command m_exampleSelectCommand = 39 new SelectCommand <> ( 40 // Maps selector values to commands 41 Map . ofEntries ( 42 Map . entry ( CommandSelector . ONE , new PrintCommand ( \"Command one was selected!\" )), 43 Map . entry ( CommandSelector . TWO , new PrintCommand ( \"Command two was selected!\" )), 44 Map . entry ( CommandSelector . THREE , new PrintCommand ( \"Command three was selected!\" ))), 45 this :: select ); C++ (Header) 26 // The enum used as keys for selecting the command to run. 27 enum CommandSelector { ONE , TWO , THREE }; 28 29 // An example of how command selector may be used with SendableChooser 30 frc :: SendableChooser < CommandSelector > m_chooser ; 31 32 // The robot's subsystems and commands are defined here... 33 34 // An example selectcommand. Will select from the three commands based on the 35 // value returned by the selector method at runtime. Note that selectcommand 36 // takes a generic type, so the selector does not have to be an enum; it could 37 // be any desired type (string, integer, boolean, double...) 38 frc2 :: CommandPtr m_exampleSelectCommand = frc2 :: cmd :: Select < CommandSelector > ( 39 [ this ] { return m_chooser . GetSelected (); }, 40 // Maps selector values to commands 41 std :: pair { ONE , frc2 :: cmd :: Print ( \"Command one was selected!\" )}, 42 std :: pair { TWO , frc2 :: cmd :: Print ( \"Command two was selected!\" )}, 43 std :: pair { THREE , frc2 :: cmd :: Print ( \"Command three was selected!\" )}); The Either factory ( Java , C++ , Python ), backed by the ConditionalCommand class ( Java , C++ , Python ), is a specialization accepting two commands and a boolean selector function. JAVA // Runs either commandOnTrue or commandOnFalse depending on the value of m_limitSwitch.get() new ConditionalCommand ( commandOnTrue , commandOnFalse , m_limitSwitch :: get ) C++ // Runs either commandOnTrue or commandOnFalse depending on the value of m_limitSwitch.get() frc2 :: ConditionalCommand ( commandOnTrue , commandOnFalse , [ & m_limitSwitch ] { return m_limitSwitch . Get (); }) PYTHON # Runs either commandOnTrue or commandOnFalse depending on the value of limitSwitch.get() ConditionalCommand ( commandOnTrue , commandOnFalse , limitSwitch . get ) The unless() decorator ( Java , C++ , Python ) composes a command with a condition that will prevent it from running. JAVA // Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . onTrue ( command . unless (() -> ! intake . isDeployed ())); C++ // Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . OnTrue ( command . Unless ([ & intake ] { return ! intake . IsDeployed (); })); PYTHON # Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . onTrue ( command . unless ( lambda : not intake . isDeployed ())) ProxyCommand described below also has a constructor overload ( Java , C++ , Python ) that calls a command-returning lambda at schedule-time and runs the returned command by proxy. Scheduling Other Commands By default, composition members are run through the command composition, and are never themselves seen by the scheduler. Accordingly, their requirements are added to the composition’s requirements. While this is usually fine, sometimes it is undesirable for the entire command composition to gain the requirements of a single command. A good solution is to “fork off” from the command composition and schedule that command separately. However, this requires synchronization between the composition and the individually-scheduled command. ProxyCommand ( Java , C++ , Python ), also creatable using the .asProxy() decorator ( Java , C++ , Python ), schedules a command “by proxy”: the command is scheduled when the proxy is scheduled, and the proxy finishes when the command finishes. In the case of “forking off” from a command composition, this allows the composition to track the command’s progress without it being in the composition. Command compositions inherit the union of their compoments’ requirements and requirements are immutable. Therefore, a SequentialCommandGroup ( Java , C++ , Python ) that intakes a game piece, indexes it, aims a shooter, and shoots it would reserve all three subsystems (the intake, indexer, and shooter), precluding any of those subsystems from performing other operations in their “downtime”. If this is not desired, the subsystems that should only be reserved for the composition while they are actively being used by it should have their commands proxied. Warning Do not use ProxyCommand unless you are sure of what you are doing and there is no other way to accomplish your need! Proxying is only intended for use as an escape hatch from command composition requirement unions. Note Because proxied commands still require their subsystem, despite not leaking that requirement to the composition, all of the commands that require a given subsystem must be proxied if one of them is. Otherwise, when the proxied command is scheduled its requirement will conflict with that of the composition, canceling the composition. JAVA // composition requirements are indexer and shooter, intake still reserved during its command but not afterwards Commands . sequence ( intake . intakeGamePiece (). asProxy (), // we want to let the intake intake another game piece while we are processing this one indexer . processGamePiece (), shooter . aimAndShoot () ); C++ // composition requirements are indexer and shooter, intake still reserved during its command but not afterwards frc2 :: cmd :: Sequence ( intake . IntakeGamePiece (). AsProxy (), // we want to let the intake intake another game piece while we are processing this one indexer . ProcessGamePiece (), shooter . AimAndShoot () ); PYTHON # composition requirements are indexer and shooter, intake still reserved during its command but not afterwards commands2 . cmd . sequence ( intake . intakeGamePiece () . asProxy (), # we want to let the intake intake another game piece while we are processing this one indexer . processGamePiece (), shooter . aimAndShoot () ) For cases that don’t need to track the proxied command, ScheduleCommand ( Java , C++ , Python ) schedules a specified command and ends instantly. JAVA // ScheduleCommand ends immediately, so the sequence continues new ScheduleCommand ( Commands . waitSeconds ( 5.0 )) . andThen ( Commands . print ( \"This will be printed immediately!\" )) C++ // ScheduleCommand ends immediately, so the sequence continues frc2 :: ScheduleCommand ( frc2 :: cmd :: Wait ( 5.0 _s )) . AndThen ( frc2 :: cmd :: Print ( \"This will be printed immediately!\" )) PYTHON # ScheduleCommand ends immediately, so the sequence continues ScheduleCommand ( commands2 . cmd . waitSeconds ( 5.0 )) . andThen ( commands2 . cmd . print ( \"This will be printed immediately!\" )) Subclassing Compositions Command compositions can also be written as a constructor-only subclass of the most exterior composition type, passing the composition members to the superclass constructor. Consider the following from the Hatch Bot example project ( Java , C++ ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.Constants.AutoConstants ; 8 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.DriveSubsystem ; 9 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.HatchSubsystem ; 10 import edu.wpi.first.wpilibj2.command.SequentialCommandGroup ; 11 12 /** A complex auto command that drives forward, releases a hatch, and then drives backward. */ 13 public class ComplexAuto extends SequentialCommandGroup { 14 /** 15 * Creates a new ComplexAuto. 16 * 17 * @param drive The drive subsystem this command will run on 18 * @param hatch The hatch subsystem this command will run on 19 */ 20 public ComplexAuto ( DriveSubsystem drive , HatchSubsystem hatch ) { 21 addCommands ( 22 // Drive forward the specified distance 23 new DriveDistance ( 24 AutoConstants . kAutoDriveDistanceInches , AutoConstants . kAutoDriveSpeed , drive ), 25 26 // Release the hatch 27 new ReleaseHatch ( hatch ), 28 29 // Drive backward the specified distance 30 new DriveDistance ( 31 AutoConstants . kAutoBackupDistanceInches , - AutoConstants . kAutoDriveSpeed , drive )); 32 } 33 } C++ (Header) 5 #pragma once 6 7 #include <frc2/command/CommandHelper.h> 8 #include <frc2/command/SequentialCommandGroup.h> 9 10 #include \"Constants.h\" 11 #include \"commands/DriveDistance.h\" 12 #include \"commands/ReleaseHatch.h\" 13 14 /** 15 * A complex auto command that drives forward, releases a hatch, and then drives 16 * backward. 17 */ 18 class ComplexAuto 19 : public frc2 :: CommandHelper < frc2 :: SequentialCommandGroup , ComplexAuto > { 20 public : 21 /** 22 * Creates a new ComplexAuto. 23 * 24 * @param drive The drive subsystem this command will run on 25 * @param hatch The hatch subsystem this command will run on 26 */ 27 ComplexAuto ( DriveSubsystem * drive , HatchSubsystem * hatch ); 28 }; C++ (Source) 5 #include \"commands/ComplexAuto.h\" 6 7 using namespace AutoConstants ; 8 9 ComplexAuto :: ComplexAuto ( DriveSubsystem * drive , HatchSubsystem * hatch ) { 10 AddCommands ( 11 // Drive forward the specified distance 12 DriveDistance ( kAutoDriveDistanceInches , kAutoDriveSpeed , drive ), 13 // Release the hatch 14 ReleaseHatch ( hatch ), 15 // Drive backward the specified distance 16 DriveDistance ( kAutoBackupDistanceInches , - kAutoDriveSpeed , drive )); 17 } Python 7 import commands2 8 9 import constants 10 11 from .drivedistance import DriveDistance 12 from .releasehatch import ReleaseHatch 13 14 from subsystems.drivesubsystem import DriveSubsystem 15 from subsystems.hatchsubsystem import HatchSubsystem 16 17 18 class ComplexAuto ( commands2 . SequentialCommandGroup ): 19 \"\"\" 20 A complex auto command that drives forward, releases a hatch, and then drives backward. 21 \"\"\" 22 23 def __init__ ( self , drive : DriveSubsystem , hatch : HatchSubsystem ): 24 super () . __init__ ( 25 # Drive forward the specified distance 26 DriveDistance ( 27 constants . kAutoDriveDistanceInches , constants . kAutoDriveSpeed , drive 28 ), 29 # Release the hatch 30 ReleaseHatch ( hatch ), 31 # Drive backward the specified distance 32 DriveDistance ( 33 constants . kAutoBackupDistanceInches , - constants . kAutoDriveSpeed , drive 34 ), 35 ) The advantages and disadvantages of this subclassing approach in comparison to others are discussed in Subclassing Command Groups .",
      "content_preview": "Command Compositions Individual commands are capable of accomplishing a large variety of robot tasks, but the simple three-state format can quickly become cumbersome when more advanced functionality requiring extended sequences of robot tasks or coordination of multiple robot subsystems is..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/command-compositions.html?present",
      "title": "Command Compositions",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Command Compositions Individual commands are capable of accomplishing a large variety of robot tasks, but the simple three-state format can quickly become cumbersome when more advanced functionality requiring extended sequences of robot tasks or coordination of multiple robot subsystems is required. In order to accomplish this, users are encouraged to use the powerful command composition functionality included in the command-based library. As the name suggests, a command composition is a composition of one or more commands. This allows code to be kept much cleaner and simpler, as the individual component commands may be written independently of the code that combines them, greatly reducing the amount of complexity at any given step of the process. Most importantly, however, command compositions are themselves commands - they extend the Command class. This allows command compositions to be further composed as a recursive composition - that is, a command composition may contain other command compositions as components. This allows very powerful and concise inline expressions: JAVA // Will run fooCommand, and then a race between barCommand and bazCommand button . onTrue ( fooCommand . andThen ( barCommand . raceWith ( bazCommand ))); C++ // Will run fooCommand, and then a race between barCommand and bazCommand button . OnTrue ( std :: move ( fooCommand ). AndThen ( std :: move ( barCommand ). RaceWith ( std :: move ( bazCommand )))); PYTHON # Will run fooCommand, and then a race between barCommand and bazCommand button . onTrue ( fooCommand . andThen ( barCommand . raceWith ( bazCommand ))) As a rule, command compositions require all subsystems their components require, may run when disabled if all their component set runsWhenDisabled as true , and are kCancelIncoming if all their components are kCancelIncoming as well. Command instances that have been passed to a command composition cannot be independently scheduled or passed to a second command composition. Attempting to do so will throw an exception and crash the user program. This is because composition members are run through their encapsulating command composition, and errors could occur if those same command instances were independently scheduled at the same time as the composition - the command would be being run from multiple places at once, and thus could end up with inconsistent internal state, causing unexpected and hard-to-diagnose behavior. The C++ command-based library uses CommandPtr , a class with move-only semantics, so this type of mistake is easier to avoid. Composition Types The command-based library includes various composition types. All of them can be constructed using factories that accept the member commands, and some can also be constructed using decorators: methods that can be called on a command object, which is transformed into a new object that is returned. Important After calling a decorator or being passed to a composition, the command object cannot be reused! Use only the command object returned from the decorator. Repeating The repeatedly() decorator ( Java , C++ , Python ), backed by the RepeatCommand class ( Java , C++ , Python ) restarts the command each time it ends, so that it runs until interrupted. JAVA // Will run forever unless externally interrupted, restarting every time command.isFinished() returns true Command repeats = command . repeatedly (); C++ // Will run forever unless externally interrupted, restarting every time command.IsFinished() returns true frc2 :: CommandPtr repeats = std :: move ( command ). Repeatedly (); PYTHON # Will run forever unless externally interrupted, restarting every time command.IsFinished() returns true repeats = command . repeatedly () Sequence The Sequence factory ( Java , C++ , Python ), backed by the SequentialCommandGroup class ( Java , C++ , Python ), runs a list of commands in sequence: the first command will be executed, then the second, then the third, and so on until the list finishes. The sequential group finishes after the last command in the sequence finishes. It is therefore usually important to ensure that each command in the sequence does actually finish (if a given command does not finish, the next command will never start!). The andThen() ( Java , C++ , Python ) and beforeStarting() ( Java , C++ , Python ) decorators can be used to construct a sequence composition with infix syntax. JAVA fooCommand . andThen ( barCommand ) C++ std :: move ( fooCommand ). AndThen ( std :: move ( barCommand )) PYTHON fooCommand . andThen ( barCommand ) Repeating Sequence As it’s a fairly common combination, the RepeatingSequence factory ( Java , C++ , Python ) creates a Repeating Sequence that runs until interrupted, restarting from the first command each time the last command finishes. Parallel There are three types of parallel compositions, differing based on when the composition finishes: The Parallel factory ( Java , C++ , Python ), backed by the ParallelCommandGroup class ( Java , C++ , Python ), constructs a parallel composition that finishes when all members finish. The alongWith decorator ( Java , C++ , Python ) does the same in infix notation. The Race factory ( Java , C++ , Python ), backed by the ParallelRaceGroup class ( Java , C++ , Python ), constructs a parallel composition that finishes as soon as any member finishes; all other members are interrupted at that point. The raceWith decorator ( Java , C++ , Python ) does the same in infix notation. The Deadline factory ( Java , C++ , Python ), ParallelDeadlineGroup ( Java , C++ , Python ) finishes when a specific command (the “deadline”) ends; all other members still running at that point are interrupted. The deadlineWith decorator ( Java , C++ , Python ) does the same in infix notation; the command the decorator was called on is the deadline. JAVA // Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . onTrue ( Commands . parallel ( twoSecCommand , oneSecCommand , threeSecCommand )); // Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . onTrue ( Commands . race ( twoSecCommand , oneSecCommand , threeSecCommand )); // Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . onTrue ( Commands . deadline ( twoSecCommand , oneSecCommand , threeSecCommand )); C++ // Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . OnTrue ( frc2 :: cmd :: Parallel ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); // Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . OnTrue ( frc2 :: cmd :: Race ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); // Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . OnTrue ( frc2 :: cmd :: Deadline ( std :: move ( twoSecCommand ), std :: move ( oneSecCommand ), std :: move ( threeSecCommand ))); PYTHON # Will be a parallel command composition that ends after three seconds with all three commands running their full duration. button . onTrue ( commands2 . cmd . parallel ( twoSecCommand , oneSecCommand , threeSecCommand )) # Will be a parallel race composition that ends after one second with the two and three second commands getting interrupted. button . onTrue ( commands2 . cmd . race ( twoSecCommand , oneSecCommand , threeSecCommand )) # Will be a parallel deadline composition that ends after two seconds (the deadline) with the three second command getting interrupted (one second command already finished). button . onTrue ( commands2 . cmd . deadline ( twoSecCommand , oneSecCommand , threeSecCommand )) Adding Command End Conditions The until() ( Java , C++ , Python ) decorator composes the command with an additional end condition. Note that the command the decorator was called on will see this end condition as an interruption. JAVA // Will be interrupted if m_limitSwitch.get() returns true button . onTrue ( command . until ( m_limitSwitch :: get )); C++ // Will be interrupted if m_limitSwitch.get() returns true button . OnTrue ( command . Until ([ & m_limitSwitch ] { return m_limitSwitch . Get (); })); PYTHON # Will be interrupted if limitSwitch.get() returns true button . onTrue ( commands2 . cmd . until ( limitSwitch . get )) The withTimeout() decorator ( Java , C++ , Python ) is a specialization of until that uses a timeout as the additional end condition. JAVA // Will time out 5 seconds after being scheduled, and be interrupted button . onTrue ( command . withTimeout ( 5 )); C++ // Will time out 5 seconds after being scheduled, and be interrupted button . OnTrue ( command . WithTimeout ( 5.0 _s )); PYTHON # Will time out 5 seconds after being scheduled, and be interrupted button . onTrue ( commands2 . cmd . withTimeout ( 5.0 )) Adding End Behavior The finallyDo() ( Java , C++ , Python ) decorator composes the command with an a lambda that will be called after the command’s end() method, with the same boolean parameter indicating whether the command finished or was interrupted. The handleInterrupt() ( Java , C++ , Python ) decorator composes the command with an a lambda that will be called only when the command is interrupted. Selecting Compositions Sometimes it’s desired to run a command out of a few options based on sensor feedback or other data known only at runtime. This can be useful for determining an auto routine, or running a different command based on whether a game piece is present or not, and so on. The Select factory ( Java , C++ , Python ), backed by the SelectCommand class ( Java , C++ , Python ), executes one command from a map, based on a selector function called when scheduled. Java 20 public class RobotContainer { 21 // The enum used as keys for selecting the command to run. 22 private enum CommandSelector { 23 ONE , 24 TWO , 25 THREE 26 } 27 28 // An example selector method for the selectcommand. Returns the selector that will select 29 // which command to run. Can base this choice on logical conditions evaluated at runtime. 30 private CommandSelector select () { 31 return CommandSelector . ONE ; 32 } 33 34 // An example selectcommand. Will select from the three commands based on the value returned 35 // by the selector method at runtime. Note that selectcommand works on Object(), so the 36 // selector does not have to be an enum; it could be any desired type (string, integer, 37 // boolean, double...) 38 private final Command m_exampleSelectCommand = 39 new SelectCommand <> ( 40 // Maps selector values to commands 41 Map . ofEntries ( 42 Map . entry ( CommandSelector . ONE , new PrintCommand ( \"Command one was selected!\" )), 43 Map . entry ( CommandSelector . TWO , new PrintCommand ( \"Command two was selected!\" )), 44 Map . entry ( CommandSelector . THREE , new PrintCommand ( \"Command three was selected!\" ))), 45 this :: select ); C++ (Header) 26 // The enum used as keys for selecting the command to run. 27 enum CommandSelector { ONE , TWO , THREE }; 28 29 // An example of how command selector may be used with SendableChooser 30 frc :: SendableChooser < CommandSelector > m_chooser ; 31 32 // The robot's subsystems and commands are defined here... 33 34 // An example selectcommand. Will select from the three commands based on the 35 // value returned by the selector method at runtime. Note that selectcommand 36 // takes a generic type, so the selector does not have to be an enum; it could 37 // be any desired type (string, integer, boolean, double...) 38 frc2 :: CommandPtr m_exampleSelectCommand = frc2 :: cmd :: Select < CommandSelector > ( 39 [ this ] { return m_chooser . GetSelected (); }, 40 // Maps selector values to commands 41 std :: pair { ONE , frc2 :: cmd :: Print ( \"Command one was selected!\" )}, 42 std :: pair { TWO , frc2 :: cmd :: Print ( \"Command two was selected!\" )}, 43 std :: pair { THREE , frc2 :: cmd :: Print ( \"Command three was selected!\" )}); The Either factory ( Java , C++ , Python ), backed by the ConditionalCommand class ( Java , C++ , Python ), is a specialization accepting two commands and a boolean selector function. JAVA // Runs either commandOnTrue or commandOnFalse depending on the value of m_limitSwitch.get() new ConditionalCommand ( commandOnTrue , commandOnFalse , m_limitSwitch :: get ) C++ // Runs either commandOnTrue or commandOnFalse depending on the value of m_limitSwitch.get() frc2 :: ConditionalCommand ( commandOnTrue , commandOnFalse , [ & m_limitSwitch ] { return m_limitSwitch . Get (); }) PYTHON # Runs either commandOnTrue or commandOnFalse depending on the value of limitSwitch.get() ConditionalCommand ( commandOnTrue , commandOnFalse , limitSwitch . get ) The unless() decorator ( Java , C++ , Python ) composes a command with a condition that will prevent it from running. JAVA // Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . onTrue ( command . unless (() -> ! intake . isDeployed ())); C++ // Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . OnTrue ( command . Unless ([ & intake ] { return ! intake . IsDeployed (); })); PYTHON # Command will only run if the intake is deployed. If the intake gets deployed while the command is running, the command will not stop running button . onTrue ( command . unless ( lambda : not intake . isDeployed ())) ProxyCommand described below also has a constructor overload ( Java , C++ , Python ) that calls a command-returning lambda at schedule-time and runs the returned command by proxy. Scheduling Other Commands By default, composition members are run through the command composition, and are never themselves seen by the scheduler. Accordingly, their requirements are added to the composition’s requirements. While this is usually fine, sometimes it is undesirable for the entire command composition to gain the requirements of a single command. A good solution is to “fork off” from the command composition and schedule that command separately. However, this requires synchronization between the composition and the individually-scheduled command. ProxyCommand ( Java , C++ , Python ), also creatable using the .asProxy() decorator ( Java , C++ , Python ), schedules a command “by proxy”: the command is scheduled when the proxy is scheduled, and the proxy finishes when the command finishes. In the case of “forking off” from a command composition, this allows the composition to track the command’s progress without it being in the composition. Command compositions inherit the union of their compoments’ requirements and requirements are immutable. Therefore, a SequentialCommandGroup ( Java , C++ , Python ) that intakes a game piece, indexes it, aims a shooter, and shoots it would reserve all three subsystems (the intake, indexer, and shooter), precluding any of those subsystems from performing other operations in their “downtime”. If this is not desired, the subsystems that should only be reserved for the composition while they are actively being used by it should have their commands proxied. Warning Do not use ProxyCommand unless you are sure of what you are doing and there is no other way to accomplish your need! Proxying is only intended for use as an escape hatch from command composition requirement unions. Note Because proxied commands still require their subsystem, despite not leaking that requirement to the composition, all of the commands that require a given subsystem must be proxied if one of them is. Otherwise, when the proxied command is scheduled its requirement will conflict with that of the composition, canceling the composition. JAVA // composition requirements are indexer and shooter, intake still reserved during its command but not afterwards Commands . sequence ( intake . intakeGamePiece (). asProxy (), // we want to let the intake intake another game piece while we are processing this one indexer . processGamePiece (), shooter . aimAndShoot () ); C++ // composition requirements are indexer and shooter, intake still reserved during its command but not afterwards frc2 :: cmd :: Sequence ( intake . IntakeGamePiece (). AsProxy (), // we want to let the intake intake another game piece while we are processing this one indexer . ProcessGamePiece (), shooter . AimAndShoot () ); PYTHON # composition requirements are indexer and shooter, intake still reserved during its command but not afterwards commands2 . cmd . sequence ( intake . intakeGamePiece () . asProxy (), # we want to let the intake intake another game piece while we are processing this one indexer . processGamePiece (), shooter . aimAndShoot () ) For cases that don’t need to track the proxied command, ScheduleCommand ( Java , C++ , Python ) schedules a specified command and ends instantly. JAVA // ScheduleCommand ends immediately, so the sequence continues new ScheduleCommand ( Commands . waitSeconds ( 5.0 )) . andThen ( Commands . print ( \"This will be printed immediately!\" )) C++ // ScheduleCommand ends immediately, so the sequence continues frc2 :: ScheduleCommand ( frc2 :: cmd :: Wait ( 5.0 _s )) . AndThen ( frc2 :: cmd :: Print ( \"This will be printed immediately!\" )) PYTHON # ScheduleCommand ends immediately, so the sequence continues ScheduleCommand ( commands2 . cmd . waitSeconds ( 5.0 )) . andThen ( commands2 . cmd . print ( \"This will be printed immediately!\" )) Subclassing Compositions Command compositions can also be written as a constructor-only subclass of the most exterior composition type, passing the composition members to the superclass constructor. Consider the following from the Hatch Bot example project ( Java , C++ ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.Constants.AutoConstants ; 8 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.DriveSubsystem ; 9 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.HatchSubsystem ; 10 import edu.wpi.first.wpilibj2.command.SequentialCommandGroup ; 11 12 /** A complex auto command that drives forward, releases a hatch, and then drives backward. */ 13 public class ComplexAuto extends SequentialCommandGroup { 14 /** 15 * Creates a new ComplexAuto. 16 * 17 * @param drive The drive subsystem this command will run on 18 * @param hatch The hatch subsystem this command will run on 19 */ 20 public ComplexAuto ( DriveSubsystem drive , HatchSubsystem hatch ) { 21 addCommands ( 22 // Drive forward the specified distance 23 new DriveDistance ( 24 AutoConstants . kAutoDriveDistanceInches , AutoConstants . kAutoDriveSpeed , drive ), 25 26 // Release the hatch 27 new ReleaseHatch ( hatch ), 28 29 // Drive backward the specified distance 30 new DriveDistance ( 31 AutoConstants . kAutoBackupDistanceInches , - AutoConstants . kAutoDriveSpeed , drive )); 32 } 33 } C++ (Header) 5 #pragma once 6 7 #include <frc2/command/CommandHelper.h> 8 #include <frc2/command/SequentialCommandGroup.h> 9 10 #include \"Constants.h\" 11 #include \"commands/DriveDistance.h\" 12 #include \"commands/ReleaseHatch.h\" 13 14 /** 15 * A complex auto command that drives forward, releases a hatch, and then drives 16 * backward. 17 */ 18 class ComplexAuto 19 : public frc2 :: CommandHelper < frc2 :: SequentialCommandGroup , ComplexAuto > { 20 public : 21 /** 22 * Creates a new ComplexAuto. 23 * 24 * @param drive The drive subsystem this command will run on 25 * @param hatch The hatch subsystem this command will run on 26 */ 27 ComplexAuto ( DriveSubsystem * drive , HatchSubsystem * hatch ); 28 }; C++ (Source) 5 #include \"commands/ComplexAuto.h\" 6 7 using namespace AutoConstants ; 8 9 ComplexAuto :: ComplexAuto ( DriveSubsystem * drive , HatchSubsystem * hatch ) { 10 AddCommands ( 11 // Drive forward the specified distance 12 DriveDistance ( kAutoDriveDistanceInches , kAutoDriveSpeed , drive ), 13 // Release the hatch 14 ReleaseHatch ( hatch ), 15 // Drive backward the specified distance 16 DriveDistance ( kAutoBackupDistanceInches , - kAutoDriveSpeed , drive )); 17 } Python 7 import commands2 8 9 import constants 10 11 from .drivedistance import DriveDistance 12 from .releasehatch import ReleaseHatch 13 14 from subsystems.drivesubsystem import DriveSubsystem 15 from subsystems.hatchsubsystem import HatchSubsystem 16 17 18 class ComplexAuto ( commands2 . SequentialCommandGroup ): 19 \"\"\" 20 A complex auto command that drives forward, releases a hatch, and then drives backward. 21 \"\"\" 22 23 def __init__ ( self , drive : DriveSubsystem , hatch : HatchSubsystem ): 24 super () . __init__ ( 25 # Drive forward the specified distance 26 DriveDistance ( 27 constants . kAutoDriveDistanceInches , constants . kAutoDriveSpeed , drive 28 ), 29 # Release the hatch 30 ReleaseHatch ( hatch ), 31 # Drive backward the specified distance 32 DriveDistance ( 33 constants . kAutoBackupDistanceInches , - constants . kAutoDriveSpeed , drive 34 ), 35 ) The advantages and disadvantages of this subclassing approach in comparison to others are discussed in Subclassing Command Groups .",
      "content_preview": "Command Compositions Individual commands are capable of accomplishing a large variety of robot tasks, but the simple three-state format can quickly become cumbersome when more advanced functionality requiring extended sequences of robot tasks or coordination of multiple robot subsystems is..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/organizing-command-based.html",
      "title": "Organizing Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Organizing Command-Based Robot Projects As robot code becomes more complicated, navigating, understanding, and maintaining the code takes up more and more time and energy. Making changes to the code often becomes more difficult, sometimes for reasons that have very little to do with the actual complexity of the underlying logic. For a simplified example: putting the logic for many unrelated robot functions into a single 1000-line file makes it difficult to find a specific piece of code within that file, particularly under stress at a competition. But spreading out closely related logic across dozens of tiny files is often just as difficult to navigate. This is not a problem unique to FRC, and in fact, good organization only becomes more and more critical as software projects become bigger and bigger. The “best” organization system is a perennial topic of debate, much like the “best” programming language, but in the end, the choice (in both cases) comes down to the specific task at hand and the programmer (or programmers) implementing said task. Even in the relatively small space of FRC robot programming, there is no right answer. The best choice for a given team will depend on the nature of the specific robot code, team structure, and pure personal preference. This article discusses various facets of command-based robot program design that advanced FRC programmers may want to be aware of when writing code. It is not a prescriptive tutorial, though it presents some recommended best practices. If this level of choice seems daunting, however, many teams have been highly successful while sticking closely to WPILib’s example code and guidelines. However, this discussion may be of interest to intermediate and advanced programmers who want to make their code not only effective, but flexible, easily changeable, and sometimes even beautiful. Why Care About Organization? Good code organization will rarely make or break a team’s competitive ability—but it does mean easier debugging, faster modifications, nicer-looking code, and happier programmers. While it’s impossible to define “good” organization by way of what the code looks like from the inside, it’s easier to define in terms of what the robot’s software looks like from the outside. What Good Organization Looks Like When code is well-designed and well-organized, the code’s internal structure is intuitive and easily comprehensible. Cumbersome boilerplate is minimized, meaning that new robot functionality can often be added with just a few lines of code. When a constant value (such as the speed of the robot’s intake) needs to be changed, it only needs to change in one place. If multiple programmers are working together, they can easily understand each others’ work. Bugs are rare, since it is difficult to accidentally introduce unintended behavior (such as creating a command that does not require necessary subsystems). Implementing more advanced functions like unit tests is easier, since the code is abstracted away from the physical hardware. Programmers are happy (most of the time). What Bad Organization Looks Like Poorly organized code often has internal structure that makes little to no sense, even to whoever wrote it. When functionality has to be added or changed, it often breaks unrelated parts of the robot: adding automatic shooter control might introduce a bug in the climbing sequence for unclear reasons. Alternatively, the organizational framework might be so strict that it’s impossible to implement necessary behavior, requiring nasty hacks or workarounds. Many lines of boilerplate code are needed for simple robot logic. Constants are scattered across the codebase, and changing basic behavior often requires making the same change to many different files. Collaboration among multiple programmers is difficult or impossible. Defining Commands In larger robot codebases, multiple copies of the same command need to be used in many different places. For instance, a command that runs a robot’s intake might be used in teleop, bound to a certain button; as part of a complicated command group for an autonomous routine; and as part of a self-test sequence. As an example, let’s look at some ways to define a simple command that simply runs the robot’s intake forward at full power until canceled. Inline Commands The easiest and most expressive way to do this is with a StartEndCommand : JAVA Command runIntake = Commands . startEnd (() -> intake . set ( 1.0 ), () -> intake . set ( 0.0 ), intake ); C++ frc2 :: CommandPtr runIntake = frc2 :: cmd :: StartEnd ([ & intake ] { intake . Set ( 1.0 ); }, [ & intake ] { intake . Set ( 0.0 ); }, { & intake }); This is sufficient for commands that are only used once. However, for a command like this that might get used in many different autonomous routines and button bindings, inline commands everywhere means a lot of repetitive code: JAVA // RobotContainer.java intakeButton . whileTrue ( Commands . startEnd (() -> intake . set ( 1.0 ), () -> intake . set ( 0.0 ), intake )); Command intakeAndShoot = Commands . startEnd (() -> intake . set ( 1.0 ), () -> intake . set ( 0.0 ), intake ) . alongWith ( new RunShooter ( shooter )); Command autonomousCommand = Commands . sequence ( Commands . startEnd (() -> intake . set ( 1.0 ), () -> intake . set ( 0.0 ), intake ). withTimeout ( 5.0 ), Commands . waitSeconds ( 3.0 ), Commands . startEnd (() -> intake . set ( 1.0 ), () -> intake . set ( 0.0 ), intake ). withTimeout ( 5.0 ) ); C++ intakeButton . WhileTrue ( frc2 :: cmd :: StartEnd ([ & intake ] { intake . Set ( 1.0 ); }, [ & intake ] { intake . Set ( 0.0 ); }, { & intake })); frc2 :: CommandPtr intakeAndShoot = frc2 :: cmd :: StartEnd ([ & intake ] { intake . Set ( 1.0 ); }, [ & intake ] { intake . Set ( 0.0 ); }, { & intake }) . AlongWith ( RunShooter ( & shooter ). ToPtr ()); frc2 :: CommandPtr autonomousCommand = frc2 :: cmd :: Sequence ( frc2 :: cmd :: StartEnd ([ & intake ] { intake . Set ( 1.0 ); }, [ & intake ] { intake . Set ( 0.0 ); }, { & intake }). WithTimeout ( 5.0 _s ), frc2 :: cmd :: Wait ( 3.0 _s ), frc2 :: cmd :: StartEnd ([ & intake ] { intake . Set ( 1.0 ); }, [ & intake ] { intake . Set ( 0.0 ); }, { & intake }). WithTimeout ( 5.0 _s ) ); Creating one StartEndCommand instance and putting it in a variable won’t work here, since once an instance of a command is added to a command group it is effectively “owned” by that command group and cannot be used in any other context. Instance Command Factory Methods One way to solve this quandary is using the “factory method” design pattern: a function that returns a new object every invocation, according to some specification. Using command composition , a factory method can construct a complex command object with merely a few lines of code. For example, a command like the intake-running command is conceptually related to exactly one subsystem: the Intake . As such, it makes sense to put a runIntakeCommand method as an instance method of the Intake class: Note In this document we will name factory methods as lowerCamelCaseCommand , but teams may decide on other conventions. In general, it is recommended to end the method name with Command if it might otherwise be confused with an ordinary method (e.g. intake.run might be the name of a method that simply turns on the intake). JAVA public class Intake extends SubsystemBase { // [code for motor controllers, configuration, etc.] // ... public Command runIntakeCommand () { // implicitly requires `this` return this . startEnd (() -> this . set ( 1.0 ), () -> this . set ( 0.0 )); } } C++ frc2 :: CommandPtr Intake::RunIntakeCommand () { // implicitly requires `this` return this -> StartEnd ([ this ] { this -> Set ( 1.0 ); }, [ this ] { this -> Set ( 0.0 ); }); } Notice how since we are in the Intake class, we no longer refer to intake ; instead, we use the this keyword to refer to the current instance. Since we are inside the Intake class, technically we can access private variables and methods directly from within the runIntakeCommand method, thus not needing intermediary methods. (For example, the runIntakeCommand method can directly interface with the motor controller objects instead of calling set() .) On the other hand, these intermediary methods can reduce code duplication and increase encapsulation. Like many other choices outlined in this document, this tradeoff is a matter of personal preference on a case-by-case basis. Using this new factory method in command groups and button bindings is highly expressive: JAVA intakeButton . whileTrue ( intake . runIntakeCommand ()); Command intakeAndShoot = intake . runIntakeCommand (). alongWith ( new RunShooter ( shooter )); Command autonomousCommand = Commands . sequence ( intake . runIntakeCommand (). withTimeout ( 5.0 ), Commands . waitSeconds ( 3.0 ), intake . runIntakeCommand (). withTimeout ( 5.0 ) ); C++ intakeButton . WhileTrue ( intake . RunIntakeCommand ()); frc2 :: CommandPtr intakeAndShoot = intake . RunIntakeCommand (). AlongWith ( RunShooter ( & shooter ). ToPtr ()); frc2 :: CommandPtr autonomousCommand = frc2 :: cmd :: Sequence ( intake . RunIntakeCommand (). WithTimeout ( 5.0 _s ), frc2 :: cmd :: Wait ( 3.0 _s ), intake . RunIntakeCommand (). WithTimeout ( 5.0 _s ) ); Adding a parameter to the runIntakeCommand method to provide the exact percentage to run the intake is easy and allows for even more flexibility. JAVA public Command runIntakeCommand ( double percent ) { return new StartEndCommand (() -> this . set ( percent ), () -> this . set ( 0.0 ), this ); } C++ frc2 :: CommandPtr Intake::RunIntakeCommand ( double percent ) { // implicitly requires `this` return this -> StartEnd ([ this , percent ] { this -> Set ( percent ); }, [ this ] { this -> Set ( 0.0 ); }); } For instance, this code creates a command group that runs the intake forwards for two seconds, waits for two seconds, and then runs the intake backwards for five seconds. JAVA Command intakeRunSequence = intake . runIntakeCommand ( 1.0 ). withTimeout ( 2.0 ) . andThen ( Commands . waitSeconds ( 2.0 )) . andThen ( intake . runIntakeCommand ( - 1.0 ). withTimeout ( 5.0 )); C++ frc2 :: CommandPtr intakeRunSequence = intake . RunIntakeCommand ( 1.0 ). WithTimeout ( 2.0 _s ) . AndThen ( frc2 :: cmd :: Wait ( 2.0 _s )) . AndThen ( intake . RunIntakeCommand ( -1.0 ). WithTimeout ( 5.0 _s )); This approach is recommended for commands that are conceptually related to only a single subsystem, and is very concise. However, it doesn’t fare well with commands related to more than one subsystem: passing in other subsystem objects is unintuitive and can cause race conditions and circular dependencies, and thus should be avoided. Therefore, this approach is best suited for single-subsystem commands, and should be used only for those cases. Static Command Factories Instance factory methods work great for single-subsystem commands. However, complicated robot actions (like the ones often required during the autonomous period) typically need to coordinate multiple subsystems at once. When we want to define an inline command that uses multiple subsystems, it doesn’t make sense for the command factory to live in any single one of those subsystems. Instead, it can be cleaner to define the command factory methods statically in some external class: Note The sequence and parallel static factories construct sequential and parallel command groups: this is equivalent to the andThen and alongWith decorators, but can be more readable. Their use is a matter of personal preference. JAVA public class AutoRoutines { public static Command driveAndIntake ( Drivetrain drivetrain , Intake intake ) { return Commands . sequence ( Commands . parallel ( drivetrain . driveCommand ( 0.5 , 0.5 ), intake . runIntakeCommand ( 1.0 ) ). withTimeout ( 5.0 ), Commands . parallel ( drivetrain . stopCommand (); intake . stopCommand (); ) ); } } C++ // TODO Non-Static Command Factories If we want to avoid the verbosity of adding required subsystems as parameters to our factory methods, we can instead construct an instance of our AutoRoutines class and inject our subsystems through the constructor: JAVA public class AutoRoutines { private Drivetrain drivetrain ; private Intake intake ; public AutoRoutines ( Drivetrain drivetrain , Intake intake ) { this . drivetrain = drivetrain ; this . intake = intake ; } public Command driveAndIntake () { return Commands . sequence ( Commands . parallel ( drivetrain . driveCommand ( 0.5 , 0.5 ), intake . runIntakeCommand ( 1.0 ) ). withTimeout ( 5.0 ), Commands . parallel ( drivetrain . stopCommand (); intake . stopCommand (); ) ); } public Command driveThenIntake () { return Commands . sequence ( drivetrain . driveCommand ( 0.5 , 0.5 ). withTimeout ( 5.0 ), drivetrain . stopCommand (), intake . runIntakeCommand ( 1.0 ). withTimeout ( 5.0 ), intake . stopCommand () ); } } C++ // TODO Then, elsewhere in our code, we can instantiate an single instance of this class and use it to produce several commands: JAVA AutoRoutines autoRoutines = new AutoRoutines ( this . drivetrain , this . intake ); Command driveAndIntake = autoRoutines . driveAndIntake (); Command driveThenIntake = autoRoutines . driveThenIntake (); Command drivingAndIntakingSequence = Commands . sequence ( autoRoutines . driveAndIntake (), autoRoutines . driveThenIntake () ); C++ // TODO Capturing State in Inline Commands Inline commands are extremely concise and expressive, but do not offer explicit support for commands that have their own internal state (such as a drivetrain trajectory following command, which may encapsulate an entire controller). This is often accomplished by instead writing a Command class, which will be covered later in this article. However, it is still possible to ergonomically write a stateful command composition using inline syntax, so long as we are working within a factory method. To do so, we declare the state as a method local and “capture” it in our inline definition. For example, consider the following instance command factory to turn a drivetrain to a specific angle with a PID controller: Note The Subsystem.run and Subsystem.runOnce factory methods sugar the creation of a RunCommand and an InstantCommand requiring this subsystem. JAVA public Command turnToAngle ( double targetDegrees ) { // Create a controller for the inline command to capture PIDController controller = new PIDController ( Constants . kTurnToAngleP , 0 , 0 ); // We can do whatever configuration we want on the created state before returning from the factory controller . setPositionTolerance ( Constants . kTurnToAngleTolerance ); // Try to turn at a rate proportional to the heading error until we're at the setpoint, then stop return run (() -> arcadeDrive ( 0 , - controller . calculate ( gyro . getHeading (), targetDegrees ))) . until ( controller :: atSetpoint ) . andThen ( runOnce (() -> arcadeDrive ( 0 , 0 ))); } C++ // TODO This pattern works very well in Java so long as the captured state is “effectively final” - i.e., it is never reassigned. This means that we cannot directly define and capture primitive types (e.g. int , double , boolean ) - to circumvent this, we need to wrap any state primitives in a mutable container type (the same way PIDController wraps its internal kP , kI , and kD values). Writing Command Classes Another possible way to define reusable commands is to write a class that represents the command. This is typically done by subclassing either Command or one of the CommandGroup classes. Subclassing Command Returning to our simple intake command from earlier, we could do this by creating a new subclass of Command that implements the necessary initialize and end methods. JAVA public class RunIntakeCommand extends Command { private Intake m_intake ; public RunIntakeCommand ( Intake intake ) { this . m_intake = intake ; addRequirements ( intake ); } @Override public void initialize () { m_intake . set ( 1.0 ); } @Override public void end ( boolean interrupted ) { m_intake . set ( 0.0 ); } // execute() defaults to do nothing // isFinished() defaults to return false } C++ // TODO This, however, is just as cumbersome as the original repetitive code, if not more verbose. The only two lines that really matter in this entire file are the two calls to intake.set() , yet there are over 20 lines of boilerplate code! Not to mention, doing this for a lot of robot actions quickly clutters up a robot project with dozens of small files. Nevertheless, this might feel more “natural,” particularly for programmers who prefer to stick closely to an object-oriented model. This approach should be used for commands with internal state (not subsystem state!), as the class can have fields to manage said state. It may also be more intuitive to write commands with complex logic as classes, especially for those less experienced with command composition. As the command is detached from any specific subsystem class and the required subsystem objects are injected through the constructor, this approach deals well with commands involving multiple subsystems. Subclassing Command Groups If we wish to write composite commands as their own classes, we may write a constructor-only subclass of the most exterior group type. For example, an intake-then-outtake sequence (with single-subsystem commands defined as instance factory methods) can look like this: JAVA public class IntakeThenOuttake extends SequentialCommandGroup { public IntakeThenOuttake ( Intake intake ) { super ( intake . runIntakeCommand ( 1.0 ). withTimeout ( 2.0 ), new WaitCommand ( 2.0 ), intake . runIntakeCommand ( - 1 ). withTimeout ( 5.0 ) ); } } C++ // TODO This is relatively short and minimizes boilerplate. It is also comfortable to use in a purely object-oriented paradigm and may be more acceptable to novice programmers. However, it has some downsides. For one, it is not immediately clear exactly what type of command group this is from the constructor definition: it is better to define this in a more inline and expressive way, particularly when nested command groups start showing up. Additionally, it requires a new file for every single command group, even when the groups are conceptually related. As with factory methods, state can be defined and captured within the command group subclass constructor, if necessary. Summary Approach Primary Use Case Single-subsystem Commands Multi-subsystem Commands Stateful Commands Complex Logic Commands Instance Factory Methods Single-subsystem commands Excels at them No Yes, but must obey capture rules Yes Subclassing Command Stateful commands Very verbose Relatively verbose Excels at them Yes; may be more natural than other approaches Static and Instance Command Factories Multi-subsystem commands Yes Yes Yes, but must obey capture rules Yes Subclassing Command Groups Multi-subsystem command groups Yes Yes Yes, but must obey capture rules Yes",
      "content_preview": "Organizing Command-Based Robot Projects As robot code becomes more complicated, navigating, understanding, and maintaining the code takes up more and more time and energy."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/cpp-command-discussion.html?present",
      "title": "A Technical Discussion on C++ Commands",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "A Technical Discussion on C++ Commands Note This article assumes that you have a fair understanding of advanced C++ concepts, including templates, smart pointers, inheritance, rvalue references, copy semantics, move semantics, and CRTP. You do not need to understand the information within this article to use the command-based framework in your robot code. This article will help you understand the reasoning behind some of the decisions made in the 2020 command-based framework (such as the use of std::unique_ptr , CRTP in the form of CommandHelper<Base, Derived> , etc.). You do not need to understand the information within this article to use the command-based framework in your robot code. Note The model was further changed in 2023, as described below . Ownership Model The old command-based framework employed the use of raw pointers, meaning that users had to use new (resulting in manual heap allocations) in their robot code. Since there was no clear indication on who owned the commands (the scheduler, the command groups, or the user themselves), it was not apparent who was supposed to take care of freeing the memory. Several examples in the old command-based framework involved code like this: #include \"PlaceSoda.h\" #include \"Elevator.h\" #include \"Wrist.h\" PlaceSoda :: PlaceSoda () { AddSequential ( new SetElevatorSetpoint ( Elevator :: TABLE_HEIGHT )); AddSequential ( new SetWristSetpoint ( Wrist :: PICKUP )); AddSequential ( new OpenClaw ()); } In the command-group above, the component commands of the command group were being heap allocated and passed into AddSequential all in the same line. This meant that user had no reference to that object in memory and therefore had no means of freeing the allocated memory once the command group ended. The command group itself never freed the memory and neither did the command scheduler. This led to memory leaks in robot programs (i.e. memory was allocated on the heap but never freed). This glaring problem was one of the reasons for the rewrite of the framework. A comprehensive ownership model was introduced with this rewrite, along with the usage of smart pointers which will automatically free memory when they go out of scope. Default commands are owned by the command scheduler whereas component commands of command compositions are owned by the command composition. Other commands are owned by whatever the user decides they should be owned by (e.g. a subsystem instance or a RobotContainer instance). This means that the ownership of the memory allocated by any commands or command compositions is clearly defined. std::unique_ptr vs. std::shared_ptr Using std::unique_ptr allows us to clearly determine who owns the object. Because an std::unique_ptr cannot be copied, there will never be more than one instance of a std::unique_ptr that points to the same block of memory on the heap. For example, a constructor for SequentialCommandGroup takes in a std::vector<std::unique_ptr<Command>>&& . This means that it requires an rvalue reference to a vector of std::unique_ptr<Command> . Let’s go through some example code step-by-step to understand this better: // Let's create a vector to store our commands that we want to run sequentially. std :: vector < std :: unique_ptr < Command >> commands ; // Add an instant command that prints to the console. commands . emplace_back ( std :: make_unique < InstantCommand > ([]{ std :: cout << \"Hello\" ; }, requirements )); // Add some other command: this can be something that a user has created. commands . emplace_back ( std :: make_unique < MyCommand > ( args , needed , for , this , command )); // Now the vector \"owns\" all of these commands. In its current state, when the vector is destroyed (i.e. // it goes out of scope), it will destroy all of the commands we just added. // Let's create a SequentialCommandGroup that will run these two commands sequentially. auto group = SequentialCommandGroup ( std :: move ( commands )); // Note that we MOVED the vector of commands into the sequential command group, meaning that the // command group now has ownership of our commands. When we call std::move on the vector, all of its // contents (i.e. the unique_ptr instances) are moved into the command group. // Even if the vector were to be destroyed while the command group was running, everything would be OK // since the vector does not own our commands anymore. With std::shared_ptr , there is no clear ownership model because there can be multiple instances of a std::shared_ptr that point to the same block of memory. If commands were in std::shared_ptr instances, a command group or the command scheduler cannot take ownership and free the memory once the command has finished executing because the user might still unknowingly still have a std::shared_ptr instance pointing to that block of memory somewhere in scope. Use of CRTP You may have noticed that in order to create a new command, you must extend CommandHelper , providing the base class (usually frc2::Command ) and the class that you just created. Let’s take a look at the reasoning behind this: Command Decorators The new command-based framework includes a feature known as “command decorators”, which allows the user to something like this: auto task = MyCommand (). AndThen ([] { std :: cout << \"This printed after my command ended.\" ; }, requirements ); When task is scheduled, it will first execute MyCommand() and once that command has finished executing, it will print the message to the console. The way this is achieved internally is by using a sequential command group. Recall from the previous section that in order to construct a sequential command group, we need a vector of unique pointers to each command. Creating the unique pointer for the print function is pretty trivial: temp . emplace_back ( std :: make_unique < InstantCommand > ( std :: move ( toRun ), requirements )); Here temp is storing the vector of commands that we need to pass into the SequentialCommandGroup constructor. But before we add that InstantCommand , we need to add MyCommand() to the SequentialCommandGroup . How do we do that? temp . emplace_back ( std :: make_unique < MyCommand > ( std :: move ( * this )); You might think it would be this straightforward, but that is not the case. Because this decorator code is in the Command class, *this refers to the Command in the subclass that you are calling the decorator from and has the type of Command . Effectively, you will be trying to move a Command instead of MyCommand . We could cast the this pointer to a MyCommand* and then dereference it but we have no information about the subclass to cast to at compile-time. Solutions to the Problem Our initial solution to this was to create a virtual method in Command called TransferOwnership() that every subclass of Command had to override. Such an override would have looked like this: std :: unique_ptr < Command > TransferOwnership () && override { return std :: make_unique < MyCommand > ( std :: move ( * this )); } Because the code would be in the derived subclass, *this would actually point to the desired subclass instance and the user has the type info of the derived class to make the unique pointer. After a few days of deliberation, a CRTP method was proposed. Here, an intermediary derived class of Command called CommandHelper would exist. CommandHelper would have two template arguments, the original base class and the desired derived subclass. Let’s take a look at a basic implementation of CommandHelper to understand this: // In the real implementation, we use SFINAE to check that Base is actually a // Command or a subclass of Command. template < typename Base , typename Derived > class CommandHelper : public Base { // Here, we are just inheriting all of the superclass (base class) constructors. using Base :: Base ; // Here, we will override the TransferOwnership() method mentioned above. std :: unique_ptr < Command > TransferOwnership () && override { // Previously, we mentioned that we had no information about the derived class // to cast to at compile-time, but because of CRTP we do! It's one of our template // arguments! return std :: make_unique < Derived > ( std :: move ( * static_cast < Derived *> ( this ))); } }; Thus, making your custom commands extend CommandHelper instead of Command will automatically implement this boilerplate for you and this is the reasoning behind asking teams to use what may seem to be a rather obscure way of doing things. Going back to our AndThen() example, we can now do the following: // Because of how inheritance works, we will call the TransferOwnership() // of the subclass. We are moving *this because TransferOwnership() can only // be called on rvalue references. temp . emplace_back ( std :: move ( * this ). TransferOwnership ()); Lack of Advanced Decorators Most of the C++ decorators take in std::function<void()> instead of actual commands themselves. The idea of taking in actual commands in decorators such as AndThen() , BeforeStarting() , etc. was considered but then abandoned due to a variety of reasons. Templating Decorators Because we need to know the types of the commands that we are adding to a command group at compile-time, we will need to use templates (variadic for multiple commands). However, this might not seem like a big deal. The constructors for command groups do this anyway: template < class ... Types , typename = std :: enable_if_t < std :: conjunction_v < std :: is_base_of < Command , std :: remove_reference_t < Types >> ... >>> explicit SequentialCommandGroup ( Types && ... commands ) { AddCommands ( std :: forward < Types > ( commands )...); } template < class ... Types , typename = std :: enable_if_t < std :: conjunction_v < std :: is_base_of < Command , std :: remove_reference_t < Types >> ... >>> void AddCommands ( Types && ... commands ) { std :: vector < std :: unique_ptr < Command >> foo ; (( void ) foo . emplace_back ( std :: make_unique < std :: remove_reference_t < Types >> ( std :: forward < Types > ( commands ))), ...); AddCommands ( std :: move ( foo )); } Note This is a secondary constructor for SequentialCommandGroup in addition to the vector constructor that we described above. However, when we make a templated function, its definition must be declared inline. This means that we will need to instantiate the SequentialCommandGroup in the Command.h header, which poses a problem. SequentialCommandGroup.h includes Command.h . If we include SequentialCommandGroup.h inside of Command.h , we have a circular dependency. How do we do it now then? We use a forward declaration at the top of Command.h : class SequentialCommandGroup ; class Command { ... }; And then we include SequentialCommandGroup.h in Command.cpp . If these decorator functions were templated however, we cannot write definitions in the .cpp files, resulting in a circular dependency. Java vs C++ Syntax These decorators usually save more verbosity in Java (because Java requires raw new calls) than in C++, so in general, it does not make much of a syntanctic difference in C++ if you create the command group manually in user code. 2023 Updates After a few years in the new command-based framework, the recommended way to create commands increasingly shifted towards inline commands, decorators, and factory methods. With this paradigm shift, it became evident that the C++ commands model introduced in 2020 and described above has some pain points when used according to the new recommendations. A significant root cause of most pain points was commands being passed by value in a non-polymorphic way. This made object slicing mistakes rather easy, and changes in composition structure could propagate type changes throughout the codebase: for example, if a ParallelRaceGroup were changed to a ParallelDeadlineGroup , those type changes would propagate through the codebase. Passing around the object as a Command (as done in Java) would result in object slicing. Additionally, various decorators weren’t supported in C++ due to reasons described above . As long as decorators were rarely used and were mainly to reduce verbosity (where Java was more verbose than C++), this was less of a problem. Once heavy usage of decorators was recommended, this became more of an issue. CommandPtr Let’s recall the mention of std::unique_ptr far above: a value type with only move semantics. This is the ownership model we want! However, plainly using std::unique_ptr<Command> had some drawbacks. Primarily, implementing decorators would be impossible: unique_ptr is defined in the standard library so we can’t define methods on it, and any methods defined on Command wouldn’t have access to the owning unique_ptr . The solution is CommandPtr : a move-only value class wrapping unique_ptr , that we can define methods on. Commands should be passed around as CommandPtr , using std::move . All decorators, including those not supported in C++ before, are defined on CommandPtr with rvalue-this. The use of rvalues, move-only semantics, and clear ownership makes it very easy to avoid mistakes such as adding the same command instance to more than one command composition . In addition to decorators, CommandPtr instances also define utility methods such as Schedule() , IsScheduled() . CommandPtr instances can be used in nearly almost every way command objects can be used in Java: they can be moved into trigger bindings, default commands, and so on. For the few things that require a Command* (such as non-owning trigger bindings), a raw pointer to the owned command can be retrieved using get() . There are multiple ways to get a CommandPtr instance: CommandPtr -returning factories are present in the frc2::cmd namespace in the Commands.h header for almost all command types. For multi-command compositions, there is a vector-taking overload as well as a variadic-templated overload for multiple CommandPtr instances. All decorators, including those defined on Command , return CommandPtr . This has allowed defining almost all decorators on Command , so a decorator chain can start from a Command . A ToPtr() method has been added to the CRTP, akin to TransferOwnership . This is useful especially for user-defined command classes, as well as other command classes that don’t have factories. For instance, consider the following from the HatchbotInlined example project : 33 frc2 :: CommandPtr autos::ComplexAuto ( DriveSubsystem * drive , 34 HatchSubsystem * hatch ) { 35 return frc2 :: cmd :: Sequence ( 36 // Drive forward the specified distance 37 frc2 :: FunctionalCommand ( 38 // Reset encoders on command start 39 [ drive ] { drive -> ResetEncoders (); }, 40 // Drive forward while the command is executing 41 [ drive ] { drive -> ArcadeDrive ( kAutoDriveSpeed , 0 ); }, 42 // Stop driving at the end of the command 43 [ drive ]( bool interrupted ) { drive -> ArcadeDrive ( 0 , 0 ); }, 44 // End the command when the robot's driven distance exceeds the 45 // desired value 46 [ drive ] { 47 return drive -> GetAverageEncoderDistance () >= 48 kAutoDriveDistanceInches ; 49 }, 50 // Requires the drive subsystem 51 { drive }) 52 . ToPtr (), 53 // Release the hatch 54 hatch -> ReleaseHatchCommand (), 55 // Drive backward the specified distance 56 // Drive forward the specified distance 57 frc2 :: FunctionalCommand ( 58 // Reset encoders on command start 59 [ drive ] { drive -> ResetEncoders (); }, 60 // Drive backward while the command is executing 61 [ drive ] { drive -> ArcadeDrive ( - kAutoDriveSpeed , 0 ); }, 62 // Stop driving at the end of the command 63 [ drive ]( bool interrupted ) { drive -> ArcadeDrive ( 0 , 0 ); }, 64 // End the command when the robot's driven distance exceeds the 65 // desired value 66 [ drive ] { 67 return drive -> GetAverageEncoderDistance () <= 68 kAutoBackupDistanceInches ; 69 }, 70 // Requires the drive subsystem 71 { drive }) 72 . ToPtr ()); 73 } To avoid breakage, command compositions still use unique_ptr<Command> , so CommandPtr instances can be destructured into a unique_ptr<Command> using the Unwrap() rvalue-this method. For vectors, the static CommandPtr::UnwrapVector(vector<CommandPtr>) function exists.",
      "content_preview": "A Technical Discussion on C++ Commands Note This article assumes that you have a fair understanding of advanced C++ concepts, including templates, smart pointers, inheritance, rvalue references, copy semantics, move semantics, and CRTP."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/command-scheduler.html",
      "title": "The Command Scheduler",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "The Command Scheduler The CommandScheduler ( Java , C++ ) is the class responsible for actually running commands. Each iteration (ordinarily once per 20ms), the scheduler polls all registered buttons, schedules commands for execution accordingly, runs the command bodies of all scheduled commands, and ends those commands that have finished or are interrupted. The CommandScheduler also runs the periodic() method of each registered Subsystem . Using the Command Scheduler The CommandScheduler is a singleton , meaning that it is a globally-accessible class with only one instance. Accordingly, in order to access the scheduler, users must call the CommandScheduler.getInstance() command. For the most part, users do not have to call scheduler methods directly - almost all important scheduler methods have convenience wrappers elsewhere (e.g. in the Command and Subsystem classes). However, there is one exception: users must call CommandScheduler.getInstance().run() from the robotPeriodic() method of their Robot class. If this is not done, the scheduler will never run, and the command framework will not work. The provided command-based project template has this call already included. The schedule() Method To schedule a command, users call the schedule() method ( Java , C++ ). This method takes a command, and attempts to add it to list of currently-running commands, pending whether it is already running or whether its requirements are available. If it is added, its initialize() method is called. This method walks through the following steps: Verifies that the command isn’t in a composition. No-op if scheduler is disabled, command is already scheduled, or robot is disabled and command doesn’t runsWhenDisabled . If requirements are in use: If all conflicting commands are interruptible, cancel them. If not, don’t schedule the new command. Call initialize() . Java 202 private void schedule ( Command command ) { 203 if ( command == null ) { 204 DriverStation . reportWarning ( \"Tried to schedule a null command\" , true ); 205 return ; 206 } 207 if ( m_inRunLoop ) { 208 m_toSchedule . add ( command ); 209 return ; 210 } 211 212 requireNotComposed ( command ); 213 214 // Do nothing if the scheduler is disabled, the robot is disabled and the command doesn't 215 // run when disabled, or the command is already scheduled. 216 if ( m_disabled 217 || isScheduled ( command ) 218 || RobotState . isDisabled () && ! command . runsWhenDisabled ()) { 219 return ; 220 } 221 222 Set < Subsystem > requirements = command . getRequirements (); 223 224 // Schedule the command if the requirements are not currently in-use. 225 if ( Collections . disjoint ( m_requirements . keySet (), requirements )) { 226 initCommand ( command , requirements ); 227 } else { 228 // Else check if the requirements that are in use have all have interruptible commands, 229 // and if so, interrupt those commands and schedule the new command. 230 for ( Subsystem requirement : requirements ) { 231 Command requiring = requiring ( requirement ); 232 if ( requiring != null 233 && requiring . getInterruptionBehavior () == InterruptionBehavior . kCancelIncoming ) { 234 return ; 235 } 236 } 237 for ( Subsystem requirement : requirements ) { 238 Command requiring = requiring ( requirement ); 239 if ( requiring != null ) { 240 cancel ( requiring ); 241 } 242 } 243 initCommand ( command , requirements ); 244 } 245 } 181 private void initCommand ( Command command , Set < Subsystem > requirements ) { 182 m_scheduledCommands . add ( command ); 183 for ( Subsystem requirement : requirements ) { 184 m_requirements . put ( requirement , command ); 185 } 186 command . initialize (); 187 for ( Consumer < Command > action : m_initActions ) { 188 action . accept ( command ); 189 } 190 191 m_watchdog . addEpoch ( command . getName () + \".initialize()\" ); C++ (Source) 114 void CommandScheduler::Schedule ( Command * command ) { 115 if ( m_impl -> inRunLoop ) { 116 m_impl -> toSchedule . emplace_back ( command ); 117 return ; 118 } 119 120 RequireUngrouped ( command ); 121 122 if ( m_impl -> disabled || m_impl -> scheduledCommands . contains ( command ) || 123 ( frc :: RobotState :: IsDisabled () && ! command -> RunsWhenDisabled ())) { 124 return ; 125 } 126 127 const auto & requirements = command -> GetRequirements (); 128 129 wpi :: SmallVector < Command * , 8 > intersection ; 130 131 bool isDisjoint = true ; 132 bool allInterruptible = true ; 133 for ( auto && i1 : m_impl -> requirements ) { 134 if ( requirements . find ( i1 . first ) != requirements . end ()) { 135 isDisjoint = false ; 136 allInterruptible &= ( i1 . second -> GetInterruptionBehavior () == 137 Command :: InterruptionBehavior :: kCancelSelf ); 138 intersection . emplace_back ( i1 . second ); 139 } 140 } 141 142 if ( isDisjoint || allInterruptible ) { 143 if ( allInterruptible ) { 144 for ( auto && cmdToCancel : intersection ) { 145 Cancel ( cmdToCancel ); 146 } 147 } 148 m_impl -> scheduledCommands . insert ( command ); 149 for ( auto && requirement : requirements ) { 150 m_impl -> requirements [ requirement ] = command ; 151 } 152 command -> Initialize (); 153 for ( auto && action : m_impl -> initActions ) { 154 action ( * command ); 155 } 156 m_watchdog . AddEpoch ( command -> GetName () + \".Initialize()\" ); 157 } 158 } The Scheduler Run Sequence Note The initialize() method of each Command is called when the command is scheduled, which is not necessarily when the scheduler runs (unless that command is bound to a button). What does a single iteration of the scheduler’s run() method ( Java , C++ ) actually do? The following section walks through the logic of a scheduler iteration. For the full implementation, see the source code ( Java , C++ ). Step 1: Run Subsystem Periodic Methods First, the scheduler runs the periodic() method of each registered Subsystem . In simulation, each subsystem’s simulationPeriodic() method is called as well. Java 278 // Run the periodic method of all registered subsystems. 279 for ( Subsystem subsystem : m_subsystems . keySet ()) { 280 subsystem . periodic (); 281 if ( RobotBase . isSimulation ()) { 282 subsystem . simulationPeriodic (); 283 } 284 m_watchdog . addEpoch ( subsystem . getClass (). getSimpleName () + \".periodic()\" ); 285 } C++ (Source) 183 // Run the periodic method of all registered subsystems. 184 for ( auto && subsystem : m_impl -> subsystems ) { 185 subsystem . getFirst () -> Periodic (); 186 if constexpr ( frc :: RobotBase :: IsSimulation ()) { 187 subsystem . getFirst () -> SimulationPeriodic (); 188 } 189 m_watchdog . AddEpoch ( \"Subsystem Periodic()\" ); 190 } Step 2: Poll Command Scheduling Triggers Note For more information on how trigger bindings work, see Binding Commands to Triggers Secondly, the scheduler polls the state of all registered triggers to see if any new commands that have been bound to those triggers should be scheduled. If the conditions for scheduling a bound command are met, the command is scheduled and its initialize() method is run. Note If a newly-scheduled command has requirement conflicts with a currently-running command, the currently-running command is interrupted first. The end(true) method of the interrupted command is called before the initialize() method of the new command. Java 290 // Poll buttons for new commands to add. 291 loopCache . poll (); 292 m_watchdog . addEpoch ( \"buttons.run()\" ); C++ (Source) 195 // Poll buttons for new commands to add. 196 loopCache -> Poll (); 197 m_watchdog . AddEpoch ( \"buttons.Run()\" ); Step 3: Run/Finish Scheduled Commands Thirdly, the scheduler calls the execute() method of each currently-scheduled command, and then checks whether the command has finished by calling the isFinished() method. If the command has finished, the end() method is also called, and the command is de-scheduled and its required subsystems are freed. Note that this sequence of calls is done in order for each command - thus, one command may have its end() method called before another has its execute() method called. Commands are handled in the order they were scheduled. Java 295 // Run scheduled commands, remove finished commands. 296 for ( Iterator < Command > iterator = m_scheduledCommands . iterator (); iterator . hasNext (); ) { 297 Command command = iterator . next (); 298 299 if ( ! command . runsWhenDisabled () && RobotState . isDisabled ()) { 300 command . end ( true ); 301 for ( Consumer < Command > action : m_interruptActions ) { 302 action . accept ( command ); 303 } 304 m_requirements . keySet (). removeAll ( command . getRequirements ()); 305 iterator . remove (); 306 m_watchdog . addEpoch ( command . getName () + \".end(true)\" ); 307 continue ; 308 } 309 310 command . execute (); 311 for ( Consumer < Command > action : m_executeActions ) { 312 action . accept ( command ); 313 } 314 m_watchdog . addEpoch ( command . getName () + \".execute()\" ); 315 if ( command . isFinished ()) { 316 command . end ( false ); 317 for ( Consumer < Command > action : m_finishActions ) { 318 action . accept ( command ); 319 } 320 iterator . remove (); 321 322 m_requirements . keySet (). removeAll ( command . getRequirements ()); 323 m_watchdog . addEpoch ( command . getName () + \".end(false)\" ); 324 } 325 } C++ (Source) 201 for ( Command * command : m_impl -> scheduledCommands ) { 202 if ( ! command -> RunsWhenDisabled () && frc :: RobotState :: IsDisabled ()) { 203 Cancel ( command ); 204 continue ; 205 } 206 207 command -> Execute (); 208 for ( auto && action : m_impl -> executeActions ) { 209 action ( * command ); 210 } 211 m_watchdog . AddEpoch ( command -> GetName () + \".Execute()\" ); 212 213 if ( command -> IsFinished ()) { 214 command -> End ( false ); 215 for ( auto && action : m_impl -> finishActions ) { 216 action ( * command ); 217 } 218 219 for ( auto && requirement : command -> GetRequirements ()) { 220 m_impl -> requirements . erase ( requirement ); 221 } 222 223 m_impl -> scheduledCommands . erase ( command ); 224 m_watchdog . AddEpoch ( command -> GetName () + \".End(false)\" ); 225 } 226 } Step 4: Schedule Default Commands Finally, any registered Subsystem has its default command scheduled (if it has one). Note that the initialize() method of the default command will be called at this time. Java 340 // Add default commands for un-required registered subsystems. 341 for ( Map . Entry < Subsystem , Command > subsystemCommand : m_subsystems . entrySet ()) { 342 if ( ! m_requirements . containsKey ( subsystemCommand . getKey ()) 343 && subsystemCommand . getValue () != null ) { 344 schedule ( subsystemCommand . getValue ()); 345 } 346 } C++ (Source) 240 // Add default commands for un-required registered subsystems. 241 for ( auto && subsystem : m_impl -> subsystems ) { 242 auto s = m_impl -> requirements . find ( subsystem . getFirst ()); 243 if ( s == m_impl -> requirements . end () && subsystem . getSecond ()) { 244 Schedule ({ subsystem . getSecond (). get ()}); 245 } 246 } Disabling the Scheduler The scheduler can be disabled by calling CommandScheduler.getInstance().disable() . When disabled, the scheduler’s schedule() and run() commands will not do anything. The scheduler may be re-enabled by calling CommandScheduler.getInstance().enable() . Command Event Methods Occasionally, it is desirable to have the scheduler execute a custom action whenever a certain command event (initialization, execution, or ending) occurs. This can be done with the following methods: onCommandInitialize ( Java , C++ ) runs a specified action whenever a command is initialized. onCommandExecute ( Java , C++ ) runs a specified action whenever a command is executed. onCommandFinish ( Java , C++ ) runs a specified action whenever a command finishes normally (i.e. the isFinished() method returned true). onCommandInterrupt ( Java , C++ ) runs a specified action whenever a command is interrupted (i.e. by being explicitly canceled or by another command that shares one of its requirements). A typical use-case for these methods is adding markers in an event log whenever a command scheduling event takes place, as demonstrated in the following code from the HatchbotInlined example project ( Java , C++ ): Java 73 // Set the scheduler to log Shuffleboard events for command initialize, interrupt, finish 74 CommandScheduler . getInstance () 75 . onCommandInitialize ( 76 command -> 77 Shuffleboard . addEventMarker ( 78 \"Command initialized\" , command . getName (), EventImportance . kNormal )); 79 CommandScheduler . getInstance () 80 . onCommandInterrupt ( 81 command -> 82 Shuffleboard . addEventMarker ( 83 \"Command interrupted\" , command . getName (), EventImportance . kNormal )); 84 CommandScheduler . getInstance () 85 . onCommandFinish ( 86 command -> 87 Shuffleboard . addEventMarker ( 88 \"Command finished\" , command . getName (), EventImportance . kNormal )); C++ (Source) 23 // Log Shuffleboard events for command initialize, execute, finish, interrupt 24 frc2 :: CommandScheduler :: GetInstance (). OnCommandInitialize ( 25 []( const frc2 :: Command & command ) { 26 frc :: Shuffleboard :: AddEventMarker ( 27 \"Command initialized\" , command . GetName (), 28 frc :: ShuffleboardEventImportance :: kNormal ); 29 }); 30 frc2 :: CommandScheduler :: GetInstance (). OnCommandExecute ( 31 []( const frc2 :: Command & command ) { 32 frc :: Shuffleboard :: AddEventMarker ( 33 \"Command executed\" , command . GetName (), 34 frc :: ShuffleboardEventImportance :: kNormal ); 35 }); 36 frc2 :: CommandScheduler :: GetInstance (). OnCommandFinish ( 37 []( const frc2 :: Command & command ) { 38 frc :: Shuffleboard :: AddEventMarker ( 39 \"Command finished\" , command . GetName (), 40 frc :: ShuffleboardEventImportance :: kNormal ); 41 }); 42 frc2 :: CommandScheduler :: GetInstance (). OnCommandInterrupt ( 43 []( const frc2 :: Command & command ) { 44 frc :: Shuffleboard :: AddEventMarker ( 45 \"Command interrupted\" , command . GetName (), 46 frc :: ShuffleboardEventImportance :: kNormal ); 47 });",
      "content_preview": "The Command Scheduler The CommandScheduler ( Java , C++ ) is the class responsible for actually running commands. Each iteration (ordinarily once per 20ms), the scheduler polls all registered buttons, schedules commands for execution accordingly, runs the command bodies of all scheduled commands,..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/commands.html",
      "title": "Commands",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Commands Commands represent actions the robot can take. Commands run when scheduled, until they are interrupted or their end condition is met. Commands are represented in the command-based library by the Command class ( Java , C++ ) or the Command class in commands2 library ( Python ). The Structure of a Command Commands specify what the command will do in each of its possible states. This is done by overriding the initialize() , execute() , and end() methods. Additionally, a command must be able to tell the scheduler when (if ever) it has finished execution - this is done by overriding the isFinished() method. All of these methods are defaulted to reduce clutter in user code: initialize() , execute() , and end() are defaulted to simply do nothing, while isFinished() is defaulted to return false (resulting in a command that never finishes naturally, and will run until interrupted). Initialization The initialize() method ( Java , C++ , Python ) marks the command start, and is called exactly once per time a command is scheduled. The initialize() method should be used to place the command in a known starting state for execution. Command objects may be reused and scheduled multiple times, so any state or resources needed for the command’s functionality should be initialized or opened in initialize (which will be called at the start of each use) rather than the constructor (which is invoked only once on object allocation). It is also useful for performing tasks that only need to be performed once per time scheduled, such as setting motors to run at a constant speed or setting the state of a solenoid actuator. Execution The execute() method ( Java , C++ , Python ) is called repeatedly while the command is scheduled; this is when the scheduler’s run() method is called (this is generally done in the main robot periodic method, which runs every 20ms by default). The execute block should be used for any task that needs to be done continually while the command is scheduled, such as updating motor outputs to match joystick inputs, or using the output of a control loop. Ending The end(bool interrupted) method ( Java , C++ , Python ) is called once when the command ends, whether it finishes normally (i.e. isFinished() returned true) or it was interrupted (either by another command or by being explicitly canceled). The method argument specifies the manner in which the command ended; users can use this to differentiate the behavior of their command end accordingly. The end block should be used to “wrap up” command state in a neat way, such as setting motors back to zero or reverting a solenoid actuator to a “default” state. Any state or resources initialized in initialize() should be closed in end() . Specifying end conditions The isFinished() method ( Java , C++ , Python ) is called repeatedly while the command is scheduled, whenever the scheduler’s run() method is called. As soon as it returns true, the command’s end() method is called and it ends. The isFinished() method is called after the execute() method, so the command will execute once on the same iteration that it ends. Command Properties In addition to the four lifecycle methods described above, each Command also has three properties, defined by getter methods that should always return the same value with no side affects. getRequirements Each command should declare any subsystems it controls as requirements. This backs the scheduler’s resource management mechanism, ensuring that no more than one command requires a given subsystem at the same time. This prevents situations such as two different pieces of code attempting to set the same motor controller to different output values. Declaring requirements is done by overriding the getRequirements() method in the relevant command class, by calling addRequirements() , or by using the requirements vararg (Java) / Requirements struct (C++) parameter / requirements argument (Python) at the end of the parameter list of most command constructors and factories in the library: JAVA Commands . run ( intake :: activate , intake ); C++ frc2 :: cmd :: Run ([ & intake ] { intake . Activate (); }, { & intake }); PYTHON commands2 . cmd . run ( intake . activate , intake ) As a rule, command compositions require all subsystems their components require. runsWhenDisabled The runsWhenDisabled() method ( Java , C++ , Python ) returns a boolean / bool specifying whether the command may run when the robot is disabled. With the default of returning false , the command will be canceled when the robot is disabled and attempts to schedule it will do nothing. Returning true will allow the command to run and be scheduled when the robot is disabled. Important When the robot is disabled, PWM outputs are disabled and CAN motor controllers may not apply voltage, regardless of runsWhenDisabled ! This property can be set either by overriding the runsWhenDisabled() method in the relevant command class, or by using the ignoringDisable decorator ( Java , C++ , Python ): JAVA Command mayRunDuringDisabled = Commands . run (() -> updateTelemetry ()). ignoringDisable ( true ); C++ frc2 :: CommandPtr mayRunDuringDisabled = frc2 :: cmd :: Run ([] { UpdateTelemetry (); }). IgnoringDisable ( true ); PYTHON may_run_during_disabled = commands2 . cmd . run ( lambda : update_telemetry ()) . ignoring_disable ( True ) As a rule, command compositions may run when disabled if all their component commands set runsWhenDisabled as true . getInterruptionBehavior The getInterruptionBehavior() method ( Java , C++ , Python ) defines what happens if another command sharing a requirement is scheduled while this one is running. In the default behavior, kCancelSelf , the current command will be canceled and the incoming command will be scheduled successfully. If kCancelIncoming is returned, the incoming command’s scheduling will be aborted and this command will continue running. Note that getInterruptionBehavior only affects resolution of requirement conflicts: all commands can be canceled, regardless of getInterruptionBehavior . Note This was previously controlled by the interruptible parameter passed when scheduling a command, and is now a property of the command object. This property can be set either by overriding the getInterruptionBehavior method in the relevant command class, or by using the withInterruptBehavior() decorator ( Java , C++ , Python ) JAVA Command noninteruptible = Commands . run ( intake :: activate , intake ). withInterruptBehavior ( Command . InterruptBehavior . kCancelIncoming ); C++ frc2 :: CommandPtr noninterruptible = frc2 :: cmd :: Run ([ & intake ] { intake . Activate (); }, { & intake }). WithInterruptBehavior ( Command :: InterruptBehavior :: kCancelIncoming ); PYTHON non_interruptible = commands2 . cmd . run ( intake . activate , intake ) . with_interrupt_behavior ( Command . InterruptBehavior . kCancelIncoming ) As a rule, command compositions are kCancelIncoming if all their components are kCancelIncoming as well. Included Command Types The command-based library includes many pre-written command types. Through the use of lambdas , these commands can cover almost all use cases and teams should rarely need to write custom command classes. Many of these commands are provided via static factory functions in the Commands utility class (Java), in the frc2::cmd namespace defined in the Commands.h header (C++), or in the commands2.cmd namespace (Python). In Java and C++, classes inheriting from Subsystem also have instance methods that implicitly require this . Running Actions The most basic commands are actions the robot takes: setting voltage to a motor, changing a solenoid’s direction, etc. For these commands, which typically consist of a method call or two, the command-based library offers several factories to be construct commands inline with one or more lambdas to be executed. The runOnce factory, backed by the InstantCommand ( Java , C++ , Python ) class, creates a command that calls a lambda once, and then finishes. Java 25 /** Grabs the hatch. */ 26 public Command grabHatchCommand () { 27 // implicitly require `this` 28 return this . runOnce (() -> m_hatchSolenoid . set ( kForward )); 29 } 30 31 /** Releases the hatch. */ 32 public Command releaseHatchCommand () { 33 // implicitly require `this` 34 return this . runOnce (() -> m_hatchSolenoid . set ( kReverse )); 35 } C++ (Header) 20 /** 21 * Grabs the hatch. 22 */ 23 frc2 :: CommandPtr GrabHatchCommand (); 24 25 /** 26 * Releases the hatch. 27 */ 28 frc2 :: CommandPtr ReleaseHatchCommand (); C++ (Source) 15 frc2 :: CommandPtr HatchSubsystem::GrabHatchCommand () { 16 // implicitly require `this` 17 return this -> RunOnce ( 18 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); }); 19 } 20 21 frc2 :: CommandPtr HatchSubsystem::ReleaseHatchCommand () { 22 // implicitly require `this` 23 return this -> RunOnce ( 24 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); }); 25 } Python 24 def grabHatch ( self ) -> commands2 . Command : 25 \"\"\"Grabs the hatch\"\"\" 26 return commands2 . cmd . runOnce ( 27 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ), self 28 ) 29 30 def releaseHatch ( self ) -> commands2 . Command : 31 \"\"\"Releases the hatch\"\"\" 32 return commands2 . cmd . runOnce ( 33 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ), self 34 ) The run factory, backed by the RunCommand ( Java , C++ , Python ) class, creates a command that calls a lambda repeatedly, until interrupted. JAVA // A split-stick arcade command, with forward/backward controlled by the left // hand, and turning controlled by the right. new RunCommand (() -> m_robotDrive . arcadeDrive ( - driverController . getLeftY (), driverController . getRightX ()), m_robotDrive ) C++ // A split-stick arcade command, with forward/backward controlled by the left // hand, and turning controlled by the right. frc2 :: RunCommand ( [ this ] { m_drive . ArcadeDrive ( - m_driverController . GetLeftY (), m_driverController . GetRightX ()); }, { & m_drive }) PYTHON # A split-stick arcade command, with forward/backward controlled by the left # hand, and turning controlled by the right. commands2 . cmd . run ( lambda : robot_drive . arcade_drive ( - driver_controller . get_left_y (), driver_controller . get_right_x ()), robot_drive ) The startEnd factory, backed by the StartEndCommand ( Java , C++ , Python ) class, calls one lambda when scheduled, and then a second lambda when interrupted. JAVA Commands . startEnd ( // Start a flywheel spinning at 50% power () -> m_shooter . shooterSpeed ( 0.5 ), // Stop the flywheel at the end of the command () -> m_shooter . shooterSpeed ( 0.0 ), // Requires the shooter subsystem m_shooter ) C++ frc2 :: cmd :: StartEnd ( // Start a flywheel spinning at 50% power [ this ] { m_shooter . shooterSpeed ( 0.5 ); }, // Stop the flywheel at the end of the command [ this ] { m_shooter . shooterSpeed ( 0.0 ); }, // Requires the shooter subsystem { & m_shooter } ) PYTHON commands2 . cmd . start_end ( # Start a flywheel spinning at 50% power lambda : shooter . shooter_speed ( 0.5 ), # Stop the flywheel at the end of the command lambda : shooter . shooter_speed ( 0.0 ), # Requires the shooter subsystem shooter ) FunctionalCommand ( Java , C++ , Python ) accepts four lambdas that constitute the four command lifecycle methods: a Runnable / std::function<void()>/Callable for each of initialize() and execute() , a BooleanConsumer / std::function<void(bool)>/Callable[bool,[]] for end() , and a BooleanSupplier / std::function<bool()>/Callable[[],bool] for isFinished() . JAVA new FunctionalCommand ( // Reset encoders on command start m_robotDrive :: resetEncoders , // Start driving forward at the start of the command () -> m_robotDrive . arcadeDrive ( kAutoDriveSpeed , 0 ), // Stop driving at the end of the command interrupted -> m_robotDrive . arcadeDrive ( 0 , 0 ), // End the command when the robot's driven distance exceeds the desired value () -> m_robotDrive . getAverageEncoderDistance () >= kAutoDriveDistanceInches , // Require the drive subsystem m_robotDrive ) C++ frc2 :: FunctionalCommand ( // Reset encoders on command start [ this ] { m_drive . ResetEncoders (); }, // Start driving forward at the start of the command [ this ] { m_drive . ArcadeDrive ( ac :: kAutoDriveSpeed , 0 ); }, // Stop driving at the end of the command [ this ] ( bool interrupted ) { m_drive . ArcadeDrive ( 0 , 0 ); }, // End the command when the robot's driven distance exceeds the desired value [ this ] { return m_drive . GetAverageEncoderDistance () >= kAutoDriveDistanceInches ; }, // Requires the drive subsystem { & m_drive } ) PYTHON commands2 . cmd . functional_command ( # Reset encoders on command start lambda : robot_drive . reset_encoders (), # Start driving forward at the start of the command lambda : robot_drive . arcade_drive ( ac . kAutoDriveSpeed , 0 ), # Stop driving at the end of the command lambda interrupted : robot_drive . arcade_drive ( 0 , 0 ), # End the command when the robot's driven distance exceeds the desired value lambda : robot_drive . get_average_encoder_distance () >= ac . kAutoDriveDistanceInches , # Require the drive subsystem robot_drive ) To print a string and ending immediately, the library offers the Commands.print(String) / frc2::cmd::Print(std::string_view) / commands2.cmd.print(String) factory, backed by the PrintCommand ( Java , C++ , Python ) subclass of InstantCommand . Waiting Waiting for a certain condition to happen or adding a delay can be useful to synchronize between different commands in a command composition or between other robot actions. To wait and end after a specified period of time elapses, the library offers the Commands.waitSeconds(double) / frc2::cmd::Wait(units::second_t) / commands2.cmd.wait(float) factory, backed by the WaitCommand ( Java , C++ , Python ) class. JAVA // Ends 5 seconds after being scheduled new WaitCommand ( 5.0 ) C++ // Ends 5 seconds after being scheduled frc2 :: WaitCommand ( 5.0 _s ) PYTHON # Ends 5 seconds after being scheduled commands2 . cmd . wait ( 5.0 ) To wait until a certain condition becomes true , the library offers the Commands.waitUntil(BooleanSupplier) / frc2::cmd::WaitUntil(std::function<bool()>) factory, backed by the WaitUntilCommand class ( Java , C++ , Python ). JAVA // Ends after m_limitSwitch.get() returns true new WaitUntilCommand ( m_limitSwitch :: get ) C++ // Ends after m_limitSwitch.Get() returns true frc2 :: WaitUntilCommand ([ & m_limitSwitch ] { return m_limitSwitch . Get (); }) PYTHON # Ends after limit_switch.get() returns True commands2 . cmd . wait_until ( limit_switch . get ) Control Algorithm Commands There are commands for various control setups: TrapezoidProfile tracks a trapezoid motion profile. For more info, see Motion Profiling in Command-based . MecanumControllerCommand ( Java , C++ ) is useful for controlling mecanum drivetrains. See API docs and the MecanumControllerCommand ( Java , C++ ) example project for more info. SwerveControllerCommand ( Java , C++ ) is useful for controlling swerve drivetrains. See API docs and the SwerveControllerCommand ( Java , C++ ) example project for more info. RamseteCommand ( Java , C++ ) is useful for path following with differential drivetrains (“tank drive”). See API docs and the Trajectory Tutorial for more info. Custom Command Classes Users may also write custom command classes. As this is significantly more verbose, it’s recommended to use the more concise factories mentioned above. Note In the C++ API, a CRTP is used to allow certain Command methods to work with the object ownership model. Users should always extend the CommandHelper class when defining their own command classes, as is shown below. To write a custom command class, subclass the abstract Command class ( Java ) or CommandHelper ( C++ ), as seen in the command-based template ( Java , C++ ): JAVA 7 import edu.wpi.first.wpilibj.templates.commandbased.subsystems.ExampleSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 10 /** An example command that uses an example subsystem. */ 11 public class ExampleCommand extends Command { 12 @SuppressWarnings ({ \"PMD.UnusedPrivateField\" , \"PMD.SingularField\" }) 13 private final ExampleSubsystem m_subsystem ; 14 15 /** 16 * Creates a new ExampleCommand. 17 * 18 * @param subsystem The subsystem used by this command. 19 */ 20 public ExampleCommand ( ExampleSubsystem subsystem ) { 21 m_subsystem = subsystem ; 22 // Use addRequirements() here to declare subsystem dependencies. 23 addRequirements ( subsystem ); 24 } C++ 5 #pragma once 6 7 #include <frc2/command/Command.h> 8 #include <frc2/command/CommandHelper.h> 9 10 #include \"subsystems/ExampleSubsystem.h\" 11 12 /** 13 * An example command that uses an example subsystem. 14 * 15 * <p>Note that this extends CommandHelper, rather extending Command 16 * directly; this is crucially important, or else the decorator functions in 17 * Command will *not* work! 18 */ 19 class ExampleCommand 20 : public frc2 :: CommandHelper < frc2 :: Command , ExampleCommand > { 21 public : 22 /** 23 * Creates a new ExampleCommand. 24 * 25 * @param subsystem The subsystem used by this command. 26 */ 27 explicit ExampleCommand ( ExampleSubsystem * subsystem ); 28 29 private : 30 ExampleSubsystem * m_subsystem ; 31 }; Simple Command Example What might a functional command look like in practice? As before, below is a simple command from the HatchBot example project ( Java , C++ ) that uses the HatchSubsystem : Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.HatchSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 10 /** 11 * A simple command that grabs a hatch with the {@link HatchSubsystem}. Written explicitly for 12 * pedagogical purposes. Actual code should inline a command this simple with {@link 13 * edu.wpi.first.wpilibj2.command.InstantCommand}. 14 */ 15 public class GrabHatch extends Command { 16 // The subsystem the command runs on 17 private final HatchSubsystem m_hatchSubsystem ; 18 19 public GrabHatch ( HatchSubsystem subsystem ) { 20 m_hatchSubsystem = subsystem ; 21 addRequirements ( m_hatchSubsystem ); 22 } 23 24 @Override 25 public void initialize () { 26 m_hatchSubsystem . grabHatch (); 27 } 28 29 @Override 30 public boolean isFinished () { 31 return true ; 32 } 33 } C++ (Header) 5 #pragma once 6 7 #include <frc2/command/Command.h> 8 #include <frc2/command/CommandHelper.h> 9 10 #include \"subsystems/HatchSubsystem.h\" 11 12 /** 13 * A simple command that grabs a hatch with the HatchSubsystem. Written 14 * explicitly for pedagogical purposes. Actual code should inline a command 15 * this simple with InstantCommand. 16 * 17 * @see InstantCommand 18 */ 19 class GrabHatch : public frc2 :: CommandHelper < frc2 :: Command , GrabHatch > { 20 public : 21 explicit GrabHatch ( HatchSubsystem * subsystem ); 22 23 void Initialize () override ; 24 25 bool IsFinished () override ; 26 27 private : 28 HatchSubsystem * m_hatch ; 29 }; C++ (Source) 5 #include \"commands/GrabHatch.h\" 6 7 GrabHatch :: GrabHatch ( HatchSubsystem * subsystem ) : m_hatch ( subsystem ) { 8 AddRequirements ( subsystem ); 9 } 10 11 void GrabHatch :: Initialize () { 12 m_hatch -> GrabHatch (); 13 } 14 15 bool GrabHatch :: IsFinished () { 16 return true ; 17 } Python 7 import commands2 8 from subsystems.hatchsubsystem import HatchSubsystem 9 10 11 class GrabHatch ( commands2 . Command ): 12 def __init__ ( self , hatch : HatchSubsystem ) -> None : 13 super () . __init__ () 14 self . hatch = hatch 15 self . addRequirements ( hatch ) 16 17 def initialize ( self ) -> None : 18 self . hatch . grabHatch () 19 20 def isFinished ( self ) -> bool : 21 return True Notice that the hatch subsystem used by the command is passed into the command through the command’s constructor. This is a pattern called dependency injection , and allows users to avoid declaring their subsystems as global variables. This is widely accepted as a best-practice - the reasoning behind this is discussed in a later section . Notice also that the above command calls the subsystem method once from initialize, and then immediately ends (as isFinished() simply returns true). This is typical for commands that toggle the states of subsystems, and as such it would be more succinct to write this command using the factories described above. What about a more complicated case? Below is a drive command, from the same example project: Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.DriveSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 import java.util.function.DoubleSupplier ; 10 11 /** 12 * A command to drive the robot with joystick input (passed in as {@link DoubleSupplier}s). Written 13 * explicitly for pedagogical purposes - actual code should inline a command this simple with {@link 14 * edu.wpi.first.wpilibj2.command.RunCommand}. 15 */ 16 public class DefaultDrive extends Command { 17 private final DriveSubsystem m_drive ; 18 private final DoubleSupplier m_forward ; 19 private final DoubleSupplier m_rotation ; 20 21 /** 22 * Creates a new DefaultDrive. 23 * 24 * @param subsystem The drive subsystem this command wil run on. 25 * @param forward The control input for driving forwards/backwards 26 * @param rotation The control input for turning 27 */ 28 public DefaultDrive ( DriveSubsystem subsystem , DoubleSupplier forward , DoubleSupplier rotation ) { 29 m_drive = subsystem ; 30 m_forward = forward ; 31 m_rotation = rotation ; 32 addRequirements ( m_drive ); 33 } 34 35 @Override 36 public void execute () { 37 m_drive . arcadeDrive ( m_forward . getAsDouble (), m_rotation . getAsDouble ()); 38 } 39 } C++ (Header) 5 #pragma once 6 7 #include <functional> 8 9 #include <frc2/command/Command.h> 10 #include <frc2/command/CommandHelper.h> 11 12 #include \"subsystems/DriveSubsystem.h\" 13 14 /** 15 * A command to drive the robot with joystick input passed in through lambdas. 16 * Written explicitly for pedagogical purposes - actual code should inline a 17 * command this simple with RunCommand. 18 * 19 * @see RunCommand 20 */ 21 class DefaultDrive : public frc2 :: CommandHelper < frc2 :: Command , DefaultDrive > { 22 public : 23 /** 24 * Creates a new DefaultDrive. 25 * 26 * @param subsystem The drive subsystem this command wil run on. 27 * @param forward The control input for driving forwards/backwards 28 * @param rotation The control input for turning 29 */ 30 DefaultDrive ( DriveSubsystem * subsystem , std :: function < double () > forward , 31 std :: function < double () > rotation ); 32 33 void Execute () override ; 34 35 private : 36 DriveSubsystem * m_drive ; 37 std :: function < double () > m_forward ; 38 std :: function < double () > m_rotation ; 39 }; C++ (Source) 5 #include \"commands/DefaultDrive.h\" 6 7 #include <utility> 8 9 DefaultDrive :: DefaultDrive ( DriveSubsystem * subsystem , 10 std :: function < double () > forward , 11 std :: function < double () > rotation ) 12 : m_drive { subsystem }, 13 m_forward { std :: move ( forward )}, 14 m_rotation { std :: move ( rotation )} { 15 AddRequirements ( subsystem ); 16 } 17 18 void DefaultDrive :: Execute () { 19 m_drive -> ArcadeDrive ( m_forward (), m_rotation ()); 20 } Python 7 import typing 8 import commands2 9 from subsystems.drivesubsystem import DriveSubsystem 10 11 12 class DefaultDrive ( commands2 . Command ): 13 def __init__ ( 14 self , 15 drive : DriveSubsystem , 16 forward : typing . Callable [[], float ], 17 rotation : typing . Callable [[], float ], 18 ) -> None : 19 super () . __init__ () 20 21 self . drive = drive 22 self . forward = forward 23 self . rotation = rotation 24 25 self . addRequirements ( self . drive ) 26 27 def execute ( self ) -> None : 28 self . drive . arcadeDrive ( self . forward (), self . rotation ()) And then usage: JAVA 59 // Configure default commands 60 // Set the default drive command to split-stick arcade drive 61 m_robotDrive . setDefaultCommand ( 62 // A split-stick arcade command, with forward/backward controlled by the left 63 // hand, and turning controlled by the right. 64 new DefaultDrive ( 65 m_robotDrive , 66 () -> - m_driverController . getLeftY (), 67 () -> - m_driverController . getRightX ())); C++ 57 // Set up default drive command 58 m_drive . SetDefaultCommand ( DefaultDrive ( 59 & m_drive , [ this ] { return - m_driverController . GetLeftY (); }, 60 [ this ] { return - m_driverController . GetRightX (); })); PYTHON 65 # set up default drive command 66 self . drive . setDefaultCommand ( 67 DefaultDrive ( 68 self . drive , 69 lambda : - self . driverController . getY (), 70 lambda : self . driverController . getX (), 71 ) 72 ) Notice that this command does not override isFinished() , and thus will never end; this is the norm for commands that are intended to be used as default commands. Once more, this command is rather simple and calls the subsystem method only from one place, and as such, could be more concisely written using factories: JAVA 51 // Configure default commands 52 // Set the default drive command to split-stick arcade drive 53 m_robotDrive . setDefaultCommand ( 54 // A split-stick arcade command, with forward/backward controlled by the left 55 // hand, and turning controlled by the right. 56 Commands . run ( 57 () -> 58 m_robotDrive . arcadeDrive ( 59 - m_driverController . getLeftY (), - m_driverController . getRightX ()), 60 m_robotDrive )); C++ 52 // Set up default drive command 53 m_drive . SetDefaultCommand ( frc2 :: cmd :: Run ( 54 [ this ] { 55 m_drive . ArcadeDrive ( - m_driverController . GetLeftY (), 56 - m_driverController . GetRightX ()); 57 }, 58 { & m_drive })); PYTHON 53 # Configure default commands 54 # Set the default drive command to split-stick arcade drive 55 self . driveSubsystem . setDefaultCommand ( 56 # A split-stick arcade command, with forward/backward controlled by the left 57 # hand, and turning controlled by the right. 58 commands2 . cmd . run ( 59 lambda : self . driveSubsystem . arcadeDrive ( 60 - self . driverController . getLeftY (), 61 - self . driverController . getRightX (), 62 ), 63 self . driveSubsystem , 64 ) 65 )",
      "content_preview": "Commands Commands represent actions the robot can take. Commands run when scheduled, until they are interrupted or their end condition is met. Commands are represented in the command-based library by the Command class ( Java , C++ ) or the Command class in commands2 library ( Python )."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/commands.html?present",
      "title": "Commands",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Commands Commands represent actions the robot can take. Commands run when scheduled, until they are interrupted or their end condition is met. Commands are represented in the command-based library by the Command class ( Java , C++ ) or the Command class in commands2 library ( Python ). The Structure of a Command Commands specify what the command will do in each of its possible states. This is done by overriding the initialize() , execute() , and end() methods. Additionally, a command must be able to tell the scheduler when (if ever) it has finished execution - this is done by overriding the isFinished() method. All of these methods are defaulted to reduce clutter in user code: initialize() , execute() , and end() are defaulted to simply do nothing, while isFinished() is defaulted to return false (resulting in a command that never finishes naturally, and will run until interrupted). Initialization The initialize() method ( Java , C++ , Python ) marks the command start, and is called exactly once per time a command is scheduled. The initialize() method should be used to place the command in a known starting state for execution. Command objects may be reused and scheduled multiple times, so any state or resources needed for the command’s functionality should be initialized or opened in initialize (which will be called at the start of each use) rather than the constructor (which is invoked only once on object allocation). It is also useful for performing tasks that only need to be performed once per time scheduled, such as setting motors to run at a constant speed or setting the state of a solenoid actuator. Execution The execute() method ( Java , C++ , Python ) is called repeatedly while the command is scheduled; this is when the scheduler’s run() method is called (this is generally done in the main robot periodic method, which runs every 20ms by default). The execute block should be used for any task that needs to be done continually while the command is scheduled, such as updating motor outputs to match joystick inputs, or using the output of a control loop. Ending The end(bool interrupted) method ( Java , C++ , Python ) is called once when the command ends, whether it finishes normally (i.e. isFinished() returned true) or it was interrupted (either by another command or by being explicitly canceled). The method argument specifies the manner in which the command ended; users can use this to differentiate the behavior of their command end accordingly. The end block should be used to “wrap up” command state in a neat way, such as setting motors back to zero or reverting a solenoid actuator to a “default” state. Any state or resources initialized in initialize() should be closed in end() . Specifying end conditions The isFinished() method ( Java , C++ , Python ) is called repeatedly while the command is scheduled, whenever the scheduler’s run() method is called. As soon as it returns true, the command’s end() method is called and it ends. The isFinished() method is called after the execute() method, so the command will execute once on the same iteration that it ends. Command Properties In addition to the four lifecycle methods described above, each Command also has three properties, defined by getter methods that should always return the same value with no side affects. getRequirements Each command should declare any subsystems it controls as requirements. This backs the scheduler’s resource management mechanism, ensuring that no more than one command requires a given subsystem at the same time. This prevents situations such as two different pieces of code attempting to set the same motor controller to different output values. Declaring requirements is done by overriding the getRequirements() method in the relevant command class, by calling addRequirements() , or by using the requirements vararg (Java) / Requirements struct (C++) parameter / requirements argument (Python) at the end of the parameter list of most command constructors and factories in the library: JAVA Commands . run ( intake :: activate , intake ); C++ frc2 :: cmd :: Run ([ & intake ] { intake . Activate (); }, { & intake }); PYTHON commands2 . cmd . run ( intake . activate , intake ) As a rule, command compositions require all subsystems their components require. runsWhenDisabled The runsWhenDisabled() method ( Java , C++ , Python ) returns a boolean / bool specifying whether the command may run when the robot is disabled. With the default of returning false , the command will be canceled when the robot is disabled and attempts to schedule it will do nothing. Returning true will allow the command to run and be scheduled when the robot is disabled. Important When the robot is disabled, PWM outputs are disabled and CAN motor controllers may not apply voltage, regardless of runsWhenDisabled ! This property can be set either by overriding the runsWhenDisabled() method in the relevant command class, or by using the ignoringDisable decorator ( Java , C++ , Python ): JAVA Command mayRunDuringDisabled = Commands . run (() -> updateTelemetry ()). ignoringDisable ( true ); C++ frc2 :: CommandPtr mayRunDuringDisabled = frc2 :: cmd :: Run ([] { UpdateTelemetry (); }). IgnoringDisable ( true ); PYTHON may_run_during_disabled = commands2 . cmd . run ( lambda : update_telemetry ()) . ignoring_disable ( True ) As a rule, command compositions may run when disabled if all their component commands set runsWhenDisabled as true . getInterruptionBehavior The getInterruptionBehavior() method ( Java , C++ , Python ) defines what happens if another command sharing a requirement is scheduled while this one is running. In the default behavior, kCancelSelf , the current command will be canceled and the incoming command will be scheduled successfully. If kCancelIncoming is returned, the incoming command’s scheduling will be aborted and this command will continue running. Note that getInterruptionBehavior only affects resolution of requirement conflicts: all commands can be canceled, regardless of getInterruptionBehavior . Note This was previously controlled by the interruptible parameter passed when scheduling a command, and is now a property of the command object. This property can be set either by overriding the getInterruptionBehavior method in the relevant command class, or by using the withInterruptBehavior() decorator ( Java , C++ , Python ) JAVA Command noninteruptible = Commands . run ( intake :: activate , intake ). withInterruptBehavior ( Command . InterruptBehavior . kCancelIncoming ); C++ frc2 :: CommandPtr noninterruptible = frc2 :: cmd :: Run ([ & intake ] { intake . Activate (); }, { & intake }). WithInterruptBehavior ( Command :: InterruptBehavior :: kCancelIncoming ); PYTHON non_interruptible = commands2 . cmd . run ( intake . activate , intake ) . with_interrupt_behavior ( Command . InterruptBehavior . kCancelIncoming ) As a rule, command compositions are kCancelIncoming if all their components are kCancelIncoming as well. Included Command Types The command-based library includes many pre-written command types. Through the use of lambdas , these commands can cover almost all use cases and teams should rarely need to write custom command classes. Many of these commands are provided via static factory functions in the Commands utility class (Java), in the frc2::cmd namespace defined in the Commands.h header (C++), or in the commands2.cmd namespace (Python). In Java and C++, classes inheriting from Subsystem also have instance methods that implicitly require this . Running Actions The most basic commands are actions the robot takes: setting voltage to a motor, changing a solenoid’s direction, etc. For these commands, which typically consist of a method call or two, the command-based library offers several factories to be construct commands inline with one or more lambdas to be executed. The runOnce factory, backed by the InstantCommand ( Java , C++ , Python ) class, creates a command that calls a lambda once, and then finishes. Java 25 /** Grabs the hatch. */ 26 public Command grabHatchCommand () { 27 // implicitly require `this` 28 return this . runOnce (() -> m_hatchSolenoid . set ( kForward )); 29 } 30 31 /** Releases the hatch. */ 32 public Command releaseHatchCommand () { 33 // implicitly require `this` 34 return this . runOnce (() -> m_hatchSolenoid . set ( kReverse )); 35 } C++ (Header) 20 /** 21 * Grabs the hatch. 22 */ 23 frc2 :: CommandPtr GrabHatchCommand (); 24 25 /** 26 * Releases the hatch. 27 */ 28 frc2 :: CommandPtr ReleaseHatchCommand (); C++ (Source) 15 frc2 :: CommandPtr HatchSubsystem::GrabHatchCommand () { 16 // implicitly require `this` 17 return this -> RunOnce ( 18 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); }); 19 } 20 21 frc2 :: CommandPtr HatchSubsystem::ReleaseHatchCommand () { 22 // implicitly require `this` 23 return this -> RunOnce ( 24 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); }); 25 } Python 24 def grabHatch ( self ) -> commands2 . Command : 25 \"\"\"Grabs the hatch\"\"\" 26 return commands2 . cmd . runOnce ( 27 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ), self 28 ) 29 30 def releaseHatch ( self ) -> commands2 . Command : 31 \"\"\"Releases the hatch\"\"\" 32 return commands2 . cmd . runOnce ( 33 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ), self 34 ) The run factory, backed by the RunCommand ( Java , C++ , Python ) class, creates a command that calls a lambda repeatedly, until interrupted. JAVA // A split-stick arcade command, with forward/backward controlled by the left // hand, and turning controlled by the right. new RunCommand (() -> m_robotDrive . arcadeDrive ( - driverController . getLeftY (), driverController . getRightX ()), m_robotDrive ) C++ // A split-stick arcade command, with forward/backward controlled by the left // hand, and turning controlled by the right. frc2 :: RunCommand ( [ this ] { m_drive . ArcadeDrive ( - m_driverController . GetLeftY (), m_driverController . GetRightX ()); }, { & m_drive }) PYTHON # A split-stick arcade command, with forward/backward controlled by the left # hand, and turning controlled by the right. commands2 . cmd . run ( lambda : robot_drive . arcade_drive ( - driver_controller . get_left_y (), driver_controller . get_right_x ()), robot_drive ) The startEnd factory, backed by the StartEndCommand ( Java , C++ , Python ) class, calls one lambda when scheduled, and then a second lambda when interrupted. JAVA Commands . startEnd ( // Start a flywheel spinning at 50% power () -> m_shooter . shooterSpeed ( 0.5 ), // Stop the flywheel at the end of the command () -> m_shooter . shooterSpeed ( 0.0 ), // Requires the shooter subsystem m_shooter ) C++ frc2 :: cmd :: StartEnd ( // Start a flywheel spinning at 50% power [ this ] { m_shooter . shooterSpeed ( 0.5 ); }, // Stop the flywheel at the end of the command [ this ] { m_shooter . shooterSpeed ( 0.0 ); }, // Requires the shooter subsystem { & m_shooter } ) PYTHON commands2 . cmd . start_end ( # Start a flywheel spinning at 50% power lambda : shooter . shooter_speed ( 0.5 ), # Stop the flywheel at the end of the command lambda : shooter . shooter_speed ( 0.0 ), # Requires the shooter subsystem shooter ) FunctionalCommand ( Java , C++ , Python ) accepts four lambdas that constitute the four command lifecycle methods: a Runnable / std::function<void()>/Callable for each of initialize() and execute() , a BooleanConsumer / std::function<void(bool)>/Callable[bool,[]] for end() , and a BooleanSupplier / std::function<bool()>/Callable[[],bool] for isFinished() . JAVA new FunctionalCommand ( // Reset encoders on command start m_robotDrive :: resetEncoders , // Start driving forward at the start of the command () -> m_robotDrive . arcadeDrive ( kAutoDriveSpeed , 0 ), // Stop driving at the end of the command interrupted -> m_robotDrive . arcadeDrive ( 0 , 0 ), // End the command when the robot's driven distance exceeds the desired value () -> m_robotDrive . getAverageEncoderDistance () >= kAutoDriveDistanceInches , // Require the drive subsystem m_robotDrive ) C++ frc2 :: FunctionalCommand ( // Reset encoders on command start [ this ] { m_drive . ResetEncoders (); }, // Start driving forward at the start of the command [ this ] { m_drive . ArcadeDrive ( ac :: kAutoDriveSpeed , 0 ); }, // Stop driving at the end of the command [ this ] ( bool interrupted ) { m_drive . ArcadeDrive ( 0 , 0 ); }, // End the command when the robot's driven distance exceeds the desired value [ this ] { return m_drive . GetAverageEncoderDistance () >= kAutoDriveDistanceInches ; }, // Requires the drive subsystem { & m_drive } ) PYTHON commands2 . cmd . functional_command ( # Reset encoders on command start lambda : robot_drive . reset_encoders (), # Start driving forward at the start of the command lambda : robot_drive . arcade_drive ( ac . kAutoDriveSpeed , 0 ), # Stop driving at the end of the command lambda interrupted : robot_drive . arcade_drive ( 0 , 0 ), # End the command when the robot's driven distance exceeds the desired value lambda : robot_drive . get_average_encoder_distance () >= ac . kAutoDriveDistanceInches , # Require the drive subsystem robot_drive ) To print a string and ending immediately, the library offers the Commands.print(String) / frc2::cmd::Print(std::string_view) / commands2.cmd.print(String) factory, backed by the PrintCommand ( Java , C++ , Python ) subclass of InstantCommand . Waiting Waiting for a certain condition to happen or adding a delay can be useful to synchronize between different commands in a command composition or between other robot actions. To wait and end after a specified period of time elapses, the library offers the Commands.waitSeconds(double) / frc2::cmd::Wait(units::second_t) / commands2.cmd.wait(float) factory, backed by the WaitCommand ( Java , C++ , Python ) class. JAVA // Ends 5 seconds after being scheduled new WaitCommand ( 5.0 ) C++ // Ends 5 seconds after being scheduled frc2 :: WaitCommand ( 5.0 _s ) PYTHON # Ends 5 seconds after being scheduled commands2 . cmd . wait ( 5.0 ) To wait until a certain condition becomes true , the library offers the Commands.waitUntil(BooleanSupplier) / frc2::cmd::WaitUntil(std::function<bool()>) factory, backed by the WaitUntilCommand class ( Java , C++ , Python ). JAVA // Ends after m_limitSwitch.get() returns true new WaitUntilCommand ( m_limitSwitch :: get ) C++ // Ends after m_limitSwitch.Get() returns true frc2 :: WaitUntilCommand ([ & m_limitSwitch ] { return m_limitSwitch . Get (); }) PYTHON # Ends after limit_switch.get() returns True commands2 . cmd . wait_until ( limit_switch . get ) Control Algorithm Commands There are commands for various control setups: TrapezoidProfile tracks a trapezoid motion profile. For more info, see Motion Profiling in Command-based . MecanumControllerCommand ( Java , C++ ) is useful for controlling mecanum drivetrains. See API docs and the MecanumControllerCommand ( Java , C++ ) example project for more info. SwerveControllerCommand ( Java , C++ ) is useful for controlling swerve drivetrains. See API docs and the SwerveControllerCommand ( Java , C++ ) example project for more info. RamseteCommand ( Java , C++ ) is useful for path following with differential drivetrains (“tank drive”). See API docs and the Trajectory Tutorial for more info. Custom Command Classes Users may also write custom command classes. As this is significantly more verbose, it’s recommended to use the more concise factories mentioned above. Note In the C++ API, a CRTP is used to allow certain Command methods to work with the object ownership model. Users should always extend the CommandHelper class when defining their own command classes, as is shown below. To write a custom command class, subclass the abstract Command class ( Java ) or CommandHelper ( C++ ), as seen in the command-based template ( Java , C++ ): JAVA 7 import edu.wpi.first.wpilibj.templates.commandbased.subsystems.ExampleSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 10 /** An example command that uses an example subsystem. */ 11 public class ExampleCommand extends Command { 12 @SuppressWarnings ({ \"PMD.UnusedPrivateField\" , \"PMD.SingularField\" }) 13 private final ExampleSubsystem m_subsystem ; 14 15 /** 16 * Creates a new ExampleCommand. 17 * 18 * @param subsystem The subsystem used by this command. 19 */ 20 public ExampleCommand ( ExampleSubsystem subsystem ) { 21 m_subsystem = subsystem ; 22 // Use addRequirements() here to declare subsystem dependencies. 23 addRequirements ( subsystem ); 24 } C++ 5 #pragma once 6 7 #include <frc2/command/Command.h> 8 #include <frc2/command/CommandHelper.h> 9 10 #include \"subsystems/ExampleSubsystem.h\" 11 12 /** 13 * An example command that uses an example subsystem. 14 * 15 * <p>Note that this extends CommandHelper, rather extending Command 16 * directly; this is crucially important, or else the decorator functions in 17 * Command will *not* work! 18 */ 19 class ExampleCommand 20 : public frc2 :: CommandHelper < frc2 :: Command , ExampleCommand > { 21 public : 22 /** 23 * Creates a new ExampleCommand. 24 * 25 * @param subsystem The subsystem used by this command. 26 */ 27 explicit ExampleCommand ( ExampleSubsystem * subsystem ); 28 29 private : 30 ExampleSubsystem * m_subsystem ; 31 }; Simple Command Example What might a functional command look like in practice? As before, below is a simple command from the HatchBot example project ( Java , C++ ) that uses the HatchSubsystem : Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.HatchSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 10 /** 11 * A simple command that grabs a hatch with the {@link HatchSubsystem}. Written explicitly for 12 * pedagogical purposes. Actual code should inline a command this simple with {@link 13 * edu.wpi.first.wpilibj2.command.InstantCommand}. 14 */ 15 public class GrabHatch extends Command { 16 // The subsystem the command runs on 17 private final HatchSubsystem m_hatchSubsystem ; 18 19 public GrabHatch ( HatchSubsystem subsystem ) { 20 m_hatchSubsystem = subsystem ; 21 addRequirements ( m_hatchSubsystem ); 22 } 23 24 @Override 25 public void initialize () { 26 m_hatchSubsystem . grabHatch (); 27 } 28 29 @Override 30 public boolean isFinished () { 31 return true ; 32 } 33 } C++ (Header) 5 #pragma once 6 7 #include <frc2/command/Command.h> 8 #include <frc2/command/CommandHelper.h> 9 10 #include \"subsystems/HatchSubsystem.h\" 11 12 /** 13 * A simple command that grabs a hatch with the HatchSubsystem. Written 14 * explicitly for pedagogical purposes. Actual code should inline a command 15 * this simple with InstantCommand. 16 * 17 * @see InstantCommand 18 */ 19 class GrabHatch : public frc2 :: CommandHelper < frc2 :: Command , GrabHatch > { 20 public : 21 explicit GrabHatch ( HatchSubsystem * subsystem ); 22 23 void Initialize () override ; 24 25 bool IsFinished () override ; 26 27 private : 28 HatchSubsystem * m_hatch ; 29 }; C++ (Source) 5 #include \"commands/GrabHatch.h\" 6 7 GrabHatch :: GrabHatch ( HatchSubsystem * subsystem ) : m_hatch ( subsystem ) { 8 AddRequirements ( subsystem ); 9 } 10 11 void GrabHatch :: Initialize () { 12 m_hatch -> GrabHatch (); 13 } 14 15 bool GrabHatch :: IsFinished () { 16 return true ; 17 } Python 7 import commands2 8 from subsystems.hatchsubsystem import HatchSubsystem 9 10 11 class GrabHatch ( commands2 . Command ): 12 def __init__ ( self , hatch : HatchSubsystem ) -> None : 13 super () . __init__ () 14 self . hatch = hatch 15 self . addRequirements ( hatch ) 16 17 def initialize ( self ) -> None : 18 self . hatch . grabHatch () 19 20 def isFinished ( self ) -> bool : 21 return True Notice that the hatch subsystem used by the command is passed into the command through the command’s constructor. This is a pattern called dependency injection , and allows users to avoid declaring their subsystems as global variables. This is widely accepted as a best-practice - the reasoning behind this is discussed in a later section . Notice also that the above command calls the subsystem method once from initialize, and then immediately ends (as isFinished() simply returns true). This is typical for commands that toggle the states of subsystems, and as such it would be more succinct to write this command using the factories described above. What about a more complicated case? Below is a drive command, from the same example project: Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.commands ; 6 7 import edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems.DriveSubsystem ; 8 import edu.wpi.first.wpilibj2.command.Command ; 9 import java.util.function.DoubleSupplier ; 10 11 /** 12 * A command to drive the robot with joystick input (passed in as {@link DoubleSupplier}s). Written 13 * explicitly for pedagogical purposes - actual code should inline a command this simple with {@link 14 * edu.wpi.first.wpilibj2.command.RunCommand}. 15 */ 16 public class DefaultDrive extends Command { 17 private final DriveSubsystem m_drive ; 18 private final DoubleSupplier m_forward ; 19 private final DoubleSupplier m_rotation ; 20 21 /** 22 * Creates a new DefaultDrive. 23 * 24 * @param subsystem The drive subsystem this command wil run on. 25 * @param forward The control input for driving forwards/backwards 26 * @param rotation The control input for turning 27 */ 28 public DefaultDrive ( DriveSubsystem subsystem , DoubleSupplier forward , DoubleSupplier rotation ) { 29 m_drive = subsystem ; 30 m_forward = forward ; 31 m_rotation = rotation ; 32 addRequirements ( m_drive ); 33 } 34 35 @Override 36 public void execute () { 37 m_drive . arcadeDrive ( m_forward . getAsDouble (), m_rotation . getAsDouble ()); 38 } 39 } C++ (Header) 5 #pragma once 6 7 #include <functional> 8 9 #include <frc2/command/Command.h> 10 #include <frc2/command/CommandHelper.h> 11 12 #include \"subsystems/DriveSubsystem.h\" 13 14 /** 15 * A command to drive the robot with joystick input passed in through lambdas. 16 * Written explicitly for pedagogical purposes - actual code should inline a 17 * command this simple with RunCommand. 18 * 19 * @see RunCommand 20 */ 21 class DefaultDrive : public frc2 :: CommandHelper < frc2 :: Command , DefaultDrive > { 22 public : 23 /** 24 * Creates a new DefaultDrive. 25 * 26 * @param subsystem The drive subsystem this command wil run on. 27 * @param forward The control input for driving forwards/backwards 28 * @param rotation The control input for turning 29 */ 30 DefaultDrive ( DriveSubsystem * subsystem , std :: function < double () > forward , 31 std :: function < double () > rotation ); 32 33 void Execute () override ; 34 35 private : 36 DriveSubsystem * m_drive ; 37 std :: function < double () > m_forward ; 38 std :: function < double () > m_rotation ; 39 }; C++ (Source) 5 #include \"commands/DefaultDrive.h\" 6 7 #include <utility> 8 9 DefaultDrive :: DefaultDrive ( DriveSubsystem * subsystem , 10 std :: function < double () > forward , 11 std :: function < double () > rotation ) 12 : m_drive { subsystem }, 13 m_forward { std :: move ( forward )}, 14 m_rotation { std :: move ( rotation )} { 15 AddRequirements ( subsystem ); 16 } 17 18 void DefaultDrive :: Execute () { 19 m_drive -> ArcadeDrive ( m_forward (), m_rotation ()); 20 } Python 7 import typing 8 import commands2 9 from subsystems.drivesubsystem import DriveSubsystem 10 11 12 class DefaultDrive ( commands2 . Command ): 13 def __init__ ( 14 self , 15 drive : DriveSubsystem , 16 forward : typing . Callable [[], float ], 17 rotation : typing . Callable [[], float ], 18 ) -> None : 19 super () . __init__ () 20 21 self . drive = drive 22 self . forward = forward 23 self . rotation = rotation 24 25 self . addRequirements ( self . drive ) 26 27 def execute ( self ) -> None : 28 self . drive . arcadeDrive ( self . forward (), self . rotation ()) And then usage: JAVA 59 // Configure default commands 60 // Set the default drive command to split-stick arcade drive 61 m_robotDrive . setDefaultCommand ( 62 // A split-stick arcade command, with forward/backward controlled by the left 63 // hand, and turning controlled by the right. 64 new DefaultDrive ( 65 m_robotDrive , 66 () -> - m_driverController . getLeftY (), 67 () -> - m_driverController . getRightX ())); C++ 57 // Set up default drive command 58 m_drive . SetDefaultCommand ( DefaultDrive ( 59 & m_drive , [ this ] { return - m_driverController . GetLeftY (); }, 60 [ this ] { return - m_driverController . GetRightX (); })); PYTHON 65 # set up default drive command 66 self . drive . setDefaultCommand ( 67 DefaultDrive ( 68 self . drive , 69 lambda : - self . driverController . getY (), 70 lambda : self . driverController . getX (), 71 ) 72 ) Notice that this command does not override isFinished() , and thus will never end; this is the norm for commands that are intended to be used as default commands. Once more, this command is rather simple and calls the subsystem method only from one place, and as such, could be more concisely written using factories: JAVA 51 // Configure default commands 52 // Set the default drive command to split-stick arcade drive 53 m_robotDrive . setDefaultCommand ( 54 // A split-stick arcade command, with forward/backward controlled by the left 55 // hand, and turning controlled by the right. 56 Commands . run ( 57 () -> 58 m_robotDrive . arcadeDrive ( 59 - m_driverController . getLeftY (), - m_driverController . getRightX ()), 60 m_robotDrive )); C++ 52 // Set up default drive command 53 m_drive . SetDefaultCommand ( frc2 :: cmd :: Run ( 54 [ this ] { 55 m_drive . ArcadeDrive ( - m_driverController . GetLeftY (), 56 - m_driverController . GetRightX ()); 57 }, 58 { & m_drive })); PYTHON 53 # Configure default commands 54 # Set the default drive command to split-stick arcade drive 55 self . driveSubsystem . setDefaultCommand ( 56 # A split-stick arcade command, with forward/backward controlled by the left 57 # hand, and turning controlled by the right. 58 commands2 . cmd . run ( 59 lambda : self . driveSubsystem . arcadeDrive ( 60 - self . driverController . getLeftY (), 61 - self . driverController . getRightX (), 62 ), 63 self . driveSubsystem , 64 ) 65 )",
      "content_preview": "Commands Commands represent actions the robot can take. Commands run when scheduled, until they are interrupted or their end condition is met. Commands are represented in the command-based library by the Command class ( Java , C++ ) or the Command class in commands2 library ( Python )."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/profile-subsystems-commands.html",
      "title": "Motion Profiling in Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Motion Profiling in Command-based Note For a description of the WPILib motion profiling features used by these command-based wrappers, see Trapezoidal Motion Profiles in WPILib . Note The TrapezoidProfile class, used on its own, is most useful when composed with external controllers, such as a “smart” motor controller with a built-in PID functionality. For combining trapezoidal motion profiling with WPILib’s PIDController , see Combining Motion Profiling and PID in Command-Based . When controlling a mechanism, is often desirable to move it smoothly between two positions, rather than to abruptly change its setpoint. This is called “motion-profiling,” and is supported in WPILib through the TrapezoidProfile class ( Java , C++ ). Note In C++, the TrapezoidProfile class is templated on the unit type used for distance measurements, which may be angular or linear. The passed-in values must have units consistent with the distance units, or a compile-time error will be thrown. For more information on C++ units, see The C++ Units Library . The following examples are taken from the DriveDistanceOffboard example project ( Java , C++ ): Java 5 package edu.wpi.first.wpilibj.examples.drivedistanceoffboard.subsystems ; 6 7 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 8 import edu.wpi.first.math.trajectory.TrapezoidProfile ; 9 import edu.wpi.first.math.trajectory.TrapezoidProfile.State ; 10 import edu.wpi.first.util.sendable.SendableRegistry ; 11 import edu.wpi.first.wpilibj.RobotController ; 12 import edu.wpi.first.wpilibj.Timer ; 13 import edu.wpi.first.wpilibj.drive.DifferentialDrive ; 14 import edu.wpi.first.wpilibj.examples.drivedistanceoffboard.Constants.DriveConstants ; 15 import edu.wpi.first.wpilibj.examples.drivedistanceoffboard.ExampleSmartMotorController ; 16 import edu.wpi.first.wpilibj2.command.Command ; 17 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 18 19 public class DriveSubsystem extends SubsystemBase { 20 // The motors on the left side of the drive. 21 private final ExampleSmartMotorController m_leftLeader = 22 new ExampleSmartMotorController ( DriveConstants . kLeftMotor1Port ); 23 24 private final ExampleSmartMotorController m_leftFollower = 25 new ExampleSmartMotorController ( DriveConstants . kLeftMotor2Port ); 26 27 // The motors on the right side of the drive. 28 private final ExampleSmartMotorController m_rightLeader = 29 new ExampleSmartMotorController ( DriveConstants . kRightMotor1Port ); 30 31 private final ExampleSmartMotorController m_rightFollower = 32 new ExampleSmartMotorController ( DriveConstants . kRightMotor2Port ); 33 34 // The feedforward controller. 35 private final SimpleMotorFeedforward m_feedforward = 36 new SimpleMotorFeedforward ( 37 DriveConstants . ksVolts , 38 DriveConstants . kvVoltSecondsPerMeter , 39 DriveConstants . kaVoltSecondsSquaredPerMeter ); 40 41 // The robot's drive 42 private final DifferentialDrive m_drive = 43 new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); 44 45 // The trapezoid profile 46 private final TrapezoidProfile m_profile = 47 new TrapezoidProfile ( 48 new TrapezoidProfile . Constraints ( 49 DriveConstants . kMaxSpeedMetersPerSecond , 50 DriveConstants . kMaxAccelerationMetersPerSecondSquared )); 51 52 // The timer 53 private final Timer m_timer = new Timer (); 54 55 /** Creates a new DriveSubsystem. */ 56 public DriveSubsystem () { 57 SendableRegistry . addChild ( m_drive , m_leftLeader ); 58 SendableRegistry . addChild ( m_drive , m_rightLeader ); 59 60 // We need to invert one side of the drivetrain so that positive voltages 61 // result in both sides moving forward. Depending on how your robot's 62 // gearbox is constructed, you might have to invert the left side instead. 63 m_rightLeader . setInverted ( true ); 64 65 m_leftFollower . follow ( m_leftLeader ); 66 m_rightFollower . follow ( m_rightLeader ); 67 68 m_leftLeader . setPID ( DriveConstants . kp , 0 , 0 ); 69 m_rightLeader . setPID ( DriveConstants . kp , 0 , 0 ); 70 } 71 72 /** 73 * Drives the robot using arcade controls. 74 * 75 * @param fwd the commanded forward movement 76 * @param rot the commanded rotation 77 */ 78 public void arcadeDrive ( double fwd , double rot ) { 79 m_drive . arcadeDrive ( fwd , rot ); 80 } 81 82 /** 83 * Attempts to follow the given drive states using offboard PID. 84 * 85 * @param currentLeft The current left wheel state. 86 * @param currentRight The current right wheel state. 87 * @param nextLeft The next left wheel state. 88 * @param nextRight The next right wheel state. 89 */ 90 public void setDriveStates ( 91 TrapezoidProfile . State currentLeft , 92 TrapezoidProfile . State currentRight , 93 TrapezoidProfile . State nextLeft , 94 TrapezoidProfile . State nextRight ) { 95 // Feedforward is divided by battery voltage to normalize it to [-1, 1] 96 m_leftLeader . setSetpoint ( 97 ExampleSmartMotorController . PIDMode . kPosition , 98 currentLeft . position , 99 m_feedforward . calculateWithVelocities ( currentLeft . velocity , nextLeft . velocity ) 100 / RobotController . getBatteryVoltage ()); 101 m_rightLeader . setSetpoint ( 102 ExampleSmartMotorController . PIDMode . kPosition , 103 currentRight . position , 104 m_feedforward . calculateWithVelocities ( currentLeft . velocity , nextLeft . velocity ) 105 / RobotController . getBatteryVoltage ()); 106 } 107 108 /** 109 * Returns the left encoder distance. 110 * 111 * @return the left encoder distance 112 */ 113 public double getLeftEncoderDistance () { 114 return m_leftLeader . getEncoderDistance (); 115 } 116 117 /** 118 * Returns the right encoder distance. 119 * 120 * @return the right encoder distance 121 */ 122 public double getRightEncoderDistance () { 123 return m_rightLeader . getEncoderDistance (); 124 } 125 126 /** Resets the drive encoders. */ 127 public void resetEncoders () { 128 m_leftLeader . resetEncoder (); 129 m_rightLeader . resetEncoder (); 130 } 131 132 /** 133 * Sets the max output of the drive. Useful for scaling the drive to drive more slowly. 134 * 135 * @param maxOutput the maximum output to which the drive will be constrained 136 */ 137 public void setMaxOutput ( double maxOutput ) { 138 m_drive . setMaxOutput ( maxOutput ); 139 } 140 141 /** 142 * Creates a command to drive forward a specified distance using a motion profile. 143 * 144 * @param distance The distance to drive forward. 145 * @return A command. 146 */ 147 public Command profiledDriveDistance ( double distance ) { 148 return startRun ( 149 () -> { 150 // Restart timer so profile setpoints start at the beginning 151 m_timer . restart (); 152 resetEncoders (); 153 }, 154 () -> { 155 // Current state never changes, so we need to use a timer to get the setpoints we need 156 // to be at 157 var currentTime = m_timer . get (); 158 var currentSetpoint = 159 m_profile . calculate ( currentTime , new State (), new State ( distance , 0 )); 160 var nextSetpoint = 161 m_profile . calculate ( 162 currentTime + DriveConstants . kDt , new State (), new State ( distance , 0 )); 163 setDriveStates ( currentSetpoint , currentSetpoint , nextSetpoint , nextSetpoint ); 164 }) 165 . until (() -> m_profile . isFinished ( 0 )); 166 } 167 168 private double m_initialLeftDistance ; 169 private double m_initialRightDistance ; 170 171 /** 172 * Creates a command to drive forward a specified distance using a motion profile without 173 * resetting the encoders. 174 * 175 * @param distance The distance to drive forward. 176 * @return A command. 177 */ 178 public Command dynamicProfiledDriveDistance ( double distance ) { 179 return startRun ( 180 () -> { 181 // Restart timer so profile setpoints start at the beginning 182 m_timer . restart (); 183 // Store distance so we know the target distance for each encoder 184 m_initialLeftDistance = getLeftEncoderDistance (); 185 m_initialRightDistance = getRightEncoderDistance (); 186 }, 187 () -> { 188 // Current state never changes for the duration of the command, so we need to use a 189 // timer to get the setpoints we need to be at 190 var currentTime = m_timer . get (); 191 var currentLeftSetpoint = 192 m_profile . calculate ( 193 currentTime , 194 new State ( m_initialLeftDistance , 0 ), 195 new State ( m_initialLeftDistance + distance , 0 )); 196 var currentRightSetpoint = 197 m_profile . calculate ( 198 currentTime , 199 new State ( m_initialRightDistance , 0 ), 200 new State ( m_initialRightDistance + distance , 0 )); 201 var nextLeftSetpoint = 202 m_profile . calculate ( 203 currentTime + DriveConstants . kDt , 204 new State ( m_initialLeftDistance , 0 ), 205 new State ( m_initialLeftDistance + distance , 0 )); 206 var nextRightSetpoint = 207 m_profile . calculate ( 208 currentTime + DriveConstants . kDt , 209 new State ( m_initialRightDistance , 0 ), 210 new State ( m_initialRightDistance + distance , 0 )); 211 setDriveStates ( 212 currentLeftSetpoint , currentRightSetpoint , nextLeftSetpoint , nextRightSetpoint ); 213 }) 214 . until (() -> m_profile . isFinished ( 0 )); 215 } 216 } C++ (Header) 5 #pragma once 6 7 #include <frc/Encoder.h> 8 #include <frc/Timer.h> 9 #include <frc/controller/SimpleMotorFeedforward.h> 10 #include <frc/drive/DifferentialDrive.h> 11 #include <frc/trajectory/TrapezoidProfile.h> 12 #include <frc2/command/CommandPtr.h> 13 #include <frc2/command/SubsystemBase.h> 14 #include <units/length.h> 15 16 #include \"Constants.h\" 17 #include \"ExampleSmartMotorController.h\" 18 19 class DriveSubsystem : public frc2 :: SubsystemBase { 20 public : 21 DriveSubsystem (); 22 23 /** 24 * Will be called periodically whenever the CommandScheduler runs. 25 */ 26 void Periodic () override ; 27 28 // Subsystem methods go here. 29 30 /** 31 * Attempts to follow the given drive states using offboard PID. 32 * 33 * @param currentLeft The current left wheel state. 34 * @param currentRight The current right wheel state. 35 * @param nextLeft The next left wheel state. 36 * @param nextRight The next right wheel state. 37 */ 38 void SetDriveStates ( frc :: TrapezoidProfile < units :: meters >:: State currentLeft , 39 frc :: TrapezoidProfile < units :: meters >:: State currentRight , 40 frc :: TrapezoidProfile < units :: meters >:: State nextLeft , 41 frc :: TrapezoidProfile < units :: meters >:: State nextRight ); 42 43 /** 44 * Drives the robot using arcade controls. 45 * 46 * @param fwd the commanded forward movement 47 * @param rot the commanded rotation 48 */ 49 void ArcadeDrive ( double fwd , double rot ); 50 51 /** 52 * Resets the drive encoders to currently read a position of 0. 53 */ 54 void ResetEncoders (); 55 56 /** 57 * Gets the distance of the left encoder. 58 * 59 * @return the average of the TWO encoder readings 60 */ 61 units :: meter_t GetLeftEncoderDistance (); 62 63 /** 64 * Gets the distance of the right encoder. 65 * 66 * @return the average of the TWO encoder readings 67 */ 68 units :: meter_t GetRightEncoderDistance (); 69 70 /** 71 * Sets the max output of the drive. Useful for scaling the drive to drive 72 * more slowly. 73 * 74 * @param maxOutput the maximum output to which the drive will be constrained 75 */ 76 void SetMaxOutput ( double maxOutput ); 77 78 /** 79 * Creates a command to drive forward a specified distance using a motion 80 * profile. 81 * 82 * @param distance The distance to drive forward. 83 * @return A command. 84 */ 85 [[ nodiscard ]] 86 frc2 :: CommandPtr ProfiledDriveDistance ( units :: meter_t distance ); 87 88 /** 89 * Creates a command to drive forward a specified distance using a motion 90 * profile without resetting the encoders. 91 * 92 * @param distance The distance to drive forward. 93 * @return A command. 94 */ 95 [[ nodiscard ]] 96 frc2 :: CommandPtr DynamicProfiledDriveDistance ( units :: meter_t distance ); 97 98 private : 99 frc :: TrapezoidProfile < units :: meters > m_profile { 100 { DriveConstants :: kMaxSpeed , DriveConstants :: kMaxAcceleration }}; 101 frc :: Timer m_timer ; 102 units :: meter_t m_initialLeftDistance ; 103 units :: meter_t m_initialRightDistance ; 104 // Components (e.g. motor controllers and sensors) should generally be 105 // declared private and exposed only through public methods. 106 107 // The motor controllers 108 ExampleSmartMotorController m_leftLeader ; 109 ExampleSmartMotorController m_leftFollower ; 110 ExampleSmartMotorController m_rightLeader ; 111 ExampleSmartMotorController m_rightFollower ; 112 113 // A feedforward component for the drive 114 frc :: SimpleMotorFeedforward < units :: meters > m_feedforward ; 115 116 // The robot's drive 117 frc :: DifferentialDrive m_drive { 118 [ & ]( double output ) { m_leftLeader . Set ( output ); }, 119 [ & ]( double output ) { m_rightLeader . Set ( output ); }}; 120 }; C++ (Source) 5 #include \"subsystems/DriveSubsystem.h\" 6 7 #include <frc/RobotController.h> 8 9 using namespace DriveConstants ; 10 11 DriveSubsystem :: DriveSubsystem () 12 : m_leftLeader { kLeftMotor1Port }, 13 m_leftFollower { kLeftMotor2Port }, 14 m_rightLeader { kRightMotor1Port }, 15 m_rightFollower { kRightMotor2Port }, 16 m_feedforward { ks , kv , ka } { 17 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_leftLeader ); 18 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_rightLeader ); 19 20 // We need to invert one side of the drivetrain so that positive voltages 21 // result in both sides moving forward. Depending on how your robot's 22 // gearbox is constructed, you might have to invert the left side instead. 23 m_rightLeader . SetInverted ( true ); 24 25 m_leftFollower . Follow ( m_leftLeader ); 26 m_rightFollower . Follow ( m_rightLeader ); 27 28 m_leftLeader . SetPID ( kp , 0 , 0 ); 29 m_rightLeader . SetPID ( kp , 0 , 0 ); 30 } 31 32 void DriveSubsystem :: Periodic () { 33 // Implementation of subsystem periodic method goes here. 34 } 35 36 void DriveSubsystem :: SetDriveStates ( 37 frc :: TrapezoidProfile < units :: meters >:: State currentLeft , 38 frc :: TrapezoidProfile < units :: meters >:: State currentRight , 39 frc :: TrapezoidProfile < units :: meters >:: State nextLeft , 40 frc :: TrapezoidProfile < units :: meters >:: State nextRight ) { 41 // Feedforward is divided by battery voltage to normalize it to [-1, 1] 42 m_leftLeader . SetSetpoint ( 43 ExampleSmartMotorController :: PIDMode :: kPosition , 44 currentLeft . position . value (), 45 m_feedforward . Calculate ( currentLeft . velocity , nextLeft . velocity ) / 46 frc :: RobotController :: GetBatteryVoltage ()); 47 m_rightLeader . SetSetpoint ( 48 ExampleSmartMotorController :: PIDMode :: kPosition , 49 currentRight . position . value (), 50 m_feedforward . Calculate ( currentRight . velocity , nextRight . velocity ) / 51 frc :: RobotController :: GetBatteryVoltage ()); 52 } 53 54 void DriveSubsystem :: ArcadeDrive ( double fwd , double rot ) { 55 m_drive . ArcadeDrive ( fwd , rot ); 56 } 57 58 void DriveSubsystem :: ResetEncoders () { 59 m_leftLeader . ResetEncoder (); 60 m_rightLeader . ResetEncoder (); 61 } 62 63 units :: meter_t DriveSubsystem :: GetLeftEncoderDistance () { 64 return units :: meter_t { m_leftLeader . GetEncoderDistance ()}; 65 } 66 67 units :: meter_t DriveSubsystem :: GetRightEncoderDistance () { 68 return units :: meter_t { m_rightLeader . GetEncoderDistance ()}; 69 } 70 71 void DriveSubsystem :: SetMaxOutput ( double maxOutput ) { 72 m_drive . SetMaxOutput ( maxOutput ); 73 } 74 75 frc2 :: CommandPtr DriveSubsystem :: ProfiledDriveDistance ( 76 units :: meter_t distance ) { 77 return StartRun ( 78 [ & ] { 79 // Restart timer so profile setpoints start at the beginning 80 m_timer . Restart (); 81 ResetEncoders (); 82 }, 83 [ & ] { 84 // Current state never changes, so we need to use a timer to get 85 // the setpoints we need to be at 86 auto currentTime = m_timer . Get (); 87 auto currentSetpoint = 88 m_profile . Calculate ( currentTime , {}, { distance , 0 _mps }); 89 auto nextSetpoint = m_profile . Calculate ( currentTime + kDt , {}, 90 { distance , 0 _mps }); 91 SetDriveStates ( currentSetpoint , currentSetpoint , nextSetpoint , 92 nextSetpoint ); 93 }) 94 . Until ([ & ] { return m_profile . IsFinished ( 0 _s ); }); 95 } 96 97 frc2 :: CommandPtr DriveSubsystem :: DynamicProfiledDriveDistance ( 98 units :: meter_t distance ) { 99 return StartRun ( 100 [ & ] { 101 // Restart timer so profile setpoints start at the beginning 102 m_timer . Restart (); 103 // Store distance so we know the target distance for each encoder 104 m_initialLeftDistance = GetLeftEncoderDistance (); 105 m_initialRightDistance = GetRightEncoderDistance (); 106 }, 107 [ & ] { 108 // Current state never changes for the duration of the command, 109 // so we need to use a timer to get the setpoints we need to be 110 // at 111 auto currentTime = m_timer . Get (); 112 113 auto currentLeftSetpoint = m_profile . Calculate ( 114 currentTime , { m_initialLeftDistance , 0 _mps }, 115 { m_initialLeftDistance + distance , 0 _mps }); 116 auto currentRightSetpoint = m_profile . Calculate ( 117 currentTime , { m_initialRightDistance , 0 _mps }, 118 { m_initialRightDistance + distance , 0 _mps }); 119 120 auto nextLeftSetpoint = m_profile . Calculate ( 121 currentTime + kDt , { m_initialLeftDistance , 0 _mps }, 122 { m_initialLeftDistance + distance , 0 _mps }); 123 auto nextRightSetpoint = m_profile . Calculate ( 124 currentTime + kDt , { m_initialRightDistance , 0 _mps }, 125 { m_initialRightDistance + distance , 0 _mps }); 126 SetDriveStates ( currentLeftSetpoint , currentRightSetpoint , 127 nextLeftSetpoint , nextRightSetpoint ); 128 }) 129 . Until ([ & ] { return m_profile . IsFinished ( 0 _s ); }); 130 } There are two commands in this example. They function very similarly, with the main difference being that one resets encoders, and the other doesn’t, which allows encoder data to be preserved. The subsystem contains a TrapezoidProfile with a Timer . The timer is used along with a kDt constant of 0.02 seconds to calculate the current and next states from the TrapezoidProfile . The current state is fed to the “smart” motor controller for PID control, while the current and next state are used to calculate feedforward outputs. Both commands end when isFinished(0) returns true, which means that the profile has reached the goal state.",
      "content_preview": "Motion Profiling in Command-based Note For a description of the WPILib motion profiling features used by these command-based wrappers, see Trapezoidal Motion Profiles in WPILib ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/structuring-command-based-project.html",
      "title": "Structuring a Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Structuring a Command-Based Robot Project While users are free to use the command-based libraries however they like (and advanced users are encouraged to do so), new users may want some guidance on how to structure a basic command-based robot project. A standard template for a command-based robot project is included in the WPILib examples repository ( Java , C++ ). This section will walk users through the structure of this template. The root package/directory generally will contain four classes: Main , which is the main robot application (Java only). New users should not touch this class. Robot , which is responsible for the main control flow of the robot code. RobotContainer , which holds robot subsystems and commands, and is where most of the declarative robot setup (e.g. button bindings) is performed. Constants , which holds globally-accessible constants to be used throughout the robot. The root directory will also contain two sub-packages/sub-directories: Subsystems contains all user-defined subsystem classes. Commands contains all user-defined command classes. Robot As Robot ( Java , C++ (Header) , C++ (Source) ) is responsible for the program’s control flow, and command-based is an declarative paradigm designed to minimize the amount of attention the user has to pay to explicit program control flow, the Robot class of a command-based project should be mostly empty. However, there are a few important things that must be included Java 21 /** 22 * This function is run when the robot is first started up and should be used for any 23 * initialization code. 24 */ 25 public Robot () { 26 // Instantiate our RobotContainer. This will perform all our button bindings, and put our 27 // autonomous chooser on the dashboard. 28 m_robotContainer = new RobotContainer (); 29 } In Java, an instance of RobotContainer should be constructed during the Robot constructor - this is important, as most of the declarative robot setup will be called from the RobotContainer constructor. In C++, this is not needed as RobotContainer is a value member and will be constructed during the construction of Robot . Java 31 /** 32 * This function is called every 20 ms, no matter the mode. Use this for items like diagnostics 33 * that you want ran during disabled, autonomous, teleoperated and test. 34 * 35 * <p>This runs after the mode specific periodic functions, but before LiveWindow and 36 * SmartDashboard integrated updating. 37 */ 38 @Override 39 public void robotPeriodic () { 40 // Runs the Scheduler. This is responsible for polling buttons, adding newly-scheduled 41 // commands, running already-scheduled commands, removing finished or interrupted commands, 42 // and running subsystem periodic() methods. This must be called from the robot's periodic 43 // block in order for anything in the Command-based framework to work. 44 CommandScheduler . getInstance (). run (); 45 } C++ (Source) 11 /** 12 * This function is called every 20 ms, no matter the mode. Use 13 * this for items like diagnostics that you want to run during disabled, 14 * autonomous, teleoperated and test. 15 * 16 * <p> This runs after the mode specific periodic functions, but before 17 * LiveWindow and SmartDashboard integrated updating. 18 */ 19 void Robot::RobotPeriodic () { 20 frc2 :: CommandScheduler :: GetInstance (). Run (); 21 } The inclusion of the CommandScheduler.getInstance().run() call in the robotPeriodic() method is essential; without this call, the scheduler will not execute any scheduled commands. Since TimedRobot runs with a default main loop frequency of 50Hz, this is the frequency with which periodic command and subsystem methods will be called. It is not recommended for new users to call this method from anywhere else in their code. Java 54 /** This autonomous runs the autonomous command selected by your {@link RobotContainer} class. */ 55 @Override 56 public void autonomousInit () { 57 m_autonomousCommand = m_robotContainer . getAutonomousCommand (); 58 59 // schedule the autonomous command (example) 60 if ( m_autonomousCommand != null ) { 61 m_autonomousCommand . schedule (); 62 } 63 } C++ (Source) 32 /** 33 * This autonomous runs the autonomous command selected by your {@link 34 * RobotContainer} class. 35 */ 36 void Robot::AutonomousInit () { 37 m_autonomousCommand = m_container . GetAutonomousCommand (); 38 39 if ( m_autonomousCommand ) { 40 m_autonomousCommand -> Schedule (); 41 } 42 } The autonomousInit() method schedules an autonomous command returned by the RobotContainer instance. The logic for selecting which autonomous command to run can be handled inside of RobotContainer . Java 69 @Override 70 public void teleopInit () { 71 // This makes sure that the autonomous stops running when 72 // teleop starts running. If you want the autonomous to 73 // continue until interrupted by another command, remove 74 // this line or comment it out. 75 if ( m_autonomousCommand != null ) { 76 m_autonomousCommand . cancel (); 77 } 78 } C++ (Source) 46 void Robot::TeleopInit () { 47 // This makes sure that the autonomous stops running when 48 // teleop starts running. If you want the autonomous to 49 // continue until interrupted by another command, remove 50 // this line or comment it out. 51 if ( m_autonomousCommand ) { 52 m_autonomousCommand -> Cancel (); 53 } 54 } The teleopInit() method cancels any still-running autonomous commands. This is generally good practice. Advanced users are free to add additional code to the various init and periodic methods as they see fit; however, it should be noted that including large amounts of imperative robot code in Robot.java is contrary to the declarative design philosophy of the command-based paradigm, and can result in confusingly-structured/disorganized code. RobotContainer This class ( Java , C++ (Header) , C++ (Source) ) is where most of the setup for your command-based robot will take place. In this class, you will define your robot’s subsystems and commands, bind those commands to triggering events (such as buttons), and specify which command you will run in your autonomous routine. There are a few aspects of this class new users may want explanations for: Java 23 private final ExampleSubsystem m_exampleSubsystem = new ExampleSubsystem (); C++ (Header) 32 ExampleSubsystem m_subsystem ; Notice that subsystems are declared as private fields in RobotContainer . This is in stark contrast to the previous incarnation of the command-based framework, but is much more-aligned with agreed-upon object-oriented best-practices. If subsystems are declared as global variables, it allows the user to access them from anywhere in the code. While this can make certain things easier (for example, there would be no need to pass subsystems to commands in order for those commands to access them), it makes the control flow of the program much harder to keep track of as it is not immediately obvious which parts of the code can change or be changed by which other parts of the code. This also circumvents the ability of the resource-management system to do its job, as ease-of-access makes it easy for users to accidentally make conflicting calls to subsystem methods outside of the resource-managed commands. Java 61 return Autos . exampleAuto ( m_exampleSubsystem ); C++ (Source) 34 return autos :: ExampleAuto ( & m_subsystem ); Since subsystems are declared as private members, they must be explicitly passed to commands (a pattern called “dependency injection”) in order for those commands to call methods on them. This is done here with ExampleCommand , which is passed a pointer to an ExampleSubsystem . Java 35 /** 36 * Use this method to define your trigger->command mappings. Triggers can be created via the 37 * {@link Trigger#Trigger(java.util.function.BooleanSupplier)} constructor with an arbitrary 38 * predicate, or via the named factories in {@link 39 * edu.wpi.first.wpilibj2.command.button.CommandGenericHID}'s subclasses for {@link 40 * CommandXboxController Xbox}/{@link edu.wpi.first.wpilibj2.command.button.CommandPS4Controller 41 * PS4} controllers or {@link edu.wpi.first.wpilibj2.command.button.CommandJoystick Flight 42 * joysticks}. 43 */ 44 private void configureBindings () { 45 // Schedule `ExampleCommand` when `exampleCondition` changes to `true` 46 new Trigger ( m_exampleSubsystem :: exampleCondition ) 47 . onTrue ( new ExampleCommand ( m_exampleSubsystem )); 48 49 // Schedule `exampleMethodCommand` when the Xbox controller's B button is pressed, 50 // cancelling on release. 51 m_driverController . b (). whileTrue ( m_exampleSubsystem . exampleMethodCommand ()); 52 } C++ (Source) 19 void RobotContainer::ConfigureBindings () { 20 // Configure your trigger bindings here 21 22 // Schedule `ExampleCommand` when `exampleCondition` changes to `true` 23 frc2 :: Trigger ([ this ] { 24 return m_subsystem . ExampleCondition (); 25 }). OnTrue ( ExampleCommand ( & m_subsystem ). ToPtr ()); 26 27 // Schedule `ExampleMethodCommand` when the Xbox controller's B button is 28 // pressed, cancelling on release. 29 m_driverController . B (). WhileTrue ( m_subsystem . ExampleMethodCommand ()); 30 } As mentioned before, the RobotContainer() constructor is where most of the declarative setup for the robot should take place, including button bindings, configuring autonomous selectors, etc. If the constructor gets too “busy,” users are encouraged to migrate code into separate subroutines (such as the configureBindings() method included by default) which are called from the constructor. Java 54 /** 55 * Use this to pass the autonomous command to the main {@link Robot} class. 56 * 57 * @return the command to run in autonomous 58 */ 59 public Command getAutonomousCommand () { 60 // An example command will be run in autonomous 61 return Autos . exampleAuto ( m_exampleSubsystem ); 62 } 63 } C++ (Source) 32 frc2 :: CommandPtr RobotContainer::GetAutonomousCommand () { 33 // An example command will be run in autonomous 34 return autos :: ExampleAuto ( & m_subsystem ); 35 } Finally, the getAutonomousCommand() method provides a convenient way for users to send their selected autonomous command to the main Robot class (which needs access to it to schedule it when autonomous starts). Constants The Constants class ( Java , C++ (Header) ) (in C++ this is not a class, but simply a header file in which several namespaces are defined) is where globally-accessible robot constants (such as speeds, unit conversion factors, PID gains, and sensor/motor ports) can be stored. It is recommended that users separate these constants into individual inner classes corresponding to subsystems or robot modes, to keep variable names shorter. In Java, all constants should be declared public static final so that they are globally accessible and cannot be changed. In C++, all constants should be constexpr . For more illustrative examples of what a constants class should look like in practice, see those of the various command-based example projects: Hatchbot ( Java , C++ ) RapidReactCommandBot ( Java , C++ ) In Java, it is recommended that the constants be used from other classes by statically importing the necessary inner class. An import static statement imports the static namespace of a class into the class in which you are working, so that any static constants can be referenced directly as if they had been defined in that class. In C++, the same effect can be attained with using namespace : JAVA import static edu.wpi.first.wpilibj.templates.commandbased.Constants.OIConstants.* ; C++ using namespace OIConstants ; Subsystems User-defined subsystems should go in this package/directory. Commands User-defined commands should go in this package/directory.",
      "content_preview": "Structuring a Command-Based Robot Project While users are free to use the command-based libraries however they like (and advanced users are encouraged to do so), new users may want some guidance on how to structure a basic command-based robot project."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/creating-following-trajectory.html",
      "title": "Step 4: Creating and Following a Trajectory",
      "section": "Path Planning",
      "language": "All",
      "content": "Step 4: Creating and Following a Trajectory With our drive subsystem written, it is now time to generate a trajectory and write an autonomous command to follow it. As per the standard command-based project structure , we will do this in the getAutonomousCommand method of the RobotContainer class. The full method from the RamseteCommand Example Project ( Java , C++ ) can be seen below. The rest of the article will break down the different parts of the method in more detail. Java 74 /** 75 * Use this to pass the autonomous command to the main {@link Robot} class. 76 * 77 * @return the command to run in autonomous 78 */ 79 public Command getAutonomousCommand () { 80 // Create a voltage constraint to ensure we don't accelerate too fast 81 var autoVoltageConstraint = 82 new DifferentialDriveVoltageConstraint ( 83 new SimpleMotorFeedforward ( 84 DriveConstants . ksVolts , 85 DriveConstants . kvVoltSecondsPerMeter , 86 DriveConstants . kaVoltSecondsSquaredPerMeter ), 87 DriveConstants . kDriveKinematics , 88 10 ); 89 90 // Create config for trajectory 91 TrajectoryConfig config = 92 new TrajectoryConfig ( 93 AutoConstants . kMaxSpeedMetersPerSecond , 94 AutoConstants . kMaxAccelerationMetersPerSecondSquared ) 95 // Add kinematics to ensure max speed is actually obeyed 96 . setKinematics ( DriveConstants . kDriveKinematics ) 97 // Apply the voltage constraint 98 . addConstraint ( autoVoltageConstraint ); 99 100 // An example trajectory to follow. All units in meters. 101 Trajectory exampleTrajectory = 102 TrajectoryGenerator . generateTrajectory ( 103 // Start at the origin facing the +X direction 104 new Pose2d ( 0 , 0 , new Rotation2d ( 0 )), 105 // Pass through these two interior waypoints, making an 's' curve path 106 List . of ( new Translation2d ( 1 , 1 ), new Translation2d ( 2 , - 1 )), 107 // End 3 meters straight ahead of where we started, facing forward 108 new Pose2d ( 3 , 0 , new Rotation2d ( 0 )), 109 // Pass config 110 config ); 111 112 RamseteCommand ramseteCommand = 113 new RamseteCommand ( 114 exampleTrajectory , 115 m_robotDrive :: getPose , 116 new RamseteController ( AutoConstants . kRamseteB , AutoConstants . kRamseteZeta ), 117 new SimpleMotorFeedforward ( 118 DriveConstants . ksVolts , 119 DriveConstants . kvVoltSecondsPerMeter , 120 DriveConstants . kaVoltSecondsSquaredPerMeter ), 121 DriveConstants . kDriveKinematics , 122 m_robotDrive :: getWheelSpeeds , 123 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), 124 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), 125 // RamseteCommand passes volts to the callback 126 m_robotDrive :: tankDriveVolts , 127 m_robotDrive ); 128 129 // Reset odometry to the initial pose of the trajectory, run path following 130 // command, then stop at the end. 131 return Commands . runOnce (() -> m_robotDrive . resetOdometry ( exampleTrajectory . getInitialPose ())) 132 . andThen ( ramseteCommand ) 133 . andThen ( Commands . runOnce (() -> m_robotDrive . tankDriveVolts ( 0 , 0 ))); 134 } 135 } C++ (Source) 45 frc2 :: CommandPtr RobotContainer::GetAutonomousCommand () { 46 // Create a voltage constraint to ensure we don't accelerate too fast 47 frc :: DifferentialDriveVoltageConstraint autoVoltageConstraint { 48 frc :: SimpleMotorFeedforward < units :: meters > { 49 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }, 50 DriveConstants :: kDriveKinematics , 10 _V }; 51 52 // Set up config for trajectory 53 frc :: TrajectoryConfig config { AutoConstants :: kMaxSpeed , 54 AutoConstants :: kMaxAcceleration }; 55 // Add kinematics to ensure max speed is actually obeyed 56 config . SetKinematics ( DriveConstants :: kDriveKinematics ); 57 // Apply the voltage constraint 58 config . AddConstraint ( autoVoltageConstraint ); 59 60 // An example trajectory to follow. All units in meters. 61 auto exampleTrajectory = frc :: TrajectoryGenerator :: GenerateTrajectory ( 62 // Start at the origin facing the +X direction 63 frc :: Pose2d { 0 _m , 0 _m , 0 _deg }, 64 // Pass through these two interior waypoints, making an 's' curve path 65 { frc :: Translation2d { 1 _m , 1 _m }, frc :: Translation2d { 2 _m , -1 _m }}, 66 // End 3 meters straight ahead of where we started, facing forward 67 frc :: Pose2d { 3 _m , 0 _m , 0 _deg }, 68 // Pass the config 69 config ); 70 71 frc2 :: CommandPtr ramseteCommand { frc2 :: RamseteCommand ( 72 exampleTrajectory , [ this ] { return m_drive . GetPose (); }, 73 frc :: RamseteController { AutoConstants :: kRamseteB , 74 AutoConstants :: kRamseteZeta }, 75 frc :: SimpleMotorFeedforward < units :: meters > { 76 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }, 77 DriveConstants :: kDriveKinematics , 78 [ this ] { return m_drive . GetWheelSpeeds (); }, 79 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, 80 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, 81 [ this ]( auto left , auto right ) { m_drive . TankDriveVolts ( left , right ); }, 82 { & m_drive })}; 83 84 // Reset odometry to the initial pose of the trajectory, run path following 85 // command, then stop at the end. 86 return frc2 :: cmd :: RunOnce ( 87 [ this , initialPose = exampleTrajectory . InitialPose ()] { 88 m_drive . ResetOdometry ( initialPose ); 89 }, 90 {}) 91 . AndThen ( std :: move ( ramseteCommand )) 92 . AndThen ( 93 frc2 :: cmd :: RunOnce ([ this ] { m_drive . TankDriveVolts ( 0 _V , 0 _V ); }, {})); 94 } Configuring the Trajectory Constraints First, we must set some configuration parameters for the trajectory which will ensure that the generated trajectory is followable. Creating a Voltage Constraint The first piece of configuration we will need is a voltage constraint. This will ensure that the generated trajectory never commands the robot to go faster than it is capable of achieving with the given voltage supply: Java 80 // Create a voltage constraint to ensure we don't accelerate too fast 81 var autoVoltageConstraint = 82 new DifferentialDriveVoltageConstraint ( 83 new SimpleMotorFeedforward ( 84 DriveConstants . ksVolts , 85 DriveConstants . kvVoltSecondsPerMeter , 86 DriveConstants . kaVoltSecondsSquaredPerMeter ), 87 DriveConstants . kDriveKinematics , 88 10 ); C++ (Source) 46 // Create a voltage constraint to ensure we don't accelerate too fast 47 frc :: DifferentialDriveVoltageConstraint autoVoltageConstraint { 48 frc :: SimpleMotorFeedforward < units :: meters > { 49 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }, 50 DriveConstants :: kDriveKinematics , 10 _V }; Notice that we set the maximum voltage to 10V, rather than the nominal battery voltage of 12V. This gives us some “headroom” to deal with “voltage sag” during operation. Creating the Configuration Now that we have our voltage constraint, we can create our TrajectoryConfig instance, which wraps together all of our path constraints: Java 90 // Create config for trajectory 91 TrajectoryConfig config = 92 new TrajectoryConfig ( 93 AutoConstants . kMaxSpeedMetersPerSecond , 94 AutoConstants . kMaxAccelerationMetersPerSecondSquared ) 95 // Add kinematics to ensure max speed is actually obeyed 96 . setKinematics ( DriveConstants . kDriveKinematics ) 97 // Apply the voltage constraint 98 . addConstraint ( autoVoltageConstraint ); C++ (Source) 52 // Set up config for trajectory 53 frc :: TrajectoryConfig config { AutoConstants :: kMaxSpeed , 54 AutoConstants :: kMaxAcceleration }; 55 // Add kinematics to ensure max speed is actually obeyed 56 config . SetKinematics ( DriveConstants :: kDriveKinematics ); 57 // Apply the voltage constraint 58 config . AddConstraint ( autoVoltageConstraint ); Generating the Trajectory With our trajectory configuration in hand, we are now ready to generate our trajectory. For this example, we will be generating a “clamped cubic” trajectory - this means we will specify full robot poses at the endpoints, and positions only for interior waypoints (also known as “knot points”). As elsewhere, all distances are in meters. Java 100 // An example trajectory to follow. All units in meters. 101 Trajectory exampleTrajectory = 102 TrajectoryGenerator . generateTrajectory ( 103 // Start at the origin facing the +X direction 104 new Pose2d ( 0 , 0 , new Rotation2d ( 0 )), 105 // Pass through these two interior waypoints, making an 's' curve path 106 List . of ( new Translation2d ( 1 , 1 ), new Translation2d ( 2 , - 1 )), 107 // End 3 meters straight ahead of where we started, facing forward 108 new Pose2d ( 3 , 0 , new Rotation2d ( 0 )), 109 // Pass config 110 config ); C++ (Source) 60 // An example trajectory to follow. All units in meters. 61 auto exampleTrajectory = frc :: TrajectoryGenerator :: GenerateTrajectory ( 62 // Start at the origin facing the +X direction 63 frc :: Pose2d { 0 _m , 0 _m , 0 _deg }, 64 // Pass through these two interior waypoints, making an 's' curve path 65 { frc :: Translation2d { 1 _m , 1 _m }, frc :: Translation2d { 2 _m , -1 _m }}, 66 // End 3 meters straight ahead of where we started, facing forward 67 frc :: Pose2d { 3 _m , 0 _m , 0 _deg }, 68 // Pass the config 69 config ); Note Instead of generating the trajectory on the roboRIO as outlined above, one can also import a PathWeaver JSON . Creating the RamseteCommand We will first reset our robot’s pose to the starting pose of the trajectory. This ensures that the robot’s location on the coordinate system and the trajectory’s starting position are the same. Java 129 // Reset odometry to the initial pose of the trajectory, run path following 130 // command, then stop at the end. 131 return Commands . runOnce (() -> m_robotDrive . resetOdometry ( exampleTrajectory . getInitialPose ())) C++ (Source) 84 // Reset odometry to the initial pose of the trajectory, run path following 85 // command, then stop at the end. 86 return frc2 :: cmd :: RunOnce ( It is very important that the initial robot pose match the first pose in the trajectory. For the purposes of our example, the robot will be reliably starting at a position of (0,0) with a heading of 0 . In actual use, however, it is probably not desirable to base your coordinate system on the robot position, and so the starting position for both the robot and the trajectory should be set to some other value. If you wish to use a trajectory that has been defined in robot-centric coordinates in such a situation, you can transform it to be relative to the robot’s current pose using the transformBy method ( Java , C++ ). For more information about transforming trajectories, see Transforming Trajectories . Now that we have a trajectory, we can create a command that, when executed, will follow that trajectory. To do this, we use the RamseteCommand class ( Java , C++ ) Java 112 RamseteCommand ramseteCommand = 113 new RamseteCommand ( 114 exampleTrajectory , 115 m_robotDrive :: getPose , 116 new RamseteController ( AutoConstants . kRamseteB , AutoConstants . kRamseteZeta ), 117 new SimpleMotorFeedforward ( 118 DriveConstants . ksVolts , 119 DriveConstants . kvVoltSecondsPerMeter , 120 DriveConstants . kaVoltSecondsSquaredPerMeter ), 121 DriveConstants . kDriveKinematics , 122 m_robotDrive :: getWheelSpeeds , 123 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), 124 new PIDController ( DriveConstants . kPDriveVel , 0 , 0 ), 125 // RamseteCommand passes volts to the callback 126 m_robotDrive :: tankDriveVolts , 127 m_robotDrive ); C++ (Source) 71 frc2 :: CommandPtr ramseteCommand { frc2 :: RamseteCommand ( 72 exampleTrajectory , [ this ] { return m_drive . GetPose (); }, 73 frc :: RamseteController { AutoConstants :: kRamseteB , 74 AutoConstants :: kRamseteZeta }, 75 frc :: SimpleMotorFeedforward < units :: meters > { 76 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }, 77 DriveConstants :: kDriveKinematics , 78 [ this ] { return m_drive . GetWheelSpeeds (); }, 79 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, 80 frc :: PIDController { DriveConstants :: kPDriveVel , 0 , 0 }, 81 [ this ]( auto left , auto right ) { m_drive . TankDriveVolts ( left , right ); }, 82 { & m_drive })}; This declaration is fairly substantial, so we’ll go through it argument-by-argument: The trajectory: This is the trajectory to be followed; accordingly, we pass the command the trajectory we just constructed in our earlier steps. The pose supplier: This is a method reference (or lambda) to the drive subsystem method that returns the pose . The RAMSETE controller needs the current pose measurement to determine the required wheel outputs. The RAMSETE controller: This is the RamseteController object ( Java , C++ ) that will perform the path-following computation that translates the current measured pose and trajectory state into a chassis speed setpoint. The drive feedforward: This is a SimpleMotorFeedforward object ( Java , C++ ) that will automatically perform the correct feedforward calculation with the feedforward gains ( kS , kV , and kA ) that we obtained from the drive identification tool. The drive kinematics: This is the DifferentialDriveKinematics object ( Java , C++ ) that we constructed earlier in our constants file, and will be used to convert chassis speeds to wheel speeds. The wheel speed supplier: This is a method reference (or lambda) to the drive subsystem method that returns the wheel speeds The left-side PIDController: This is the PIDController object ( Java , C++ ) that will track the left-side wheel speed setpoint, using the P gain that we obtained from the drive identification tool. The right-side PIDController: This is the PIDController object ( Java , C++ ) that will track the right-side wheel speed setpoint, using the P gain that we obtained from the drive identification tool. The output consumer: This is a method reference (or lambda) to the drive subsystem method that passes the voltage outputs to the drive motors . The robot drive: This is the drive subsystem itself, included to ensure the command does not operate on the drive at the same time as any other command that uses the drive. Finally, note that we append a final “stop” command in sequence after the path-following command, to ensure that the robot stops moving at the end of the trajectory. Video If all has gone well, your robot’s autonomous routine should look something like this:",
      "content_preview": "Step 4: Creating and Following a Trajectory With our drive subsystem written, it is now time to generate a trajectory and write an autonomous command to follow it. As per the standard command-based project structure , we will do this in the getAutonomousCommand method of the RobotContainer class."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/command-scheduler.html?present",
      "title": "The Command Scheduler",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "The Command Scheduler The CommandScheduler ( Java , C++ ) is the class responsible for actually running commands. Each iteration (ordinarily once per 20ms), the scheduler polls all registered buttons, schedules commands for execution accordingly, runs the command bodies of all scheduled commands, and ends those commands that have finished or are interrupted. The CommandScheduler also runs the periodic() method of each registered Subsystem . Using the Command Scheduler The CommandScheduler is a singleton , meaning that it is a globally-accessible class with only one instance. Accordingly, in order to access the scheduler, users must call the CommandScheduler.getInstance() command. For the most part, users do not have to call scheduler methods directly - almost all important scheduler methods have convenience wrappers elsewhere (e.g. in the Command and Subsystem classes). However, there is one exception: users must call CommandScheduler.getInstance().run() from the robotPeriodic() method of their Robot class. If this is not done, the scheduler will never run, and the command framework will not work. The provided command-based project template has this call already included. The schedule() Method To schedule a command, users call the schedule() method ( Java , C++ ). This method takes a command, and attempts to add it to list of currently-running commands, pending whether it is already running or whether its requirements are available. If it is added, its initialize() method is called. This method walks through the following steps: Verifies that the command isn’t in a composition. No-op if scheduler is disabled, command is already scheduled, or robot is disabled and command doesn’t runsWhenDisabled . If requirements are in use: If all conflicting commands are interruptible, cancel them. If not, don’t schedule the new command. Call initialize() . Java 202 private void schedule ( Command command ) { 203 if ( command == null ) { 204 DriverStation . reportWarning ( \"Tried to schedule a null command\" , true ); 205 return ; 206 } 207 if ( m_inRunLoop ) { 208 m_toSchedule . add ( command ); 209 return ; 210 } 211 212 requireNotComposed ( command ); 213 214 // Do nothing if the scheduler is disabled, the robot is disabled and the command doesn't 215 // run when disabled, or the command is already scheduled. 216 if ( m_disabled 217 || isScheduled ( command ) 218 || RobotState . isDisabled () && ! command . runsWhenDisabled ()) { 219 return ; 220 } 221 222 Set < Subsystem > requirements = command . getRequirements (); 223 224 // Schedule the command if the requirements are not currently in-use. 225 if ( Collections . disjoint ( m_requirements . keySet (), requirements )) { 226 initCommand ( command , requirements ); 227 } else { 228 // Else check if the requirements that are in use have all have interruptible commands, 229 // and if so, interrupt those commands and schedule the new command. 230 for ( Subsystem requirement : requirements ) { 231 Command requiring = requiring ( requirement ); 232 if ( requiring != null 233 && requiring . getInterruptionBehavior () == InterruptionBehavior . kCancelIncoming ) { 234 return ; 235 } 236 } 237 for ( Subsystem requirement : requirements ) { 238 Command requiring = requiring ( requirement ); 239 if ( requiring != null ) { 240 cancel ( requiring ); 241 } 242 } 243 initCommand ( command , requirements ); 244 } 245 } 181 private void initCommand ( Command command , Set < Subsystem > requirements ) { 182 m_scheduledCommands . add ( command ); 183 for ( Subsystem requirement : requirements ) { 184 m_requirements . put ( requirement , command ); 185 } 186 command . initialize (); 187 for ( Consumer < Command > action : m_initActions ) { 188 action . accept ( command ); 189 } 190 191 m_watchdog . addEpoch ( command . getName () + \".initialize()\" ); C++ (Source) 114 void CommandScheduler::Schedule ( Command * command ) { 115 if ( m_impl -> inRunLoop ) { 116 m_impl -> toSchedule . emplace_back ( command ); 117 return ; 118 } 119 120 RequireUngrouped ( command ); 121 122 if ( m_impl -> disabled || m_impl -> scheduledCommands . contains ( command ) || 123 ( frc :: RobotState :: IsDisabled () && ! command -> RunsWhenDisabled ())) { 124 return ; 125 } 126 127 const auto & requirements = command -> GetRequirements (); 128 129 wpi :: SmallVector < Command * , 8 > intersection ; 130 131 bool isDisjoint = true ; 132 bool allInterruptible = true ; 133 for ( auto && i1 : m_impl -> requirements ) { 134 if ( requirements . find ( i1 . first ) != requirements . end ()) { 135 isDisjoint = false ; 136 allInterruptible &= ( i1 . second -> GetInterruptionBehavior () == 137 Command :: InterruptionBehavior :: kCancelSelf ); 138 intersection . emplace_back ( i1 . second ); 139 } 140 } 141 142 if ( isDisjoint || allInterruptible ) { 143 if ( allInterruptible ) { 144 for ( auto && cmdToCancel : intersection ) { 145 Cancel ( cmdToCancel ); 146 } 147 } 148 m_impl -> scheduledCommands . insert ( command ); 149 for ( auto && requirement : requirements ) { 150 m_impl -> requirements [ requirement ] = command ; 151 } 152 command -> Initialize (); 153 for ( auto && action : m_impl -> initActions ) { 154 action ( * command ); 155 } 156 m_watchdog . AddEpoch ( command -> GetName () + \".Initialize()\" ); 157 } 158 } The Scheduler Run Sequence Note The initialize() method of each Command is called when the command is scheduled, which is not necessarily when the scheduler runs (unless that command is bound to a button). What does a single iteration of the scheduler’s run() method ( Java , C++ ) actually do? The following section walks through the logic of a scheduler iteration. For the full implementation, see the source code ( Java , C++ ). Step 1: Run Subsystem Periodic Methods First, the scheduler runs the periodic() method of each registered Subsystem . In simulation, each subsystem’s simulationPeriodic() method is called as well. Java 278 // Run the periodic method of all registered subsystems. 279 for ( Subsystem subsystem : m_subsystems . keySet ()) { 280 subsystem . periodic (); 281 if ( RobotBase . isSimulation ()) { 282 subsystem . simulationPeriodic (); 283 } 284 m_watchdog . addEpoch ( subsystem . getClass (). getSimpleName () + \".periodic()\" ); 285 } C++ (Source) 183 // Run the periodic method of all registered subsystems. 184 for ( auto && subsystem : m_impl -> subsystems ) { 185 subsystem . getFirst () -> Periodic (); 186 if constexpr ( frc :: RobotBase :: IsSimulation ()) { 187 subsystem . getFirst () -> SimulationPeriodic (); 188 } 189 m_watchdog . AddEpoch ( \"Subsystem Periodic()\" ); 190 } Step 2: Poll Command Scheduling Triggers Note For more information on how trigger bindings work, see Binding Commands to Triggers Secondly, the scheduler polls the state of all registered triggers to see if any new commands that have been bound to those triggers should be scheduled. If the conditions for scheduling a bound command are met, the command is scheduled and its initialize() method is run. Note If a newly-scheduled command has requirement conflicts with a currently-running command, the currently-running command is interrupted first. The end(true) method of the interrupted command is called before the initialize() method of the new command. Java 290 // Poll buttons for new commands to add. 291 loopCache . poll (); 292 m_watchdog . addEpoch ( \"buttons.run()\" ); C++ (Source) 195 // Poll buttons for new commands to add. 196 loopCache -> Poll (); 197 m_watchdog . AddEpoch ( \"buttons.Run()\" ); Step 3: Run/Finish Scheduled Commands Thirdly, the scheduler calls the execute() method of each currently-scheduled command, and then checks whether the command has finished by calling the isFinished() method. If the command has finished, the end() method is also called, and the command is de-scheduled and its required subsystems are freed. Note that this sequence of calls is done in order for each command - thus, one command may have its end() method called before another has its execute() method called. Commands are handled in the order they were scheduled. Java 295 // Run scheduled commands, remove finished commands. 296 for ( Iterator < Command > iterator = m_scheduledCommands . iterator (); iterator . hasNext (); ) { 297 Command command = iterator . next (); 298 299 if ( ! command . runsWhenDisabled () && RobotState . isDisabled ()) { 300 command . end ( true ); 301 for ( Consumer < Command > action : m_interruptActions ) { 302 action . accept ( command ); 303 } 304 m_requirements . keySet (). removeAll ( command . getRequirements ()); 305 iterator . remove (); 306 m_watchdog . addEpoch ( command . getName () + \".end(true)\" ); 307 continue ; 308 } 309 310 command . execute (); 311 for ( Consumer < Command > action : m_executeActions ) { 312 action . accept ( command ); 313 } 314 m_watchdog . addEpoch ( command . getName () + \".execute()\" ); 315 if ( command . isFinished ()) { 316 command . end ( false ); 317 for ( Consumer < Command > action : m_finishActions ) { 318 action . accept ( command ); 319 } 320 iterator . remove (); 321 322 m_requirements . keySet (). removeAll ( command . getRequirements ()); 323 m_watchdog . addEpoch ( command . getName () + \".end(false)\" ); 324 } 325 } C++ (Source) 201 for ( Command * command : m_impl -> scheduledCommands ) { 202 if ( ! command -> RunsWhenDisabled () && frc :: RobotState :: IsDisabled ()) { 203 Cancel ( command ); 204 continue ; 205 } 206 207 command -> Execute (); 208 for ( auto && action : m_impl -> executeActions ) { 209 action ( * command ); 210 } 211 m_watchdog . AddEpoch ( command -> GetName () + \".Execute()\" ); 212 213 if ( command -> IsFinished ()) { 214 command -> End ( false ); 215 for ( auto && action : m_impl -> finishActions ) { 216 action ( * command ); 217 } 218 219 for ( auto && requirement : command -> GetRequirements ()) { 220 m_impl -> requirements . erase ( requirement ); 221 } 222 223 m_impl -> scheduledCommands . erase ( command ); 224 m_watchdog . AddEpoch ( command -> GetName () + \".End(false)\" ); 225 } 226 } Step 4: Schedule Default Commands Finally, any registered Subsystem has its default command scheduled (if it has one). Note that the initialize() method of the default command will be called at this time. Java 340 // Add default commands for un-required registered subsystems. 341 for ( Map . Entry < Subsystem , Command > subsystemCommand : m_subsystems . entrySet ()) { 342 if ( ! m_requirements . containsKey ( subsystemCommand . getKey ()) 343 && subsystemCommand . getValue () != null ) { 344 schedule ( subsystemCommand . getValue ()); 345 } 346 } C++ (Source) 240 // Add default commands for un-required registered subsystems. 241 for ( auto && subsystem : m_impl -> subsystems ) { 242 auto s = m_impl -> requirements . find ( subsystem . getFirst ()); 243 if ( s == m_impl -> requirements . end () && subsystem . getSecond ()) { 244 Schedule ({ subsystem . getSecond (). get ()}); 245 } 246 } Disabling the Scheduler The scheduler can be disabled by calling CommandScheduler.getInstance().disable() . When disabled, the scheduler’s schedule() and run() commands will not do anything. The scheduler may be re-enabled by calling CommandScheduler.getInstance().enable() . Command Event Methods Occasionally, it is desirable to have the scheduler execute a custom action whenever a certain command event (initialization, execution, or ending) occurs. This can be done with the following methods: onCommandInitialize ( Java , C++ ) runs a specified action whenever a command is initialized. onCommandExecute ( Java , C++ ) runs a specified action whenever a command is executed. onCommandFinish ( Java , C++ ) runs a specified action whenever a command finishes normally (i.e. the isFinished() method returned true). onCommandInterrupt ( Java , C++ ) runs a specified action whenever a command is interrupted (i.e. by being explicitly canceled or by another command that shares one of its requirements). A typical use-case for these methods is adding markers in an event log whenever a command scheduling event takes place, as demonstrated in the following code from the HatchbotInlined example project ( Java , C++ ): Java 73 // Set the scheduler to log Shuffleboard events for command initialize, interrupt, finish 74 CommandScheduler . getInstance () 75 . onCommandInitialize ( 76 command -> 77 Shuffleboard . addEventMarker ( 78 \"Command initialized\" , command . getName (), EventImportance . kNormal )); 79 CommandScheduler . getInstance () 80 . onCommandInterrupt ( 81 command -> 82 Shuffleboard . addEventMarker ( 83 \"Command interrupted\" , command . getName (), EventImportance . kNormal )); 84 CommandScheduler . getInstance () 85 . onCommandFinish ( 86 command -> 87 Shuffleboard . addEventMarker ( 88 \"Command finished\" , command . getName (), EventImportance . kNormal )); C++ (Source) 23 // Log Shuffleboard events for command initialize, execute, finish, interrupt 24 frc2 :: CommandScheduler :: GetInstance (). OnCommandInitialize ( 25 []( const frc2 :: Command & command ) { 26 frc :: Shuffleboard :: AddEventMarker ( 27 \"Command initialized\" , command . GetName (), 28 frc :: ShuffleboardEventImportance :: kNormal ); 29 }); 30 frc2 :: CommandScheduler :: GetInstance (). OnCommandExecute ( 31 []( const frc2 :: Command & command ) { 32 frc :: Shuffleboard :: AddEventMarker ( 33 \"Command executed\" , command . GetName (), 34 frc :: ShuffleboardEventImportance :: kNormal ); 35 }); 36 frc2 :: CommandScheduler :: GetInstance (). OnCommandFinish ( 37 []( const frc2 :: Command & command ) { 38 frc :: Shuffleboard :: AddEventMarker ( 39 \"Command finished\" , command . GetName (), 40 frc :: ShuffleboardEventImportance :: kNormal ); 41 }); 42 frc2 :: CommandScheduler :: GetInstance (). OnCommandInterrupt ( 43 []( const frc2 :: Command & command ) { 44 frc :: Shuffleboard :: AddEventMarker ( 45 \"Command interrupted\" , command . GetName (), 46 frc :: ShuffleboardEventImportance :: kNormal ); 47 });",
      "content_preview": "The Command Scheduler The CommandScheduler ( Java , C++ ) is the class responsible for actually running commands. Each iteration (ordinarily once per 20ms), the scheduler polls all registered buttons, schedules commands for execution accordingly, runs the command bodies of all scheduled commands,..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/examples-tutorials/wpilib-examples.html",
      "title": "WPILib Example Projects",
      "section": "General",
      "language": "All",
      "content": "WPILib Example Projects Warning While every attempt is made to keep WPILib examples functional, they are not intended to be used “as-is.” At the very least, robot-specific constants will need to be changed for the code to work on a user robot. Many empirical constants have their values “faked” for demonstration purposes. Users are strongly encouraged to write their own code (from scratch or from an existing template) rather than copy example code. WPILib example projects demonstrate a large number of library features and use patterns. Projects range from simple demonstrations of a single functionality to complete, competition-capable robot programs. All of these examples are available in VS Code by entering Ctrl + Shift + P , then selecting WPILib: Create a new project and choosing example. Basic Examples These examples demonstrate basic/minimal robot functionality. They are useful for beginning teams who are gaining initial familiarity with robot programming, but are highly limited in functionality. Arcade Drive ( Java , C++ , Python ): Demonstrates a simple differential drive implementation using “arcade”-style controls through the DifferentialDrive class. Arcade Drive Xbox Controller ( Java , C++ , Python ): Demonstrates the same functionality seen in the previous example, except using an XboxController instead of an ordinary joystick. Getting Started ( Java , C++ , Python ): Demonstrates a simple autonomous routine that drives forwards for two seconds at half speed. Mecanum Drive ( Java , C++ , Python ): Demonstrates a simple mecanum drive implementation using the MecanumDrive class. Motor Controller ( Java , C++ , Python ): Demonstrates how to control the output of a motor with a joystick with an encoder to read motor position. Simple Vision ( Java , C++ , Python ): Demonstrates how to stream video from a USB camera to the dashboard. Relay ( Java , C++ , Python ): Demonstrates the use of the Relay class to control a relay output with a set of joystick buttons. Solenoids ( Java , C++ , Python ): Demonstrates the use of the Solenoid and DoubleSolenoid classes to control solenoid outputs with a set of joystick buttons. TankDrive ( Java , C++ , Python ): Demonstrates a simple differential drive implementation using “tank”-style controls through the DifferentialDrive class. Tank Drive Xbox Controller ( Java , C++ , Python ): Demonstrates the same functionality seen in the previous example, except using an XboxController instead of an ordinary joystick. Control Examples These examples demonstrate WPILib implementations of common robot controls. Sensors may be present, but are not the emphasized concept of these examples. DifferentialDriveBot ( Java , C++ , Python ): Demonstrates an advanced differential drive implementation, including encoder-and-gyro odometry through the DifferentialDriveOdometry class, and composition with PID velocity control through the DifferentialDriveKinematics and PIDController classes. DifferentialDrivePoseEstimator ( Java , C++ ): Demonstrates an advanced differential drive implementation with all the features of DifferentialDriveBot . In addition this example uses DifferentialDrivePoseEstimator to track the robots position on the field. It demonstrates these features by using WPILib Simulation. Elevator with Profiled PID Controller ( Java , C++ , Python ): Demonstrates the use of the ProfiledPIDController class to control the position of an elevator mechanism. Elevator with Trapezoid Profiled PID ( Java , C++ , Python ): Demonstrates the use of the TrapezoidProfile class in conjunction with a “smart motor controller” to control the position of an elevator mechanism. Elevator with Exponential Profiled PID ( Java , C++ ): Demonstrates the use of the ExponentialProfile class in conjunction with a “smart motor controller” to control the position of an elevator mechanism. Flywheel Bang-Bang Controller ( Java , C++ , Python ): Uses the BangBangController class to simply yet effectively control a flywheel. Gyro Mecanum ( Java , C++ , Python ): Demonstrates field-oriented control of a mecanum robot through the MecanumDrive class in conjunction with a gyro. MecanumBot ( Java , C++ , Python ): Demonstrates an advanced mecanum drive implementation, including encoder-and-gyro odometry through the MecanumDriveOdometry class, and composition with PID velocity control through the MecanumDriveKinematics and PIDController classes. Mecanum Drive PoseEstimator ( Java , C++ ): Demonstrates an advanced mecanum drive implementation with all the features of MecanumBot . In addition this example uses MecanumDrivePoseEstimator to track the robots position on the field. PotentiometerPID ( Java , C++ , Python ): Demonstrates the use of the PIDController class and a potentiometer to control the position of an elevator mechanism. SwerveBot ( Java , C++ , Python ): Demonstrates an advanced swerve drive implementation, including encoder-and-gyro odometry through the SwerveDriveOdometry class, and composition with PID position and velocity control through the SwerveDriveKinematics and PIDController classes. Swerve Drive PoseEstimator ( Java , C++ ): Demonstrates an advanced swerve drive implementation with all the features of SwerveBot . In addition this example uses SwerveDrivePoseEstimator to track the robots position on the field. UltrasonicPID ( Java , C++ , Python ): Demonstrates the use of the PIDController class in conjunction with an ultrasonic sensor to drive to a set distance from an object. Sensor Examples These examples demonstrate sensor reading and data processing using WPILib. Mechanisms control may be present, but is not the emphasized concept of these examples. HTTP Camera ( Java , C++ ): Demonstrates the use of OpenCV and a HTTP Camera to overlay a rectangle on a captured video feed and stream it to the dashboard. Power Distribution CAN Monitoring ( Java , C++ , Python ): Demonstrates obtaining sensor information from a Power Distribution module over CAN using the PowerDistribution class. Duty Cycle Encoder ( Java , C++ , Python ): Demonstrates the use of the DutyCycleEncoder class to read values from a PWM-type absolute encoder. DutyCycleInput ( Java , C++ , Python ): Demonstrates the use of the DutyCycleInput class to read the frequency and fractional duty cycle of a PWM input. Encoder ( Java , C++ , Python ): Demonstrates the use of the Encoder class to read values from a quadrature encoder. Gyro ( Java , C++ , Python ): Demonstrates the use of the AnalogGyro class to measure robot heading and stabilize driving. Intermediate Vision ( Java , C++ , Python ): Demonstrates the use of OpenCV and a USB camera to overlay a rectangle on a captured video feed and stream it to the dashboard. AprilTagsVision ( Java , C++ , Python ): Demonstrates on-roboRIO detection of AprilTags using an attached USB camera. Ultrasonic ( Java , C++ , Python ): Demonstrates the use of the Ultrasonic class to read data from an ultrasonic sensor in conjunction with the MedianFilter class to reduce signal noise. SysIdRoutine ( Java , C++ , Python ): Demonstrates the use of the SysIdRoutine API to gather characterization data for a differential drivetrain. Command-Based Examples These examples demonstrate the use of the Command-Based framework . DriveDistanceOffboard ( Java , C++ , Python ): Demonstrates the use of a TrapezoidProfileCommand in conjunction with a “smart motor controller” to drive forward by a set distance with a trapezoidal motion profile. Rapid React Command Bot ( Java , C++ ): This project uses the latest command based best practices and the Epilogue logging system. It is capable of playing the FRC 2022 game Rapid React. Inlined Hatchbot ( Java , C++ , Python ): A complete set of robot code for a simple hatch-delivery bot typical of the 2019 FRC game Destination: Deep Space . Commands are written in an “inline” style, in which explicit subclassing of Command is avoided. Traditional Hatchbot ( Java , C++ , Python ): A complete set of robot code for a simple hatch-delivery bot typical of the 2019 FRC game Destination: Deep Space . Commands are written in a “traditional” style, in which subclasses of Command are written for each robot action. MecanumControllerCommand ( Java , C++ ): Demonstrates trajectory generation and following with a mecanum drive using the TrajectoryGenerator and MecanumControllerCommand classes. Select Command Example ( Java , C++ , Python ): Demonstrates the use of the SelectCommand class to run one of a selection of commands depending on a runtime-evaluated condition. SwerveControllerCommand ( Java , C++ ): Demonstrates trajectory generation and following with a swerve drive using the TrajectoryGenerator and SwerveControllerCommand classes. State-Space Examples These examples demonstrate the use of the State-Space Control . StateSpaceFlywheel ( Java , C++ , Python ): Demonstrates state-space control of a flywheel. StateSpaceFlywheelSysId ( Java , C++ , Python ): Demonstrates state-space control using SysId’s System Identification for controlling a flywheel. StateSpaceElevator ( Java , C++ , Python ): Demonstrates state-space control of an elevator. StateSpaceArm ( Java , C++ , Python ): Demonstrates state-space control of an Arm. Simulation Physics Examples These examples demonstrate the use of the physics simulation. ElevatorSimulation ( Java , C++ , Python ): Demonstrates the use of physics simulation with a simple elevator. ElevatorSimulation with Exponential PID ( Java , C++ ): Demonstrates the use of physics simulation of an elevator being controlled with exponential profiled PID. ArmSimulation ( Java , C++ , Python ): Demonstrates the use of physics simulation with a simple single-jointed arm. SimpleDifferentialDriveSimulation ( Java , C++ ): A barebones example of a basic drivetrain that can be used in simulation. Miscellaneous Examples These examples demonstrate miscellaneous WPILib functionality that does not fit into any of the above categories. Addressable LED ( Java , C++ , Python ): Demonstrates the use of the AddressableLED class to control RGB LEDs for robot decoration and/or driver feedback. Digital Communication ( Java , C++ , Python ): This is a sample program demonstrating how to communicate to a light controller from the robot code using the roboRIO’s DIO ports. I2C Communication ( Java , C++ , Python ): This is a sample program demonstrating how to communicate to a light controller from the robot code using the roboRIO’s I2C port. DMA ( Java , C++ ): Demonstrates the use of DMA (Direct Memory Access) to read from sensors without using the RoboRIO’s CPU. HAL ( C++ ): Demonstrates the use of HAL (Hardware Abstraction Layer) without the use of the rest of WPILib. This example is for advanced users (C++ only). HID Rumble ( Java , C++ , Python ): Demonstrates the use of the “rumble” functionality for tactile feedback on supported HIDs (such as XboxControllers). Shuffleboard ( Java , C++ , Python ): Demonstrates configuring tab/widget layouts on the “Shuffleboard” dashboard from robot code through the Shuffleboard class’s fluent builder API. RomiReference ( Java , C++ , Python ): A command based example of how to run the Romi robot . XRPReference ( Java , C++ ): A command based example of how to run the XRP robot . Mechanism2d ( Java , C++ , Python ): A simple example of using Mechanism2d . EventLoop ( Java , C++ ): Demonstrates the use of the EventLoop class that allows code to be called based on a boolean condition in the event-driven programming style. UnitTest ( Java , C++ ): Shows how to do Unit Testing . The test files need to be in a separate Test directory ( Java , C++ ).",
      "content_preview": "WPILib Example Projects Warning While every attempt is made to keep WPILib examples functional, they are not intended to be used “as-is.” At the very least, robot-specific constants will need to be changed for the code to work on a user robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/unit-testing.html",
      "title": "Unit Testing",
      "section": "General",
      "language": "All",
      "content": "Unit Testing Unit testing is a method of testing code by dividing the code into the smallest “units” possible and testing each unit. In robot code, this can mean testing the code for each subsystem individually. There are many unit testing frameworks for most languages. Java robot projects have JUnit 5 available by default, and C++ robot projects have Google Test . Writing Testable Code Note This example can be easily adapted to the command-based paradigm by having Intake inherit from SubsystemBase . Our subsystem will be an Infinite Recharge intake mechanism containing a piston and a motor: the piston deploys/retracts the intake, and the motor will pull the Power Cells inside. We don’t want the motor to run if the intake mechanism isn’t deployed because it won’t do anything. To provide a “clean slate” for each test, we need to have a function to destroy the object and free all hardware allocations. In Java, this is done by implementing the AutoCloseable interface and its .close() method, destroying each member object by calling the member’s .close() method - an object without a .close() method probably doesn’t need to be closed. In C++, the default destructor will be called automatically when the object goes out of scope and will call destructors of member objects. Note Vendors might not support resource closing identically to the way shown here. See your vendor’s documentation for more information as to what they support and how. Java import edu.wpi.first.wpilibj.DoubleSolenoid ; import edu.wpi.first.wpilibj.PneumaticsModuleType ; import edu.wpi.first.wpilibj.examples.unittest.Constants.IntakeConstants ; import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; public class Intake implements AutoCloseable { private final PWMSparkMax m_motor ; private final DoubleSolenoid m_piston ; public Intake () { m_motor = new PWMSparkMax ( IntakeConstants . kMotorPort ); m_piston = new DoubleSolenoid ( PneumaticsModuleType . CTREPCM , IntakeConstants . kPistonFwdChannel , IntakeConstants . kPistonRevChannel ); } public void deploy () { m_piston . set ( DoubleSolenoid . Value . kForward ); } public void retract () { m_piston . set ( DoubleSolenoid . Value . kReverse ); m_motor . set ( 0 ); // turn off the motor } public void activate ( double speed ) { if ( isDeployed ()) { m_motor . set ( speed ); } else { // if piston isn't open, do nothing m_motor . set ( 0 ); } } public boolean isDeployed () { return m_piston . get () == DoubleSolenoid . Value . kForward ; } @Override public void close () { m_piston . close (); m_motor . close (); } } C++ (Header) #include <frc/DoubleSolenoid.h> #include <frc/motorcontrol/PWMSparkMax.h> #include \"Constants.h\" class Intake { public : void Deploy (); void Retract (); void Activate ( double speed ); bool IsDeployed () const ; private : frc :: PWMSparkMax m_motor { IntakeConstants :: kMotorPort }; frc :: DoubleSolenoid m_piston { frc :: PneumaticsModuleType :: CTREPCM , IntakeConstants :: kPistonFwdChannel , IntakeConstants :: kPistonRevChannel }; }; C++ (Source) #include \"subsystems/Intake.h\" void Intake::Deploy () { m_piston . Set ( frc :: DoubleSolenoid :: Value :: kForward ); } void Intake::Retract () { m_piston . Set ( frc :: DoubleSolenoid :: Value :: kReverse ); m_motor . Set ( 0 ); // turn off the motor } void Intake::Activate ( double speed ) { if ( IsDeployed ()) { m_motor . Set ( speed ); } else { // if piston isn't open, do nothing m_motor . Set ( 0 ); } } bool Intake::IsDeployed () const { return m_piston . Get () == frc :: DoubleSolenoid :: Value :: kForward ; } Writing Tests Important Tests are placed inside the test source set: /src/test/java/ and /src/test/cpp/ for Java and C++ tests, respectively. Files outside that source root do not have access to the test framework - this will fail compilation due to unresolved references. In Java, each test class contains at least one test method marked with @org.junit.jupiter.api.Test , each method representing a test case. Additional methods for opening resources (such as our Intake object) before each test and closing them after are respectively marked with @org.junit.jupiter.api.BeforeEach and @org.junit.jupiter.api.AfterEach . In C++, test fixture classes inheriting from testing::Test contain our subsystem and simulation hardware objects, and test methods are written using the TEST_F(testfixture, testname) macro. The SetUp() and TearDown() methods can be overridden in the test fixture class and will be run respectively before and after each test. Each test method should contain at least one assertion ( assert*() in Java or EXPECT_*() in C++). These assertions verify a condition at runtime and fail the test if the condition isn’t met. If there is more than one assertion in a test method, the first failed assertion will crash the test - execution won’t reach the later assertions. Both JUnit and GoogleTest have multiple assertion types; the most common is equality: assertEquals(expected, actual) / EXPECT_EQ(expected, actual) . When comparing numbers, a third parameter - delta , the acceptable error, can be given. In JUnit (Java), these assertions are static methods and can be used without qualification by adding the static star import import static org.junit.jupiter.api.Assertions.* . In Google Test (C++), assertions are macros from the <gtest/gtest.h> header. Note Comparison of floating-point values isn’t accurate, so comparing them should be done with an acceptable error parameter ( DELTA ). Java import static org.junit.jupiter.api.Assertions.assertEquals ; import edu.wpi.first.hal.HAL ; import edu.wpi.first.wpilibj.DoubleSolenoid ; import edu.wpi.first.wpilibj.PneumaticsModuleType ; import edu.wpi.first.wpilibj.examples.unittest.Constants.IntakeConstants ; import edu.wpi.first.wpilibj.simulation.DoubleSolenoidSim ; import edu.wpi.first.wpilibj.simulation.PWMSim ; import org.junit.jupiter.api.AfterEach ; import org.junit.jupiter.api.BeforeEach ; import org.junit.jupiter.api.Test ; class IntakeTest { static final double DELTA = 1e-2 ; // acceptable deviation range Intake m_intake ; PWMSim m_simMotor ; DoubleSolenoidSim m_simPiston ; @BeforeEach // this method will run before each test void setup () { assert HAL . initialize ( 500 , 0 ); // initialize the HAL, crash if failed m_intake = new Intake (); // create our intake m_simMotor = new PWMSim ( IntakeConstants . kMotorPort ); // create our simulation PWM motor controller m_simPiston = new DoubleSolenoidSim ( PneumaticsModuleType . CTREPCM , IntakeConstants . kPistonFwdChannel , IntakeConstants . kPistonRevChannel ); // create our simulation solenoid } @SuppressWarnings ( \"PMD.SignatureDeclareThrowsException\" ) @AfterEach // this method will run after each test void shutdown () throws Exception { m_intake . close (); // destroy our intake object } @Test // marks this method as a test void doesntWorkWhenClosed () { m_intake . retract (); // close the intake m_intake . activate ( 0.5 ); // try to activate the motor assertEquals ( 0.0 , m_simMotor . getSpeed (), DELTA ); // make sure that the value set to the motor is 0 } @Test void worksWhenOpen () { m_intake . deploy (); m_intake . activate ( 0.5 ); assertEquals ( 0.5 , m_simMotor . getSpeed (), DELTA ); } @Test void retractTest () { m_intake . retract (); assertEquals ( DoubleSolenoid . Value . kReverse , m_simPiston . get ()); } @Test void deployTest () { m_intake . deploy (); assertEquals ( DoubleSolenoid . Value . kForward , m_simPiston . get ()); } } C++ #include <frc/DoubleSolenoid.h> #include <frc/simulation/DoubleSolenoidSim.h> #include <frc/simulation/PWMSim.h> #include <gtest/gtest.h> #include \"Constants.h\" #include \"subsystems/Intake.h\" class IntakeTest : public testing :: Test { protected : Intake intake ; // create our intake frc :: sim :: PWMSim simMotor { IntakeConstants :: kMotorPort }; // create our simulation PWM frc :: sim :: DoubleSolenoidSim simPiston { frc :: PneumaticsModuleType :: CTREPCM , IntakeConstants :: kPistonFwdChannel , IntakeConstants :: kPistonRevChannel }; // create our simulation solenoid }; TEST_F ( IntakeTest , DoesntWorkWhenClosed ) { intake . Retract (); // close the intake intake . Activate ( 0.5 ); // try to activate the motor EXPECT_DOUBLE_EQ ( 0.0 , simMotor . GetSpeed ()); // make sure that the value set to the motor is 0 } TEST_F ( IntakeTest , WorksWhenOpen ) { intake . Deploy (); intake . Activate ( 0.5 ); EXPECT_DOUBLE_EQ ( 0.5 , simMotor . GetSpeed ()); } TEST_F ( IntakeTest , Retract ) { intake . Retract (); EXPECT_EQ ( frc :: DoubleSolenoid :: Value :: kReverse , simPiston . Get ()); } TEST_F ( IntakeTest , Deploy ) { intake . Deploy (); EXPECT_EQ ( frc :: DoubleSolenoid :: Value :: kForward , simPiston . Get ()); } For more advanced usage of JUnit and Google Test, see the framework docs. Running Tests Note Tests will always be run in simulation on your desktop. For prerequisites and more info, see the simulation introduction . For Java tests to run, make sure that your build.gradle file contains the following block: 77 test { 78 useJUnitPlatform () 79 systemProperty 'junit.jupiter.extensions.autodetection.enabled' , 'true' 80 } Use Test Robot Code from the Command Palette to run the tests. Results will be reported in the terminal output, each test will have a FAILED or PASSED / OK label next to the test name in the output. JUnit (Java only) will generate a HTML document in build/reports/tests/test/index.html with a more detailed overview of the results; if there are any failed tests a link to render the document in your browser will be printed in the terminal output. By default, Gradle runs the tests whenever robot code is built, including deploys. This will increase deploy time, and failing tests will cause the build and deploy to fail. To prevent this from happening, you can use Change Skip Tests On Deploy Setting from the Command Palette to configure whether to run tests when deploying.",
      "content_preview": "Unit Testing Unit testing is a method of testing code by dividing the code into the smallest “units” possible and testing each unit. In robot code, this can mean testing the code for each subsystem individually. There are many unit testing frameworks for most languages."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/index.html",
      "title": "Robot Simulation",
      "section": "General",
      "language": "All",
      "content": "Robot Simulation Introduction to Robot Simulation Simulation Specific User Interface Elements Glass Widgets Widgets for the Command-Based Framework The Field2d Widget Plots Physics Simulation with WPILib Device Simulation Drivetrain Simulation Tutorial Unit Testing",
      "content_preview": "Robot Simulation Introduction to Robot Simulation Simulation Specific User Interface Elements Glass Widgets Widgets for the Command-Based Framework The Field2d Widget Plots Physics Simulation with WPILib Device Simulation Drivetrain Simulation Tutorial Unit Testing"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/introduction.html",
      "title": "Introduction to Robot Simulation",
      "section": "General",
      "language": "All",
      "content": "Introduction to Robot Simulation Often a team may want to test their code without having an actual robot available. WPILib provides teams with the ability to simulate various robot features using simple gradle commands. Java/C++ Use of the Desktop Simulator requires Desktop Support to be enabled. This can be done by checking the “Enable Desktop Support Checkbox” when creating your robot project or by running “WPILib: Change Desktop Support Enabled Setting” from the Visual Studio Code command palette. Desktop support can also be enabled by manually editing your build.gradle file located at the root of your robot project. Simply change includeDesktopSupport = false to includeDesktopSupport = true Important It is important to note that enabling desktop/simulation support can have unintended consequences. Not all vendors will support this option, and code that uses their libraries may even crash when attempting to run simulation! If at any point in time you want to disable Desktop Support, simply re-run the “WPILib: Change Desktop Support Enabled Setting” from the command palette or change includeDesktopSupport to false in build.gradle. Note C++ robot simulation requires that a native compiler to be installed. For Windows, this would be Visual Studio 2022 version 17.9 or later ( not VS Code), macOS requires Xcode 14 or later , and Linux (Ubuntu) requires the build-essential package. Ensure the Desktop Development with C++ option is checked in the Visual Studio installer for simulation support. Running Robot Simulation Basic robot simulation can be run using VS Code. This can be done by using VS Code’s command palette WPILib: Simulate Robot Code as shown below. The Sim GUI option will be selected by default. This will launch the Simulation GUI . You can also launch simulation without a GUI by unchecking Sim GUI in which case your console output in Visual Studio Code should look like the below. ********** Robot program starting ********** Default disabledInit() method... Override me! Default disabledPeriodic() method... Override me! Default robotPeriodic() method... Override me! If you would would like to prevent the pop up and only use build.gradle to configure your simulation settings you can add the following in your vscode settings.json file. \"wpilib.skipSelectSimulateExtension\" : true Warning You may see a run button next to the WPILib button. This button does not set up simulation appropriately and should not be used. Instead, the menu item shown above WPILib: Simulate Robot Code should be used. Note Simulation can also be run outside of VS Code using ./gradlew simulateJava for Java or ./gradlew simulateNative for C++. Note Some vendors support attaching hardware to your PC and using the hardware in desktop simulation (e.g. CANivore). See vendor documentation for more information about the command WPILib: Hardware Sim Robot Code . Python GUI simulation support is installed by default when you install RobotPy. There is a robotpy subcommand that you can execute to run your code in simulation: Windows py -3 -m robotpy sim macOS python3 -m robotpy sim Linux python3 -m robotpy sim Running Robot Dashboards Shuffleboard, SmartDashboard, Glass, and AdvantageScope can be used with WPILib simulation when they are configured to connect to the local computer (i.e. localhost ). Shuffleboard Shuffleboard is automatically configured to look for a NetworkTables instance from the robotRIO but not from other sources . To connect to a simulation, open Shuffleboard preferences from the File menu and select NetworkTables under Plugins on the left navigation bar. In the Server field, type in the IP address or hostname of the NetworkTables host. For a standard simulation configuration, use localhost . SmartDashboard SmartDashboard is automatically configured to look for a NetworkTables instance from the roboRIO, but not from other sources . To connect to a simulation, open SmartDashboard preferences under the File menu and in the Team Number field, enter the IP address or hostname of the NetworkTables host. For a standard simulation configuration, use localhost . Glass Glass is automatically configured to look for a NetworkTables instance from the roboRIO, but not from other sources . To connect to a simulation, open NetworkTables Settings under the NetworkTables menu and in the Team/IP field, enter the IP address or hostname of the NetworkTables host. For a standard simulation configuration, use localhost . AdvantageScope No configuration is required to connect to a NetworkTables instance running on the local computer. To connect to a simulation, click Connect to Simulator under the File menu or press Ctrl + Shift + K .",
      "content_preview": "Introduction to Robot Simulation Often a team may want to test their code without having an actual robot available. WPILib provides teams with the ability to simulate various robot features using simple gradle commands. Java/C++ Use of the Desktop Simulator requires Desktop Support to be enabled."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/unit-testing.html?present",
      "title": "Unit Testing",
      "section": "General",
      "language": "All",
      "content": "Unit Testing Unit testing is a method of testing code by dividing the code into the smallest “units” possible and testing each unit. In robot code, this can mean testing the code for each subsystem individually. There are many unit testing frameworks for most languages. Java robot projects have JUnit 5 available by default, and C++ robot projects have Google Test . Writing Testable Code Note This example can be easily adapted to the command-based paradigm by having Intake inherit from SubsystemBase . Our subsystem will be an Infinite Recharge intake mechanism containing a piston and a motor: the piston deploys/retracts the intake, and the motor will pull the Power Cells inside. We don’t want the motor to run if the intake mechanism isn’t deployed because it won’t do anything. To provide a “clean slate” for each test, we need to have a function to destroy the object and free all hardware allocations. In Java, this is done by implementing the AutoCloseable interface and its .close() method, destroying each member object by calling the member’s .close() method - an object without a .close() method probably doesn’t need to be closed. In C++, the default destructor will be called automatically when the object goes out of scope and will call destructors of member objects. Note Vendors might not support resource closing identically to the way shown here. See your vendor’s documentation for more information as to what they support and how. Java import edu.wpi.first.wpilibj.DoubleSolenoid ; import edu.wpi.first.wpilibj.PneumaticsModuleType ; import edu.wpi.first.wpilibj.examples.unittest.Constants.IntakeConstants ; import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; public class Intake implements AutoCloseable { private final PWMSparkMax m_motor ; private final DoubleSolenoid m_piston ; public Intake () { m_motor = new PWMSparkMax ( IntakeConstants . kMotorPort ); m_piston = new DoubleSolenoid ( PneumaticsModuleType . CTREPCM , IntakeConstants . kPistonFwdChannel , IntakeConstants . kPistonRevChannel ); } public void deploy () { m_piston . set ( DoubleSolenoid . Value . kForward ); } public void retract () { m_piston . set ( DoubleSolenoid . Value . kReverse ); m_motor . set ( 0 ); // turn off the motor } public void activate ( double speed ) { if ( isDeployed ()) { m_motor . set ( speed ); } else { // if piston isn't open, do nothing m_motor . set ( 0 ); } } public boolean isDeployed () { return m_piston . get () == DoubleSolenoid . Value . kForward ; } @Override public void close () { m_piston . close (); m_motor . close (); } } C++ (Header) #include <frc/DoubleSolenoid.h> #include <frc/motorcontrol/PWMSparkMax.h> #include \"Constants.h\" class Intake { public : void Deploy (); void Retract (); void Activate ( double speed ); bool IsDeployed () const ; private : frc :: PWMSparkMax m_motor { IntakeConstants :: kMotorPort }; frc :: DoubleSolenoid m_piston { frc :: PneumaticsModuleType :: CTREPCM , IntakeConstants :: kPistonFwdChannel , IntakeConstants :: kPistonRevChannel }; }; C++ (Source) #include \"subsystems/Intake.h\" void Intake::Deploy () { m_piston . Set ( frc :: DoubleSolenoid :: Value :: kForward ); } void Intake::Retract () { m_piston . Set ( frc :: DoubleSolenoid :: Value :: kReverse ); m_motor . Set ( 0 ); // turn off the motor } void Intake::Activate ( double speed ) { if ( IsDeployed ()) { m_motor . Set ( speed ); } else { // if piston isn't open, do nothing m_motor . Set ( 0 ); } } bool Intake::IsDeployed () const { return m_piston . Get () == frc :: DoubleSolenoid :: Value :: kForward ; } Writing Tests Important Tests are placed inside the test source set: /src/test/java/ and /src/test/cpp/ for Java and C++ tests, respectively. Files outside that source root do not have access to the test framework - this will fail compilation due to unresolved references. In Java, each test class contains at least one test method marked with @org.junit.jupiter.api.Test , each method representing a test case. Additional methods for opening resources (such as our Intake object) before each test and closing them after are respectively marked with @org.junit.jupiter.api.BeforeEach and @org.junit.jupiter.api.AfterEach . In C++, test fixture classes inheriting from testing::Test contain our subsystem and simulation hardware objects, and test methods are written using the TEST_F(testfixture, testname) macro. The SetUp() and TearDown() methods can be overridden in the test fixture class and will be run respectively before and after each test. Each test method should contain at least one assertion ( assert*() in Java or EXPECT_*() in C++). These assertions verify a condition at runtime and fail the test if the condition isn’t met. If there is more than one assertion in a test method, the first failed assertion will crash the test - execution won’t reach the later assertions. Both JUnit and GoogleTest have multiple assertion types; the most common is equality: assertEquals(expected, actual) / EXPECT_EQ(expected, actual) . When comparing numbers, a third parameter - delta , the acceptable error, can be given. In JUnit (Java), these assertions are static methods and can be used without qualification by adding the static star import import static org.junit.jupiter.api.Assertions.* . In Google Test (C++), assertions are macros from the <gtest/gtest.h> header. Note Comparison of floating-point values isn’t accurate, so comparing them should be done with an acceptable error parameter ( DELTA ). Java import static org.junit.jupiter.api.Assertions.assertEquals ; import edu.wpi.first.hal.HAL ; import edu.wpi.first.wpilibj.DoubleSolenoid ; import edu.wpi.first.wpilibj.PneumaticsModuleType ; import edu.wpi.first.wpilibj.examples.unittest.Constants.IntakeConstants ; import edu.wpi.first.wpilibj.simulation.DoubleSolenoidSim ; import edu.wpi.first.wpilibj.simulation.PWMSim ; import org.junit.jupiter.api.AfterEach ; import org.junit.jupiter.api.BeforeEach ; import org.junit.jupiter.api.Test ; class IntakeTest { static final double DELTA = 1e-2 ; // acceptable deviation range Intake m_intake ; PWMSim m_simMotor ; DoubleSolenoidSim m_simPiston ; @BeforeEach // this method will run before each test void setup () { assert HAL . initialize ( 500 , 0 ); // initialize the HAL, crash if failed m_intake = new Intake (); // create our intake m_simMotor = new PWMSim ( IntakeConstants . kMotorPort ); // create our simulation PWM motor controller m_simPiston = new DoubleSolenoidSim ( PneumaticsModuleType . CTREPCM , IntakeConstants . kPistonFwdChannel , IntakeConstants . kPistonRevChannel ); // create our simulation solenoid } @SuppressWarnings ( \"PMD.SignatureDeclareThrowsException\" ) @AfterEach // this method will run after each test void shutdown () throws Exception { m_intake . close (); // destroy our intake object } @Test // marks this method as a test void doesntWorkWhenClosed () { m_intake . retract (); // close the intake m_intake . activate ( 0.5 ); // try to activate the motor assertEquals ( 0.0 , m_simMotor . getSpeed (), DELTA ); // make sure that the value set to the motor is 0 } @Test void worksWhenOpen () { m_intake . deploy (); m_intake . activate ( 0.5 ); assertEquals ( 0.5 , m_simMotor . getSpeed (), DELTA ); } @Test void retractTest () { m_intake . retract (); assertEquals ( DoubleSolenoid . Value . kReverse , m_simPiston . get ()); } @Test void deployTest () { m_intake . deploy (); assertEquals ( DoubleSolenoid . Value . kForward , m_simPiston . get ()); } } C++ #include <frc/DoubleSolenoid.h> #include <frc/simulation/DoubleSolenoidSim.h> #include <frc/simulation/PWMSim.h> #include <gtest/gtest.h> #include \"Constants.h\" #include \"subsystems/Intake.h\" class IntakeTest : public testing :: Test { protected : Intake intake ; // create our intake frc :: sim :: PWMSim simMotor { IntakeConstants :: kMotorPort }; // create our simulation PWM frc :: sim :: DoubleSolenoidSim simPiston { frc :: PneumaticsModuleType :: CTREPCM , IntakeConstants :: kPistonFwdChannel , IntakeConstants :: kPistonRevChannel }; // create our simulation solenoid }; TEST_F ( IntakeTest , DoesntWorkWhenClosed ) { intake . Retract (); // close the intake intake . Activate ( 0.5 ); // try to activate the motor EXPECT_DOUBLE_EQ ( 0.0 , simMotor . GetSpeed ()); // make sure that the value set to the motor is 0 } TEST_F ( IntakeTest , WorksWhenOpen ) { intake . Deploy (); intake . Activate ( 0.5 ); EXPECT_DOUBLE_EQ ( 0.5 , simMotor . GetSpeed ()); } TEST_F ( IntakeTest , Retract ) { intake . Retract (); EXPECT_EQ ( frc :: DoubleSolenoid :: Value :: kReverse , simPiston . Get ()); } TEST_F ( IntakeTest , Deploy ) { intake . Deploy (); EXPECT_EQ ( frc :: DoubleSolenoid :: Value :: kForward , simPiston . Get ()); } For more advanced usage of JUnit and Google Test, see the framework docs. Running Tests Note Tests will always be run in simulation on your desktop. For prerequisites and more info, see the simulation introduction . For Java tests to run, make sure that your build.gradle file contains the following block: 77 test { 78 useJUnitPlatform () 79 systemProperty 'junit.jupiter.extensions.autodetection.enabled' , 'true' 80 } Use Test Robot Code from the Command Palette to run the tests. Results will be reported in the terminal output, each test will have a FAILED or PASSED / OK label next to the test name in the output. JUnit (Java only) will generate a HTML document in build/reports/tests/test/index.html with a more detailed overview of the results; if there are any failed tests a link to render the document in your browser will be printed in the terminal output. By default, Gradle runs the tests whenever robot code is built, including deploys. This will increase deploy time, and failing tests will cause the build and deploy to fail. To prevent this from happening, you can use Change Skip Tests On Deploy Setting from the Command Palette to configure whether to run tests when deploying.",
      "content_preview": "Unit Testing Unit testing is a method of testing code by dividing the code into the smallest “units” possible and testing each unit. In robot code, this can mean testing the code for each subsystem individually. There are many unit testing frameworks for most languages."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/examples-tutorials/wpilib-examples.html?present",
      "title": "WPILib Example Projects",
      "section": "General",
      "language": "All",
      "content": "WPILib Example Projects Warning While every attempt is made to keep WPILib examples functional, they are not intended to be used “as-is.” At the very least, robot-specific constants will need to be changed for the code to work on a user robot. Many empirical constants have their values “faked” for demonstration purposes. Users are strongly encouraged to write their own code (from scratch or from an existing template) rather than copy example code. WPILib example projects demonstrate a large number of library features and use patterns. Projects range from simple demonstrations of a single functionality to complete, competition-capable robot programs. All of these examples are available in VS Code by entering Ctrl + Shift + P , then selecting WPILib: Create a new project and choosing example. Basic Examples These examples demonstrate basic/minimal robot functionality. They are useful for beginning teams who are gaining initial familiarity with robot programming, but are highly limited in functionality. Arcade Drive ( Java , C++ , Python ): Demonstrates a simple differential drive implementation using “arcade”-style controls through the DifferentialDrive class. Arcade Drive Xbox Controller ( Java , C++ , Python ): Demonstrates the same functionality seen in the previous example, except using an XboxController instead of an ordinary joystick. Getting Started ( Java , C++ , Python ): Demonstrates a simple autonomous routine that drives forwards for two seconds at half speed. Mecanum Drive ( Java , C++ , Python ): Demonstrates a simple mecanum drive implementation using the MecanumDrive class. Motor Controller ( Java , C++ , Python ): Demonstrates how to control the output of a motor with a joystick with an encoder to read motor position. Simple Vision ( Java , C++ , Python ): Demonstrates how to stream video from a USB camera to the dashboard. Relay ( Java , C++ , Python ): Demonstrates the use of the Relay class to control a relay output with a set of joystick buttons. Solenoids ( Java , C++ , Python ): Demonstrates the use of the Solenoid and DoubleSolenoid classes to control solenoid outputs with a set of joystick buttons. TankDrive ( Java , C++ , Python ): Demonstrates a simple differential drive implementation using “tank”-style controls through the DifferentialDrive class. Tank Drive Xbox Controller ( Java , C++ , Python ): Demonstrates the same functionality seen in the previous example, except using an XboxController instead of an ordinary joystick. Control Examples These examples demonstrate WPILib implementations of common robot controls. Sensors may be present, but are not the emphasized concept of these examples. DifferentialDriveBot ( Java , C++ , Python ): Demonstrates an advanced differential drive implementation, including encoder-and-gyro odometry through the DifferentialDriveOdometry class, and composition with PID velocity control through the DifferentialDriveKinematics and PIDController classes. DifferentialDrivePoseEstimator ( Java , C++ ): Demonstrates an advanced differential drive implementation with all the features of DifferentialDriveBot . In addition this example uses DifferentialDrivePoseEstimator to track the robots position on the field. It demonstrates these features by using WPILib Simulation. Elevator with Profiled PID Controller ( Java , C++ , Python ): Demonstrates the use of the ProfiledPIDController class to control the position of an elevator mechanism. Elevator with Trapezoid Profiled PID ( Java , C++ , Python ): Demonstrates the use of the TrapezoidProfile class in conjunction with a “smart motor controller” to control the position of an elevator mechanism. Elevator with Exponential Profiled PID ( Java , C++ ): Demonstrates the use of the ExponentialProfile class in conjunction with a “smart motor controller” to control the position of an elevator mechanism. Flywheel Bang-Bang Controller ( Java , C++ , Python ): Uses the BangBangController class to simply yet effectively control a flywheel. Gyro Mecanum ( Java , C++ , Python ): Demonstrates field-oriented control of a mecanum robot through the MecanumDrive class in conjunction with a gyro. MecanumBot ( Java , C++ , Python ): Demonstrates an advanced mecanum drive implementation, including encoder-and-gyro odometry through the MecanumDriveOdometry class, and composition with PID velocity control through the MecanumDriveKinematics and PIDController classes. Mecanum Drive PoseEstimator ( Java , C++ ): Demonstrates an advanced mecanum drive implementation with all the features of MecanumBot . In addition this example uses MecanumDrivePoseEstimator to track the robots position on the field. PotentiometerPID ( Java , C++ , Python ): Demonstrates the use of the PIDController class and a potentiometer to control the position of an elevator mechanism. SwerveBot ( Java , C++ , Python ): Demonstrates an advanced swerve drive implementation, including encoder-and-gyro odometry through the SwerveDriveOdometry class, and composition with PID position and velocity control through the SwerveDriveKinematics and PIDController classes. Swerve Drive PoseEstimator ( Java , C++ ): Demonstrates an advanced swerve drive implementation with all the features of SwerveBot . In addition this example uses SwerveDrivePoseEstimator to track the robots position on the field. UltrasonicPID ( Java , C++ , Python ): Demonstrates the use of the PIDController class in conjunction with an ultrasonic sensor to drive to a set distance from an object. Sensor Examples These examples demonstrate sensor reading and data processing using WPILib. Mechanisms control may be present, but is not the emphasized concept of these examples. HTTP Camera ( Java , C++ ): Demonstrates the use of OpenCV and a HTTP Camera to overlay a rectangle on a captured video feed and stream it to the dashboard. Power Distribution CAN Monitoring ( Java , C++ , Python ): Demonstrates obtaining sensor information from a Power Distribution module over CAN using the PowerDistribution class. Duty Cycle Encoder ( Java , C++ , Python ): Demonstrates the use of the DutyCycleEncoder class to read values from a PWM-type absolute encoder. DutyCycleInput ( Java , C++ , Python ): Demonstrates the use of the DutyCycleInput class to read the frequency and fractional duty cycle of a PWM input. Encoder ( Java , C++ , Python ): Demonstrates the use of the Encoder class to read values from a quadrature encoder. Gyro ( Java , C++ , Python ): Demonstrates the use of the AnalogGyro class to measure robot heading and stabilize driving. Intermediate Vision ( Java , C++ , Python ): Demonstrates the use of OpenCV and a USB camera to overlay a rectangle on a captured video feed and stream it to the dashboard. AprilTagsVision ( Java , C++ , Python ): Demonstrates on-roboRIO detection of AprilTags using an attached USB camera. Ultrasonic ( Java , C++ , Python ): Demonstrates the use of the Ultrasonic class to read data from an ultrasonic sensor in conjunction with the MedianFilter class to reduce signal noise. SysIdRoutine ( Java , C++ , Python ): Demonstrates the use of the SysIdRoutine API to gather characterization data for a differential drivetrain. Command-Based Examples These examples demonstrate the use of the Command-Based framework . DriveDistanceOffboard ( Java , C++ , Python ): Demonstrates the use of a TrapezoidProfileCommand in conjunction with a “smart motor controller” to drive forward by a set distance with a trapezoidal motion profile. Rapid React Command Bot ( Java , C++ ): This project uses the latest command based best practices and the Epilogue logging system. It is capable of playing the FRC 2022 game Rapid React. Inlined Hatchbot ( Java , C++ , Python ): A complete set of robot code for a simple hatch-delivery bot typical of the 2019 FRC game Destination: Deep Space . Commands are written in an “inline” style, in which explicit subclassing of Command is avoided. Traditional Hatchbot ( Java , C++ , Python ): A complete set of robot code for a simple hatch-delivery bot typical of the 2019 FRC game Destination: Deep Space . Commands are written in a “traditional” style, in which subclasses of Command are written for each robot action. MecanumControllerCommand ( Java , C++ ): Demonstrates trajectory generation and following with a mecanum drive using the TrajectoryGenerator and MecanumControllerCommand classes. Select Command Example ( Java , C++ , Python ): Demonstrates the use of the SelectCommand class to run one of a selection of commands depending on a runtime-evaluated condition. SwerveControllerCommand ( Java , C++ ): Demonstrates trajectory generation and following with a swerve drive using the TrajectoryGenerator and SwerveControllerCommand classes. State-Space Examples These examples demonstrate the use of the State-Space Control . StateSpaceFlywheel ( Java , C++ , Python ): Demonstrates state-space control of a flywheel. StateSpaceFlywheelSysId ( Java , C++ , Python ): Demonstrates state-space control using SysId’s System Identification for controlling a flywheel. StateSpaceElevator ( Java , C++ , Python ): Demonstrates state-space control of an elevator. StateSpaceArm ( Java , C++ , Python ): Demonstrates state-space control of an Arm. Simulation Physics Examples These examples demonstrate the use of the physics simulation. ElevatorSimulation ( Java , C++ , Python ): Demonstrates the use of physics simulation with a simple elevator. ElevatorSimulation with Exponential PID ( Java , C++ ): Demonstrates the use of physics simulation of an elevator being controlled with exponential profiled PID. ArmSimulation ( Java , C++ , Python ): Demonstrates the use of physics simulation with a simple single-jointed arm. SimpleDifferentialDriveSimulation ( Java , C++ ): A barebones example of a basic drivetrain that can be used in simulation. Miscellaneous Examples These examples demonstrate miscellaneous WPILib functionality that does not fit into any of the above categories. Addressable LED ( Java , C++ , Python ): Demonstrates the use of the AddressableLED class to control RGB LEDs for robot decoration and/or driver feedback. Digital Communication ( Java , C++ , Python ): This is a sample program demonstrating how to communicate to a light controller from the robot code using the roboRIO’s DIO ports. I2C Communication ( Java , C++ , Python ): This is a sample program demonstrating how to communicate to a light controller from the robot code using the roboRIO’s I2C port. DMA ( Java , C++ ): Demonstrates the use of DMA (Direct Memory Access) to read from sensors without using the RoboRIO’s CPU. HAL ( C++ ): Demonstrates the use of HAL (Hardware Abstraction Layer) without the use of the rest of WPILib. This example is for advanced users (C++ only). HID Rumble ( Java , C++ , Python ): Demonstrates the use of the “rumble” functionality for tactile feedback on supported HIDs (such as XboxControllers). Shuffleboard ( Java , C++ , Python ): Demonstrates configuring tab/widget layouts on the “Shuffleboard” dashboard from robot code through the Shuffleboard class’s fluent builder API. RomiReference ( Java , C++ , Python ): A command based example of how to run the Romi robot . XRPReference ( Java , C++ ): A command based example of how to run the XRP robot . Mechanism2d ( Java , C++ , Python ): A simple example of using Mechanism2d . EventLoop ( Java , C++ ): Demonstrates the use of the EventLoop class that allows code to be called based on a boolean condition in the event-driven programming style. UnitTest ( Java , C++ ): Shows how to do Unit Testing . The test files need to be in a separate Test directory ( Java , C++ ).",
      "content_preview": "WPILib Example Projects Warning While every attempt is made to keep WPILib examples functional, they are not intended to be used “as-is.” At the very least, robot-specific constants will need to be changed for the code to work on a user robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/dashboards/glass/mech2d-widget.html",
      "title": "The Mechanism2d Widget",
      "section": "General",
      "language": "All",
      "content": "The Mechanism2d Widget Glass supports displaying stick-figure representations of your robot’s mechanisms using the Mechanism2d widget. It supports combinations of ligaments that can rotate and / or extend or retract, such as arms and elevators and they can be combined for more complicated mechanisms. An instance of the Mechanism2d class should be created and populated, sent over NetworkTables, and updated periodically with the latest mechanism states in your robot code. It can also be used with the Physics Simulation to visualize and program your robot’s mechanisms before the robot is built. Creating and Configuring the Mechanism2d Instance The Mechanism2d object is the “canvas” where the mechanism is drawn. The root node is where the mechanism is anchored to Mechanism2d . For a single jointed arm this would the pivot point. For an elevator, this would be where it’s attached to the robot’s base. To get a root node (represented by a MechanismRoot2d object), call getRoot(name, x, y) on the container Mechanism2d object. The name is used to name the root within NetworkTables, and should be unique, but otherwise isn’t important. The x / y coordinate system follows the same orientation as Field2d - (0,0) is bottom left. In the examples below, an elevator is drawn, with a rotational wrist on top of the elevator. The full Mechanism2d example is available in Java / C++ JAVA 43 // the main mechanism object 44 Mechanism2d mech = new Mechanism2d ( 3 , 3 ); 45 // the mechanism root node 46 MechanismRoot2d root = mech . getRoot ( \"climber\" , 2 , 0 ); C++ 59 // the main mechanism object 60 frc :: Mechanism2d m_mech { 3 , 3 }; 61 // the mechanism root node 62 frc :: MechanismRoot2d * m_root = m_mech . GetRoot ( \"climber\" , 2 , 0 ); PYTHON 32 # the main mechanism object 33 self . mech = wpilib . Mechanism2d ( 3 , 3 ) 34 # the mechanism root node 35 self . root = self . mech . getRoot ( \"climber\" , 2 , 0 ) Each MechanismLigament2d object represents a stage of the mechanism. It has a three required parameters, a name, an initial length to draw (relative to the size of the Mechanism2d object), and an initial angle to draw the ligament in degrees. Ligament angles are relative to the parent ligament, and follow math notation - the same as Rotation2d (counterclockwise-positive). A ligament based on the root with an angle of zero will point right. Two optional parameters let you change the width (also relative to the size of the Mechanism2d object) and the color. Call append() / Append() on a root node or ligament node to add another node to the figure. In Java, pass a constructed MechanismLigament2d object to add it. In C++, pass the construction parameters in order to construct and add a ligament. JAVA 48 // MechanismLigament2d objects represent each \"section\"/\"stage\" of the mechanism, and are based 49 // off the root node or another ligament object 50 m_elevator = root . append ( new MechanismLigament2d ( \"elevator\" , kElevatorMinimumLength , 90 )); 51 m_wrist = 52 m_elevator . append ( 53 new MechanismLigament2d ( \"wrist\" , 0.5 , 90 , 6 , new Color8Bit ( Color . kPurple ))); C++ 63 // MechanismLigament2d objects represent each \"section\"/\"stage\" of the 64 // mechanism, and are based off the root node or another ligament object 65 frc :: MechanismLigament2d * m_elevator = 66 m_root -> Append < frc :: MechanismLigament2d > ( \"elevator\" , 1 , 90 _deg ); 67 frc :: MechanismLigament2d * m_wrist = 68 m_elevator -> Append < frc :: MechanismLigament2d > ( 69 \"wrist\" , 0.5 , 90 _deg , 6 , frc :: Color8Bit { frc :: Color :: kPurple }); PYTHON 37 # MechanismLigament2d objects represent each \"section\"/\"stage\" of the mechanism, and are based 38 # off the root node or another ligament object 39 self . elevator = self . root . appendLigament ( 40 \"elevator\" , self . kElevatorMinimumLength , 90 41 ) 42 self . wrist = self . elevator . appendLigament ( 43 \"wrist\" , 0.5 , 90 , 6 , wpilib . Color8Bit ( wpilib . Color . kPurple ) 44 ) Then, publish the Mechanism2d object to NetworkTables: JAVA 55 // post the mechanism to the dashboard 56 SmartDashboard . putData ( \"Mech2d\" , mech ); C++ 36 // publish to dashboard 37 frc :: SmartDashboard :: PutData ( \"Mech2d\" , & m_mech ); PYTHON 46 # post the mechanism to the dashboard 47 wpilib . SmartDashboard . putData ( \"Mech2d\" , self . mech ) Note The Mechanism2d instance can also be sent using a lower-level NetworkTables API or using the Shuffleboard API . In this case, the SmartDashboard API was used, meaning that the Mechanism2d widget will appear under the SmartDashboard table name. To manipulate a ligament angle or length, call setLength() or setAngle() on the MechanismLigament2d object. When manipulating ligament length based off of sensor measurements, make sure to add the minimum length to prevent 0-length (and therefore invisible) ligaments. JAVA 59 @Override 60 public void robotPeriodic () { 61 // update the dashboard mechanism's state 62 m_elevator . setLength ( kElevatorMinimumLength + m_elevatorEncoder . getDistance ()); 63 m_wrist . setAngle ( m_wristPot . get ()); 64 } C++ 40 void RobotPeriodic () override { 41 // update the dashboard mechanism's state 42 m_elevator -> SetLength ( kElevatorMinimumLength + 43 m_elevatorEncoder . GetDistance ()); 44 m_wrist -> SetAngle ( units :: degree_t { m_wristPotentiometer . Get ()}); 45 } PYTHON 49 def robotPeriodic ( self ): 50 # update the dashboard mechanism's state 51 self . elevator . setLength ( 52 self . kElevatorMinimumLength + self . elevatorEncoder . getDistance () 53 ) 54 self . wrist . setAngle ( self . wristPot . get ()) Viewing the Mechanism2d in Glass After sending the Mechanism2d instance over NetworkTables, the Mechanism2d widget can be added to Glass by selecting NetworkTables in the menu bar, choosing the table name that the instance was sent over, and then clicking on the Field button. Once the widget appears as shown below, you can resize and place it on the Glass workspace as you desire. Right-clicking the top of the widget will allow you to customize the name of the widget. As the wrist potentiometer and elevator encoder changes, the mechanism will update in the widget. Viewing the Mechanism2d in AdvantageScope AdvantageScope is an alternative option for viewing a Mechanism2d object, including data recorded to a log file using WPILib data logs . Both 2D and 3D visualizations are supported. See the documentation for the mechanism and 3D field tabs for more details. Next Steps As mentioned above, the Mechanism2d visualization can be combined with Physics Simulation to help you program mechanisms before your robot is built. The ArmSimulation ( Java / C++ / Python ) and ElevatorSimulation ( Java / C++ / Python ) examples combine physics simulation and Mechanism2d visualization so that you can practice programming a single jointed arm and elevator without a robot.",
      "content_preview": "The Mechanism2d Widget Glass supports displaying stick-figure representations of your robot’s mechanisms using the Mechanism2d widget. It supports combinations of ligaments that can rotate and / or extend or retract, such as arms and elevators and they can be combined for more complicated..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/what-is-command-based.html",
      "title": "What Is “Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "What Is “Command-Based” Programming? WPILib supports a robot programming methodology called “command-based” programming. In general, “command-based” can refer both the general programming paradigm, and to the set of WPILib library resources included to facilitate it. “Command-based” programming is one possible design pattern for robot software. It is not the only way to write a robot program, but it is a very effective one. Command-based robot code tends to be clean, extensible, and (with some tricks) easy to reuse from year to year. The command-based paradigm is also an example of declarative programming . The command-based library allow users to define desired robot behaviors while minimizing the amount of iteration-by-iteration robot logic that they must write. For example, in the command-based program, a user can specify that “the robot should perform an action when a condition is true” (note the use of a lambda ): JAVA new Trigger ( condition :: get ). onTrue ( Commands . runOnce (() -> piston . set ( DoubleSolenoid . Value . kForward ))); C++ Trigger ([ & condition ] { return condition . Get (); }). OnTrue ( frc2 :: cmd :: RunOnce ([ & piston ] { piston . Set ( frc :: DoubleSolenoid :: kForward ); })); PYTHON Trigger ( condition . get ) . onTrue ( Commands . runOnce ( lambda : piston . set ( DoubleSolenoid . Value . kForward ))) In contrast, without using command-based, the user would need to check the button state every iteration, and perform the appropriate action based on the state of the button. JAVA if ( condition . get ()) { if ( ! pressed ) { piston . set ( DoubleSolenoid . Value . kForward ); pressed = true ; } } else { pressed = false ; } C++ if ( condition . Get ()) { if ( ! pressed ) { piston . Set ( frc :: DoubleSolenoid :: kForward ); pressed = true ; } } else { pressed = false ; } PYTHON if condition . get (): if not pressed : piston . set ( DoubleSolenoid . Value . kForward ) pressed = True else : pressed = False Subsystems and Commands The command-based pattern is based around two core abstractions: commands , and subsystems. Commands represent actions the robot can take. Commands run when scheduled, until they are interrupted or their end condition is met. Commands are very recursively composable: commands can be composed to accomplish more-complicated tasks. See Commands for more info. Subsystems represent independently-controlled collections of robot hardware (such as motor controllers, sensors, pneumatic actuators, etc.) that operate together. Subsystems back the resource-management system of command-based: only one command can use a given subsystem at the same time. Subsystems allow users to “hide” the internal complexity of their actual hardware from the rest of their code - this both simplifies the rest of the robot code, and allows changes to the internal details of a subsystem’s hardware without also changing the rest of the robot code. How Commands Are Run Note For a more detailed explanation, see The Command Scheduler . Commands are run by the CommandScheduler ( Java , C++ , Python ) singleton, which polls triggers (such as buttons) for commands to schedule, preventing resource conflicts, and executing scheduled commands. The scheduler’s run() method must be called; it is generally recommended to call it from the robotPeriodic() method of the Robot class, which is run at a default frequency of 50Hz (once every 20ms). Multiple commands can run concurrently, as long as they do not require the same resources on the robot. Resource management is handled on a per-subsystem basis: commands specify which subsystems they interact with, and the scheduler will ensure that no more more than one command requiring a given subsystem is scheduled at a time. This ensures that, for example, users will not end up with two different pieces of code attempting to set the same motor controller to different output values. Command Compositions It is often desirable to build complex commands from simple pieces. This is achievable by creating a composition of commands. The command-based library provides several types of command compositions for teams to use, and users may write their own. As command compositions are commands themselves, they may be used in a recursive composition . That is to say - one can create a command compositions from multiple command compositions. This provides an extremely powerful way of building complex robot actions from simple components.",
      "content_preview": "What Is “Command-Based” Programming? WPILib supports a robot programming methodology called “command-based” programming. In general, “command-based” can refer both the general programming paradigm, and to the set of WPILib library resources included to facilitate it."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/pid-subsystems-commands.html",
      "title": "PID Control in Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "PID Control in Command-based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . One of the most common control algorithms used in FRC® is the PID controller. WPILib offers its own PIDController class to help teams implement this functionality on their robots. The following example is from the RapidReactCommandBot example project ( Java , C++ ) and shows how PIDControllers can be used within the command-based framework: Java 5 package edu.wpi.first.wpilibj.examples.rapidreactcommandbot.subsystems ; 6 7 import static edu.wpi.first.wpilibj2.command.Commands.parallel ; 8 import static edu.wpi.first.wpilibj2.command.Commands.waitUntil ; 9 10 import edu.wpi.first.epilogue.Logged ; 11 import edu.wpi.first.math.controller.PIDController ; 12 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 13 import edu.wpi.first.wpilibj.Encoder ; 14 import edu.wpi.first.wpilibj.examples.rapidreactcommandbot.Constants.ShooterConstants ; 15 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 16 import edu.wpi.first.wpilibj2.command.Command ; 17 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 18 19 @Logged 20 public class Shooter extends SubsystemBase { 21 private final PWMSparkMax m_shooterMotor = new PWMSparkMax ( ShooterConstants . kShooterMotorPort ); 22 private final PWMSparkMax m_feederMotor = new PWMSparkMax ( ShooterConstants . kFeederMotorPort ); 23 private final Encoder m_shooterEncoder = 24 new Encoder ( 25 ShooterConstants . kEncoderPorts [ 0 ] , 26 ShooterConstants . kEncoderPorts [ 1 ] , 27 ShooterConstants . kEncoderReversed ); 28 private final SimpleMotorFeedforward m_shooterFeedforward = 29 new SimpleMotorFeedforward ( 30 ShooterConstants . kSVolts , ShooterConstants . kVVoltSecondsPerRotation ); 31 private final PIDController m_shooterFeedback = new PIDController ( ShooterConstants . kP , 0.0 , 0.0 ); 32 33 /** The shooter subsystem for the robot. */ 34 public Shooter () { 35 m_shooterFeedback . setTolerance ( ShooterConstants . kShooterToleranceRPS ); 36 m_shooterEncoder . setDistancePerPulse ( ShooterConstants . kEncoderDistancePerPulse ); 37 38 // Set default command to turn off both the shooter and feeder motors, and then idle 39 setDefaultCommand ( 40 runOnce ( 41 () -> { 42 m_shooterMotor . disable (); 43 m_feederMotor . disable (); 44 }) 45 . andThen ( run (() -> {})) 46 . withName ( \"Idle\" )); 47 } 48 49 /** 50 * Returns a command to shoot the balls currently stored in the robot. Spins the shooter flywheel 51 * up to the specified setpoint, and then runs the feeder motor. 52 * 53 * @param setpointRotationsPerSecond The desired shooter velocity 54 */ 55 public Command shootCommand ( double setpointRotationsPerSecond ) { 56 return parallel ( 57 // Run the shooter flywheel at the desired setpoint using feedforward and feedback 58 run ( 59 () -> { 60 m_shooterMotor . set ( 61 m_shooterFeedforward . calculate ( setpointRotationsPerSecond ) 62 + m_shooterFeedback . calculate ( 63 m_shooterEncoder . getRate (), setpointRotationsPerSecond )); 64 }), 65 66 // Wait until the shooter has reached the setpoint, and then run the feeder 67 waitUntil ( m_shooterFeedback :: atSetpoint ). andThen (() -> m_feederMotor . set ( 1 ))) 68 . withName ( \"Shoot\" ); 69 } 70 } C++ 5 #pragma once 6 7 #include <functional> 8 9 #include <frc/Encoder.h> 10 #include <frc/controller/PIDController.h> 11 #include <frc/controller/SimpleMotorFeedforward.h> 12 #include <frc/motorcontrol/PWMSparkMax.h> 13 #include <frc2/command/CommandPtr.h> 14 #include <frc2/command/SubsystemBase.h> 15 #include <units/angle.h> 16 #include <units/angular_velocity.h> 17 18 #include \"Constants.h\" 19 20 class Shooter : public frc2 :: SubsystemBase { 21 public : 22 Shooter (); 23 24 /** 25 * Returns a command to shoot the balls currently stored in the robot. Spins 26 * the shooter flywheel up to the specified setpoint, and then runs the feeder 27 * motor. 28 * 29 * @param setpointRotationsPerSecond The desired shooter velocity 30 */ 31 [[ nodiscard ]] 32 frc2 :: CommandPtr ShootCommand ( units :: turns_per_second_t setpoint ); 33 34 private : 35 frc :: PWMSparkMax m_shooterMotor { ShooterConstants :: kShooterMotorPort }; 36 frc :: PWMSparkMax m_feederMotor { ShooterConstants :: kFeederMotorPort }; 37 38 frc :: Encoder m_shooterEncoder { ShooterConstants :: kEncoderPorts [ 0 ], 39 ShooterConstants :: kEncoderPorts [ 1 ], 40 ShooterConstants :: kEncoderReversed }; 41 frc :: SimpleMotorFeedforward < units :: radians > m_shooterFeedforward { 42 ShooterConstants :: kS , ShooterConstants :: kV }; 43 frc :: PIDController m_shooterFeedback { ShooterConstants :: kP , 0.0 , 0.0 }; 44 }; C++ (Source) 5 #include \"subsystems/Shooter.h\" 6 7 #include <frc2/command/Commands.h> 8 9 Shooter :: Shooter () { 10 m_shooterFeedback . SetTolerance ( ShooterConstants :: kShooterTolerance . value ()); 11 m_shooterEncoder . SetDistancePerPulse ( 12 ShooterConstants :: kEncoderDistancePerPulse ); 13 14 SetDefaultCommand ( RunOnce ([ this ] { 15 m_shooterMotor . Disable (); 16 m_feederMotor . Disable (); 17 }) 18 . AndThen ( Run ([] {})) 19 . WithName ( \"Idle\" )); 20 } 21 22 frc2 :: CommandPtr Shooter :: ShootCommand ( units :: turns_per_second_t setpoint ) { 23 return frc2 :: cmd :: Parallel ( 24 // Run the shooter flywheel at the desired setpoint using 25 // feedforward and feedback 26 Run ([ this , setpoint ] { 27 m_shooterMotor . SetVoltage ( 28 m_shooterFeedforward . Calculate ( setpoint ) + 29 units :: volt_t ( m_shooterFeedback . Calculate ( 30 m_shooterEncoder . GetRate (), setpoint . value ()))); 31 }), 32 // Wait until the shooter has reached the setpoint, and then 33 // run the feeder 34 frc2 :: cmd :: WaitUntil ([ this ] { 35 return m_shooterFeedback . AtSetpoint (); 36 }). AndThen ([ this ] { m_feederMotor . Set ( 1.0 ); })) 37 . WithName ( \"Shoot\" ); 38 } A PIDController is declared inside the Shooter subsystem. It is used by ShootCommand alongside a feedforward to spin the shooter flywheel to the specified velocity. Once the PIDController reaches the specified velocity, the ShootCommand runs the feeder.",
      "content_preview": "PID Control in Command-based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . One of the most common control algorithms used in FRC® is the PID controller."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/pid-subsystems-commands.html?present",
      "title": "PID Control in Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "PID Control in Command-based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . One of the most common control algorithms used in FRC® is the PID controller. WPILib offers its own PIDController class to help teams implement this functionality on their robots. The following example is from the RapidReactCommandBot example project ( Java , C++ ) and shows how PIDControllers can be used within the command-based framework: Java 5 package edu.wpi.first.wpilibj.examples.rapidreactcommandbot.subsystems ; 6 7 import static edu.wpi.first.wpilibj2.command.Commands.parallel ; 8 import static edu.wpi.first.wpilibj2.command.Commands.waitUntil ; 9 10 import edu.wpi.first.epilogue.Logged ; 11 import edu.wpi.first.math.controller.PIDController ; 12 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 13 import edu.wpi.first.wpilibj.Encoder ; 14 import edu.wpi.first.wpilibj.examples.rapidreactcommandbot.Constants.ShooterConstants ; 15 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 16 import edu.wpi.first.wpilibj2.command.Command ; 17 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 18 19 @Logged 20 public class Shooter extends SubsystemBase { 21 private final PWMSparkMax m_shooterMotor = new PWMSparkMax ( ShooterConstants . kShooterMotorPort ); 22 private final PWMSparkMax m_feederMotor = new PWMSparkMax ( ShooterConstants . kFeederMotorPort ); 23 private final Encoder m_shooterEncoder = 24 new Encoder ( 25 ShooterConstants . kEncoderPorts [ 0 ] , 26 ShooterConstants . kEncoderPorts [ 1 ] , 27 ShooterConstants . kEncoderReversed ); 28 private final SimpleMotorFeedforward m_shooterFeedforward = 29 new SimpleMotorFeedforward ( 30 ShooterConstants . kSVolts , ShooterConstants . kVVoltSecondsPerRotation ); 31 private final PIDController m_shooterFeedback = new PIDController ( ShooterConstants . kP , 0.0 , 0.0 ); 32 33 /** The shooter subsystem for the robot. */ 34 public Shooter () { 35 m_shooterFeedback . setTolerance ( ShooterConstants . kShooterToleranceRPS ); 36 m_shooterEncoder . setDistancePerPulse ( ShooterConstants . kEncoderDistancePerPulse ); 37 38 // Set default command to turn off both the shooter and feeder motors, and then idle 39 setDefaultCommand ( 40 runOnce ( 41 () -> { 42 m_shooterMotor . disable (); 43 m_feederMotor . disable (); 44 }) 45 . andThen ( run (() -> {})) 46 . withName ( \"Idle\" )); 47 } 48 49 /** 50 * Returns a command to shoot the balls currently stored in the robot. Spins the shooter flywheel 51 * up to the specified setpoint, and then runs the feeder motor. 52 * 53 * @param setpointRotationsPerSecond The desired shooter velocity 54 */ 55 public Command shootCommand ( double setpointRotationsPerSecond ) { 56 return parallel ( 57 // Run the shooter flywheel at the desired setpoint using feedforward and feedback 58 run ( 59 () -> { 60 m_shooterMotor . set ( 61 m_shooterFeedforward . calculate ( setpointRotationsPerSecond ) 62 + m_shooterFeedback . calculate ( 63 m_shooterEncoder . getRate (), setpointRotationsPerSecond )); 64 }), 65 66 // Wait until the shooter has reached the setpoint, and then run the feeder 67 waitUntil ( m_shooterFeedback :: atSetpoint ). andThen (() -> m_feederMotor . set ( 1 ))) 68 . withName ( \"Shoot\" ); 69 } 70 } C++ 5 #pragma once 6 7 #include <functional> 8 9 #include <frc/Encoder.h> 10 #include <frc/controller/PIDController.h> 11 #include <frc/controller/SimpleMotorFeedforward.h> 12 #include <frc/motorcontrol/PWMSparkMax.h> 13 #include <frc2/command/CommandPtr.h> 14 #include <frc2/command/SubsystemBase.h> 15 #include <units/angle.h> 16 #include <units/angular_velocity.h> 17 18 #include \"Constants.h\" 19 20 class Shooter : public frc2 :: SubsystemBase { 21 public : 22 Shooter (); 23 24 /** 25 * Returns a command to shoot the balls currently stored in the robot. Spins 26 * the shooter flywheel up to the specified setpoint, and then runs the feeder 27 * motor. 28 * 29 * @param setpointRotationsPerSecond The desired shooter velocity 30 */ 31 [[ nodiscard ]] 32 frc2 :: CommandPtr ShootCommand ( units :: turns_per_second_t setpoint ); 33 34 private : 35 frc :: PWMSparkMax m_shooterMotor { ShooterConstants :: kShooterMotorPort }; 36 frc :: PWMSparkMax m_feederMotor { ShooterConstants :: kFeederMotorPort }; 37 38 frc :: Encoder m_shooterEncoder { ShooterConstants :: kEncoderPorts [ 0 ], 39 ShooterConstants :: kEncoderPorts [ 1 ], 40 ShooterConstants :: kEncoderReversed }; 41 frc :: SimpleMotorFeedforward < units :: radians > m_shooterFeedforward { 42 ShooterConstants :: kS , ShooterConstants :: kV }; 43 frc :: PIDController m_shooterFeedback { ShooterConstants :: kP , 0.0 , 0.0 }; 44 }; C++ (Source) 5 #include \"subsystems/Shooter.h\" 6 7 #include <frc2/command/Commands.h> 8 9 Shooter :: Shooter () { 10 m_shooterFeedback . SetTolerance ( ShooterConstants :: kShooterTolerance . value ()); 11 m_shooterEncoder . SetDistancePerPulse ( 12 ShooterConstants :: kEncoderDistancePerPulse ); 13 14 SetDefaultCommand ( RunOnce ([ this ] { 15 m_shooterMotor . Disable (); 16 m_feederMotor . Disable (); 17 }) 18 . AndThen ( Run ([] {})) 19 . WithName ( \"Idle\" )); 20 } 21 22 frc2 :: CommandPtr Shooter :: ShootCommand ( units :: turns_per_second_t setpoint ) { 23 return frc2 :: cmd :: Parallel ( 24 // Run the shooter flywheel at the desired setpoint using 25 // feedforward and feedback 26 Run ([ this , setpoint ] { 27 m_shooterMotor . SetVoltage ( 28 m_shooterFeedforward . Calculate ( setpoint ) + 29 units :: volt_t ( m_shooterFeedback . Calculate ( 30 m_shooterEncoder . GetRate (), setpoint . value ()))); 31 }), 32 // Wait until the shooter has reached the setpoint, and then 33 // run the feeder 34 frc2 :: cmd :: WaitUntil ([ this ] { 35 return m_shooterFeedback . AtSetpoint (); 36 }). AndThen ([ this ] { m_feederMotor . Set ( 1.0 ); })) 37 . WithName ( \"Shoot\" ); 38 } A PIDController is declared inside the Shooter subsystem. It is used by ShootCommand alongside a feedforward to spin the shooter flywheel to the specified velocity. Once the PIDController reaches the specified velocity, the ShootCommand runs the feeder.",
      "content_preview": "PID Control in Command-based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . One of the most common control algorithms used in FRC® is the PID controller."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/functions-as-data.html",
      "title": "Treating Functions as Data",
      "section": "Basic Programming",
      "language": "Java",
      "content": "Treating Functions as Data Regardless of programming language, one of the first things anyone learns to do when programming a computer is to write a function (also known as a “method” or a “subroutine”). Functions are a fundamental part of organized code - writing functions lets us avoid duplicating the same piece of code over and over again. Instead of writing duplicated sections of code, we call a single function that contains the code we want to execute from multiple places (provided we named the function well, the function name is also easier to read than the code itself!). If the section of code needs some additional information about its surrounding context to run, we pass those to the function as “parameters”, and if it needs to yield something back to the rest of the code once it finishes, we call that a “return value” (together, the parameters and return value are called the function’s “signature”); Sometimes, we need to pass functions from one part of the code to another part of the code. This might seem like a strange concept, if we’re used to thinking of functions as part of a class definition rather than objects in their own right. But at a basic level, functions are just data - in the same way we can store an integer or a double as a variable and pass it around our program, we can do the same thing with a function. A variable whose value is a function is called a “functional interface” in Java, and a “function pointer” or “functor” in C++. Why Would We Want to Treat Functions as Data? Typically, code that calls a function is coupled to (depends on) the definition of the function. While this occurs all the time, it becomes problematic when the code calling the function (for example, WPILib) is developed independently and without direct knowledge of the code that defines the function (for example, code from an FRC team). Sometimes we solve this challenge through the use of class interfaces, which define collections of data and functions that are meant to be used together. However, often we really only have a dependency on a single function , rather than on an entire class . For example, WPILib offers several ways for users to execute certain code whenever a joystick button is pressed - one of the easiest and cleanest ways to do this is to allow the user to pass a function to one of the WPILib joystick methods. This way, the user only has to write the code that deals with the interesting and team-specific things (e.g., “move my robot arm”) and not the boring, error-prone, and universal thing (“properly read button inputs from a standard joystick”). For another example, the Command-based framework is built on Command objects that refer to methods defined on various Subsystem classes. Many of the included Command types (such as InstantCommand and RunCommand ) work with any function - not just functions associated with a single Subsystem . To support building commands generically, we need to support passing functions from a Subsystem (which interacts with the hardware) to a Command (which interacts with the scheduler). In these cases, we want to be able to pass a single function as a piece of data, as if it were a variable - it doesn’t make sense to ask the user to provide an entire class, when we really just want them to give us a single appropriately-shaped function. It’s important that passing a function is not the same as calling a function. When we call a function, we execute the code inside of it and either receive a return value, cause some side-effects elsewhere in the code, or both. When we pass a function, nothing in particular happens immediately. Instead, by passing the function we are allowing some other code to call the function in the future. Seeing the name of a function in code does not always mean that the code in the function is being run! Inside of code that passes a function, we will see some syntax that either refers to the name of an existing function in a special way, or else defines a new function to be passed inside of the call expression. The specific syntax needed (and the rules around it) depends on which programming language we are using. Treating Functions as Data in Java Java represents functions-as-data as instances of functional interfaces . A “functional interface” is a special kind of class that has only a single method - since Java was originally designed strictly for object-oriented programming, it has no way of representing a single function detached from a class. Instead, it defines a particular group of classes that only represent single functions. Each type of function signature has its own functional interface, which is an interface with a single function definition of that signature. This might sound complicated, but in the context of WPILib we don’t really need to worry much about using the functional interfaces themselves - the code that does that is internal to WPILib. Instead, all we need to know is how to pass a function that we’ve written to a method that takes a functional interface as a parameter. For a simple example, consider the signature of Commands.runOnce (which creates an InstantCommand that, when scheduled, runs the given function once and then terminates): Note The requirements parameter is explained in the Command-based documentation , and will not be discussed here. public static Command runOnce ( Runnable action , Subsystem ... requirements ) runOnce expects us to give it a Runnable parameter (named action ). A Runnable is the Java term for a function that takes no parameters and returns no value. When we call runOnce , we need to give it a function with no parameters and no return value. There are two ways to do this: we can refer to some existing function using a “method reference”, or we can define the function we want inline using a “lambda expression”. Method References A method reference lets us pass an already-existing function as our Runnable : // Create an InstantCommand that runs the `resetEncoders` method of the `drivetrain` object Command disableCommand = runOnce ( drivetrain :: resetEncoders , drivetrain ); The expression drivetrain::resetEncoders is a reference to the resetEncoders method of the drivetrain object. It is not a method call - this line of code does not itself reset the encoders of the drivetrain. Instead, it returns a Command that will do so when it is scheduled. Remember that in order for this to work, resetEncoders must be a Runnable - that is, it must take no parameters and return no value. So, its signature must look like this: // void because it returns no parameters, and has an empty parameter list public void resetEncoders () If the function signature does not match this, Java will not be able to interpret the method reference as a Runnable and the code will not compile. Note that all we need to do is make sure that the signature matches the signature of the single method in the Runnable functional interface - we don’t need to explicitly name it as a Runnable . Lambda Expressions in Java If we do not already have a named function that does what we want, we can define a function “inline” - that means, right inside of the call to runOnce ! We do this by writing our function with a special syntax that uses an “arrow” symbol to link the argument list to the function body: // Create an InstantCommand that runs the drive forward at half speed Command driveHalfSpeed = runOnce (() -> { drivetrain . arcadeDrive ( 0.5 , 0.0 ); }, drivetrain ); Java calls () -> { drivetrain.arcadeDrive(0.5, 0.0); } a “lambda expression”; it may be less-confusingly called an “arrow function”, “inline function”, or “anonymous function” (because it has no name). While this may look a bit funky, it is just another way of writing a function - the parentheses before the arrow are the function’s argument list, and the code contained in the brackets is the function body. The “lambda expression” here represents a function that calls drivetrain.arcadeDrive with a specific set of parameters - note again that this does not call the function, but merely defines it and passes it to the Command to be run later when the Command is scheduled. As with method references, we do not need to explicitly name the lambda expression as a Runnable - Java can infer that our lambda expression is a Runnable so long as its signature matches that of the single method in the Runnable interface. Accordingly, our lambda takes no arguments and has no return statement - if it did not match the Runnable contract, our code would fail to compile. Capturing State in Java Lambda Expressions In the above example, our function body references an object that lives outside of the function itself (namely, the drivetrain object). This is called a “capture” of a variable from the surrounding code (which is sometimes called the “outer scope” or “enclosing scope”). Usually the captured variables are either local variables from the enclosing method body in which the lambda expression is defined, or else fields of an enclosing class definition in which that method is defined. In Java capturing state is a fairly safe thing to do in general, with one major caveat: we can only capture state that is “effectively final”. That means it is only legal to capture a variable from the enclosing scope if that variable is never reassigned after initialization. Note that this does not mean that the captured state cannot change: Remember that Java objects are references, so the object that the reference points to may change after capture - but the reference itself cannot be made to point to another object. This means we can only capture primitive types (like int , double , and boolean ) if they’re constants. If we want to capture a state variable that can change, it must be wrapped in a mutable object . Syntactic Sugar for Java Lambda Expressions The full lambda expression syntax can be needlessly verbose in some cases. To help with this, Java lets us take some shortcuts (called “syntactic sugar”) in cases where some of the notation is redundant. Omitting Function Body Brackets for One-Line Lambdas If the function body of our lambda expression is only one line, Java lets us omit the brackets around the function body. When omitting function brackets, we also omit trailing semicolons And the return keyword. So, our Runnable lambda above could instead be written: // Create an InstantCommand that runs the drive forward at half speed Command driveHalfSpeed = runOnce (() -> drivetrain . arcadeDrive ( 0.5 , 0.0 ), drivetrain ); Omitting Parentheses around Single Lambda Parameters If the lambda expression is for a functional interface that takes only a single argument, we can omit the parenthesis around the parameter list: // We can write this lambda with no parenthesis around its single argument IntConsumer exampleLambda = ( a -> System . out . println ( a )); Treating Functions as Data in C++ C++ has a number of ways to treat functions as data. For the sake of this article, we’ll only talk about the parts that are relevant to using WPILibC. In WPILibC, function types are represented with the std::function class ( https://en.cppreference.com/w/cpp/utility/functional/function ). This standard library class is templated on the function’s signature - that means we have to provide it a function type as a template parameter to specify the signature of the function (compare this to Java above, where we have a separate interface type for each kind of signature). This sounds a lot more complicated than it is to use in practice. Let’s look at the call signature of cmd::RunOnce (which creates an InstantCommand that, when scheduled, runs the given function once and then terminates): Note The requirements parameter is explained in the Command-based documentation , and will not be discussed here. CommandPtr RunOnce ( std :: function < void () > action , Requirements requirements ); runOnce expects us to give it a std::function<void()> parameter (named action ). A std::function<void()> is the C++ type for a std::function that takes no parameters and returns no value (the template parameter, void() , is a function type with no parameters and no return value). When we call runOnce , we need to give it a function with no parameters and no return value. C++ lacks a clean way to refer to existing class methods in a way that can automatically be converted to a std::function , so the typical way to do this is to define a new function inline with a “lambda expression”. Lambda Expressions in C++ To pass a function to runOnce , we need to write a short inline function expression using a special syntax that resembles ordinary C++ function declarations, but varies in a few important ways: // Create an InstantCommand that runs the drive forward at half speed CommandPtr driveHalfSpeed = cmd :: RunOnce ([ this ] { drivetrain . ArcadeDrive ( 0.5 , 0.0 ); }, { drivetrain }); C++ calls [captures] (params) { body; } a “lambda expression”. It has three parts: a capture list (square brackets), an optional parameter list (parentheses), and a function body (curly brackets). It may look a little strange, but the only real difference between a lambda expression and an ordinary function (apart from the lack of a function name) is the addition of the capture list. Since RunOnce wants a function with no parameters and no return value, our lambda expression has no parameter list and no return statement. The “lambda expression” here represents a function that calls drivetrain.ArcadeDrive with a specific set of parameters - note again that the above code does not call the function, but merely defines it and passes it to the Command to be run later when the Command is scheduled. Capturing State in C++ Lambda Expressions In the above example, our function body references an object that lives outside of the function itself (namely, the drivetrain object). This is called a “capture” of a variable from the surrounding code (which is sometimes called the “outer scope” or “enclosing scope”). Usually the captured variables are either local variables from the enclosing method body in which the lambda expression is defined, or else fields of an enclosing class definition in which that method is defined. C++ has somewhat more-powerful semantics than Java. One cost of this is that we generally need to give the C++ compiler some help to figure out how exactly we want it to capture state from the enclosing scope. This is the purpose of the capture list . For the purposes of using the WPILibC Command-based framework, it is usually sufficient to use a capture list of [this] , which gives access to members of the enclosing class by capturing the enclosing class’s this pointer by value. Method locals cannot be captured with the this pointer, and must be captured explicitly either by reference or by value by including them in the capture list (or by implicitly by instead specifying a default capture semantics). It is typically safer to capture locals by-value, since a lambda can outlive the lifespan of an object it captures by reference. For more details, consult the C++ standard library documentation on capture semantics .",
      "content_preview": "Treating Functions as Data Regardless of programming language, one of the first things anyone learns to do when programming a computer is to write a function (also known as a “method” or a “subroutine”)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/functions-as-data.html?present",
      "title": "Treating Functions as Data",
      "section": "Basic Programming",
      "language": "Java",
      "content": "Treating Functions as Data Regardless of programming language, one of the first things anyone learns to do when programming a computer is to write a function (also known as a “method” or a “subroutine”). Functions are a fundamental part of organized code - writing functions lets us avoid duplicating the same piece of code over and over again. Instead of writing duplicated sections of code, we call a single function that contains the code we want to execute from multiple places (provided we named the function well, the function name is also easier to read than the code itself!). If the section of code needs some additional information about its surrounding context to run, we pass those to the function as “parameters”, and if it needs to yield something back to the rest of the code once it finishes, we call that a “return value” (together, the parameters and return value are called the function’s “signature”); Sometimes, we need to pass functions from one part of the code to another part of the code. This might seem like a strange concept, if we’re used to thinking of functions as part of a class definition rather than objects in their own right. But at a basic level, functions are just data - in the same way we can store an integer or a double as a variable and pass it around our program, we can do the same thing with a function. A variable whose value is a function is called a “functional interface” in Java, and a “function pointer” or “functor” in C++. Why Would We Want to Treat Functions as Data? Typically, code that calls a function is coupled to (depends on) the definition of the function. While this occurs all the time, it becomes problematic when the code calling the function (for example, WPILib) is developed independently and without direct knowledge of the code that defines the function (for example, code from an FRC team). Sometimes we solve this challenge through the use of class interfaces, which define collections of data and functions that are meant to be used together. However, often we really only have a dependency on a single function , rather than on an entire class . For example, WPILib offers several ways for users to execute certain code whenever a joystick button is pressed - one of the easiest and cleanest ways to do this is to allow the user to pass a function to one of the WPILib joystick methods. This way, the user only has to write the code that deals with the interesting and team-specific things (e.g., “move my robot arm”) and not the boring, error-prone, and universal thing (“properly read button inputs from a standard joystick”). For another example, the Command-based framework is built on Command objects that refer to methods defined on various Subsystem classes. Many of the included Command types (such as InstantCommand and RunCommand ) work with any function - not just functions associated with a single Subsystem . To support building commands generically, we need to support passing functions from a Subsystem (which interacts with the hardware) to a Command (which interacts with the scheduler). In these cases, we want to be able to pass a single function as a piece of data, as if it were a variable - it doesn’t make sense to ask the user to provide an entire class, when we really just want them to give us a single appropriately-shaped function. It’s important that passing a function is not the same as calling a function. When we call a function, we execute the code inside of it and either receive a return value, cause some side-effects elsewhere in the code, or both. When we pass a function, nothing in particular happens immediately. Instead, by passing the function we are allowing some other code to call the function in the future. Seeing the name of a function in code does not always mean that the code in the function is being run! Inside of code that passes a function, we will see some syntax that either refers to the name of an existing function in a special way, or else defines a new function to be passed inside of the call expression. The specific syntax needed (and the rules around it) depends on which programming language we are using. Treating Functions as Data in Java Java represents functions-as-data as instances of functional interfaces . A “functional interface” is a special kind of class that has only a single method - since Java was originally designed strictly for object-oriented programming, it has no way of representing a single function detached from a class. Instead, it defines a particular group of classes that only represent single functions. Each type of function signature has its own functional interface, which is an interface with a single function definition of that signature. This might sound complicated, but in the context of WPILib we don’t really need to worry much about using the functional interfaces themselves - the code that does that is internal to WPILib. Instead, all we need to know is how to pass a function that we’ve written to a method that takes a functional interface as a parameter. For a simple example, consider the signature of Commands.runOnce (which creates an InstantCommand that, when scheduled, runs the given function once and then terminates): Note The requirements parameter is explained in the Command-based documentation , and will not be discussed here. public static Command runOnce ( Runnable action , Subsystem ... requirements ) runOnce expects us to give it a Runnable parameter (named action ). A Runnable is the Java term for a function that takes no parameters and returns no value. When we call runOnce , we need to give it a function with no parameters and no return value. There are two ways to do this: we can refer to some existing function using a “method reference”, or we can define the function we want inline using a “lambda expression”. Method References A method reference lets us pass an already-existing function as our Runnable : // Create an InstantCommand that runs the `resetEncoders` method of the `drivetrain` object Command disableCommand = runOnce ( drivetrain :: resetEncoders , drivetrain ); The expression drivetrain::resetEncoders is a reference to the resetEncoders method of the drivetrain object. It is not a method call - this line of code does not itself reset the encoders of the drivetrain. Instead, it returns a Command that will do so when it is scheduled. Remember that in order for this to work, resetEncoders must be a Runnable - that is, it must take no parameters and return no value. So, its signature must look like this: // void because it returns no parameters, and has an empty parameter list public void resetEncoders () If the function signature does not match this, Java will not be able to interpret the method reference as a Runnable and the code will not compile. Note that all we need to do is make sure that the signature matches the signature of the single method in the Runnable functional interface - we don’t need to explicitly name it as a Runnable . Lambda Expressions in Java If we do not already have a named function that does what we want, we can define a function “inline” - that means, right inside of the call to runOnce ! We do this by writing our function with a special syntax that uses an “arrow” symbol to link the argument list to the function body: // Create an InstantCommand that runs the drive forward at half speed Command driveHalfSpeed = runOnce (() -> { drivetrain . arcadeDrive ( 0.5 , 0.0 ); }, drivetrain ); Java calls () -> { drivetrain.arcadeDrive(0.5, 0.0); } a “lambda expression”; it may be less-confusingly called an “arrow function”, “inline function”, or “anonymous function” (because it has no name). While this may look a bit funky, it is just another way of writing a function - the parentheses before the arrow are the function’s argument list, and the code contained in the brackets is the function body. The “lambda expression” here represents a function that calls drivetrain.arcadeDrive with a specific set of parameters - note again that this does not call the function, but merely defines it and passes it to the Command to be run later when the Command is scheduled. As with method references, we do not need to explicitly name the lambda expression as a Runnable - Java can infer that our lambda expression is a Runnable so long as its signature matches that of the single method in the Runnable interface. Accordingly, our lambda takes no arguments and has no return statement - if it did not match the Runnable contract, our code would fail to compile. Capturing State in Java Lambda Expressions In the above example, our function body references an object that lives outside of the function itself (namely, the drivetrain object). This is called a “capture” of a variable from the surrounding code (which is sometimes called the “outer scope” or “enclosing scope”). Usually the captured variables are either local variables from the enclosing method body in which the lambda expression is defined, or else fields of an enclosing class definition in which that method is defined. In Java capturing state is a fairly safe thing to do in general, with one major caveat: we can only capture state that is “effectively final”. That means it is only legal to capture a variable from the enclosing scope if that variable is never reassigned after initialization. Note that this does not mean that the captured state cannot change: Remember that Java objects are references, so the object that the reference points to may change after capture - but the reference itself cannot be made to point to another object. This means we can only capture primitive types (like int , double , and boolean ) if they’re constants. If we want to capture a state variable that can change, it must be wrapped in a mutable object . Syntactic Sugar for Java Lambda Expressions The full lambda expression syntax can be needlessly verbose in some cases. To help with this, Java lets us take some shortcuts (called “syntactic sugar”) in cases where some of the notation is redundant. Omitting Function Body Brackets for One-Line Lambdas If the function body of our lambda expression is only one line, Java lets us omit the brackets around the function body. When omitting function brackets, we also omit trailing semicolons And the return keyword. So, our Runnable lambda above could instead be written: // Create an InstantCommand that runs the drive forward at half speed Command driveHalfSpeed = runOnce (() -> drivetrain . arcadeDrive ( 0.5 , 0.0 ), drivetrain ); Omitting Parentheses around Single Lambda Parameters If the lambda expression is for a functional interface that takes only a single argument, we can omit the parenthesis around the parameter list: // We can write this lambda with no parenthesis around its single argument IntConsumer exampleLambda = ( a -> System . out . println ( a )); Treating Functions as Data in C++ C++ has a number of ways to treat functions as data. For the sake of this article, we’ll only talk about the parts that are relevant to using WPILibC. In WPILibC, function types are represented with the std::function class ( https://en.cppreference.com/w/cpp/utility/functional/function ). This standard library class is templated on the function’s signature - that means we have to provide it a function type as a template parameter to specify the signature of the function (compare this to Java above, where we have a separate interface type for each kind of signature). This sounds a lot more complicated than it is to use in practice. Let’s look at the call signature of cmd::RunOnce (which creates an InstantCommand that, when scheduled, runs the given function once and then terminates): Note The requirements parameter is explained in the Command-based documentation , and will not be discussed here. CommandPtr RunOnce ( std :: function < void () > action , Requirements requirements ); runOnce expects us to give it a std::function<void()> parameter (named action ). A std::function<void()> is the C++ type for a std::function that takes no parameters and returns no value (the template parameter, void() , is a function type with no parameters and no return value). When we call runOnce , we need to give it a function with no parameters and no return value. C++ lacks a clean way to refer to existing class methods in a way that can automatically be converted to a std::function , so the typical way to do this is to define a new function inline with a “lambda expression”. Lambda Expressions in C++ To pass a function to runOnce , we need to write a short inline function expression using a special syntax that resembles ordinary C++ function declarations, but varies in a few important ways: // Create an InstantCommand that runs the drive forward at half speed CommandPtr driveHalfSpeed = cmd :: RunOnce ([ this ] { drivetrain . ArcadeDrive ( 0.5 , 0.0 ); }, { drivetrain }); C++ calls [captures] (params) { body; } a “lambda expression”. It has three parts: a capture list (square brackets), an optional parameter list (parentheses), and a function body (curly brackets). It may look a little strange, but the only real difference between a lambda expression and an ordinary function (apart from the lack of a function name) is the addition of the capture list. Since RunOnce wants a function with no parameters and no return value, our lambda expression has no parameter list and no return statement. The “lambda expression” here represents a function that calls drivetrain.ArcadeDrive with a specific set of parameters - note again that the above code does not call the function, but merely defines it and passes it to the Command to be run later when the Command is scheduled. Capturing State in C++ Lambda Expressions In the above example, our function body references an object that lives outside of the function itself (namely, the drivetrain object). This is called a “capture” of a variable from the surrounding code (which is sometimes called the “outer scope” or “enclosing scope”). Usually the captured variables are either local variables from the enclosing method body in which the lambda expression is defined, or else fields of an enclosing class definition in which that method is defined. C++ has somewhat more-powerful semantics than Java. One cost of this is that we generally need to give the C++ compiler some help to figure out how exactly we want it to capture state from the enclosing scope. This is the purpose of the capture list . For the purposes of using the WPILibC Command-based framework, it is usually sufficient to use a capture list of [this] , which gives access to members of the enclosing class by capturing the enclosing class’s this pointer by value. Method locals cannot be captured with the this pointer, and must be captured explicitly either by reference or by value by including them in the capture list (or by implicitly by instead specifying a default capture semantics). It is typically safer to capture locals by-value, since a lambda can outlive the lifespan of an object it captures by reference. For more details, consult the C++ standard library documentation on capture semantics .",
      "content_preview": "Treating Functions as Data Regardless of programming language, one of the first things anyone learns to do when programming a computer is to write a function (also known as a “method” or a “subroutine”)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/subsystems.html",
      "title": "Subsystems",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Subsystems Subsystems are the basic unit of robot organization in the command-based paradigm. A subsystem is an abstraction for a collection of robot hardware that operates together as a unit . Subsystems form an encapsulation for this hardware, “hiding” it from the rest of the robot code and restricting access to it except through the subsystem’s public methods. Restricting the access in this way provides a single convenient place for code that might otherwise be duplicated in multiple places (such as scaling motor outputs or checking limit switches) if the subsystem internals were exposed. It also allows changes to the specific details of how the subsystem works (the “implementation”) to be isolated from the rest of robot code, making it far easier to make substantial changes if/when the design constraints change. Subsystems also serve as the backbone of the CommandScheduler ’s resource management system. Commands may declare resource requirements by specifying which subsystems they interact with; the scheduler will never concurrently schedule more than one command that requires a given subsystem. An attempt to schedule a command that requires a subsystem that is already-in-use will either interrupt the currently-running command or be ignored, based on the running command’s Interruption Behavior . Subsystems can be associated with “default commands” that will be automatically scheduled when no other command is currently using the subsystem. This is useful for “background” actions such as controlling the robot drive, keeping an arm held at a setpoint, or stopping motors when the subsystem isn’t used. Similar functionality can be achieved in the subsystem’s periodic() method, which is run once per run of the scheduler; teams should try to be consistent within their codebase about which functionality is achieved through either of these methods. Subsystems are represented in the command-based library by the Subsystem interface ( Java , C++ , Python ). Creating a Subsystem The recommended method to create a subsystem for most users is to subclass the abstract SubsystemBase class in ( Java , C++ ), as seen in the command-based template ( Java , C++ ). In Python, because Python does not have interfaces, the Subsystem class is a concrete class that can be subclassed directly ( Python ). The following example demonstrates how to create a simple subsystem in each of the supported languages: Java 7 import edu.wpi.first.wpilibj2.command.Command ; 8 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 9 10 public class ExampleSubsystem extends SubsystemBase { 11 /** Creates a new ExampleSubsystem. */ 12 public ExampleSubsystem () {} 13 14 /** 15 * Example command factory method. 16 * 17 * @return a command 18 */ 19 public Command exampleMethodCommand () { 20 // Inline construction of command goes here. 21 // Subsystem::RunOnce implicitly requires `this` subsystem. 22 return runOnce ( 23 () -> { 24 /* one-time action goes here */ 25 }); 26 } 27 28 /** 29 * An example method querying a boolean state of the subsystem (for example, a digital sensor). 30 * 31 * @return value of some boolean subsystem state, such as a digital sensor. 32 */ 33 public boolean exampleCondition () { 34 // Query some boolean state, such as a digital sensor. 35 return false ; 36 } 37 38 @Override 39 public void periodic () { 40 // This method will be called once per scheduler run 41 } 42 43 @Override 44 public void simulationPeriodic () { 45 // This method will be called once per scheduler run during simulation 46 } 47 } C++ 5 #pragma once 6 7 #include <frc2/command/CommandPtr.h> 8 #include <frc2/command/SubsystemBase.h> 9 10 class ExampleSubsystem : public frc2 :: SubsystemBase { 11 public : 12 ExampleSubsystem (); 13 14 /** 15 * Example command factory method. 16 */ 17 frc2 :: CommandPtr ExampleMethodCommand (); 18 19 /** 20 * An example method querying a boolean state of the subsystem (for example, a 21 * digital sensor). 22 * 23 * @return value of some boolean subsystem state, such as a digital sensor. 24 */ 25 bool ExampleCondition (); 26 27 /** 28 * Will be called periodically whenever the CommandScheduler runs. 29 */ 30 void Periodic () override ; 31 32 /** 33 * Will be called periodically whenever the CommandScheduler runs during 34 * simulation. 35 */ 36 void SimulationPeriodic () override ; 37 38 private : 39 // Components (e.g. motor controllers and sensors) should generally be 40 // declared private and exposed only through public methods. 41 }; Python from commands2 import Command from commands2 import Subsystem class ExampleSubsystem ( Subsystem ): def __init__ ( self ): \"\"\"Creates a new ExampleSubsystem.\"\"\" super () . __init__ () def exampleMethodCommand () -> Command : \"\"\" Example command factory method. :return a command \"\"\" return self . runOnce ( lambda : # one-time action goes here # ) def exampleCondition ( self ) -> bool : \"\"\" An example method querying a boolean state of the subsystem (for example, a digital sensor). :return value of some boolean subsystem state, such as a digital sensor. \"\"\" #Query some boolean state, such as a digital sensor. return False def periodic ( self ): # This method will be called once per scheduler run pass def simulationPeriodic ( self ): # This method will be called once per scheduler run during simulation pass This class contains a few convenience features on top of the basic Subsystem interface: it automatically calls the register() method in its constructor to register the subsystem with the scheduler (this is necessary for the periodic() method to be called when the scheduler runs), and also implements the Sendable interface so that it can be sent to the dashboard to display/log relevant status information. Advanced users seeking more flexibility may simply create a class that implements the Subsystem interface. Simple Subsystem Example What might a functional subsystem look like in practice? Below is a simple pneumatically-actuated hatch mechanism from the HatchBotTraditional example project ( Java , C++ , Python ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems ; 6 7 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kForward ; 8 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kReverse ; 9 10 import edu.wpi.first.util.sendable.SendableBuilder ; 11 import edu.wpi.first.wpilibj.DoubleSolenoid ; 12 import edu.wpi.first.wpilibj.PneumaticsModuleType ; 13 import edu.wpi.first.wpilibj.examples.hatchbottraditional.Constants.HatchConstants ; 14 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 15 16 /** A hatch mechanism actuated by a single {@link DoubleSolenoid}. */ 17 public class HatchSubsystem extends SubsystemBase { 18 private final DoubleSolenoid m_hatchSolenoid = 19 new DoubleSolenoid ( 20 PneumaticsModuleType . CTREPCM , 21 HatchConstants . kHatchSolenoidPorts [ 0 ] , 22 HatchConstants . kHatchSolenoidPorts [ 1 ] ); 23 24 /** Grabs the hatch. */ 25 public void grabHatch () { 26 m_hatchSolenoid . set ( kForward ); 27 } 28 29 /** Releases the hatch. */ 30 public void releaseHatch () { 31 m_hatchSolenoid . set ( kReverse ); 32 } 33 34 @Override 35 public void initSendable ( SendableBuilder builder ) { 36 super . initSendable ( builder ); 37 // Publish the solenoid state to telemetry. 38 builder . addBooleanProperty ( \"extended\" , () -> m_hatchSolenoid . get () == kForward , null ); 39 } 40 } C++ (Header) 5 #pragma once 6 7 #include <frc/DoubleSolenoid.h> 8 #include <frc/PneumaticsControlModule.h> 9 #include <frc2/command/SubsystemBase.h> 10 11 #include \"Constants.h\" 12 13 class HatchSubsystem : public frc2 :: SubsystemBase { 14 public : 15 HatchSubsystem (); 16 17 // Subsystem methods go here. 18 19 /** 20 * Grabs the hatch. 21 */ 22 void GrabHatch (); 23 24 /** 25 * Releases the hatch. 26 */ 27 void ReleaseHatch (); 28 29 void InitSendable ( wpi :: SendableBuilder & builder ) override ; 30 31 private : 32 // Components (e.g. motor controllers and sensors) should generally be 33 // declared private and exposed only through public methods. 34 frc :: DoubleSolenoid m_hatchSolenoid ; 35 }; C++ (Source) 5 #include \"subsystems/HatchSubsystem.h\" 6 7 #include <wpi/sendable/SendableBuilder.h> 8 9 using namespace HatchConstants ; 10 11 HatchSubsystem :: HatchSubsystem () 12 : m_hatchSolenoid { frc :: PneumaticsModuleType :: CTREPCM , 13 kHatchSolenoidPorts [ 0 ], kHatchSolenoidPorts [ 1 ]} {} 14 15 void HatchSubsystem :: GrabHatch () { 16 m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); 17 } 18 19 void HatchSubsystem :: ReleaseHatch () { 20 m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); 21 } 22 23 void HatchSubsystem :: InitSendable ( wpi :: SendableBuilder & builder ) { 24 SubsystemBase :: InitSendable ( builder ); 25 26 // Publish the solenoid state to telemetry. 27 builder . AddBooleanProperty ( 28 \"extended\" , 29 [ this ] { return m_hatchSolenoid . Get () == frc :: DoubleSolenoid :: kForward ; }, 30 nullptr ); 31 } Python 7 import wpilib 8 import commands2 9 10 import constants 11 12 13 class HatchSubsystem ( commands2 . Subsystem ): 14 def __init__ ( self ) -> None : 15 super () . __init__ () 16 17 self . hatchSolenoid = wpilib . DoubleSolenoid ( 18 constants . kHatchSolenoidModule , 19 constants . kHatchSolenoidModuleType , 20 * constants . kHatchSolenoidPorts 21 ) 22 23 def grabHatch ( self ) -> None : 24 \"\"\"Grabs the hatch\"\"\" 25 self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ) 26 27 def releaseHatch ( self ) -> None : 28 \"\"\"Releases the hatch\"\"\" 29 self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ) Notice that the subsystem hides the presence of the DoubleSolenoid from outside code (it is declared private ), and instead publicly exposes two higher-level, descriptive robot actions: grabHatch() and releaseHatch() . It is extremely important that “implementation details” such as the double solenoid be “hidden” in this manner; this ensures that code outside the subsystem will never cause the solenoid to be in an unexpected state. It also allows the user to change the implementation (for instance, a motor could be used instead of a pneumatic) without any of the code outside of the subsystem having to change with it. Alternatively, instead of writing void public methods that are called from commands, we can define the public methods as factories that return a command. Consider the following from the HatchBotInlined example project ( Java , C++ , Python ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbotinlined.subsystems ; 6 7 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kForward ; 8 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kReverse ; 9 10 import edu.wpi.first.util.sendable.SendableBuilder ; 11 import edu.wpi.first.wpilibj.DoubleSolenoid ; 12 import edu.wpi.first.wpilibj.PneumaticsModuleType ; 13 import edu.wpi.first.wpilibj.examples.hatchbotinlined.Constants.HatchConstants ; 14 import edu.wpi.first.wpilibj2.command.Command ; 15 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 16 17 /** A hatch mechanism actuated by a single {@link edu.wpi.first.wpilibj.DoubleSolenoid}. */ 18 public class HatchSubsystem extends SubsystemBase { 19 private final DoubleSolenoid m_hatchSolenoid = 20 new DoubleSolenoid ( 21 PneumaticsModuleType . CTREPCM , 22 HatchConstants . kHatchSolenoidPorts [ 0 ] , 23 HatchConstants . kHatchSolenoidPorts [ 1 ] ); 24 25 /** Grabs the hatch. */ 26 public Command grabHatchCommand () { 27 // implicitly require `this` 28 return this . runOnce (() -> m_hatchSolenoid . set ( kForward )); 29 } 30 31 /** Releases the hatch. */ 32 public Command releaseHatchCommand () { 33 // implicitly require `this` 34 return this . runOnce (() -> m_hatchSolenoid . set ( kReverse )); 35 } 36 37 @Override 38 public void initSendable ( SendableBuilder builder ) { 39 super . initSendable ( builder ); 40 // Publish the solenoid state to telemetry. 41 builder . addBooleanProperty ( \"extended\" , () -> m_hatchSolenoid . get () == kForward , null ); 42 } 43 } C++ (Header) 5 #pragma once 6 7 #include <frc/DoubleSolenoid.h> 8 #include <frc/PneumaticsControlModule.h> 9 #include <frc2/command/CommandPtr.h> 10 #include <frc2/command/SubsystemBase.h> 11 12 #include \"Constants.h\" 13 14 class HatchSubsystem : public frc2 :: SubsystemBase { 15 public : 16 HatchSubsystem (); 17 18 // Subsystem methods go here. 19 20 /** 21 * Grabs the hatch. 22 */ 23 frc2 :: CommandPtr GrabHatchCommand (); 24 25 /** 26 * Releases the hatch. 27 */ 28 frc2 :: CommandPtr ReleaseHatchCommand (); 29 30 void InitSendable ( wpi :: SendableBuilder & builder ) override ; 31 32 private : 33 // Components (e.g. motor controllers and sensors) should generally be 34 // declared private and exposed only through public methods. 35 frc :: DoubleSolenoid m_hatchSolenoid ; 36 }; C++ (Source) 5 #include \"subsystems/HatchSubsystem.h\" 6 7 #include <wpi/sendable/SendableBuilder.h> 8 9 using namespace HatchConstants ; 10 11 HatchSubsystem :: HatchSubsystem () 12 : m_hatchSolenoid { frc :: PneumaticsModuleType :: CTREPCM , 13 kHatchSolenoidPorts [ 0 ], kHatchSolenoidPorts [ 1 ]} {} 14 15 frc2 :: CommandPtr HatchSubsystem :: GrabHatchCommand () { 16 // implicitly require `this` 17 return this -> RunOnce ( 18 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); }); 19 } 20 21 frc2 :: CommandPtr HatchSubsystem :: ReleaseHatchCommand () { 22 // implicitly require `this` 23 return this -> RunOnce ( 24 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); }); 25 } 26 27 void HatchSubsystem :: InitSendable ( wpi :: SendableBuilder & builder ) { 28 SubsystemBase :: InitSendable ( builder ); 29 30 // Publish the solenoid state to telemetry. 31 builder . AddBooleanProperty ( 32 \"extended\" , 33 [ this ] { return m_hatchSolenoid . Get () == frc :: DoubleSolenoid :: kForward ; }, 34 nullptr ); 35 } Python 7 import wpilib 8 import commands2 9 import commands2.cmd 10 11 import constants 12 13 14 class HatchSubsystem ( commands2 . Subsystem ): 15 def __init__ ( self ) -> None : 16 super () . __init__ () 17 18 self . hatchSolenoid = wpilib . DoubleSolenoid ( 19 constants . kHatchSolenoidModule , 20 constants . kHatchSolenoidModuleType , 21 * constants . kHatchSolenoidPorts 22 ) 23 24 def grabHatch ( self ) -> commands2 . Command : 25 \"\"\"Grabs the hatch\"\"\" 26 return commands2 . cmd . runOnce ( 27 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ), self 28 ) 29 30 def releaseHatch ( self ) -> commands2 . Command : 31 \"\"\"Releases the hatch\"\"\" 32 return commands2 . cmd . runOnce ( 33 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ), self 34 ) Note the qualification of the RunOnce factory used here: this isn’t the static factory in Commands ! Subsystems have similar instance factories that return commands requiring this (Java/C++) or self (Python) subsystem. Here, the Subsystem.runOnce(Runnable) factory ( Java , C++ , Python ) is used. For a comparison between these options, see Instance Command Factory Methods . Periodic Subsystems have a periodic method that is called once every scheduler iteration (usually, once every 20 ms). This method is typically used for telemetry and other periodic actions that do not interfere with whatever command is requiring the subsystem. Java 117 @Override 118 public void periodic () { 119 // Update the odometry in the periodic block 120 m_odometry . update ( 121 Rotation2d . fromDegrees ( getHeading ()), 122 m_leftEncoder . getDistance (), 123 m_rightEncoder . getDistance ()); 124 m_fieldSim . setRobotPose ( getPose ()); 125 } C++ (Header) 30 void Periodic () override ; C++ (Source) 30 void DriveSubsystem::Periodic () { 31 // Implementation of subsystem periodic method goes here. 32 m_odometry . Update ( m_gyro . GetRotation2d (), 33 units :: meter_t { m_leftEncoder . GetDistance ()}, 34 units :: meter_t { m_rightEncoder . GetDistance ()}); 35 m_fieldSim . SetRobotPose ( m_odometry . GetPose ()); 36 } Python def periodic ( self ): #Update the odometry in the periodic block self . odometry . update ( Rotation2d . fromDegrees ( getHeading ()), self . leftEncoder . getDistance (), self . rightEncoder . getDistance ()) self . fieldSim . setRobotPose ( getPose ()) There is also a simulationPeriodic() method that is similar to periodic() except that it is only run during Simulation and can be used to update the state of the robot. Default Commands Note In the C++ command-based library, the CommandScheduler owns the default command object. “Default commands” are commands that run automatically whenever a subsystem is not being used by another command. This can be useful for “background” actions such as controlling the robot drive, or keeping an arm held at a setpoint. Setting a default command for a subsystem is very easy; one simply calls CommandScheduler.getInstance().setDefaultCommand() , or, more simply, the setDefaultCommand() method of the Subsystem interface: JAVA CommandScheduler . getInstance (). setDefaultCommand ( exampleSubsystem , exampleCommand ); C++ CommandScheduler . GetInstance (). SetDefaultCommand ( exampleSubsystem , std :: move ( exampleCommand )); PYTHON CommandScheduler . getInstance () . setDefaultCommand ( exampleSubsystem , exampleCommand ) JAVA exampleSubsystem . setDefaultCommand ( exampleCommand ); C++ exampleSubsystem . SetDefaultCommand ( std :: move ( exampleCommand )); PYTHON exampleSubsystem . setDefaultCommand ( exampleCommand ) Note A command that is assigned as the default command for a subsystem must require that subsystem.",
      "content_preview": "Subsystems Subsystems are the basic unit of robot organization in the command-based paradigm. A subsystem is an abstraction for a collection of robot hardware that operates together as a unit ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/subsystems.html?present",
      "title": "Subsystems",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Subsystems Subsystems are the basic unit of robot organization in the command-based paradigm. A subsystem is an abstraction for a collection of robot hardware that operates together as a unit . Subsystems form an encapsulation for this hardware, “hiding” it from the rest of the robot code and restricting access to it except through the subsystem’s public methods. Restricting the access in this way provides a single convenient place for code that might otherwise be duplicated in multiple places (such as scaling motor outputs or checking limit switches) if the subsystem internals were exposed. It also allows changes to the specific details of how the subsystem works (the “implementation”) to be isolated from the rest of robot code, making it far easier to make substantial changes if/when the design constraints change. Subsystems also serve as the backbone of the CommandScheduler ’s resource management system. Commands may declare resource requirements by specifying which subsystems they interact with; the scheduler will never concurrently schedule more than one command that requires a given subsystem. An attempt to schedule a command that requires a subsystem that is already-in-use will either interrupt the currently-running command or be ignored, based on the running command’s Interruption Behavior . Subsystems can be associated with “default commands” that will be automatically scheduled when no other command is currently using the subsystem. This is useful for “background” actions such as controlling the robot drive, keeping an arm held at a setpoint, or stopping motors when the subsystem isn’t used. Similar functionality can be achieved in the subsystem’s periodic() method, which is run once per run of the scheduler; teams should try to be consistent within their codebase about which functionality is achieved through either of these methods. Subsystems are represented in the command-based library by the Subsystem interface ( Java , C++ , Python ). Creating a Subsystem The recommended method to create a subsystem for most users is to subclass the abstract SubsystemBase class in ( Java , C++ ), as seen in the command-based template ( Java , C++ ). In Python, because Python does not have interfaces, the Subsystem class is a concrete class that can be subclassed directly ( Python ). The following example demonstrates how to create a simple subsystem in each of the supported languages: Java 7 import edu.wpi.first.wpilibj2.command.Command ; 8 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 9 10 public class ExampleSubsystem extends SubsystemBase { 11 /** Creates a new ExampleSubsystem. */ 12 public ExampleSubsystem () {} 13 14 /** 15 * Example command factory method. 16 * 17 * @return a command 18 */ 19 public Command exampleMethodCommand () { 20 // Inline construction of command goes here. 21 // Subsystem::RunOnce implicitly requires `this` subsystem. 22 return runOnce ( 23 () -> { 24 /* one-time action goes here */ 25 }); 26 } 27 28 /** 29 * An example method querying a boolean state of the subsystem (for example, a digital sensor). 30 * 31 * @return value of some boolean subsystem state, such as a digital sensor. 32 */ 33 public boolean exampleCondition () { 34 // Query some boolean state, such as a digital sensor. 35 return false ; 36 } 37 38 @Override 39 public void periodic () { 40 // This method will be called once per scheduler run 41 } 42 43 @Override 44 public void simulationPeriodic () { 45 // This method will be called once per scheduler run during simulation 46 } 47 } C++ 5 #pragma once 6 7 #include <frc2/command/CommandPtr.h> 8 #include <frc2/command/SubsystemBase.h> 9 10 class ExampleSubsystem : public frc2 :: SubsystemBase { 11 public : 12 ExampleSubsystem (); 13 14 /** 15 * Example command factory method. 16 */ 17 frc2 :: CommandPtr ExampleMethodCommand (); 18 19 /** 20 * An example method querying a boolean state of the subsystem (for example, a 21 * digital sensor). 22 * 23 * @return value of some boolean subsystem state, such as a digital sensor. 24 */ 25 bool ExampleCondition (); 26 27 /** 28 * Will be called periodically whenever the CommandScheduler runs. 29 */ 30 void Periodic () override ; 31 32 /** 33 * Will be called periodically whenever the CommandScheduler runs during 34 * simulation. 35 */ 36 void SimulationPeriodic () override ; 37 38 private : 39 // Components (e.g. motor controllers and sensors) should generally be 40 // declared private and exposed only through public methods. 41 }; Python from commands2 import Command from commands2 import Subsystem class ExampleSubsystem ( Subsystem ): def __init__ ( self ): \"\"\"Creates a new ExampleSubsystem.\"\"\" super () . __init__ () def exampleMethodCommand () -> Command : \"\"\" Example command factory method. :return a command \"\"\" return self . runOnce ( lambda : # one-time action goes here # ) def exampleCondition ( self ) -> bool : \"\"\" An example method querying a boolean state of the subsystem (for example, a digital sensor). :return value of some boolean subsystem state, such as a digital sensor. \"\"\" #Query some boolean state, such as a digital sensor. return False def periodic ( self ): # This method will be called once per scheduler run pass def simulationPeriodic ( self ): # This method will be called once per scheduler run during simulation pass This class contains a few convenience features on top of the basic Subsystem interface: it automatically calls the register() method in its constructor to register the subsystem with the scheduler (this is necessary for the periodic() method to be called when the scheduler runs), and also implements the Sendable interface so that it can be sent to the dashboard to display/log relevant status information. Advanced users seeking more flexibility may simply create a class that implements the Subsystem interface. Simple Subsystem Example What might a functional subsystem look like in practice? Below is a simple pneumatically-actuated hatch mechanism from the HatchBotTraditional example project ( Java , C++ , Python ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbottraditional.subsystems ; 6 7 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kForward ; 8 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kReverse ; 9 10 import edu.wpi.first.util.sendable.SendableBuilder ; 11 import edu.wpi.first.wpilibj.DoubleSolenoid ; 12 import edu.wpi.first.wpilibj.PneumaticsModuleType ; 13 import edu.wpi.first.wpilibj.examples.hatchbottraditional.Constants.HatchConstants ; 14 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 15 16 /** A hatch mechanism actuated by a single {@link DoubleSolenoid}. */ 17 public class HatchSubsystem extends SubsystemBase { 18 private final DoubleSolenoid m_hatchSolenoid = 19 new DoubleSolenoid ( 20 PneumaticsModuleType . CTREPCM , 21 HatchConstants . kHatchSolenoidPorts [ 0 ] , 22 HatchConstants . kHatchSolenoidPorts [ 1 ] ); 23 24 /** Grabs the hatch. */ 25 public void grabHatch () { 26 m_hatchSolenoid . set ( kForward ); 27 } 28 29 /** Releases the hatch. */ 30 public void releaseHatch () { 31 m_hatchSolenoid . set ( kReverse ); 32 } 33 34 @Override 35 public void initSendable ( SendableBuilder builder ) { 36 super . initSendable ( builder ); 37 // Publish the solenoid state to telemetry. 38 builder . addBooleanProperty ( \"extended\" , () -> m_hatchSolenoid . get () == kForward , null ); 39 } 40 } C++ (Header) 5 #pragma once 6 7 #include <frc/DoubleSolenoid.h> 8 #include <frc/PneumaticsControlModule.h> 9 #include <frc2/command/SubsystemBase.h> 10 11 #include \"Constants.h\" 12 13 class HatchSubsystem : public frc2 :: SubsystemBase { 14 public : 15 HatchSubsystem (); 16 17 // Subsystem methods go here. 18 19 /** 20 * Grabs the hatch. 21 */ 22 void GrabHatch (); 23 24 /** 25 * Releases the hatch. 26 */ 27 void ReleaseHatch (); 28 29 void InitSendable ( wpi :: SendableBuilder & builder ) override ; 30 31 private : 32 // Components (e.g. motor controllers and sensors) should generally be 33 // declared private and exposed only through public methods. 34 frc :: DoubleSolenoid m_hatchSolenoid ; 35 }; C++ (Source) 5 #include \"subsystems/HatchSubsystem.h\" 6 7 #include <wpi/sendable/SendableBuilder.h> 8 9 using namespace HatchConstants ; 10 11 HatchSubsystem :: HatchSubsystem () 12 : m_hatchSolenoid { frc :: PneumaticsModuleType :: CTREPCM , 13 kHatchSolenoidPorts [ 0 ], kHatchSolenoidPorts [ 1 ]} {} 14 15 void HatchSubsystem :: GrabHatch () { 16 m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); 17 } 18 19 void HatchSubsystem :: ReleaseHatch () { 20 m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); 21 } 22 23 void HatchSubsystem :: InitSendable ( wpi :: SendableBuilder & builder ) { 24 SubsystemBase :: InitSendable ( builder ); 25 26 // Publish the solenoid state to telemetry. 27 builder . AddBooleanProperty ( 28 \"extended\" , 29 [ this ] { return m_hatchSolenoid . Get () == frc :: DoubleSolenoid :: kForward ; }, 30 nullptr ); 31 } Python 7 import wpilib 8 import commands2 9 10 import constants 11 12 13 class HatchSubsystem ( commands2 . Subsystem ): 14 def __init__ ( self ) -> None : 15 super () . __init__ () 16 17 self . hatchSolenoid = wpilib . DoubleSolenoid ( 18 constants . kHatchSolenoidModule , 19 constants . kHatchSolenoidModuleType , 20 * constants . kHatchSolenoidPorts 21 ) 22 23 def grabHatch ( self ) -> None : 24 \"\"\"Grabs the hatch\"\"\" 25 self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ) 26 27 def releaseHatch ( self ) -> None : 28 \"\"\"Releases the hatch\"\"\" 29 self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ) Notice that the subsystem hides the presence of the DoubleSolenoid from outside code (it is declared private ), and instead publicly exposes two higher-level, descriptive robot actions: grabHatch() and releaseHatch() . It is extremely important that “implementation details” such as the double solenoid be “hidden” in this manner; this ensures that code outside the subsystem will never cause the solenoid to be in an unexpected state. It also allows the user to change the implementation (for instance, a motor could be used instead of a pneumatic) without any of the code outside of the subsystem having to change with it. Alternatively, instead of writing void public methods that are called from commands, we can define the public methods as factories that return a command. Consider the following from the HatchBotInlined example project ( Java , C++ , Python ): Java 5 package edu.wpi.first.wpilibj.examples.hatchbotinlined.subsystems ; 6 7 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kForward ; 8 import static edu.wpi.first.wpilibj.DoubleSolenoid.Value.kReverse ; 9 10 import edu.wpi.first.util.sendable.SendableBuilder ; 11 import edu.wpi.first.wpilibj.DoubleSolenoid ; 12 import edu.wpi.first.wpilibj.PneumaticsModuleType ; 13 import edu.wpi.first.wpilibj.examples.hatchbotinlined.Constants.HatchConstants ; 14 import edu.wpi.first.wpilibj2.command.Command ; 15 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 16 17 /** A hatch mechanism actuated by a single {@link edu.wpi.first.wpilibj.DoubleSolenoid}. */ 18 public class HatchSubsystem extends SubsystemBase { 19 private final DoubleSolenoid m_hatchSolenoid = 20 new DoubleSolenoid ( 21 PneumaticsModuleType . CTREPCM , 22 HatchConstants . kHatchSolenoidPorts [ 0 ] , 23 HatchConstants . kHatchSolenoidPorts [ 1 ] ); 24 25 /** Grabs the hatch. */ 26 public Command grabHatchCommand () { 27 // implicitly require `this` 28 return this . runOnce (() -> m_hatchSolenoid . set ( kForward )); 29 } 30 31 /** Releases the hatch. */ 32 public Command releaseHatchCommand () { 33 // implicitly require `this` 34 return this . runOnce (() -> m_hatchSolenoid . set ( kReverse )); 35 } 36 37 @Override 38 public void initSendable ( SendableBuilder builder ) { 39 super . initSendable ( builder ); 40 // Publish the solenoid state to telemetry. 41 builder . addBooleanProperty ( \"extended\" , () -> m_hatchSolenoid . get () == kForward , null ); 42 } 43 } C++ (Header) 5 #pragma once 6 7 #include <frc/DoubleSolenoid.h> 8 #include <frc/PneumaticsControlModule.h> 9 #include <frc2/command/CommandPtr.h> 10 #include <frc2/command/SubsystemBase.h> 11 12 #include \"Constants.h\" 13 14 class HatchSubsystem : public frc2 :: SubsystemBase { 15 public : 16 HatchSubsystem (); 17 18 // Subsystem methods go here. 19 20 /** 21 * Grabs the hatch. 22 */ 23 frc2 :: CommandPtr GrabHatchCommand (); 24 25 /** 26 * Releases the hatch. 27 */ 28 frc2 :: CommandPtr ReleaseHatchCommand (); 29 30 void InitSendable ( wpi :: SendableBuilder & builder ) override ; 31 32 private : 33 // Components (e.g. motor controllers and sensors) should generally be 34 // declared private and exposed only through public methods. 35 frc :: DoubleSolenoid m_hatchSolenoid ; 36 }; C++ (Source) 5 #include \"subsystems/HatchSubsystem.h\" 6 7 #include <wpi/sendable/SendableBuilder.h> 8 9 using namespace HatchConstants ; 10 11 HatchSubsystem :: HatchSubsystem () 12 : m_hatchSolenoid { frc :: PneumaticsModuleType :: CTREPCM , 13 kHatchSolenoidPorts [ 0 ], kHatchSolenoidPorts [ 1 ]} {} 14 15 frc2 :: CommandPtr HatchSubsystem :: GrabHatchCommand () { 16 // implicitly require `this` 17 return this -> RunOnce ( 18 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); }); 19 } 20 21 frc2 :: CommandPtr HatchSubsystem :: ReleaseHatchCommand () { 22 // implicitly require `this` 23 return this -> RunOnce ( 24 [ this ] { m_hatchSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); }); 25 } 26 27 void HatchSubsystem :: InitSendable ( wpi :: SendableBuilder & builder ) { 28 SubsystemBase :: InitSendable ( builder ); 29 30 // Publish the solenoid state to telemetry. 31 builder . AddBooleanProperty ( 32 \"extended\" , 33 [ this ] { return m_hatchSolenoid . Get () == frc :: DoubleSolenoid :: kForward ; }, 34 nullptr ); 35 } Python 7 import wpilib 8 import commands2 9 import commands2.cmd 10 11 import constants 12 13 14 class HatchSubsystem ( commands2 . Subsystem ): 15 def __init__ ( self ) -> None : 16 super () . __init__ () 17 18 self . hatchSolenoid = wpilib . DoubleSolenoid ( 19 constants . kHatchSolenoidModule , 20 constants . kHatchSolenoidModuleType , 21 * constants . kHatchSolenoidPorts 22 ) 23 24 def grabHatch ( self ) -> commands2 . Command : 25 \"\"\"Grabs the hatch\"\"\" 26 return commands2 . cmd . runOnce ( 27 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kForward ), self 28 ) 29 30 def releaseHatch ( self ) -> commands2 . Command : 31 \"\"\"Releases the hatch\"\"\" 32 return commands2 . cmd . runOnce ( 33 lambda : self . hatchSolenoid . set ( wpilib . DoubleSolenoid . Value . kReverse ), self 34 ) Note the qualification of the RunOnce factory used here: this isn’t the static factory in Commands ! Subsystems have similar instance factories that return commands requiring this (Java/C++) or self (Python) subsystem. Here, the Subsystem.runOnce(Runnable) factory ( Java , C++ , Python ) is used. For a comparison between these options, see Instance Command Factory Methods . Periodic Subsystems have a periodic method that is called once every scheduler iteration (usually, once every 20 ms). This method is typically used for telemetry and other periodic actions that do not interfere with whatever command is requiring the subsystem. Java 117 @Override 118 public void periodic () { 119 // Update the odometry in the periodic block 120 m_odometry . update ( 121 Rotation2d . fromDegrees ( getHeading ()), 122 m_leftEncoder . getDistance (), 123 m_rightEncoder . getDistance ()); 124 m_fieldSim . setRobotPose ( getPose ()); 125 } C++ (Header) 30 void Periodic () override ; C++ (Source) 30 void DriveSubsystem::Periodic () { 31 // Implementation of subsystem periodic method goes here. 32 m_odometry . Update ( m_gyro . GetRotation2d (), 33 units :: meter_t { m_leftEncoder . GetDistance ()}, 34 units :: meter_t { m_rightEncoder . GetDistance ()}); 35 m_fieldSim . SetRobotPose ( m_odometry . GetPose ()); 36 } Python def periodic ( self ): #Update the odometry in the periodic block self . odometry . update ( Rotation2d . fromDegrees ( getHeading ()), self . leftEncoder . getDistance (), self . rightEncoder . getDistance ()) self . fieldSim . setRobotPose ( getPose ()) There is also a simulationPeriodic() method that is similar to periodic() except that it is only run during Simulation and can be used to update the state of the robot. Default Commands Note In the C++ command-based library, the CommandScheduler owns the default command object. “Default commands” are commands that run automatically whenever a subsystem is not being used by another command. This can be useful for “background” actions such as controlling the robot drive, or keeping an arm held at a setpoint. Setting a default command for a subsystem is very easy; one simply calls CommandScheduler.getInstance().setDefaultCommand() , or, more simply, the setDefaultCommand() method of the Subsystem interface: JAVA CommandScheduler . getInstance (). setDefaultCommand ( exampleSubsystem , exampleCommand ); C++ CommandScheduler . GetInstance (). SetDefaultCommand ( exampleSubsystem , std :: move ( exampleCommand )); PYTHON CommandScheduler . getInstance () . setDefaultCommand ( exampleSubsystem , exampleCommand ) JAVA exampleSubsystem . setDefaultCommand ( exampleCommand ); C++ exampleSubsystem . SetDefaultCommand ( std :: move ( exampleCommand )); PYTHON exampleSubsystem . setDefaultCommand ( exampleCommand ) Note A command that is assigned as the default command for a subsystem must require that subsystem.",
      "content_preview": "Subsystems Subsystems are the basic unit of robot organization in the command-based paradigm. A subsystem is an abstraction for a collection of robot hardware that operates together as a unit ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/profilepid-subsystems-commands.html",
      "title": "Combining Motion Profiling and PID in Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Combining Motion Profiling and PID in Command-Based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . A common FRC® controls solution is to pair a trapezoidal motion profile for setpoint generation with a PID controller for setpoint tracking. To facilitate this, WPILib includes its own ProfiledPIDController class. The following example is from the RapidReactCommandBot example project ( Java , C++ ) and shows how ProfiledPIDController can be used within the command-based framework to turn a drivetrain to a specified angle: Java 5 package edu.wpi.first.wpilibj.examples.rapidreactcommandbot.subsystems ; 6 7 import edu.wpi.first.epilogue.Logged ; 8 import edu.wpi.first.epilogue.NotLogged ; 9 import edu.wpi.first.math.controller.ProfiledPIDController ; 10 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 11 import edu.wpi.first.math.trajectory.TrapezoidProfile ; 12 import edu.wpi.first.util.sendable.SendableRegistry ; 13 import edu.wpi.first.wpilibj.ADXRS450_Gyro ; 14 import edu.wpi.first.wpilibj.Encoder ; 15 import edu.wpi.first.wpilibj.RobotController ; 16 import edu.wpi.first.wpilibj.drive.DifferentialDrive ; 17 import edu.wpi.first.wpilibj.examples.rapidreactcommandbot.Constants.DriveConstants ; 18 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 19 import edu.wpi.first.wpilibj2.command.Command ; 20 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 21 import java.util.function.DoubleSupplier ; 22 23 @Logged 24 public class Drive extends SubsystemBase { 25 // The motors on the left side of the drive. 26 private final PWMSparkMax m_leftLeader = new PWMSparkMax ( DriveConstants . kLeftMotor1Port ); 27 private final PWMSparkMax m_leftFollower = new PWMSparkMax ( DriveConstants . kLeftMotor2Port ); 28 29 // The motors on the right side of the drive. 30 private final PWMSparkMax m_rightLeader = new PWMSparkMax ( DriveConstants . kRightMotor1Port ); 31 private final PWMSparkMax m_rightFollower = new PWMSparkMax ( DriveConstants . kRightMotor2Port ); 32 33 // The robot's drive 34 @NotLogged // Would duplicate motor data, there's no point sending it twice 35 private final DifferentialDrive m_drive = 36 new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); 37 38 // The left-side drive encoder 39 private final Encoder m_leftEncoder = 40 new Encoder ( 41 DriveConstants . kLeftEncoderPorts [ 0 ] , 42 DriveConstants . kLeftEncoderPorts [ 1 ] , 43 DriveConstants . kLeftEncoderReversed ); 44 45 // The right-side drive encoder 46 private final Encoder m_rightEncoder = 47 new Encoder ( 48 DriveConstants . kRightEncoderPorts [ 0 ] , 49 DriveConstants . kRightEncoderPorts [ 1 ] , 50 DriveConstants . kRightEncoderReversed ); 51 52 private final ADXRS450_Gyro m_gyro = new ADXRS450_Gyro (); 53 private final ProfiledPIDController m_controller = 54 new ProfiledPIDController ( 55 DriveConstants . kTurnP , 56 DriveConstants . kTurnI , 57 DriveConstants . kTurnD , 58 new TrapezoidProfile . Constraints ( 59 DriveConstants . kMaxTurnRateDegPerS , 60 DriveConstants . kMaxTurnAccelerationDegPerSSquared )); 61 private final SimpleMotorFeedforward m_feedforward = 62 new SimpleMotorFeedforward ( 63 DriveConstants . ksVolts , 64 DriveConstants . kvVoltSecondsPerDegree , 65 DriveConstants . kaVoltSecondsSquaredPerDegree ); 66 67 /** Creates a new Drive subsystem. */ 68 public Drive () { 69 SendableRegistry . addChild ( m_drive , m_leftLeader ); 70 SendableRegistry . addChild ( m_drive , m_rightLeader ); 71 72 m_leftLeader . addFollower ( m_leftFollower ); 73 m_rightLeader . addFollower ( m_rightFollower ); 74 75 // We need to invert one side of the drivetrain so that positive voltages 76 // result in both sides moving forward. Depending on how your robot's 77 // gearbox is constructed, you might have to invert the left side instead. 78 m_rightLeader . setInverted ( true ); 79 80 // Sets the distance per pulse for the encoders 81 m_leftEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 82 m_rightEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 83 84 // Set the controller to be continuous (because it is an angle controller) 85 m_controller . enableContinuousInput ( - 180 , 180 ); 86 // Set the controller tolerance - the delta tolerance ensures the robot is stationary at the 87 // setpoint before it is considered as having reached the reference 88 m_controller . setTolerance ( 89 DriveConstants . kTurnToleranceDeg , DriveConstants . kTurnRateToleranceDegPerS ); 90 } 91 92 /** 93 * Returns a command that drives the robot with arcade controls. 94 * 95 * @param fwd the commanded forward movement 96 * @param rot the commanded rotation 97 */ 98 public Command arcadeDriveCommand ( DoubleSupplier fwd , DoubleSupplier rot ) { 99 // A split-stick arcade command, with forward/backward controlled by the left 100 // hand, and turning controlled by the right. 101 return run (() -> m_drive . arcadeDrive ( fwd . getAsDouble (), rot . getAsDouble ())) 102 . withName ( \"arcadeDrive\" ); 103 } 104 105 /** 106 * Returns a command that drives the robot forward a specified distance at a specified speed. 107 * 108 * @param distanceMeters The distance to drive forward in meters 109 * @param speed The fraction of max speed at which to drive 110 */ 111 public Command driveDistanceCommand ( double distanceMeters , double speed ) { 112 return runOnce ( 113 () -> { 114 // Reset encoders at the start of the command 115 m_leftEncoder . reset (); 116 m_rightEncoder . reset (); 117 }) 118 // Drive forward at specified speed 119 . andThen ( run (() -> m_drive . arcadeDrive ( speed , 0 ))) 120 // End command when we've traveled the specified distance 121 . until ( 122 () -> 123 Math . max ( m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()) 124 >= distanceMeters ) 125 // Stop the drive when the command ends 126 . finallyDo ( interrupted -> m_drive . stopMotor ()); 127 } 128 129 /** 130 * Returns a command that turns to robot to the specified angle using a motion profile and PID 131 * controller. 132 * 133 * @param angleDeg The angle to turn to 134 */ 135 public Command turnToAngleCommand ( double angleDeg ) { 136 return startRun ( 137 () -> m_controller . reset ( m_gyro . getRotation2d (). getDegrees ()), 138 () -> 139 m_drive . arcadeDrive ( 140 0 , 141 m_controller . calculate ( m_gyro . getRotation2d (). getDegrees (), angleDeg ) 142 // Divide feedforward voltage by battery voltage to normalize it to [-1, 1] 143 + m_feedforward . calculate ( m_controller . getSetpoint (). velocity ) 144 / RobotController . getBatteryVoltage ())) 145 . until ( m_controller :: atGoal ) 146 . finallyDo (() -> m_drive . arcadeDrive ( 0 , 0 )); 147 } 148 } C++ (Header) 5 #pragma once 6 7 #include <functional> 8 9 #include <frc/ADXRS450_Gyro.h> 10 #include <frc/Encoder.h> 11 #include <frc/controller/ProfiledPIDController.h> 12 #include <frc/controller/SimpleMotorFeedforward.h> 13 #include <frc/drive/DifferentialDrive.h> 14 #include <frc/motorcontrol/PWMSparkMax.h> 15 #include <frc2/command/CommandPtr.h> 16 #include <frc2/command/SubsystemBase.h> 17 #include <units/angle.h> 18 #include <units/length.h> 19 20 #include \"Constants.h\" 21 22 class Drive : public frc2 :: SubsystemBase { 23 public : 24 Drive (); 25 /** 26 * Returns a command that drives the robot with arcade controls. 27 * 28 * @param fwd the commanded forward movement 29 * @param rot the commanded rotation 30 */ 31 [[ nodiscard ]] 32 frc2 :: CommandPtr ArcadeDriveCommand ( std :: function < double () > fwd , 33 std :: function < double () > rot ); 34 35 /** 36 * Returns a command that drives the robot forward a specified distance at a 37 * specified speed. 38 * 39 * @param distance The distance to drive forward in meters 40 * @param speed The fraction of max speed at which to drive 41 */ 42 [[ nodiscard ]] 43 frc2 :: CommandPtr DriveDistanceCommand ( units :: meter_t distance , double speed ); 44 45 /** 46 * Returns a command that turns to robot to the specified angle using a motion 47 * profile and PID controller. 48 * 49 * @param angle The angle to turn to 50 */ 51 [[ nodiscard ]] 52 frc2 :: CommandPtr TurnToAngleCommand ( units :: degree_t angle ); 53 54 private : 55 frc :: PWMSparkMax m_leftLeader { DriveConstants :: kLeftMotor1Port }; 56 frc :: PWMSparkMax m_leftFollower { DriveConstants :: kLeftMotor2Port }; 57 frc :: PWMSparkMax m_rightLeader { DriveConstants :: kRightMotor1Port }; 58 frc :: PWMSparkMax m_rightFollower { DriveConstants :: kRightMotor2Port }; 59 60 frc :: DifferentialDrive m_drive { 61 [ & ]( double output ) { m_leftLeader . Set ( output ); }, 62 [ & ]( double output ) { m_rightLeader . Set ( output ); }}; 63 64 frc :: Encoder m_leftEncoder { DriveConstants :: kLeftEncoderPorts [ 0 ], 65 DriveConstants :: kLeftEncoderPorts [ 1 ], 66 DriveConstants :: kLeftEncoderReversed }; 67 frc :: Encoder m_rightEncoder { DriveConstants :: kRightEncoderPorts [ 0 ], 68 DriveConstants :: kRightEncoderPorts [ 1 ], 69 DriveConstants :: kRightEncoderReversed }; 70 71 frc :: ADXRS450_Gyro m_gyro ; 72 73 frc :: ProfiledPIDController < units :: radians > m_controller { 74 DriveConstants :: kTurnP , 75 DriveConstants :: kTurnI , 76 DriveConstants :: kTurnD , 77 { DriveConstants :: kMaxTurnRate , DriveConstants :: kMaxTurnAcceleration }}; 78 frc :: SimpleMotorFeedforward < units :: radians > m_feedforward { 79 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }; 80 }; C++ (Source) 5 #include \"subsystems/Drive.h\" 6 7 #include <utility> 8 9 #include <frc/RobotController.h> 10 #include <frc2/command/Commands.h> 11 12 Drive :: Drive () { 13 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_leftLeader ); 14 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_rightLeader ); 15 16 m_leftLeader . AddFollower ( m_leftFollower ); 17 m_rightLeader . AddFollower ( m_rightFollower ); 18 19 // We need to invert one side of the drivetrain so that positive voltages 20 // result in both sides moving forward. Depending on how your robot's 21 // gearbox is constructed, you might have to invert the left side instead. 22 m_rightLeader . SetInverted ( true ); 23 24 // Sets the distance per pulse for the encoders 25 m_leftEncoder . SetDistancePerPulse ( DriveConstants :: kEncoderDistancePerPulse ); 26 m_rightEncoder . SetDistancePerPulse ( DriveConstants :: kEncoderDistancePerPulse ); 27 28 // Set the controller to be continuous (because it is an angle controller) 29 m_controller . EnableContinuousInput ( -180 _deg , 180 _deg ); 30 // Set the controller tolerance - the delta tolerance ensures the robot is 31 // stationary at the setpoint before it is considered as having reached the 32 // reference 33 m_controller . SetTolerance ( DriveConstants :: kTurnTolerance , 34 DriveConstants :: kTurnRateTolerance ); 35 } 36 37 frc2 :: CommandPtr Drive :: ArcadeDriveCommand ( std :: function < double () > fwd , 38 std :: function < double () > rot ) { 39 return Run ([ this , fwd = std :: move ( fwd ), rot = std :: move ( rot )] { 40 m_drive . ArcadeDrive ( fwd (), rot ()); 41 }) 42 . WithName ( \"ArcadeDrive\" ); 43 } 44 45 frc2 :: CommandPtr Drive :: DriveDistanceCommand ( units :: meter_t distance , 46 double speed ) { 47 return RunOnce ([ this ] { 48 // Reset encoders at the start of the command 49 m_leftEncoder . Reset (); 50 m_rightEncoder . Reset (); 51 }) 52 // Drive forward at specified speed 53 . AndThen ( Run ([ this , speed ] { m_drive . ArcadeDrive ( speed , 0.0 ); })) 54 . Until ([ this , distance ] { 55 return units :: math :: max ( units :: meter_t ( m_leftEncoder . GetDistance ()), 56 units :: meter_t ( m_rightEncoder . GetDistance ())) >= 57 distance ; 58 }) 59 // Stop the drive when the command ends 60 . FinallyDo ([ this ]( bool interrupted ) { m_drive . StopMotor (); }); 61 } 62 63 frc2 :: CommandPtr Drive :: TurnToAngleCommand ( units :: degree_t angle ) { 64 return StartRun ( 65 [ this ] { m_controller . Reset ( m_gyro . GetRotation2d (). Degrees ()); }, 66 [ this , angle ] { 67 m_drive . ArcadeDrive ( 68 0 , m_controller . Calculate ( m_gyro . GetRotation2d (). Degrees (), 69 angle ) + 70 // Divide feedforward voltage by battery voltage to 71 // normalize it to [-1, 1] 72 m_feedforward . Calculate ( 73 m_controller . GetSetpoint (). velocity ) / 74 frc :: RobotController :: GetBatteryVoltage ()); 75 }) 76 . Until ([ this ] { return m_controller . AtGoal (); }) 77 . FinallyDo ([ this ] { m_drive . ArcadeDrive ( 0 , 0 ); }); 78 } turnToAngleCommand uses a ProfiledPIDController to smoothly turn the drivetrain. The startRun command factory is used to reset the ProfiledPIDController when the command is scheduled to avoid unwanted behavior, and to calculate PID and feedforward outputs to pass into the arcadeDrive method in order to drive the robot. The command is decorated using the until decorator to end the command when the ProfiledPIDController is finished with the profile. To ensure the drivetrain stops when the command ends, the finallyDo decorator is used to stop the drivetrain by setting the speed to zero.",
      "content_preview": "Combining Motion Profiling and PID in Command-Based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/commandbased/profilepid-subsystems-commands.html?present",
      "title": "Combining Motion Profiling and PID in Command",
      "section": "Command-Based Programming",
      "language": "All",
      "content": "Combining Motion Profiling and PID in Command-Based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib . A common FRC® controls solution is to pair a trapezoidal motion profile for setpoint generation with a PID controller for setpoint tracking. To facilitate this, WPILib includes its own ProfiledPIDController class. The following example is from the RapidReactCommandBot example project ( Java , C++ ) and shows how ProfiledPIDController can be used within the command-based framework to turn a drivetrain to a specified angle: Java 5 package edu.wpi.first.wpilibj.examples.rapidreactcommandbot.subsystems ; 6 7 import edu.wpi.first.epilogue.Logged ; 8 import edu.wpi.first.epilogue.NotLogged ; 9 import edu.wpi.first.math.controller.ProfiledPIDController ; 10 import edu.wpi.first.math.controller.SimpleMotorFeedforward ; 11 import edu.wpi.first.math.trajectory.TrapezoidProfile ; 12 import edu.wpi.first.util.sendable.SendableRegistry ; 13 import edu.wpi.first.wpilibj.ADXRS450_Gyro ; 14 import edu.wpi.first.wpilibj.Encoder ; 15 import edu.wpi.first.wpilibj.RobotController ; 16 import edu.wpi.first.wpilibj.drive.DifferentialDrive ; 17 import edu.wpi.first.wpilibj.examples.rapidreactcommandbot.Constants.DriveConstants ; 18 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 19 import edu.wpi.first.wpilibj2.command.Command ; 20 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 21 import java.util.function.DoubleSupplier ; 22 23 @Logged 24 public class Drive extends SubsystemBase { 25 // The motors on the left side of the drive. 26 private final PWMSparkMax m_leftLeader = new PWMSparkMax ( DriveConstants . kLeftMotor1Port ); 27 private final PWMSparkMax m_leftFollower = new PWMSparkMax ( DriveConstants . kLeftMotor2Port ); 28 29 // The motors on the right side of the drive. 30 private final PWMSparkMax m_rightLeader = new PWMSparkMax ( DriveConstants . kRightMotor1Port ); 31 private final PWMSparkMax m_rightFollower = new PWMSparkMax ( DriveConstants . kRightMotor2Port ); 32 33 // The robot's drive 34 @NotLogged // Would duplicate motor data, there's no point sending it twice 35 private final DifferentialDrive m_drive = 36 new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); 37 38 // The left-side drive encoder 39 private final Encoder m_leftEncoder = 40 new Encoder ( 41 DriveConstants . kLeftEncoderPorts [ 0 ] , 42 DriveConstants . kLeftEncoderPorts [ 1 ] , 43 DriveConstants . kLeftEncoderReversed ); 44 45 // The right-side drive encoder 46 private final Encoder m_rightEncoder = 47 new Encoder ( 48 DriveConstants . kRightEncoderPorts [ 0 ] , 49 DriveConstants . kRightEncoderPorts [ 1 ] , 50 DriveConstants . kRightEncoderReversed ); 51 52 private final ADXRS450_Gyro m_gyro = new ADXRS450_Gyro (); 53 private final ProfiledPIDController m_controller = 54 new ProfiledPIDController ( 55 DriveConstants . kTurnP , 56 DriveConstants . kTurnI , 57 DriveConstants . kTurnD , 58 new TrapezoidProfile . Constraints ( 59 DriveConstants . kMaxTurnRateDegPerS , 60 DriveConstants . kMaxTurnAccelerationDegPerSSquared )); 61 private final SimpleMotorFeedforward m_feedforward = 62 new SimpleMotorFeedforward ( 63 DriveConstants . ksVolts , 64 DriveConstants . kvVoltSecondsPerDegree , 65 DriveConstants . kaVoltSecondsSquaredPerDegree ); 66 67 /** Creates a new Drive subsystem. */ 68 public Drive () { 69 SendableRegistry . addChild ( m_drive , m_leftLeader ); 70 SendableRegistry . addChild ( m_drive , m_rightLeader ); 71 72 m_leftLeader . addFollower ( m_leftFollower ); 73 m_rightLeader . addFollower ( m_rightFollower ); 74 75 // We need to invert one side of the drivetrain so that positive voltages 76 // result in both sides moving forward. Depending on how your robot's 77 // gearbox is constructed, you might have to invert the left side instead. 78 m_rightLeader . setInverted ( true ); 79 80 // Sets the distance per pulse for the encoders 81 m_leftEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 82 m_rightEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 83 84 // Set the controller to be continuous (because it is an angle controller) 85 m_controller . enableContinuousInput ( - 180 , 180 ); 86 // Set the controller tolerance - the delta tolerance ensures the robot is stationary at the 87 // setpoint before it is considered as having reached the reference 88 m_controller . setTolerance ( 89 DriveConstants . kTurnToleranceDeg , DriveConstants . kTurnRateToleranceDegPerS ); 90 } 91 92 /** 93 * Returns a command that drives the robot with arcade controls. 94 * 95 * @param fwd the commanded forward movement 96 * @param rot the commanded rotation 97 */ 98 public Command arcadeDriveCommand ( DoubleSupplier fwd , DoubleSupplier rot ) { 99 // A split-stick arcade command, with forward/backward controlled by the left 100 // hand, and turning controlled by the right. 101 return run (() -> m_drive . arcadeDrive ( fwd . getAsDouble (), rot . getAsDouble ())) 102 . withName ( \"arcadeDrive\" ); 103 } 104 105 /** 106 * Returns a command that drives the robot forward a specified distance at a specified speed. 107 * 108 * @param distanceMeters The distance to drive forward in meters 109 * @param speed The fraction of max speed at which to drive 110 */ 111 public Command driveDistanceCommand ( double distanceMeters , double speed ) { 112 return runOnce ( 113 () -> { 114 // Reset encoders at the start of the command 115 m_leftEncoder . reset (); 116 m_rightEncoder . reset (); 117 }) 118 // Drive forward at specified speed 119 . andThen ( run (() -> m_drive . arcadeDrive ( speed , 0 ))) 120 // End command when we've traveled the specified distance 121 . until ( 122 () -> 123 Math . max ( m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()) 124 >= distanceMeters ) 125 // Stop the drive when the command ends 126 . finallyDo ( interrupted -> m_drive . stopMotor ()); 127 } 128 129 /** 130 * Returns a command that turns to robot to the specified angle using a motion profile and PID 131 * controller. 132 * 133 * @param angleDeg The angle to turn to 134 */ 135 public Command turnToAngleCommand ( double angleDeg ) { 136 return startRun ( 137 () -> m_controller . reset ( m_gyro . getRotation2d (). getDegrees ()), 138 () -> 139 m_drive . arcadeDrive ( 140 0 , 141 m_controller . calculate ( m_gyro . getRotation2d (). getDegrees (), angleDeg ) 142 // Divide feedforward voltage by battery voltage to normalize it to [-1, 1] 143 + m_feedforward . calculate ( m_controller . getSetpoint (). velocity ) 144 / RobotController . getBatteryVoltage ())) 145 . until ( m_controller :: atGoal ) 146 . finallyDo (() -> m_drive . arcadeDrive ( 0 , 0 )); 147 } 148 } C++ (Header) 5 #pragma once 6 7 #include <functional> 8 9 #include <frc/ADXRS450_Gyro.h> 10 #include <frc/Encoder.h> 11 #include <frc/controller/ProfiledPIDController.h> 12 #include <frc/controller/SimpleMotorFeedforward.h> 13 #include <frc/drive/DifferentialDrive.h> 14 #include <frc/motorcontrol/PWMSparkMax.h> 15 #include <frc2/command/CommandPtr.h> 16 #include <frc2/command/SubsystemBase.h> 17 #include <units/angle.h> 18 #include <units/length.h> 19 20 #include \"Constants.h\" 21 22 class Drive : public frc2 :: SubsystemBase { 23 public : 24 Drive (); 25 /** 26 * Returns a command that drives the robot with arcade controls. 27 * 28 * @param fwd the commanded forward movement 29 * @param rot the commanded rotation 30 */ 31 [[ nodiscard ]] 32 frc2 :: CommandPtr ArcadeDriveCommand ( std :: function < double () > fwd , 33 std :: function < double () > rot ); 34 35 /** 36 * Returns a command that drives the robot forward a specified distance at a 37 * specified speed. 38 * 39 * @param distance The distance to drive forward in meters 40 * @param speed The fraction of max speed at which to drive 41 */ 42 [[ nodiscard ]] 43 frc2 :: CommandPtr DriveDistanceCommand ( units :: meter_t distance , double speed ); 44 45 /** 46 * Returns a command that turns to robot to the specified angle using a motion 47 * profile and PID controller. 48 * 49 * @param angle The angle to turn to 50 */ 51 [[ nodiscard ]] 52 frc2 :: CommandPtr TurnToAngleCommand ( units :: degree_t angle ); 53 54 private : 55 frc :: PWMSparkMax m_leftLeader { DriveConstants :: kLeftMotor1Port }; 56 frc :: PWMSparkMax m_leftFollower { DriveConstants :: kLeftMotor2Port }; 57 frc :: PWMSparkMax m_rightLeader { DriveConstants :: kRightMotor1Port }; 58 frc :: PWMSparkMax m_rightFollower { DriveConstants :: kRightMotor2Port }; 59 60 frc :: DifferentialDrive m_drive { 61 [ & ]( double output ) { m_leftLeader . Set ( output ); }, 62 [ & ]( double output ) { m_rightLeader . Set ( output ); }}; 63 64 frc :: Encoder m_leftEncoder { DriveConstants :: kLeftEncoderPorts [ 0 ], 65 DriveConstants :: kLeftEncoderPorts [ 1 ], 66 DriveConstants :: kLeftEncoderReversed }; 67 frc :: Encoder m_rightEncoder { DriveConstants :: kRightEncoderPorts [ 0 ], 68 DriveConstants :: kRightEncoderPorts [ 1 ], 69 DriveConstants :: kRightEncoderReversed }; 70 71 frc :: ADXRS450_Gyro m_gyro ; 72 73 frc :: ProfiledPIDController < units :: radians > m_controller { 74 DriveConstants :: kTurnP , 75 DriveConstants :: kTurnI , 76 DriveConstants :: kTurnD , 77 { DriveConstants :: kMaxTurnRate , DriveConstants :: kMaxTurnAcceleration }}; 78 frc :: SimpleMotorFeedforward < units :: radians > m_feedforward { 79 DriveConstants :: ks , DriveConstants :: kv , DriveConstants :: ka }; 80 }; C++ (Source) 5 #include \"subsystems/Drive.h\" 6 7 #include <utility> 8 9 #include <frc/RobotController.h> 10 #include <frc2/command/Commands.h> 11 12 Drive :: Drive () { 13 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_leftLeader ); 14 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_rightLeader ); 15 16 m_leftLeader . AddFollower ( m_leftFollower ); 17 m_rightLeader . AddFollower ( m_rightFollower ); 18 19 // We need to invert one side of the drivetrain so that positive voltages 20 // result in both sides moving forward. Depending on how your robot's 21 // gearbox is constructed, you might have to invert the left side instead. 22 m_rightLeader . SetInverted ( true ); 23 24 // Sets the distance per pulse for the encoders 25 m_leftEncoder . SetDistancePerPulse ( DriveConstants :: kEncoderDistancePerPulse ); 26 m_rightEncoder . SetDistancePerPulse ( DriveConstants :: kEncoderDistancePerPulse ); 27 28 // Set the controller to be continuous (because it is an angle controller) 29 m_controller . EnableContinuousInput ( -180 _deg , 180 _deg ); 30 // Set the controller tolerance - the delta tolerance ensures the robot is 31 // stationary at the setpoint before it is considered as having reached the 32 // reference 33 m_controller . SetTolerance ( DriveConstants :: kTurnTolerance , 34 DriveConstants :: kTurnRateTolerance ); 35 } 36 37 frc2 :: CommandPtr Drive :: ArcadeDriveCommand ( std :: function < double () > fwd , 38 std :: function < double () > rot ) { 39 return Run ([ this , fwd = std :: move ( fwd ), rot = std :: move ( rot )] { 40 m_drive . ArcadeDrive ( fwd (), rot ()); 41 }) 42 . WithName ( \"ArcadeDrive\" ); 43 } 44 45 frc2 :: CommandPtr Drive :: DriveDistanceCommand ( units :: meter_t distance , 46 double speed ) { 47 return RunOnce ([ this ] { 48 // Reset encoders at the start of the command 49 m_leftEncoder . Reset (); 50 m_rightEncoder . Reset (); 51 }) 52 // Drive forward at specified speed 53 . AndThen ( Run ([ this , speed ] { m_drive . ArcadeDrive ( speed , 0.0 ); })) 54 . Until ([ this , distance ] { 55 return units :: math :: max ( units :: meter_t ( m_leftEncoder . GetDistance ()), 56 units :: meter_t ( m_rightEncoder . GetDistance ())) >= 57 distance ; 58 }) 59 // Stop the drive when the command ends 60 . FinallyDo ([ this ]( bool interrupted ) { m_drive . StopMotor (); }); 61 } 62 63 frc2 :: CommandPtr Drive :: TurnToAngleCommand ( units :: degree_t angle ) { 64 return StartRun ( 65 [ this ] { m_controller . Reset ( m_gyro . GetRotation2d (). Degrees ()); }, 66 [ this , angle ] { 67 m_drive . ArcadeDrive ( 68 0 , m_controller . Calculate ( m_gyro . GetRotation2d (). Degrees (), 69 angle ) + 70 // Divide feedforward voltage by battery voltage to 71 // normalize it to [-1, 1] 72 m_feedforward . Calculate ( 73 m_controller . GetSetpoint (). velocity ) / 74 frc :: RobotController :: GetBatteryVoltage ()); 75 }) 76 . Until ([ this ] { return m_controller . AtGoal (); }) 77 . FinallyDo ([ this ] { m_drive . ArcadeDrive ( 0 , 0 ); }); 78 } turnToAngleCommand uses a ProfiledPIDController to smoothly turn the drivetrain. The startRun command factory is used to reset the ProfiledPIDController when the command is scheduled to avoid unwanted behavior, and to calculate PID and feedforward outputs to pass into the arcadeDrive method in order to drive the robot. The command is decorated using the until decorator to end the command when the ProfiledPIDController is finished with the profile. To ensure the drivetrain stops when the command ends, the finallyDo decorator is used to stop the drivetrain by setting the speed to zero.",
      "content_preview": "Combining Motion Profiling and PID in Command-Based Note For a description of the WPILib PID control features used by these command-based wrappers, see PID Control in WPILib ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/index.html",
      "title": "Hardware APIs",
      "section": "Hardware APIs",
      "language": "Java",
      "content": "Hardware APIs This section discusses the control of motors and pneumatics through motor controllers, solenoids, and pneumatics, and their interface with Java and C++ WPILib. Motors APIs Pneumatics APIs Sensors Miscellaneous Hardware APIs Motor Controllers A motor controller is responsible on your robot for making motors move. For brushed DC motors such as the CIM or 775, the motor controller regulates the voltage that the motor receives, much like a light bulb. For brushless motor controllers such as the Spark MAX, the controller regulates the power delivered to each “phase” of the motor. Note Another name for a motor controller is a speed controller. Hint One can make a quick, non-competition-legal motor controller by removing the motor from a cordless BRUSHED drill and attaching PowerPoles or equivalents to the motor’s leads. Make sure that the voltage supplied by the drill will not damage the motor, but note that the 775 is fine at up to 24 volts. Warning Connecting a BRUSHLESS motor controller straight to power, such as to a conventional brushed motor controller, will destroy the motor! FRC Legal Motor Controllers Motor controllers come in lots of shapes, sizes, and feature sets. This is the full list of FRC® Legal motor controllers as of 2025: DMC 60/DMC 60c Motor Controller (P/N: 410-334-1, 410-334-2) Jaguar Motor Controller (P/N: MDL-BDC, MDL-BDC24, and 217-3367) connected to PWM only Koors40 Motor Controller (P/N am-5600) Nidec Dynamo BLDC Motor with Controller to control integral actuator only (P/N 840205-000, am-3740) SD540 Motor Controller (P/N: SD540x1, SD540x2, SD540x4, SD540Bx1, SD540Bx2, SD540Bx4, SD540C) Spark Flex Motor Controller (P/N REV-11-2159, am-5276) Spark Motor Controller (P/N: REV-11-1200, am-4260) Spark MAX Motor Controller (P/N: REV-11-2158, am-4261) Talon FX Motor Controller (P/N 217-6515, 19-708850, am-6515, am-6515_Short, WCP-0940) for controlling integral Falcon 500 or Kraken X60 only, Talon FXS Motor Controller (P/N 24-708883, WCP-1692) Talon Motor Controller (P/N: CTRE_Talon, CTRE_Talon_SR, and am-2195) Talon SRX Motor Controller (P/N: 217-8080, am-2854, 14-838288) Thrifty Nova (P/N TTB-0100) Venom Motor with Controller (P/N BDC-10001) for controlling integral motor only​ Victor 884 Motor Controller (P/N: VICTOR-884-12/12) Victor 888 Motor Controller (P/N: 217-2769) Victor SP Motor Controller (P/N: 217-9090, am-2855, 14-868380) Victor SPX Motor Controller (P/N: 217-9191, 17-868388, am-3748) Pneumatics Pneumatics are a quick and easy way to make something that’s in one state or another using compressed air. For information on operating pneumatics, see Pneumatics APIs . FRC Legal Pneumatics controllers Pneumatics Control Module (P/N: am-2858, 217-4243) Pneumatic Hub (P/N REV-11-1852) Relays A relay controls power to a motor or custom electronics in an On/Off fashion. FRC Legal Relay Modules Spike H-Bridge Relay (P/N: 217-0220 and SPIKE-RELAY-H) Automation Direct Relay (P/N: AD-SSR6M12-DC200D, AD-SSR6M25-DC200D, AD-SSR6M40-DC200D) Power Distribution Hub (PDH) switched channel (P/N REV-11-1850)",
      "content_preview": "Hardware APIs This section discusses the control of motors and pneumatics through motor controllers, solenoids, and pneumatics, and their interface with Java and C++ WPILib."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/misc/index.html",
      "title": "Miscellaneous Hardware APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Miscellaneous Hardware APIs This section highlights miscellaneous hardware APIs that are standalone. Addressable LEDs",
      "content_preview": "Miscellaneous Hardware APIs This section highlights miscellaneous hardware APIs that are standalone. Addressable LEDs"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/misc/addressable-leds.html",
      "title": "Addressable LEDs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Addressable LEDs LED strips have been commonly used by teams for several years for a variety of reasons. They allow teams to debug robot functionality from the audience, provide a visual marker for their robot, and can simply add some visual appeal. WPILib has an API for controlling WS2812, WS2812B, and WS2815 LEDs with their data pin connected via PWM . Note LEDs can be controlled through this API while the robot is disabled. Important The roboRIO can only control one AddressableLED object at a time through its PWM ports. Attempting to create multiple AddressableLED objects will result in a HAL allocation error. If you need to control multiple physical LED strips, you have several options: Daisy-chain strips in series : Connect multiple LED strips end-to-end as a single long strip, then use buffer views to control different sections independently Use PWM Y-cables : If you need identical patterns on multiple strips, use PWM Y-cables to send the same signal to multiple strips simultaneously See also For detailed information about powering and best practices for addressable LEDs, see the Adafruit NeoPixel Überguide . Warning WS2812B LEDs are designed for 5V, but roboRIO PWM/Servo ports output 6V. While the LEDs will function, this may reduce their lifespan. Consider using a voltage regulator or level shifter if longevity is a concern. Instantiating the AddressableLED Object You first create an AddressableLED object that takes the PWM port as an argument. It must be a PWM header on the roboRIO. Then you set the number of LEDs located on your LED strip, which can be done with the setLength() function. Warning It is important to note that setting the length of the LED header is an expensive task and it’s not recommended to run this periodically. After the length of the strip has been set, you’ll have to create an AddressableLEDBuffer object that takes the number of LEDs as an input. You’ll then call myAddressableLed.setData(myAddressableLEDBuffer) to set the led output data. Finally, you can call myAddressableLed.start() to write the output continuously. Below is a full example of the initialization process. Note C++ does not have an AddressableLEDBuffer, and instead uses an Array. Java 32 /** Called once at the beginning of the robot program. */ 33 public Robot () { 34 // PWM port 9 35 // Must be a PWM header, not MXP or DIO 36 m_led = new AddressableLED ( 9 ); 37 38 // Reuse buffer 39 // Default to a length of 60, start empty output 40 // Length is expensive to set, so only set it once, then just update data 41 m_ledBuffer = new AddressableLEDBuffer ( 60 ); 42 m_led . setLength ( m_ledBuffer . getLength ()); 43 44 // Set the data 45 m_led . setData ( m_ledBuffer ); 46 m_led . start (); 47 } C++ 12 private : 13 static constexpr int kLength = 60 ; 14 15 // PWM port 9 16 // Must be a PWM header, not MXP or DIO 17 frc :: AddressableLED m_led { 9 }; 18 std :: array < frc :: AddressableLED :: LEDData , kLength > 19 m_ledBuffer ; // Reuse the buffer 20 21 // Our LED strip has a density of 120 LEDs per meter 7 Robot :: Robot () { 8 // Default to a length of 60, start empty output 9 // Length is expensive to set, so only set it once, then just update data 10 m_led . SetLength ( kLength ); 11 m_led . SetData ( m_ledBuffer ); 12 m_led . Start (); 13 } Controlling Sections of an LED Strip The roboRIO can only control a single addressable LED output at a time, but there are often multiple physical LED strips daisy-chained around a robot, or a single flexible LED strip wrapped around structures on a robot. Individual sections can be accessed in Java using AddressableLEDBufferView . Buffer views behave like subsections of the larger buffer, and can be accessed using indices in the typical [0, length) range. They can also be reversed, to allow for parallel serpentine sections to be animated in the same physical orientation (i.e. both sections would animate “forward” in the same direction, even if the strips are physically tip-to-tail). Java // Create the buffer AddressableLEDBuffer m_buffer = new AddressableLEDBuffer ( 120 ); // Create the view for the section of the strip on the left side of the robot. // This section spans LEDs from index 0 through index 59, inclusive. AddressableLEDBufferView m_left = m_buffer . createView ( 0 , 59 ); // The section of the strip on the right side of the robot. // This section spans LEDs from index 60 through index 119, inclusive. // This view is reversed to cancel out the serpentine arrangement of the // physical LED strip on the robot. AddressableLEDBufferView m_right = m_buffer . createView ( 60 , 119 ). reversed (); C++ // Create the buffer std :: array < frc :: AddressableLED :: LEDData , 120 > m_buffer ; // Create the view for the section of the strip on the left side of the robot. // This section spans LEDs from index 0 through index 59, inclusive. std :: view < frc :: AddressableLED :: LEDData > m_left = std :: ranges :: take_view ( m_buffer , 60 ); // The section of the strip on the right side of the robot. // This section spans LEDs from index 60 through index 119, inclusive. // This view is reversed to cancel out the serpentine arrangement of the // physical LED strip on the robot. std :: view < frc :: AddressableLED :: LEDData > m_right = std :: ranges :: reverse_view ( std :: ranges :: drop_view ( m_buffer , 60 )); LED Patterns The LEDPattern API simplifies setting LED data. Rather than needing to manually loop over every LED index, you can apply a pattern object to the data buffer directly. LED patterns are stateless, and can safely be applied to multiple buffers or views. Java // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . solid ( Color . kRed ); // Apply the LED pattern to the data buffer red . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . Solid ( Color :: kRed ); // Apply the LED pattern to the data buffer red . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Creating a Rainbow Effect Using the built in LEDPattern.rainbow method, we can create a pattern that displays a full rainbow across an entire LED strip. Then, by calling scrollAtAbsoluteSpeed we can make it animate and cycle around the strip. rainbow accepts two arguments - one for the saturation and one for the value, expressed as a number from 0 to 255. Note Animating effects like scrolling use the Java units library and the C++ units library for speeds and durations. The base rainbow pattern will look like this: Java 21 // all hues at maximum saturation and half brightness 22 private final LEDPattern m_rainbow = LEDPattern . rainbow ( 255 , 128 ); 23 24 // Our LED strip has a density of 120 LEDs per meter 25 private static final Distance kLedSpacing = Meters . of ( 1 / 120.0 ); 26 27 // Create a new pattern that scrolls the rainbow pattern across the LED strip, moving at a speed 28 // of 1 meter per second. 29 private final LEDPattern m_scrollingRainbow = 30 m_rainbow . scrollAtAbsoluteSpeed ( MetersPerSecond . of ( 1 ), kLedSpacing ); C++ 27 // Our LED strip has a density of 120 LEDs per meter 28 units :: meter_t kLedSpacing { 1 / 120.0 }; 29 30 // Create an LED pattern that will display a rainbow across 31 // all hues at maximum saturation and half brightness 32 frc :: LEDPattern m_rainbow = frc :: LEDPattern :: Rainbow ( 255 , 128 ); 33 34 // Create a new pattern that scrolls the rainbow pattern across the LED 35 // strip, moving at a speed of 1 meter per second. 36 frc :: LEDPattern m_scrollingRainbow = 37 m_rainbow . ScrollAtAbsoluteSpeed ( 1 _mps , kLedSpacing ); Now that the rainbow pattern is defined, we only need to apply it. Java 50 public void robotPeriodic () { 51 // Update the buffer with the rainbow animation 52 m_scrollingRainbow . applyTo ( m_ledBuffer ); 53 // Set the LEDs 54 m_led . setData ( m_ledBuffer ); 55 } 56 } C++ 15 void Robot::RobotPeriodic () { 16 // Run the rainbow pattern and apply it to the buffer 17 m_scrollingRainbow . ApplyTo ( m_ledBuffer ); 18 // Set the LEDs 19 m_led . SetData ( m_ledBuffer ); 20 } Controlling when patterns are applied Use commands. The command framework is specifically built for managing when actions run and stop, and prevents multiple actions from running simultaneously. Java public class LEDSubsystem extends SubsystemBase { private static final int kPort = 9 ; private static final int kLength = 120 ; private final AddressableLED m_led ; private final AddressableLEDBuffer m_buffer ; public LEDSubsystem () { m_led = new AddressableLED ( kPort ); m_buffer = new AddressableLEDBuffer ( kLength ); m_led . setLength ( kLength ); m_led . start (); // Set the default command to turn the strip off, otherwise the last colors written by // the last command to run will continue to be displayed. // Note: Other default patterns could be used instead! setDefaultCommand ( runPattern ( LEDPattern . solid ( Color . kBlack )). withName ( \"Off\" )); } @Override public void periodic () { // Periodically send the latest LED color data to the LED strip for it to display m_led . setData ( m_buffer ); } /** * Creates a command that runs a pattern on the entire LED strip. * * @param pattern the LED pattern to run */ public Command runPattern ( LEDPattern pattern ) { return run (() -> pattern . applyTo ( m_buffer )); } } C++ Header: class LEDSubsystem : public SubsystemBase { public : LEDSubsystem (); void Periodic () override ; frc :: CommandPtr RunPattern ( frc :: LEDPattern pattern ); private : static constexpr int kPort = 9 ; static constexpr int kLength = 120 ; frc :: AddressableLED m_led { kPort }; std :: array < frc :: AddressableLED :: LEDData , kLength > m_ledBuffer ; } LEDSubsystem :: LEDSubsystem () { m_led . SetLength ( kLength ); m_led . Start (); // Set the default command to turn the strip off, otherwise the last colors written by // the last command to run will continue to be displayed. // Note: Other default patterns could be used instead! SetDefaultCommand ( RunPattern ( frc :: LEDPattern :: Solid ( frc :: Color :: kBlack )). WithName ( \"Off\" )); } LEDSubsystem :: Periodic () { // Periodically send the latest LED color data to the LED strip for it to display m_led . SetData ( m_ledBuffer ); } frc :: CommandPtr LEDSubsystem :: RunPattern ( frc :: LEDPattern pattern ) { // std::move is necessary for inline pattern declarations to work // Otherwise we could have a use-after-free! return Run ([ this , pattern = std :: move ( pattern )] { pattern . ApplyTo ( m_buffer ); }); } Basic effects The basic effects can all be created from the factory methods declared in the LEDPattern class Solid color The solid color pattern sets the target LED buffer to a single solid color. Java // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . solid ( Color . kRed ); // Apply the LED pattern to the data buffer red . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . Solid ( Color :: kRed ); // Apply the LED pattern to the data buffer red . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Continuous Gradient The gradient pattern sets the target buffer to display a smooth gradient between the specified colors. The gradient wraps around so scrolling effects can be seamless. Java // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at both ends and blue in the center, // with smooth gradients between LEDPattern gradient = LEDPattern . gradient ( LEDPattern . GradientType . kContinuous , Color . kRed , Color . kBlue ); // Apply the LED pattern to the data buffer gradient . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at both ends and blue in the center, // with smooth gradients between std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern gradient = LEDPattern . Gradient ( LEDPattern :: GradientType :: kContinuous , colors ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Discontinuous Gradient The gradient pattern sets the target buffer to display a smooth gradient between the specified colors. The gradient does not wrap around so it can be used for non-scrolling patterns that don’t care about continuity. Java // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at one end and blue at the other. LEDPattern gradient = LEDPattern . gradient ( LEDPattern . GradientType . kDiscontinuous , Color . kRed , Color . kBlue ); // Apply the LED pattern to the data buffer gradient . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at one end and blue at the other. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern gradient = LEDPattern . Gradient ( LEDPattern :: GradientType :: kDiscontinuous , colors ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Steps Displays segments of solid colors along the target buffer. This combines well with mask and overlay combination effects. Steps are specified as a combination of the starting position of that color, as a number between 0 (start of the buffer) and 1 (end of the buffer). Note If the first step does not start at zero, every LED before that step starts will be set to black - effectively, as if there is a default step of (0, Color.kBlack) that can be overwritten. Java // Create an LED pattern that displays the first half of a strip as solid red, // and the second half of the strip as solid blue. LEDPattern steps = LEDPattern . steps ( Map . of ( 0 , Color . kRed , 0.5 , Color . kBlue )); // Apply the LED pattern to the data buffer steps . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays the first half of a strip as solid red, // and the second half of the strip as solid blue. std :: array < std :: pair < double , Color > , 2 > colorSteps { std :: pair { 0.0 , Color :: kRed }, std :: pair { 0.5 , Color :: kBlue }}; LEDPattern steps = LEDPattern . Steps ( colorSteps ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Progress mask Slightly different from the basic color patterns, the progress mask pattern generates a white-and-black pattern where the white portion is a varying length depending on the value of the value function. This can be combined with another pattern using a mask to display a portion of another base pattern depending on the progress of some process - such as the position of a mechanism in its range of motion (eg an elevator’s height) or the progress of a PID controller towards its goal. Java // Create an LED pattern that displays a black-and-white mask that displays the current height of an elevator // mechanism. This can be combined with other patterns to change the displayed color to something other than white. LEDPattern pattern = LEDPattern . progressMaskLayer (() -> m_elevator . getHeight () / m_elevator . getMaxHeight ()); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a black-and-white mask that displays the current height of an elevator // mechanism. This can be combined with other patterns to change the displayed color to something other than white. LEDPattern pattern = LEDPattern :: ProgressMaskLayer ([ & ]() { return m_elevator . GetHeight () / m_elevator . GetMaxHeight (); }); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Modifying effects Basic LED patterns can be combined with modifier effects to create new patterns with a combination of effects. Multiple modifiers can be used together to create complex patterns. Note The built in animating effects like blinking and scrolling are based on the time returned by WPIUtilJNI.now() - in effect, they will play as if they started when the robot booted. Because all built in animation patterns are periodic, this means that the first period of a pattern may be truncated at any arbitrary point between 0% and 100%, and every period after that will play normally. Offset Offsets can be used to bias patterns forward of backward by a certain number of pixels. Offset patterns will wrap around the end of an LED strip; offset values can be positive (biasing away from the start of the strip) or negative (biasing towards the start of the strip). Java // Create an LED pattern that displays a red-to-blue gradient, offset 40 pixels forward. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . offsetBy ( 40 ); LEDPattern negative = base . offsetBy ( - 20 ); // Equivalent to the above when applied to a 60-LED buffer // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, offset 40 pixels forward. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . OffsetBy ( 40 ); LEDPattern negative = base . OffsetBy ( -20 ); // Equivalent to the above when applied to a 60-LED buffer // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Reverse Patterns and animations can be reversed to flip the direction that patterns are applied in; instead of starting from the lowest-indexed pixel in a buffer or view, a reversed pattern will start from the highest-indexed pixel and move toward the lowest-index pixel. A reversed scrolling pattern will scroll in reverse, as if its velocity’s sign was flipped. Java // Create an LED pattern that displays a red-to-blue gradient, then reverse it so it displays blue-to-red. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . reversed (); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, then reverse it so it displays blue-to-red. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . Reversed (); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Scroll Scrolling can be controlled in two different ways: either at a speed as a function of the length of the buffer or view to which it is applied (i.e., the scrolling speed is in terms of percentage per second, or a similar unit), or as a function of the density of the physical LED strips (i.e. scrolling speed is in meters per second, or a similar unit). Relative velocities are particularly useful when a scrolling pattern is applied to different LED strips with different LED spacing (such as one strip with 120 LEDs per meter daisy chained to a second strip with 60 or 144 LEDs per meter), when prototyping before having a particular LED strip in mind (where the density isn’t yet known), or when LED strips are quickly changed out. Scrolling at a fixed real-world speed (eg InchesPerSecond.of(2) ) may be more understandable to readers, but will move faster or slower when applied to an LED strip with a lower or higher pixel density, respectively. Java // Create an LED pattern that displays a red-to-blue gradient, then scroll at one quarter of the LED strip's length per second. // For a half-meter length of a 120 LED-per-meter strip, this is equivalent to scrolling at 12.5 centimeters per second. Distance ledSpacing = Meters . of ( 1 / 120.0 ); LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . scrollAtRelativeSpeed ( Percent . per ( Second ). of ( 25 )); LEDPattern absolute = base . scrollAtAbsoluteSpeed ( Centimeters . per ( Second ). of ( 12.5 ), ledSpacing ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, then scroll at one quarter of the LED strip's length per second. // For a half-meter length of a 120 LED-per-meter strip, this is equivalent to scrolling at 12.5 centimeters per second. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . ScrollAtRelativeSpeed ( units :: hertz_t { 0.25 }); LEDPattern absolute = base . ScrollAtAbsoluteSpeed ( 0.125 _mps , units :: meter_t { 1 / 120.0 }); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Breathe A breathing modifier will make the base pattern brighten and dim in a sinusoidal pattern over the given period of time. Brightness is relative to the original brightness of the base pattern - breathing will only make it dimmer, never brighter than the original. Java // Create an LED pattern that displays a red-to-blue gradient, breathing at a 2 second period (0.5 Hz) LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . breathe ( Seconds . of ( 2 )); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, breathing at a 2 second period (0.5 Hz) std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . Breathe ( 2 _s ); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Blink Blinking can be done in one of three ways: Symmetrically, where an equal amount of time is spent in the “on” and “off” states per cycle Asymetrically, where the time spent “on” can be configured independently from the time spent “off” Synchronously, where the time spent on and off is synchronized with an external source (for example, the state of the RSL) Java // Create an LED pattern that displays a red-to-blue gradient, blinking at various rates. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); // 1.5 seconds on, 1.5 seconds off, for a total period of 3 seconds LEDPattern pattern = base . blink ( Seconds . of ( 1.5 )); // 2 seconds on, 1 second off, for a total period of 3 seconds LEDPattern asymmetric = base . blink ( Seconds . of ( 2 ), Seconds . of ( 1 )); // Turn the base pattern on when the RSL is on, and off when the RSL is off LEDPattern sycned = base . synchronizedBlink ( RobotController :: getRSLState ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, blinking at various rates. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); // 1.5 seconds on, 1.5 seconds off, for a total period of 3 seconds LEDPattern pattern = base . Blink ( 1.5 _s ); // 2 seconds on, 1 second off, for a total period of 3 seconds LEDPattern asymmetric = base . Blink ( 2 _s , 1 _s )); // Turn the base pattern on when the RSL is on, and off when the RSL is off LEDPattern sycned = base . SynchronizedBlink ([]() { return RobotController . GetRSLState (); }); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Brightness Patterns can be brightened and dimmed relative to their original brightness; a brightness value of 100% is identical to the original pattern, a value of 200% is twice as bright, and a value of 0% is completely turned off. This can be useful in a pinch to tone down patterns that are too bright (apologies to the 2024 NE Greater Boston district event staff, who were subjected to a maximimum brightness white flashing pattern with a precursor version of this library before the brightness modifier was added). Note For speed, brightness calculations are done naively in the RGB color space instead of HSL/HSV/Lab. This sacrifices accuracy, so large changes in brightness may look undersaturated. Java // Create an LED pattern that displays a red-to-blue gradient at half brightness LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . atBrightness ( Percent . of ( 50 )); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient at half brightness std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . AtBrightness ( 0.5 ); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Combinatory effects Complex LED patterns are built up from combining simple base patterns (such as solid colors or gradients) with animating effects (such as scrolling or breathing) and combinatory effects (like masks and overlays). Multiple effects can be combined at once, like in the scrolling rainbow effect above that takes a basic base effect - a static rainbow - and then adds a scrolling effect to it. Mask Masks work by combining the RGB values of two patterns and keeping only the values that are shared by both. The combination works on the individual bits of each color using a bitwise AND operation - for example, if a pixel’s red channel were set to 255 by one pattern (represented as 11111111 in binary), then the output red color would be identical to the red channel of the second pattern. If the first pattern sets it to zero (00000000 in binary), then the output red color would also be zero, regardless of whatever the second pattern sets. For this reason, black (all zeroes) and white (all ones) masks are very useful for selectively enabling and disabling parts of another pattern. Other mask colors can be used as well: masking with solid red would keep only the red channel of the original pattern, while discarding all green and blue values. Java // Create an LED pattern that displays a red-to-blue gradient at a variable length // depending on the relative position of the elevator. The blue end of the gradient // will only be shown when the elevator gets close to its maximum height; otherwise, // that end will be solid black when the elevator is at lower heights. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern mask = LEDPattern . progressMaskLayer (() -> m_elevator . getHeight () / m_elevator . getMaxHeight ()); LEDPattern heightDisplay = base . mask ( mask ); // Apply the LED pattern to the data buffer heightDisplay . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient at a variable length // depending on the relative position of the elevator. The blue end of the gradient // will only be shown when the elevator gets close to its maximum height; otherwise, // that end will be solid black when the elevator is at lower heights. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern mask = LEDPattern :: ProgressMaskLayer ([ & ]() { m_elevator . GetHeight () / m_elevator . GetMaxHeight () }); LEDPattern heightDisplay = base . Mask ( mask ); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Masks can also be animated (see progressMask ). Masking a base pattern with a scrolling pattern will result in a panning effect. The animation above was generated by masking a rainbow pattern with a scrolling white/black pattern Java Map < Double , Color > maskSteps = Map . of ( 0 , Color . kWhite , 0.5 , Color . kBlack ); LEDPattern base = LEDPattern . rainbow ( 255 , 255 ); LEDPattern mask = LEDPattern . steps ( maskSteps ). scrollAtRelativeSpeed ( Percent . per ( Second ). of ( 0.25 )); LEDPattern pattern = base . mask ( mask ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ std :: array < std :: pair < double , Color > , 2 > maskSteps { std :: pair { 0.0 , Color :: kWhite }, std :: pair { 0.5 , Color :: kBlack }}; LEDPattern base = LEDPattern :: Rainbow ( 255 , 255 ); LEDPattern mask = LEDPattern :: Steps ( maskSteps ). ScrollAtRelativeSpeed ( units :: hertz_t { 0.25 }); LEDPattern pattern = base . Mask ( mask ); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Overlay Overlays can be used to “stack” patterns atop each other, where black pixels (set to Color.kBlack , RGB value #000000) are treated as transparent and allow a lower layer to be displayed. Upper layers are typically combined with masks to set transparent sections; recall that masking a pixel with Color.kBlack will set that pixel to black, which will then be treated by the overlay as transparent. Blend Blends will combine the output colors of patterns together, by averaging out the individual RGB colors for every pixel. Like the brightness modifier , this tends to output colors that are more desaturated than its inputs. Low Level Access LEDPattern is an easy and convenient way of controlling LEDs, but direct access to the LED colors is sometimes needed for custom patterns and animations. Color can be set to an individual led on the strip using two methods: setRGB() , which takes RGB values as an input, and setHSV() , which takes HSV values as an input. Low-level access is typically done with an indexed for-loop that iterates over each LED index of the section to control. This method can be used for both AddressableLEDBuffer and AddressableLEDBufferView objects in Java, and for std::span for C++. Note RGB stands for Red, Green, and Blue. This is a fairly common color model as it’s quite easy to understand, and it corresponds with a typical LED configuration that’s comprised of one red, one green, and one blue sub-LED. LEDs can be set with the setRGB method that takes 4 arguments: index of the LED, amount of red, amount of green, amount of blue. The amount of red, green, and blue are integer values between 0-255. Note HSV stands for Hue, Saturation, and Value. Hue describes the color or tint, saturation being the amount of gray, and value being the brightness. In WPILib, Hue is an integer from 0 - 180. Saturation and Value are integers from 0 - 255. If you look at a color picker like Google’s , Hue will be 0 - 360 and Saturation and Value are from 0% to 100%. This is the same way that OpenCV handles HSV colors. Make sure the HSV values entered to WPILib are correct, or the color produced might not be the same as was expected. These examples demonstrate setting an entire LED strip to solid red using the RGB and HSV methods: Java (RGB) for ( var i = 0 ; i < m_ledBuffer . getLength (); i ++ ) { // Sets the specified LED to the RGB values for red m_ledBuffer . setRGB ( i , 255 , 0 , 0 ); } m_led . setData ( m_ledBuffer ); C++ (RGB) for ( int i = 0 ; i < kLength ; i ++ ) { m_ledBuffer [ i ]. SetRGB ( 255 , 0 , 0 ); } m_led . SetData ( m_ledBuffer ); Java (HSV) for ( var i = 0 ; i < m_ledBuffer . getLength (); i ++ ) { // Sets the specified LED to the HSV values for red m_ledBuffer . setHSV ( i , 0 , 100 , 100 ); } m_led . setData ( m_ledBuffer ); C++ (HSV) for ( int i = 0 ; i < kLength ; i ++ ) { m_ledBuffer [ i ]. SetHSV ( 0 , 100 , 100 ); } m_led . SetData ( m_ledBuffer ); Using HSV Values",
      "content_preview": "Addressable LEDs LED strips have been commonly used by teams for several years for a variety of reasons. They allow teams to debug robot functionality from the audience, provide a visual marker for their robot, and can simply add some visual appeal."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/java-units.html",
      "title": "The Java Units Library",
      "section": "Basic Programming",
      "language": "Java",
      "content": "The Java Units Library Note New for 2025: The units library has been refactored to have unit-specific measurement classes instead of a single generic Measure class. The new measurement classes have clearer names ( Distance instead of Measure<Distance> , or LinearAcceleration instead of Measure<Velocity<Velocity<Distance>>> ), and implement math operations to return the most specific result types possible instead of a wildcard Measure<?> . The units library is a tool that helps programmers avoid mistakes related to units of measurement. It does this by keeping track of the units of measurement, and by ensuring that all operations are performed with the correct units. This can help to prevent errors that can lead to incorrect results, such as adding a distance in inches to a distance in meters. An added benefit is readability and maintainability, which also reduces bugs. By making the units of measurement explicit in your code, it becomes easier to read and understand what your code is doing. This can also help to make your code more maintainable, as it is easier to identify and fix errors related to units of measurement. The units library has a number of features: A set of predefined units, such as meters, degrees, and seconds. The ability to convert between different units. Support for performing arithmetic and comparisons on quantities with units. Support for displaying quantities with units in a human-readable format. Terminology Dimension Dimensions represent the nature of a physical quantity, such as length, time, or mass. They are independent of any specific unit system. For example, the dimension of meters is length, regardless of whether the length is expressed in meters, millimeters, or inches. Unit Units are specific realizations of dimensions. They are the way of expressing physical quantities. Each dimension has a base unit, such as the meter for length, the second for time, the kilogram for mass. Derived units are formed by combining base units, such as meters per second for velocity. Measure Measures are the specific magnitude of physical quantities, expressed in a particular unit. For example, 5 meters is a measure of distance. These concepts are used within the Units Library. For example, the measure 10 seconds has a magnitude of 10, the dimension is time, and the unit is seconds. Using the Units Library The Java units library is available in the edu.wpi.first.units package. The most relevant classes are: The various classes for predefined dimensions, such as DistanceUnit and TimeUnit Units , which contains a set of predefined units. Take a look a the Units javadoc to browse the available units and their types. Measure , which is used to tag a value with a unit, and the dimension-specific implementations like Distance and Time Note It is recommended to static import edu.wpi.first.units.Units.* to get full access to all the predefined units. Creating Measures Every dimension has a measurement class with the corresponding name - for example, a Distance measures distance, Time measures time, and LinearVelocity measures linear velocity. To instantiate one of these measurements, call the Unit.of method on the appropriate unit object. For example, to create a Distance object representing a distance of 6 inches, you would write: Distance wheelDiameter = Inches . of ( 6 ); Other measures can also be created using their Unit.of method: Mass kArmMass = Kilograms . of ( 1.423 ); Distance kArmLength = Inches . of ( 32.25 ); Angle kMinArmAngle = Degrees . of ( 5 ); Angle kArmMaxTravel = Rotations . of ( 0.45 ); LinearVelocity kMaxSpeed = MetersPerSecond . of ( 2.5 ); Warning Composite units with PerUnit and MultUnit have special requirements, and the of method is not recommended to be used with them Using Composite Unit Types Due to requirements of inheritance in Java’s type system, PerUnit and MultUnit cannot return a normal Per or Mult object from their of factory methods. Instead, they need to return a bounded wildcard Measure<? extends PerUnit<...>> or Measure<? extends MultUnit<...>> to allow subclasses like LinearVelocity to return a compatible type. New ofNative methods are provided to be able to work with known Per and Mult objects // Using ofNative: Per < VoltageUnit , DistanceUnit > kP = VoltsPerMeter . ofNative ( 1 ); kP . in ( VoltsPerMeter ); // 1.0 Measure < VoltageUnit > output = kP . timesDivisor ( Meters . of ( 1 )); output . in ( Volts ); // 1.0 // Without ofNative Measure <? extends PerUnit < VoltageUnit , DistanceUnit >> kP = VoltsPerMeter . of ( 1 ); kP . in ( VoltsPerMeter ); // Compilation error! Measure <?> output = kP . times ( Meters . of ( 1 )); // The compiler can't know what unit this is output . in ( Volts ); // Compilation error! Performing Calculations The Measure class also supports arithmetic operations, such as addition, subtraction, multiplication, and division. These are done by calling methods on the objects. These operations always ensure that the units are compatible before performing the calculation, and they return a new Measure object. For example, you can add two Distance objects together, even if they have different units: Distance distance1 = Inches . of ( 10 ); Distance distance2 = Meters . of ( 0.254 ); Distance totalDistance = distance1 . plus ( distance2 ); In this code, the units library will automatically convert the measures to the same unit before adding the two distances. The resulting totalDistance object will be a new Distance object that has a value of 0.508 meters, or 20 inches. Note Mathematical operations are type safe. It is impossible to add a distance to a time, or subtract an angle from a voltage. However, multiplication and division operations make a best-effort attempt to return results in the most appropriate unit type; dividing a distance by time results in a LinearVelocity measurement, and multiplying it by time returns a Distance . This example combines the wheel diameter and gear ratio to calculate the distance per rotation of the wheel: Distance wheelDiameter = Inches . of ( 3 ); double gearRatio = 10.48 ; Distance distancePerRotation = wheelDiameter . times ( Math . PI ). divide ( gearRatio ); Warning By default, arithmetic operations create new Measure instances for their results. See Java Garbage Collection for discussion on creating a large number of short-lived objects. See also, the Mutability and Object Creation section below for a possible workaround. Converting Units Unit conversions can be done by calling Measure.in(Unit) . The Java type system will prevent units from being converted between incompatible types, such as distances to angles. The returned values will be bare double values without unit information - it is up to you, the programmer, to interpret them correctly! It is strongly recommended to only use unit conversions when interacting with APIs that do not support the units library. LinearVelocity kMaxVelocity = FeetPerSecond . of ( 12.5 ); LinearAcceleration kMaxAcceleration = FeetPerSecond . per ( Second ). of ( 22.9 ); kMaxVelocity . in ( MetersPerSecond ); // => OK! Returns 3.81 kMaxVelocity . in ( RadiansPerSecond ); // => Compile error! LinearVelocity cannot be converted to AngularVelocity // The WPILib math libraries use SI metric units, so we have to convert to meters: TrapezoidProfile . Constraints kDriveConstraints = new TrapezoidProfile . Constraints ( maxVelocity . in ( MetersPerSecond ), maxAcceleration . in ( MetersPerSecondPerSecond ) ); Usage Example Pulling all of the concepts together, we can create an example that calculates the end effector position of an arm mechanism: Distance armLength = Feet . of ( 3 ). plus ( Inches . of ( 4.25 )); Distance endEffectorX = armLength . times ( Math . cos ( getArmAngle (). in ( Radians ))); Distance endEffectorY = armLength . times ( Math . sin ( getArmAngle (). in ( Radians ))); Human-readable Formatting The Measure class has methods that can be used to get a human-readable representation of the measure. This feature is useful to display a measure on a dashboard or in logs. toString() and toShortString() return a string representation of the measure in a shorthand form. The symbol of the backing unit is used, rather than the full name, and the magnitude is represented in scientific notation. For example, 1.234e+04 V/m toLongString() returns a string representation of the measure in a longhand form. The name of the backing unit is used, rather than its symbol, and the magnitude is represented in a full string, not scientific notation. For example, 1234 Volt per Meter Mutability and Object Creation To reduce the number of object instances you create, and reduce memory usage, a special MutableMeasure class is available, with unit-specific subtypes like MutDistance and MutTime . You may want to consider using mutable objects if you are using the units library repeatedly, such as in the robot’s periodic loop. See Java Garbage Collection for more discussion on creating a large number of short-lived objects. Mutable measures can be created in a similar way to regular, immutable measures using the Unit.mutable method (instead of Unit.of ). MutableMeasure allows the internal state of the object to be updated, such as with the results of arithmetic operations, to avoid allocating new objects. Special care needs to be taken when mutating a measure because it will change the value every place that instance is referenced. If the object will be exposed as part of a public method, have that method return a regular Measure in its signature to prevent the caller from modifying your internal state. Extra methods are available on MutableMeasure for updating the internal value. Note that these methods all begin with the mut_ prefix - this is to make it obvious that these methods will be mutating the object and are potentially unsafe! For the full list of methods and API documentation, see the MutableMeasure API documentation mut_plus(double, Unit) Increments the internal value by an amount in another unit. The internal unit will stay the same mut_plus(Measure) Increments the internal value by another measurement. The internal unit will stay the same mut_minus(double, Unit) Decrements the internal value by an amount in another unit. The internal unit will stay the same mut_minus(Measure) Decrements the internal value by another measurement. The internal unit will stay the same mut_times(double) Multiplies the internal value by a scalar mut_divide(double) Divides the internal value by a scalar mut_replace(double, Unit) Overrides the internal state and sets it to equal the given value and unit mut_replace(Measure) Overrides the internal state to make it identical to the given measurement mut_setMagnitude(double) Overrides the internal value, keeping the internal unit. Be careful when using this! MutDistance measure = Feet . mutable ( 0 ); measure . mut_plus ( 10 , Inches ); // 0.8333 feet measure . mut_plus ( Inches . of ( 10 )); // 1.6667 feet measure . mut_minus ( 5 , Inches ); // 1.25 feet measure . mut_minus ( Inches . of ( 5 )); // 0.8333 feet measure . mut_times ( 6 ); // 0.8333 * 6 = 5 feet measure . mut_divide ( 5 ); // 5 / 5 = 1 foot measure . mut_replace ( 6.2 , Meters ) // 6.2 meters - note the unit changed! measure . mut_replace ( Millimeters . of ( 14.2 )) // 14.2mm - the unit changed again! measure . mut_setMagnitude ( 72 ) // 72mm Revisiting the arm example from above, we can use mut_replace - and, optionally, mut_times - to calculate the end effector position import edu.wpi.first.units.Measure ; import edu.wpi.first.units.MutableMeasure ; import static edu.wpi.first.units.Units.* ; public class Arm { // Note the two ephemeral object allocations for the Feet.of and Inches.of calls. // Because this is a constant value computed just once, they will easily be garbage collected without // any problems with memory use or loop timing jitter. private static final Distance kArmLength = Feet . of ( 3 ). plus ( Inches . of ( 4.25 )); // Angle and X/Y locations will likely be called in the main robot loop, let's store them in a MutableMeasure // to avoid allocating lots of short-lived objects private final MutAngle m_angle = Degrees . mutable ( 0 ); private final MutDistance m_endEffectorX = Feet . mutable ( 0 ); private final MutDistance m_endEffectorY = Feet . mutable ( 0 ); private final Encoder m_encoder = new Encoder (...); public Distance getEndEffectorX () { return m_endEffectorX . mut_replace ( Math . cos ( getAngle (). in ( Radians )) * kArmLength . in ( Feet ), // the new magnitude to store Feet // the units of the new magnitude ); } public Distance getEndEffectorY () { // An alternative approach so we don't have to unpack and repack the units m_endEffectorY . mut_replace ( kArmLength ); m_endEffectorY . mut_times ( Math . sin ( getAngle (). in ( Radians ))); return m_endEffectorY ; } public Angle getAngle () { double rawAngle = m_encoder . getPosition (); m_angle . mut_replace ( rawAngle , Degrees ); // NOTE: the encoder must be configured with distancePerPulse in terms of degrees! return m_angle ; } } Warning MutableMeasure objects can - by definition - change their values at any time! It is unsafe to keep a stateful reference to them - prefer to extract a value using the Measure.in method, or create a copy with Measure.copy that can be safely stored. For the same reason, library authors must also be careful about methods accepting Measure . Can you spot the bug in this code? private Distance m_lastDistance ; public Distance calculateDelta ( Distance currentDistance ) { if ( m_lastDistance == null ) { m_lastDistance = currentDistance ; return currentDistance ; } else { Distance delta = currentDistance . minus ( m_lastDistance ); m_lastDistance = currentDistance ; return delta ; } } If we run the calculateDelta method a few times, we can see a pattern: MutDistance distance = Inches . mutable ( 0 ); distance . mut_plus ( 10 , Inches ); calculateDelta ( distance ); // expect 10 inches and get 10 - good! distance . mut_plus ( 2 , Inches ); calculateDelta ( distance ); // expect 2 inches, but get 0 instead! distance . mut_plus ( 8 , Inches ); calculateDelta ( distance ); // expect 8 inches, but get 0 instead! This is because the m_lastDistance field is a reference to the same MutDistance object as the input! Effectively, the delta is calculated as (currentDistance - currentDistance) on every call after the first, which naturally always returns zero. One solution would be to track m_lastDistance as a copy of the input measure to take a snapshot; however, this approach does incur one extra object allocation for the copy. If you need to be careful about object allocations, m_lastDistance could also be stored as a MutDistance . Immutable Copies private Distance m_lastDistance ; public Distance calculateDelta ( Distance currentDistance ) { if ( m_lastDistance == null ) { m_lastDistance = currentDistance . copy (); return currentDistance ; } else { var delta = currentDistance . minus ( m_lastDistance ); m_lastDistance = currentDistance . copy (); return delta ; } } Zero-allocation Mutables private final MutDistance m_lastDistance = Meters . mutable ( 0 ); private final MutDistance m_delta = Meters . mutable ( 0 ); public Distance calculateDelta ( Distance currentDistance ) { // m_delta = currentDistance - m_lastDistance m_delta . mut_replace ( currentDistance ); m_delta . mut_minus ( m_lastDistance ); m_lastDistance . mut_replace ( currentDistance ); return m_delta ; } Defining New Units There are four ways to define a new unit that isn’t already present in the library: Using the Unit.per or Unit.mult methods to create a composite of two other units; Using the Milli , Micro , and Kilo helper methods; Using the derive method and customizing how the new unit relates to the base unit; and Subclassing Unit to define a new dimension. New units can be defined as combinations of existing units using the Unit.mult and Unit.per methods. PerUnit < VoltageUnit , DistanceUnit > VoltsPerInch = Volts . per ( Inch ); VelocityUnit < MassUnit > KgPerSecond = Kilograms . per ( Second ); // Could also be declared as PerUnit<MassUnit, TimeUnit> DistanceUnit FootMinutesPerSecond = FeetPerSecond . mult ( Minutes ); Using mult and per will store the resulting unit. Every call will return the same object to avoid unnecessary allocations and garbage collector pressure. @Override public void robotPeriodic () { // Feet.per(Millisecond) creates a new unit on the first loop, // which will be reused on every successive loop SmartDashboard . putNumber ( \"Speed\" , m_drivebase . getSpeed (). in ( Feet . per ( Millisecond ))); } Note Calling Unit.per(Time) will return a Velocity unit, which is different from and incompatible with a Per unit! New dimensions can also be created by subclassing Unit and implementing the two constructors. Dimension-specific measurement types are recommended, but take considerable effort to implement all the unit-specific math operations. public class ElectricChargeUnit extends Unit { public ElectricCharge ( double baseUnitEquivalent , String name , String symbol ) { super ( ElectricCharge . class , baseUnitEquivalent , name , symbol ); } // required for derivation with Milli, Kilo, etc. public ElectricCharge ( UnaryFunction toBaseConverter , UnaryFunction fromBaseConverter , String name , String symbol ) { super ( ElectricCharge . class , toBaseConverter , fromBaseConverter , name , symbol ); } @Override public ElectricChargeUnit getBaseUnit () { // The base method must be overridden in order to return the correct type return ( ElectricChargeUnit ) super . getBaseUnit (); } @Override public Measure < ElectricChargeUnit > of ( double magnitude ) { return ImmutableMeasure . ofRelativeUnits ( magnitude , this ); } @Override public Measure < ElectricChargeUnit > ofBaseUnits ( double baseUnitMagnitude ) { return ImmutableMeasure . ofBaseUnits ( baseUnitMagnitude , this ); } @Override public Measure < ElectricChargeUnit > zero () { return ( Measure < ElectricChargeUnit > ) super . zero (); } @Override public Measure < ElectricChargeUnit > one () { return ( Measure < ElectricChargeUnit > ) super . one (); } @Override public MutableMeasure < ElectricChargeUnit > mutable ( double magnitude ) { return new GenericMutableMeasureImpl ( magnitude , toBaseUnits ( magnitude ), this ); } @Override public VelocityUnit < ElectricChargeUnit > per ( TimeUnit period ) { // Note: technically, this would return a CurrentUnit, since electric charge per time is current (measured in Amperes) return VelocityUnit . combine ( this , period ); } public double convertFrom ( double magnitude , ElectricChargeUnit otherUnit ) { return fromBaseUnits ( otherUnit . toBaseUnits ( magnitude )); } } public static final ElectricCharge Coulomb = new ElectricCharge ( 1 , \"Coulomb\" , \"C\" ); public static final ElectricCharge ElectronCharge = new ElectricCharge ( 1.60217646e-19 , \"Electron Charge\" , \"e\" ); public static final ElectricCharge AmpHour = new ElectricCharge ( 3600 , \"Amp Hour\" , \"Ah\" ); public static final ElectricCharge MilliampHour = Milli ( AmpHour );",
      "content_preview": "The Java Units Library Note New for 2025: The units library has been refactored to have unit-specific measurement classes instead of a single generic Measure class."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/java-gc.html",
      "title": "Java Garbage Collection",
      "section": "Basic Programming",
      "language": "Java",
      "content": "Java Garbage Collection Java garbage collection is the process of automatically managing memory for Java objects. The Java Virtual Machine (JVM) is responsible for creating and destroying objects, and the garbage collector is responsible for identifying and reclaiming unused objects. Java garbage collection is an automatic process, which means that the programmer does not need to explicitly deallocate memory. The garbage collector keeps track of which objects are in use and which are not, and it periodically reclaims unused objects. Object Creation Creating a large number of objects in Java can lead to memory and performance issues. While the Java Garbage Collector (GC) is designed to handle memory management efficiently, creating too many objects can overwhelm the GC and cause performance degradation. Memory Concerns When a large number of objects are created, it increases the overall memory footprint of the application. While the overhead for a single object may be insignificant, it can become substantial when multiplied by a large number of objects. Note VisualVM can be used to see where memory is allocated. Performance Concerns The GC’s job is to periodically identify and reclaim unused objects in memory. While garbage collection is running on an FRC robot coded in Java, execution of the robot program is paused. When the GC has to collect a large number of objects, it has to pause the application to run more frequently or for longer periods of time. This is because the GC has to perform more work to collect and process each object. GC-related performance degradation in robot programs can manifest as occasional pauses, freezes, or loop overruns as the GC works to reclaim memory. Design Considerations If you anticipate your application creating a large number of short-lived objects, it is important to consider design strategies to mitigate the potential memory and performance issues. Here are some strategies to consider: Minimize object creation: Carefully evaluate the need for each object creation. If possible, reuse existing objects or use alternative data structures, such as arrays or primitives, to avoid creating new objects. Efficient data structures: Use data structures that are well-suited for the type of data you are working with. For example, if you are dealing with a large number of primitive values, consider using arrays or collections specifically designed for primitives. Diagnosing Out of Memory Errors with Heap Dumps All objects in Java are retained in a section of memory called the heap . As objects typically consume the greatest amount of memory in a Java program, it is often useful to take a snapshot of the state of the heap—a heap dump—to analyze memory issues. Heap dumps only capture the state of a program’s heap at a single point in time, so they are unlikely to be useful if not captured exactly at the time the program is experiencing memory issues. Since OutOfMemoryError s both crash the program and are a common reason to want a heap dump, the JVM can be configured to automatically take a heap dump the moment an OutOfMemoryError is caught by the JVM. To configure these options, locate the frcJava code block in your project’s build.gradle : 15 deploy { 16 targets { 17 roborio ( getTargetTypeClass ( 'RoboRIO' )) { 18 // Team number is loaded either from the .wpilib/wpilib_preferences.json 19 // or from command line. If not found an exception will be thrown. 20 // You can use getTeamOrDefault(team) instead of getTeamNumber if you 21 // want to store a team number in this file. 22 team = project . frc . getTeamNumber () 23 debug = project . frc . getDebugOrDefault ( false ) 24 25 artifacts { 26 // First part is artifact name, 2nd is artifact type 27 // getTargetTypeClass is a shortcut to get the class type using a string 28 29 frcJava ( getArtifactTypeClass ( 'FRCJavaArtifact' )) { 30 } 31 32 // Static files artifact 33 frcStaticFileDeploy ( getArtifactTypeClass ( 'FileTreeArtifact' )) { 34 files = project . fileTree ( 'src/main/deploy' ) 35 directory = '/home/lvuser/deploy' 36 deleteOldFiles = false // Change to true to delete files on roboRIO that no 37 // longer exist in deploy directory of this project 38 } 39 } 40 } 41 } 42 } Add to the code block so that it contains two jvmArgs commands, as shown below: frcJava ( getArtifactTypeClass ( 'FRCJavaArtifact' )) { // If you have other configuration here, you do not need to remove it. // Enable automatic heap dumps on OutOfMemoryError // Note: the heap dump path here is a path on a USB flash drive, see below jvmArgs . add ( \"-XX:+HeapDumpOnOutOfMemoryError\" ) jvmArgs . add ( \"-XX:HeapDumpPath=/u/frc-usercode.hprof\" ) } This will cause the JVM to write heap dumps to a file named frc-usercode.hprof at the root of a USB flash drive attached to the roboRIO when the code runs out of memory. It is recommended to save these heap dumps to a USB flash drive because heap dumps intrinsically consume the same amount of space on disk as the program heap did in memory when the program crashed, and are likely to be larger than the roboRIO’s internal storage has capacity for. Once you have reproduced the OutOfMemoryError , redeploy your code without these options enabled, and use the USB flash drive to transfer the heap dump to a computer for analysis in a memory profiler such as VisualVM . Warning Configuring the JVM this way requires that the flash drive remain connected to the roboRIO while your code is running. Larger SD cards may provide enough onboard storage to allow the use of these options on the roboRIO 2 without a USB flash drive. To do this, set the -XX:HeapDumpPath option to reference a path on the SD card, and use FTP/SFTP to transfer the heap dump to a computer before deleting it from the SD card. Note that the JVM will not overwrite heap dumps with the exact path and filename specified by -XX:HeapDumpPath if they already exist, nor will it dump the process heap to a file with a different name. If a path to a directory is supplied instead of a path to a file, the JVM will instead write out heap dumps with unique filenames within the specified directory, with the name java_pidNNNN.hprof , where NNNN is the process ID of the JVM that ran out of memory. Note that this can cause large files to build up on disk if they are not cleaned out, so if you configure the JVM this way, be sure to frequently copy heap dumps to a computer and delete them from the flash drive/SD card afterward. Caution Always be vigilant about the amount of available space on the underlying storage medium while you use this feature. Use of this feature is not recommended during competitive play. System Memory Tuning If the JVM cannot allocate memory, the program will be terminated. As an embedded system with only a small amount of memory available (256 MB on the roboRIO 1, 512 MB on the roboRIO 2), the roboRIO is particularly susceptible to running out of memory. No amount of system tuning can fix out of memory errors caused by out-of-control allocations. If you are running out of memory, always investigate allocations with heap dumps and/or VisualVM first. If you continue to run out of memory even after investigating with VisualVM and taking steps to minimize the number of allocated objects, a few different options are available to make additional memory available to the robot program. Disabling the system web server Setting sysctls (Linux kernel options) Periodically calling the garbage collector Setting up swap on a USB flash drive Implementing most of these options require connecting with SSH to the roboRIO and running commands. If run incorrectly, it may require a reimage to recover, so be careful when following the instructions. Disabling the System Web Server The built-in NI system web server provides the webpage (the roboRIO Web Dashboard ) seen when using a web browser to connect to the roboRIO, e.g. to change IP address settings. It also is used by the Driver Station’s data log download functionality. However, it consumes several MB of RAM, so disabling it will free up that memory for the robot program to use. There are several ways to disable the web server: The first and easiest is to use the RoboRIO Team Number Setter tool. Versions 2024.2.1 and later of the tool have a button to disable or enable the web server. However, a few teams have reported that this does not work or does not persist between reboots. There are two alternate ways to disable the web server; both require connecting to the roboRIO with SSH and logging in as the admin user. Run /etc/init.d/systemWebServer stop; update-rc.d -f systemWebServer remove; sync Run chmod a-x /usr/local/natinst/etc/init.d/systemWebServer; sync To revert the alternate ways and re-enable the web server, take the corresponding step: Run update-rc.d -f systemWebServer defaults; /etc/init.d/systemWebServer start; sync Run chmod a+x /usr/local/natinst/etc/init.d/systemWebServer; sync Setting sysctls Several Linux kernel options (called sysctls) can be set to tweak how the kernel allocates memory. Several options have been found to reduce out-of-memory errors: Setting vm.overcommit_memory to 1 (the default value is 2). This causes the kernel to always pretend there is enough memory for a requested memory allocation at the time of allocation; the default setting always checks to see if there’s actually enough memory to back an allocation at the time of allocation, not when the memory is actually used. Setting vm.vfs_cache_pressure to 1000 (the default value is 100). Increasing this causes the kernel to much more aggressively reclaim file system object caches; it may slightly degrade performance. Setting vm.swappiness to 100 (the default value is 60). This causes the kernel to more aggressively swap process memory to the swap file. Changing this option has no effect unless you add a swap file. You can set some or all of these options; the most important one is vm.overcommit_memory . Setting these options requires connecting to the roboRIO with SSH and logging in as the admin user, then running the following commands: echo \"vm.overcommit_memory=1\" >> /etc/sysctl.conf echo \"vm.vfs_cache_pressure=1000\" >> /etc/sysctl.conf echo \"vm.swappiness=100\" >> /etc/sysctl.conf sync The /etc/sysctl.conf file should contain the following lines at the end when done (to check, you can run the command cat /etc/sysctl.conf ): vm.overcommit_memory=1 vm.vfs_cache_pressure=1000 vm.swappiness=100 To revert the change, edit /etc/sysctl.conf (this will require the use of the vi editor) and remove these 3 lines. Periodically Calling the Garbage Collector Sometimes the garbage collector won’t run frequently enough to keep up with the quantity of allocations. As Java provides a way to trigger a garbage collection to occur, running it on a periodic basis may reduce peak memory usage. This can be done by adding a Timer and a periodic check: Timer m_gcTimer = new Timer (); public Robot () { m_gcTimer . start (); } public void periodic () { // run the garbage collector every 5 seconds if ( m_gcTimer . advanceIfElapsed ( 5 )) { System . gc (); } } Setting Up Swap on a USB Flash Drive A swap file on a Linux system provides disk-backed space that can be used by the system as additional virtual memory to put infrequently used data and programs when they aren’t being used, freeing up physical RAM for active use such as the robot program. It is strongly recommended to not use the built-in non-replaceable flash storage on the roboRIO 1 for a swap file, as it has very limited write cycles and may wear out quickly. Instead, however, a FAT32-formatted USB flash drive may be used for this purpose. This does require the USB flash drive to always be plugged into the roboRIO before boot. Caution Having a swap file on a USB stick means it’s critical the USB stick stay connected to the roboRIO at all times it is powered. This should be used as a last resort if none of the other steps above help. Generally needing swap is indicative of some other allocation issue, so use VisualVM first to optimize allocations. A swap file can be set up by plugging the USB flash drive into the roboRIO USB port, connecting to the roboRIO with SSH and logging in as the admin user, and running the following commands. Note the vi step requires knowledge of how to edit and save a file in vi. fallocate -l 100M /u/swapfile mkswap /u/swapfile swapon /u/swapfile vi /etc/init.d/addswap.sh chmod a+x /etc/init.d/addswap.sh update-rc.d -v addswap.sh defaults sync The /etc/init.d/addswap.sh file contents should look like this: #!/bin/sh [ -x /sbin/swapon ] && swapon -e /u/swapfile : exit 0 To revert the change, run update-rc.d -f addswap.sh remove; rm /etc/init.d/addswap.sh; sync; reboot .",
      "content_preview": "Java Garbage Collection Java garbage collection is the process of automatically managing memory for Java objects. The Java Virtual Machine (JVM) is responsible for creating and destroying objects, and the garbage collector is responsible for identifying and reclaiming unused objects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/java-units.html?present",
      "title": "The Java Units Library",
      "section": "Basic Programming",
      "language": "Java",
      "content": "The Java Units Library Note New for 2025: The units library has been refactored to have unit-specific measurement classes instead of a single generic Measure class. The new measurement classes have clearer names ( Distance instead of Measure<Distance> , or LinearAcceleration instead of Measure<Velocity<Velocity<Distance>>> ), and implement math operations to return the most specific result types possible instead of a wildcard Measure<?> . The units library is a tool that helps programmers avoid mistakes related to units of measurement. It does this by keeping track of the units of measurement, and by ensuring that all operations are performed with the correct units. This can help to prevent errors that can lead to incorrect results, such as adding a distance in inches to a distance in meters. An added benefit is readability and maintainability, which also reduces bugs. By making the units of measurement explicit in your code, it becomes easier to read and understand what your code is doing. This can also help to make your code more maintainable, as it is easier to identify and fix errors related to units of measurement. The units library has a number of features: A set of predefined units, such as meters, degrees, and seconds. The ability to convert between different units. Support for performing arithmetic and comparisons on quantities with units. Support for displaying quantities with units in a human-readable format. Terminology Dimension Dimensions represent the nature of a physical quantity, such as length, time, or mass. They are independent of any specific unit system. For example, the dimension of meters is length, regardless of whether the length is expressed in meters, millimeters, or inches. Unit Units are specific realizations of dimensions. They are the way of expressing physical quantities. Each dimension has a base unit, such as the meter for length, the second for time, the kilogram for mass. Derived units are formed by combining base units, such as meters per second for velocity. Measure Measures are the specific magnitude of physical quantities, expressed in a particular unit. For example, 5 meters is a measure of distance. These concepts are used within the Units Library. For example, the measure 10 seconds has a magnitude of 10, the dimension is time, and the unit is seconds. Using the Units Library The Java units library is available in the edu.wpi.first.units package. The most relevant classes are: The various classes for predefined dimensions, such as DistanceUnit and TimeUnit Units , which contains a set of predefined units. Take a look a the Units javadoc to browse the available units and their types. Measure , which is used to tag a value with a unit, and the dimension-specific implementations like Distance and Time Note It is recommended to static import edu.wpi.first.units.Units.* to get full access to all the predefined units. Creating Measures Every dimension has a measurement class with the corresponding name - for example, a Distance measures distance, Time measures time, and LinearVelocity measures linear velocity. To instantiate one of these measurements, call the Unit.of method on the appropriate unit object. For example, to create a Distance object representing a distance of 6 inches, you would write: Distance wheelDiameter = Inches . of ( 6 ); Other measures can also be created using their Unit.of method: Mass kArmMass = Kilograms . of ( 1.423 ); Distance kArmLength = Inches . of ( 32.25 ); Angle kMinArmAngle = Degrees . of ( 5 ); Angle kArmMaxTravel = Rotations . of ( 0.45 ); LinearVelocity kMaxSpeed = MetersPerSecond . of ( 2.5 ); Warning Composite units with PerUnit and MultUnit have special requirements, and the of method is not recommended to be used with them Using Composite Unit Types Due to requirements of inheritance in Java’s type system, PerUnit and MultUnit cannot return a normal Per or Mult object from their of factory methods. Instead, they need to return a bounded wildcard Measure<? extends PerUnit<...>> or Measure<? extends MultUnit<...>> to allow subclasses like LinearVelocity to return a compatible type. New ofNative methods are provided to be able to work with known Per and Mult objects // Using ofNative: Per < VoltageUnit , DistanceUnit > kP = VoltsPerMeter . ofNative ( 1 ); kP . in ( VoltsPerMeter ); // 1.0 Measure < VoltageUnit > output = kP . timesDivisor ( Meters . of ( 1 )); output . in ( Volts ); // 1.0 // Without ofNative Measure <? extends PerUnit < VoltageUnit , DistanceUnit >> kP = VoltsPerMeter . of ( 1 ); kP . in ( VoltsPerMeter ); // Compilation error! Measure <?> output = kP . times ( Meters . of ( 1 )); // The compiler can't know what unit this is output . in ( Volts ); // Compilation error! Performing Calculations The Measure class also supports arithmetic operations, such as addition, subtraction, multiplication, and division. These are done by calling methods on the objects. These operations always ensure that the units are compatible before performing the calculation, and they return a new Measure object. For example, you can add two Distance objects together, even if they have different units: Distance distance1 = Inches . of ( 10 ); Distance distance2 = Meters . of ( 0.254 ); Distance totalDistance = distance1 . plus ( distance2 ); In this code, the units library will automatically convert the measures to the same unit before adding the two distances. The resulting totalDistance object will be a new Distance object that has a value of 0.508 meters, or 20 inches. Note Mathematical operations are type safe. It is impossible to add a distance to a time, or subtract an angle from a voltage. However, multiplication and division operations make a best-effort attempt to return results in the most appropriate unit type; dividing a distance by time results in a LinearVelocity measurement, and multiplying it by time returns a Distance . This example combines the wheel diameter and gear ratio to calculate the distance per rotation of the wheel: Distance wheelDiameter = Inches . of ( 3 ); double gearRatio = 10.48 ; Distance distancePerRotation = wheelDiameter . times ( Math . PI ). divide ( gearRatio ); Warning By default, arithmetic operations create new Measure instances for their results. See Java Garbage Collection for discussion on creating a large number of short-lived objects. See also, the Mutability and Object Creation section below for a possible workaround. Converting Units Unit conversions can be done by calling Measure.in(Unit) . The Java type system will prevent units from being converted between incompatible types, such as distances to angles. The returned values will be bare double values without unit information - it is up to you, the programmer, to interpret them correctly! It is strongly recommended to only use unit conversions when interacting with APIs that do not support the units library. LinearVelocity kMaxVelocity = FeetPerSecond . of ( 12.5 ); LinearAcceleration kMaxAcceleration = FeetPerSecond . per ( Second ). of ( 22.9 ); kMaxVelocity . in ( MetersPerSecond ); // => OK! Returns 3.81 kMaxVelocity . in ( RadiansPerSecond ); // => Compile error! LinearVelocity cannot be converted to AngularVelocity // The WPILib math libraries use SI metric units, so we have to convert to meters: TrapezoidProfile . Constraints kDriveConstraints = new TrapezoidProfile . Constraints ( maxVelocity . in ( MetersPerSecond ), maxAcceleration . in ( MetersPerSecondPerSecond ) ); Usage Example Pulling all of the concepts together, we can create an example that calculates the end effector position of an arm mechanism: Distance armLength = Feet . of ( 3 ). plus ( Inches . of ( 4.25 )); Distance endEffectorX = armLength . times ( Math . cos ( getArmAngle (). in ( Radians ))); Distance endEffectorY = armLength . times ( Math . sin ( getArmAngle (). in ( Radians ))); Human-readable Formatting The Measure class has methods that can be used to get a human-readable representation of the measure. This feature is useful to display a measure on a dashboard or in logs. toString() and toShortString() return a string representation of the measure in a shorthand form. The symbol of the backing unit is used, rather than the full name, and the magnitude is represented in scientific notation. For example, 1.234e+04 V/m toLongString() returns a string representation of the measure in a longhand form. The name of the backing unit is used, rather than its symbol, and the magnitude is represented in a full string, not scientific notation. For example, 1234 Volt per Meter Mutability and Object Creation To reduce the number of object instances you create, and reduce memory usage, a special MutableMeasure class is available, with unit-specific subtypes like MutDistance and MutTime . You may want to consider using mutable objects if you are using the units library repeatedly, such as in the robot’s periodic loop. See Java Garbage Collection for more discussion on creating a large number of short-lived objects. Mutable measures can be created in a similar way to regular, immutable measures using the Unit.mutable method (instead of Unit.of ). MutableMeasure allows the internal state of the object to be updated, such as with the results of arithmetic operations, to avoid allocating new objects. Special care needs to be taken when mutating a measure because it will change the value every place that instance is referenced. If the object will be exposed as part of a public method, have that method return a regular Measure in its signature to prevent the caller from modifying your internal state. Extra methods are available on MutableMeasure for updating the internal value. Note that these methods all begin with the mut_ prefix - this is to make it obvious that these methods will be mutating the object and are potentially unsafe! For the full list of methods and API documentation, see the MutableMeasure API documentation mut_plus(double, Unit) Increments the internal value by an amount in another unit. The internal unit will stay the same mut_plus(Measure) Increments the internal value by another measurement. The internal unit will stay the same mut_minus(double, Unit) Decrements the internal value by an amount in another unit. The internal unit will stay the same mut_minus(Measure) Decrements the internal value by another measurement. The internal unit will stay the same mut_times(double) Multiplies the internal value by a scalar mut_divide(double) Divides the internal value by a scalar mut_replace(double, Unit) Overrides the internal state and sets it to equal the given value and unit mut_replace(Measure) Overrides the internal state to make it identical to the given measurement mut_setMagnitude(double) Overrides the internal value, keeping the internal unit. Be careful when using this! MutDistance measure = Feet . mutable ( 0 ); measure . mut_plus ( 10 , Inches ); // 0.8333 feet measure . mut_plus ( Inches . of ( 10 )); // 1.6667 feet measure . mut_minus ( 5 , Inches ); // 1.25 feet measure . mut_minus ( Inches . of ( 5 )); // 0.8333 feet measure . mut_times ( 6 ); // 0.8333 * 6 = 5 feet measure . mut_divide ( 5 ); // 5 / 5 = 1 foot measure . mut_replace ( 6.2 , Meters ) // 6.2 meters - note the unit changed! measure . mut_replace ( Millimeters . of ( 14.2 )) // 14.2mm - the unit changed again! measure . mut_setMagnitude ( 72 ) // 72mm Revisiting the arm example from above, we can use mut_replace - and, optionally, mut_times - to calculate the end effector position import edu.wpi.first.units.Measure ; import edu.wpi.first.units.MutableMeasure ; import static edu.wpi.first.units.Units.* ; public class Arm { // Note the two ephemeral object allocations for the Feet.of and Inches.of calls. // Because this is a constant value computed just once, they will easily be garbage collected without // any problems with memory use or loop timing jitter. private static final Distance kArmLength = Feet . of ( 3 ). plus ( Inches . of ( 4.25 )); // Angle and X/Y locations will likely be called in the main robot loop, let's store them in a MutableMeasure // to avoid allocating lots of short-lived objects private final MutAngle m_angle = Degrees . mutable ( 0 ); private final MutDistance m_endEffectorX = Feet . mutable ( 0 ); private final MutDistance m_endEffectorY = Feet . mutable ( 0 ); private final Encoder m_encoder = new Encoder (...); public Distance getEndEffectorX () { return m_endEffectorX . mut_replace ( Math . cos ( getAngle (). in ( Radians )) * kArmLength . in ( Feet ), // the new magnitude to store Feet // the units of the new magnitude ); } public Distance getEndEffectorY () { // An alternative approach so we don't have to unpack and repack the units m_endEffectorY . mut_replace ( kArmLength ); m_endEffectorY . mut_times ( Math . sin ( getAngle (). in ( Radians ))); return m_endEffectorY ; } public Angle getAngle () { double rawAngle = m_encoder . getPosition (); m_angle . mut_replace ( rawAngle , Degrees ); // NOTE: the encoder must be configured with distancePerPulse in terms of degrees! return m_angle ; } } Warning MutableMeasure objects can - by definition - change their values at any time! It is unsafe to keep a stateful reference to them - prefer to extract a value using the Measure.in method, or create a copy with Measure.copy that can be safely stored. For the same reason, library authors must also be careful about methods accepting Measure . Can you spot the bug in this code? private Distance m_lastDistance ; public Distance calculateDelta ( Distance currentDistance ) { if ( m_lastDistance == null ) { m_lastDistance = currentDistance ; return currentDistance ; } else { Distance delta = currentDistance . minus ( m_lastDistance ); m_lastDistance = currentDistance ; return delta ; } } If we run the calculateDelta method a few times, we can see a pattern: MutDistance distance = Inches . mutable ( 0 ); distance . mut_plus ( 10 , Inches ); calculateDelta ( distance ); // expect 10 inches and get 10 - good! distance . mut_plus ( 2 , Inches ); calculateDelta ( distance ); // expect 2 inches, but get 0 instead! distance . mut_plus ( 8 , Inches ); calculateDelta ( distance ); // expect 8 inches, but get 0 instead! This is because the m_lastDistance field is a reference to the same MutDistance object as the input! Effectively, the delta is calculated as (currentDistance - currentDistance) on every call after the first, which naturally always returns zero. One solution would be to track m_lastDistance as a copy of the input measure to take a snapshot; however, this approach does incur one extra object allocation for the copy. If you need to be careful about object allocations, m_lastDistance could also be stored as a MutDistance . Immutable Copies private Distance m_lastDistance ; public Distance calculateDelta ( Distance currentDistance ) { if ( m_lastDistance == null ) { m_lastDistance = currentDistance . copy (); return currentDistance ; } else { var delta = currentDistance . minus ( m_lastDistance ); m_lastDistance = currentDistance . copy (); return delta ; } } Zero-allocation Mutables private final MutDistance m_lastDistance = Meters . mutable ( 0 ); private final MutDistance m_delta = Meters . mutable ( 0 ); public Distance calculateDelta ( Distance currentDistance ) { // m_delta = currentDistance - m_lastDistance m_delta . mut_replace ( currentDistance ); m_delta . mut_minus ( m_lastDistance ); m_lastDistance . mut_replace ( currentDistance ); return m_delta ; } Defining New Units There are four ways to define a new unit that isn’t already present in the library: Using the Unit.per or Unit.mult methods to create a composite of two other units; Using the Milli , Micro , and Kilo helper methods; Using the derive method and customizing how the new unit relates to the base unit; and Subclassing Unit to define a new dimension. New units can be defined as combinations of existing units using the Unit.mult and Unit.per methods. PerUnit < VoltageUnit , DistanceUnit > VoltsPerInch = Volts . per ( Inch ); VelocityUnit < MassUnit > KgPerSecond = Kilograms . per ( Second ); // Could also be declared as PerUnit<MassUnit, TimeUnit> DistanceUnit FootMinutesPerSecond = FeetPerSecond . mult ( Minutes ); Using mult and per will store the resulting unit. Every call will return the same object to avoid unnecessary allocations and garbage collector pressure. @Override public void robotPeriodic () { // Feet.per(Millisecond) creates a new unit on the first loop, // which will be reused on every successive loop SmartDashboard . putNumber ( \"Speed\" , m_drivebase . getSpeed (). in ( Feet . per ( Millisecond ))); } Note Calling Unit.per(Time) will return a Velocity unit, which is different from and incompatible with a Per unit! New dimensions can also be created by subclassing Unit and implementing the two constructors. Dimension-specific measurement types are recommended, but take considerable effort to implement all the unit-specific math operations. public class ElectricChargeUnit extends Unit { public ElectricCharge ( double baseUnitEquivalent , String name , String symbol ) { super ( ElectricCharge . class , baseUnitEquivalent , name , symbol ); } // required for derivation with Milli, Kilo, etc. public ElectricCharge ( UnaryFunction toBaseConverter , UnaryFunction fromBaseConverter , String name , String symbol ) { super ( ElectricCharge . class , toBaseConverter , fromBaseConverter , name , symbol ); } @Override public ElectricChargeUnit getBaseUnit () { // The base method must be overridden in order to return the correct type return ( ElectricChargeUnit ) super . getBaseUnit (); } @Override public Measure < ElectricChargeUnit > of ( double magnitude ) { return ImmutableMeasure . ofRelativeUnits ( magnitude , this ); } @Override public Measure < ElectricChargeUnit > ofBaseUnits ( double baseUnitMagnitude ) { return ImmutableMeasure . ofBaseUnits ( baseUnitMagnitude , this ); } @Override public Measure < ElectricChargeUnit > zero () { return ( Measure < ElectricChargeUnit > ) super . zero (); } @Override public Measure < ElectricChargeUnit > one () { return ( Measure < ElectricChargeUnit > ) super . one (); } @Override public MutableMeasure < ElectricChargeUnit > mutable ( double magnitude ) { return new GenericMutableMeasureImpl ( magnitude , toBaseUnits ( magnitude ), this ); } @Override public VelocityUnit < ElectricChargeUnit > per ( TimeUnit period ) { // Note: technically, this would return a CurrentUnit, since electric charge per time is current (measured in Amperes) return VelocityUnit . combine ( this , period ); } public double convertFrom ( double magnitude , ElectricChargeUnit otherUnit ) { return fromBaseUnits ( otherUnit . toBaseUnits ( magnitude )); } } public static final ElectricCharge Coulomb = new ElectricCharge ( 1 , \"Coulomb\" , \"C\" ); public static final ElectricCharge ElectronCharge = new ElectricCharge ( 1.60217646e-19 , \"Electron Charge\" , \"e\" ); public static final ElectricCharge AmpHour = new ElectricCharge ( 3600 , \"Amp Hour\" , \"Ah\" ); public static final ElectricCharge MilliampHour = Milli ( AmpHour );",
      "content_preview": "The Java Units Library Note New for 2025: The units library has been refactored to have unit-specific measurement classes instead of a single generic Measure class."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/misc/addressable-leds.html?present",
      "title": "Addressable LEDs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Addressable LEDs LED strips have been commonly used by teams for several years for a variety of reasons. They allow teams to debug robot functionality from the audience, provide a visual marker for their robot, and can simply add some visual appeal. WPILib has an API for controlling WS2812, WS2812B, and WS2815 LEDs with their data pin connected via PWM . Note LEDs can be controlled through this API while the robot is disabled. Important The roboRIO can only control one AddressableLED object at a time through its PWM ports. Attempting to create multiple AddressableLED objects will result in a HAL allocation error. If you need to control multiple physical LED strips, you have several options: Daisy-chain strips in series : Connect multiple LED strips end-to-end as a single long strip, then use buffer views to control different sections independently Use PWM Y-cables : If you need identical patterns on multiple strips, use PWM Y-cables to send the same signal to multiple strips simultaneously See also For detailed information about powering and best practices for addressable LEDs, see the Adafruit NeoPixel Überguide . Warning WS2812B LEDs are designed for 5V, but roboRIO PWM/Servo ports output 6V. While the LEDs will function, this may reduce their lifespan. Consider using a voltage regulator or level shifter if longevity is a concern. Instantiating the AddressableLED Object You first create an AddressableLED object that takes the PWM port as an argument. It must be a PWM header on the roboRIO. Then you set the number of LEDs located on your LED strip, which can be done with the setLength() function. Warning It is important to note that setting the length of the LED header is an expensive task and it’s not recommended to run this periodically. After the length of the strip has been set, you’ll have to create an AddressableLEDBuffer object that takes the number of LEDs as an input. You’ll then call myAddressableLed.setData(myAddressableLEDBuffer) to set the led output data. Finally, you can call myAddressableLed.start() to write the output continuously. Below is a full example of the initialization process. Note C++ does not have an AddressableLEDBuffer, and instead uses an Array. Java 32 /** Called once at the beginning of the robot program. */ 33 public Robot () { 34 // PWM port 9 35 // Must be a PWM header, not MXP or DIO 36 m_led = new AddressableLED ( 9 ); 37 38 // Reuse buffer 39 // Default to a length of 60, start empty output 40 // Length is expensive to set, so only set it once, then just update data 41 m_ledBuffer = new AddressableLEDBuffer ( 60 ); 42 m_led . setLength ( m_ledBuffer . getLength ()); 43 44 // Set the data 45 m_led . setData ( m_ledBuffer ); 46 m_led . start (); 47 } C++ 12 private : 13 static constexpr int kLength = 60 ; 14 15 // PWM port 9 16 // Must be a PWM header, not MXP or DIO 17 frc :: AddressableLED m_led { 9 }; 18 std :: array < frc :: AddressableLED :: LEDData , kLength > 19 m_ledBuffer ; // Reuse the buffer 20 21 // Our LED strip has a density of 120 LEDs per meter 7 Robot :: Robot () { 8 // Default to a length of 60, start empty output 9 // Length is expensive to set, so only set it once, then just update data 10 m_led . SetLength ( kLength ); 11 m_led . SetData ( m_ledBuffer ); 12 m_led . Start (); 13 } Controlling Sections of an LED Strip The roboRIO can only control a single addressable LED output at a time, but there are often multiple physical LED strips daisy-chained around a robot, or a single flexible LED strip wrapped around structures on a robot. Individual sections can be accessed in Java using AddressableLEDBufferView . Buffer views behave like subsections of the larger buffer, and can be accessed using indices in the typical [0, length) range. They can also be reversed, to allow for parallel serpentine sections to be animated in the same physical orientation (i.e. both sections would animate “forward” in the same direction, even if the strips are physically tip-to-tail). Java // Create the buffer AddressableLEDBuffer m_buffer = new AddressableLEDBuffer ( 120 ); // Create the view for the section of the strip on the left side of the robot. // This section spans LEDs from index 0 through index 59, inclusive. AddressableLEDBufferView m_left = m_buffer . createView ( 0 , 59 ); // The section of the strip on the right side of the robot. // This section spans LEDs from index 60 through index 119, inclusive. // This view is reversed to cancel out the serpentine arrangement of the // physical LED strip on the robot. AddressableLEDBufferView m_right = m_buffer . createView ( 60 , 119 ). reversed (); C++ // Create the buffer std :: array < frc :: AddressableLED :: LEDData , 120 > m_buffer ; // Create the view for the section of the strip on the left side of the robot. // This section spans LEDs from index 0 through index 59, inclusive. std :: view < frc :: AddressableLED :: LEDData > m_left = std :: ranges :: take_view ( m_buffer , 60 ); // The section of the strip on the right side of the robot. // This section spans LEDs from index 60 through index 119, inclusive. // This view is reversed to cancel out the serpentine arrangement of the // physical LED strip on the robot. std :: view < frc :: AddressableLED :: LEDData > m_right = std :: ranges :: reverse_view ( std :: ranges :: drop_view ( m_buffer , 60 )); LED Patterns The LEDPattern API simplifies setting LED data. Rather than needing to manually loop over every LED index, you can apply a pattern object to the data buffer directly. LED patterns are stateless, and can safely be applied to multiple buffers or views. Java // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . solid ( Color . kRed ); // Apply the LED pattern to the data buffer red . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . Solid ( Color :: kRed ); // Apply the LED pattern to the data buffer red . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Creating a Rainbow Effect Using the built in LEDPattern.rainbow method, we can create a pattern that displays a full rainbow across an entire LED strip. Then, by calling scrollAtAbsoluteSpeed we can make it animate and cycle around the strip. rainbow accepts two arguments - one for the saturation and one for the value, expressed as a number from 0 to 255. Note Animating effects like scrolling use the Java units library and the C++ units library for speeds and durations. The base rainbow pattern will look like this: Java 21 // all hues at maximum saturation and half brightness 22 private final LEDPattern m_rainbow = LEDPattern . rainbow ( 255 , 128 ); 23 24 // Our LED strip has a density of 120 LEDs per meter 25 private static final Distance kLedSpacing = Meters . of ( 1 / 120.0 ); 26 27 // Create a new pattern that scrolls the rainbow pattern across the LED strip, moving at a speed 28 // of 1 meter per second. 29 private final LEDPattern m_scrollingRainbow = 30 m_rainbow . scrollAtAbsoluteSpeed ( MetersPerSecond . of ( 1 ), kLedSpacing ); C++ 27 // Our LED strip has a density of 120 LEDs per meter 28 units :: meter_t kLedSpacing { 1 / 120.0 }; 29 30 // Create an LED pattern that will display a rainbow across 31 // all hues at maximum saturation and half brightness 32 frc :: LEDPattern m_rainbow = frc :: LEDPattern :: Rainbow ( 255 , 128 ); 33 34 // Create a new pattern that scrolls the rainbow pattern across the LED 35 // strip, moving at a speed of 1 meter per second. 36 frc :: LEDPattern m_scrollingRainbow = 37 m_rainbow . ScrollAtAbsoluteSpeed ( 1 _mps , kLedSpacing ); Now that the rainbow pattern is defined, we only need to apply it. Java 50 public void robotPeriodic () { 51 // Update the buffer with the rainbow animation 52 m_scrollingRainbow . applyTo ( m_ledBuffer ); 53 // Set the LEDs 54 m_led . setData ( m_ledBuffer ); 55 } 56 } C++ 15 void Robot::RobotPeriodic () { 16 // Run the rainbow pattern and apply it to the buffer 17 m_scrollingRainbow . ApplyTo ( m_ledBuffer ); 18 // Set the LEDs 19 m_led . SetData ( m_ledBuffer ); 20 } Controlling when patterns are applied Use commands. The command framework is specifically built for managing when actions run and stop, and prevents multiple actions from running simultaneously. Java public class LEDSubsystem extends SubsystemBase { private static final int kPort = 9 ; private static final int kLength = 120 ; private final AddressableLED m_led ; private final AddressableLEDBuffer m_buffer ; public LEDSubsystem () { m_led = new AddressableLED ( kPort ); m_buffer = new AddressableLEDBuffer ( kLength ); m_led . setLength ( kLength ); m_led . start (); // Set the default command to turn the strip off, otherwise the last colors written by // the last command to run will continue to be displayed. // Note: Other default patterns could be used instead! setDefaultCommand ( runPattern ( LEDPattern . solid ( Color . kBlack )). withName ( \"Off\" )); } @Override public void periodic () { // Periodically send the latest LED color data to the LED strip for it to display m_led . setData ( m_buffer ); } /** * Creates a command that runs a pattern on the entire LED strip. * * @param pattern the LED pattern to run */ public Command runPattern ( LEDPattern pattern ) { return run (() -> pattern . applyTo ( m_buffer )); } } C++ Header: class LEDSubsystem : public SubsystemBase { public : LEDSubsystem (); void Periodic () override ; frc :: CommandPtr RunPattern ( frc :: LEDPattern pattern ); private : static constexpr int kPort = 9 ; static constexpr int kLength = 120 ; frc :: AddressableLED m_led { kPort }; std :: array < frc :: AddressableLED :: LEDData , kLength > m_ledBuffer ; } LEDSubsystem :: LEDSubsystem () { m_led . SetLength ( kLength ); m_led . Start (); // Set the default command to turn the strip off, otherwise the last colors written by // the last command to run will continue to be displayed. // Note: Other default patterns could be used instead! SetDefaultCommand ( RunPattern ( frc :: LEDPattern :: Solid ( frc :: Color :: kBlack )). WithName ( \"Off\" )); } LEDSubsystem :: Periodic () { // Periodically send the latest LED color data to the LED strip for it to display m_led . SetData ( m_ledBuffer ); } frc :: CommandPtr LEDSubsystem :: RunPattern ( frc :: LEDPattern pattern ) { // std::move is necessary for inline pattern declarations to work // Otherwise we could have a use-after-free! return Run ([ this , pattern = std :: move ( pattern )] { pattern . ApplyTo ( m_buffer ); }); } Basic effects The basic effects can all be created from the factory methods declared in the LEDPattern class Solid color The solid color pattern sets the target LED buffer to a single solid color. Java // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . solid ( Color . kRed ); // Apply the LED pattern to the data buffer red . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that sets the entire strip to solid red LEDPattern red = LEDPattern . Solid ( Color :: kRed ); // Apply the LED pattern to the data buffer red . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Continuous Gradient The gradient pattern sets the target buffer to display a smooth gradient between the specified colors. The gradient wraps around so scrolling effects can be seamless. Java // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at both ends and blue in the center, // with smooth gradients between LEDPattern gradient = LEDPattern . gradient ( LEDPattern . GradientType . kContinuous , Color . kRed , Color . kBlue ); // Apply the LED pattern to the data buffer gradient . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at both ends and blue in the center, // with smooth gradients between std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern gradient = LEDPattern . Gradient ( LEDPattern :: GradientType :: kContinuous , colors ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Discontinuous Gradient The gradient pattern sets the target buffer to display a smooth gradient between the specified colors. The gradient does not wrap around so it can be used for non-scrolling patterns that don’t care about continuity. Java // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at one end and blue at the other. LEDPattern gradient = LEDPattern . gradient ( LEDPattern . GradientType . kDiscontinuous , Color . kRed , Color . kBlue ); // Apply the LED pattern to the data buffer gradient . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient. // The LED strip will be red at one end and blue at the other. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern gradient = LEDPattern . Gradient ( LEDPattern :: GradientType :: kDiscontinuous , colors ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Steps Displays segments of solid colors along the target buffer. This combines well with mask and overlay combination effects. Steps are specified as a combination of the starting position of that color, as a number between 0 (start of the buffer) and 1 (end of the buffer). Note If the first step does not start at zero, every LED before that step starts will be set to black - effectively, as if there is a default step of (0, Color.kBlack) that can be overwritten. Java // Create an LED pattern that displays the first half of a strip as solid red, // and the second half of the strip as solid blue. LEDPattern steps = LEDPattern . steps ( Map . of ( 0 , Color . kRed , 0.5 , Color . kBlue )); // Apply the LED pattern to the data buffer steps . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays the first half of a strip as solid red, // and the second half of the strip as solid blue. std :: array < std :: pair < double , Color > , 2 > colorSteps { std :: pair { 0.0 , Color :: kRed }, std :: pair { 0.5 , Color :: kBlue }}; LEDPattern steps = LEDPattern . Steps ( colorSteps ); // Apply the LED pattern to the data buffer gradient . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Progress mask Slightly different from the basic color patterns, the progress mask pattern generates a white-and-black pattern where the white portion is a varying length depending on the value of the value function. This can be combined with another pattern using a mask to display a portion of another base pattern depending on the progress of some process - such as the position of a mechanism in its range of motion (eg an elevator’s height) or the progress of a PID controller towards its goal. Java // Create an LED pattern that displays a black-and-white mask that displays the current height of an elevator // mechanism. This can be combined with other patterns to change the displayed color to something other than white. LEDPattern pattern = LEDPattern . progressMaskLayer (() -> m_elevator . getHeight () / m_elevator . getMaxHeight ()); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a black-and-white mask that displays the current height of an elevator // mechanism. This can be combined with other patterns to change the displayed color to something other than white. LEDPattern pattern = LEDPattern :: ProgressMaskLayer ([ & ]() { return m_elevator . GetHeight () / m_elevator . GetMaxHeight (); }); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Modifying effects Basic LED patterns can be combined with modifier effects to create new patterns with a combination of effects. Multiple modifiers can be used together to create complex patterns. Note The built in animating effects like blinking and scrolling are based on the time returned by WPIUtilJNI.now() - in effect, they will play as if they started when the robot booted. Because all built in animation patterns are periodic, this means that the first period of a pattern may be truncated at any arbitrary point between 0% and 100%, and every period after that will play normally. Offset Offsets can be used to bias patterns forward of backward by a certain number of pixels. Offset patterns will wrap around the end of an LED strip; offset values can be positive (biasing away from the start of the strip) or negative (biasing towards the start of the strip). Java // Create an LED pattern that displays a red-to-blue gradient, offset 40 pixels forward. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . offsetBy ( 40 ); LEDPattern negative = base . offsetBy ( - 20 ); // Equivalent to the above when applied to a 60-LED buffer // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, offset 40 pixels forward. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . OffsetBy ( 40 ); LEDPattern negative = base . OffsetBy ( -20 ); // Equivalent to the above when applied to a 60-LED buffer // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Reverse Patterns and animations can be reversed to flip the direction that patterns are applied in; instead of starting from the lowest-indexed pixel in a buffer or view, a reversed pattern will start from the highest-indexed pixel and move toward the lowest-index pixel. A reversed scrolling pattern will scroll in reverse, as if its velocity’s sign was flipped. Java // Create an LED pattern that displays a red-to-blue gradient, then reverse it so it displays blue-to-red. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . reversed (); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, then reverse it so it displays blue-to-red. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . Reversed (); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Scroll Scrolling can be controlled in two different ways: either at a speed as a function of the length of the buffer or view to which it is applied (i.e., the scrolling speed is in terms of percentage per second, or a similar unit), or as a function of the density of the physical LED strips (i.e. scrolling speed is in meters per second, or a similar unit). Relative velocities are particularly useful when a scrolling pattern is applied to different LED strips with different LED spacing (such as one strip with 120 LEDs per meter daisy chained to a second strip with 60 or 144 LEDs per meter), when prototyping before having a particular LED strip in mind (where the density isn’t yet known), or when LED strips are quickly changed out. Scrolling at a fixed real-world speed (eg InchesPerSecond.of(2) ) may be more understandable to readers, but will move faster or slower when applied to an LED strip with a lower or higher pixel density, respectively. Java // Create an LED pattern that displays a red-to-blue gradient, then scroll at one quarter of the LED strip's length per second. // For a half-meter length of a 120 LED-per-meter strip, this is equivalent to scrolling at 12.5 centimeters per second. Distance ledSpacing = Meters . of ( 1 / 120.0 ); LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . scrollAtRelativeSpeed ( Percent . per ( Second ). of ( 25 )); LEDPattern absolute = base . scrollAtAbsoluteSpeed ( Centimeters . per ( Second ). of ( 12.5 ), ledSpacing ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, then scroll at one quarter of the LED strip's length per second. // For a half-meter length of a 120 LED-per-meter strip, this is equivalent to scrolling at 12.5 centimeters per second. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . ScrollAtRelativeSpeed ( units :: hertz_t { 0.25 }); LEDPattern absolute = base . ScrollAtAbsoluteSpeed ( 0.125 _mps , units :: meter_t { 1 / 120.0 }); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Breathe A breathing modifier will make the base pattern brighten and dim in a sinusoidal pattern over the given period of time. Brightness is relative to the original brightness of the base pattern - breathing will only make it dimmer, never brighter than the original. Java // Create an LED pattern that displays a red-to-blue gradient, breathing at a 2 second period (0.5 Hz) LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . breathe ( Seconds . of ( 2 )); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, breathing at a 2 second period (0.5 Hz) std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . Breathe ( 2 _s ); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Blink Blinking can be done in one of three ways: Symmetrically, where an equal amount of time is spent in the “on” and “off” states per cycle Asymetrically, where the time spent “on” can be configured independently from the time spent “off” Synchronously, where the time spent on and off is synchronized with an external source (for example, the state of the RSL) Java // Create an LED pattern that displays a red-to-blue gradient, blinking at various rates. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); // 1.5 seconds on, 1.5 seconds off, for a total period of 3 seconds LEDPattern pattern = base . blink ( Seconds . of ( 1.5 )); // 2 seconds on, 1 second off, for a total period of 3 seconds LEDPattern asymmetric = base . blink ( Seconds . of ( 2 ), Seconds . of ( 1 )); // Turn the base pattern on when the RSL is on, and off when the RSL is off LEDPattern sycned = base . synchronizedBlink ( RobotController :: getRSLState ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient, blinking at various rates. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); // 1.5 seconds on, 1.5 seconds off, for a total period of 3 seconds LEDPattern pattern = base . Blink ( 1.5 _s ); // 2 seconds on, 1 second off, for a total period of 3 seconds LEDPattern asymmetric = base . Blink ( 2 _s , 1 _s )); // Turn the base pattern on when the RSL is on, and off when the RSL is off LEDPattern sycned = base . SynchronizedBlink ([]() { return RobotController . GetRSLState (); }); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Brightness Patterns can be brightened and dimmed relative to their original brightness; a brightness value of 100% is identical to the original pattern, a value of 200% is twice as bright, and a value of 0% is completely turned off. This can be useful in a pinch to tone down patterns that are too bright (apologies to the 2024 NE Greater Boston district event staff, who were subjected to a maximimum brightness white flashing pattern with a precursor version of this library before the brightness modifier was added). Note For speed, brightness calculations are done naively in the RGB color space instead of HSL/HSV/Lab. This sacrifices accuracy, so large changes in brightness may look undersaturated. Java // Create an LED pattern that displays a red-to-blue gradient at half brightness LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern pattern = base . atBrightness ( Percent . of ( 50 )); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient at half brightness std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern pattern = base . AtBrightness ( 0.5 ); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Combinatory effects Complex LED patterns are built up from combining simple base patterns (such as solid colors or gradients) with animating effects (such as scrolling or breathing) and combinatory effects (like masks and overlays). Multiple effects can be combined at once, like in the scrolling rainbow effect above that takes a basic base effect - a static rainbow - and then adds a scrolling effect to it. Mask Masks work by combining the RGB values of two patterns and keeping only the values that are shared by both. The combination works on the individual bits of each color using a bitwise AND operation - for example, if a pixel’s red channel were set to 255 by one pattern (represented as 11111111 in binary), then the output red color would be identical to the red channel of the second pattern. If the first pattern sets it to zero (00000000 in binary), then the output red color would also be zero, regardless of whatever the second pattern sets. For this reason, black (all zeroes) and white (all ones) masks are very useful for selectively enabling and disabling parts of another pattern. Other mask colors can be used as well: masking with solid red would keep only the red channel of the original pattern, while discarding all green and blue values. Java // Create an LED pattern that displays a red-to-blue gradient at a variable length // depending on the relative position of the elevator. The blue end of the gradient // will only be shown when the elevator gets close to its maximum height; otherwise, // that end will be solid black when the elevator is at lower heights. LEDPattern base = LEDPattern . discontinuousGradient ( Color . kRed , Color . kBlue ); LEDPattern mask = LEDPattern . progressMaskLayer (() -> m_elevator . getHeight () / m_elevator . getMaxHeight ()); LEDPattern heightDisplay = base . mask ( mask ); // Apply the LED pattern to the data buffer heightDisplay . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ // Create an LED pattern that displays a red-to-blue gradient at a variable length // depending on the relative position of the elevator. The blue end of the gradient // will only be shown when the elevator gets close to its maximum height; otherwise, // that end will be solid black when the elevator is at lower heights. std :: array < Color , 2 > colors { Color :: kRed , Color :: kBlue }; LEDPattern base = LEDPattern :: DiscontinuousGradient ( colors ); LEDPattern mask = LEDPattern :: ProgressMaskLayer ([ & ]() { m_elevator . GetHeight () / m_elevator . GetMaxHeight () }); LEDPattern heightDisplay = base . Mask ( mask ); // Apply the LED pattern to the data buffer heightDisplay . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Masks can also be animated (see progressMask ). Masking a base pattern with a scrolling pattern will result in a panning effect. The animation above was generated by masking a rainbow pattern with a scrolling white/black pattern Java Map < Double , Color > maskSteps = Map . of ( 0 , Color . kWhite , 0.5 , Color . kBlack ); LEDPattern base = LEDPattern . rainbow ( 255 , 255 ); LEDPattern mask = LEDPattern . steps ( maskSteps ). scrollAtRelativeSpeed ( Percent . per ( Second ). of ( 0.25 )); LEDPattern pattern = base . mask ( mask ); // Apply the LED pattern to the data buffer pattern . applyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . setData ( m_ledBuffer ); C++ std :: array < std :: pair < double , Color > , 2 > maskSteps { std :: pair { 0.0 , Color :: kWhite }, std :: pair { 0.5 , Color :: kBlack }}; LEDPattern base = LEDPattern :: Rainbow ( 255 , 255 ); LEDPattern mask = LEDPattern :: Steps ( maskSteps ). ScrollAtRelativeSpeed ( units :: hertz_t { 0.25 }); LEDPattern pattern = base . Mask ( mask ); // Apply the LED pattern to the data buffer pattern . ApplyTo ( m_ledBuffer ); // Write the data to the LED strip m_led . SetData ( m_ledBuffer ); Overlay Overlays can be used to “stack” patterns atop each other, where black pixels (set to Color.kBlack , RGB value #000000) are treated as transparent and allow a lower layer to be displayed. Upper layers are typically combined with masks to set transparent sections; recall that masking a pixel with Color.kBlack will set that pixel to black, which will then be treated by the overlay as transparent. Blend Blends will combine the output colors of patterns together, by averaging out the individual RGB colors for every pixel. Like the brightness modifier , this tends to output colors that are more desaturated than its inputs. Low Level Access LEDPattern is an easy and convenient way of controlling LEDs, but direct access to the LED colors is sometimes needed for custom patterns and animations. Color can be set to an individual led on the strip using two methods: setRGB() , which takes RGB values as an input, and setHSV() , which takes HSV values as an input. Low-level access is typically done with an indexed for-loop that iterates over each LED index of the section to control. This method can be used for both AddressableLEDBuffer and AddressableLEDBufferView objects in Java, and for std::span for C++. Note RGB stands for Red, Green, and Blue. This is a fairly common color model as it’s quite easy to understand, and it corresponds with a typical LED configuration that’s comprised of one red, one green, and one blue sub-LED. LEDs can be set with the setRGB method that takes 4 arguments: index of the LED, amount of red, amount of green, amount of blue. The amount of red, green, and blue are integer values between 0-255. Note HSV stands for Hue, Saturation, and Value. Hue describes the color or tint, saturation being the amount of gray, and value being the brightness. In WPILib, Hue is an integer from 0 - 180. Saturation and Value are integers from 0 - 255. If you look at a color picker like Google’s , Hue will be 0 - 360 and Saturation and Value are from 0% to 100%. This is the same way that OpenCV handles HSV colors. Make sure the HSV values entered to WPILib are correct, or the color produced might not be the same as was expected. These examples demonstrate setting an entire LED strip to solid red using the RGB and HSV methods: Java (RGB) for ( var i = 0 ; i < m_ledBuffer . getLength (); i ++ ) { // Sets the specified LED to the RGB values for red m_ledBuffer . setRGB ( i , 255 , 0 , 0 ); } m_led . setData ( m_ledBuffer ); C++ (RGB) for ( int i = 0 ; i < kLength ; i ++ ) { m_ledBuffer [ i ]. SetRGB ( 255 , 0 , 0 ); } m_led . SetData ( m_ledBuffer ); Java (HSV) for ( var i = 0 ; i < m_ledBuffer . getLength (); i ++ ) { // Sets the specified LED to the HSV values for red m_ledBuffer . setHSV ( i , 0 , 100 , 100 ); } m_led . setData ( m_ledBuffer ); C++ (HSV) for ( int i = 0 ; i < kLength ; i ++ ) { m_ledBuffer [ i ]. SetHSV ( 0 , 100 , 100 ); } m_led . SetData ( m_ledBuffer ); Using HSV Values",
      "content_preview": "Addressable LEDs LED strips have been commonly used by teams for several years for a variety of reasons. They allow teams to debug robot functionality from the audience, provide a visual marker for their robot, and can simply add some visual appeal."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/cpp-units.html",
      "title": "The C++ Units Library",
      "section": "Basic Programming",
      "language": "All",
      "content": "The C++ Units Library WPILib is coupled with a Units library for C++ teams. This library leverages the C++ type system to enforce proper dimensionality for method parameters, automatically perform unit conversions, and even allow users to define arbitrary defined unit types. Since the C++ type system is enforced at compile-time, the library has essentially no runtime cost. Using the Units Library The units library is a header-only library. You must include the relevant header in your source files for the units you want to use. Here’s a list of available units. #include <units/acceleration.h> #include <units/angle.h> #include <units/angular_acceleration.h> #include <units/angular_velocity.h> #include <units/area.h> #include <units/capacitance.h> #include <units/charge.h> #include <units/concentration.h> #include <units/conductance.h> #include <units/current.h> #include <units/curvature.h> #include <units/data.h> #include <units/data_transfer_rate.h> #include <units/density.h> #include <units/dimensionless.h> #include <units/energy.h> #include <units/force.h> #include <units/frequency.h> #include <units/illuminance.h> #include <units/impedance.h> #include <units/inductance.h> #include <units/length.h> #include <units/luminous_flux.h> #include <units/luminous_intensity.h> #include <units/magnetic_field_strength.h> #include <units/magnetic_flux.h> #include <units/mass.h> #include <units/moment_of_inertia.h> #include <units/power.h> #include <units/pressure.h> #include <units/radiation.h> #include <units/solid_angle.h> #include <units/substance.h> #include <units/temperature.h> #include <units/time.h> #include <units/torque.h> #include <units/velocity.h> #include <units/voltage.h> #include <units/volume.h> The units/math.h header provides unit-aware functions like units::math::abs() . Unit Types and Container Types The C++ units library is based around two sorts of type definitions: unit types and container types. Unit Types Unit types correspond to the abstract concept of a unit, without any actual stored value. Unit types are the fundamental “building block” of the units library - all unit types are defined constructively (using the compound_unit template) from a small number of “basic” unit types (such as meters , seconds , etc). While unit types cannot contain numerical values, their use in building other unit types means that when a type or method uses a template parameter to specify its dimensionality, that parameter will be a unit type. Container Types Container types correspond to an actual quantity dimensioned according to some unit - that is, they are what actually hold the numerical value. Container types are constructed from unit types with the unit_t template. Most unit types have a corresponding container type that has the same name suffixed by _t - for example, the unit type units::meter corresponds to the container type units::meter_t . Whenever a specific quantity of a unit is used (as a variable or a method parameter), it will be an instance of the container type. By default, container types will store the actual value as a double - advanced users may change this by calling the unit_t template manually. A full list of unit and container types can be found in the documentation . Creating Instances of Units To create an instance of a specific unit, we create an instance of its container type: // The variable speed has a value of 5 meters per second. units :: meters_per_second_t speed { 5.0 }; Alternatively, the units library has type literals defined for some of the more common container types. These can be used in conjunction with type inference via auto to define a unit more succinctly: // The variable speed has a value of 5 meters per second. auto speed = 5 _mps ; Units can also be initialized using a value of an another container type, as long as the types can be converted between one another. For example, a meter_t value can be created from a foot_t value. auto feet = 6 _ft ; units :: meter_t meters { feet }; In fact, all container types representing convertible unit types are implicitly convertible . Thus, the following is perfectly legal: units :: meter_t distance = 6 _ft ; In short, we can use any unit of length in place of any other unit of length, anywhere in our code; the units library will automatically perform the correct conversion for us. Performing Arithmetic with Units Container types support all of the ordinary arithmetic operations of their underlying data type, with the added condition that the operation must be dimensionally sound. Thus, addition must always be performed on two compatible container types: // Add two meter_t values together auto sum = 5 _m + 7 _m ; // sum is 12_m // Adds meters to feet; both are length, so this is fine auto sum = 5 _m + 7 _ft ; // Tries to add a meter_t to a second_t, will throw a compile-time error auto sum = 5 _m + 7 _s ; Multiplication may be performed on any pair of container types, and yields the container type of a compound unit: Note When a calculation yields a compound unit type, this type will only be checked for validity at the point of operation if the result type is specified explicitly. If auto is used, this check will not occur. For example, when we divide distance by time, we may want to ensure the result is, indeed, a velocity (i.e. units::meters_per_second_t ). If the return type is declared as auto , this check will not be made. // Multiply two meter_t values, result is square_meter_t auto product = 5 _m * 7 _m ; // product is 35_sq_m // Divide a meter_t value by a second_t, result is a meter_per_second_t units :: meters_per_second_t speed = 6 _m / 0.5 _s ; // speed is 12_mps <cmath> Functions Some std functions (such as clamp ) are templated to accept any type on which the arithmetic operations can be performed. Quantities stored as container types will work with these functions without issue. However, other std functions work only on ordinary numerical types (e.g. double ). The units library’s units::math namespace contains wrappers for several of these functions that accept units. Examples of such functions include sqrt , pow , etc. auto area = 36 _sq_m ; units :: meter_t sideLength = units :: math :: sqrt ( area ); Removing the Unit Wrapper To convert a container type to its underlying value, use the value() method. This serves as an escape hatch from the units type system, which should be used only when necessary. units :: meter_t distance = 6.5 _m ; double distanceMeters = distance . value (); Example of the Units Library in WPILib Code Several arguments for methods in new features of WPILib (ex. kinematics ) use the units library. Here is an example of sampling a trajectory . // Sample the trajectory at 1.2 seconds. This represents where the robot // should be after 1.2 seconds of traversal. Trajectory :: State point = trajectory . Sample ( 1.2 _s ); // Since units of time are implicitly convertible, this is exactly equivalent to the above code Trajectory :: State point = trajectory . Sample ( 1200 _ms ); Some WPILib classes represent objects that could naturally work with multiple choices of unit types - for example, a motion profile might operate on either linear distance (e.g. meters) or angular distance (e.g. radians). For such classes, the unit type is required as a template parameter: // Creates a new set of trapezoidal motion profile constraints // Max velocity of 10 meters per second // Max acceleration of 20 meters per second squared frc :: TrapezoidProfile < units :: meters >:: Constraints { 10 _mps , 20 _mps_sq }; // Creates a new set of trapezoidal motion profile constraints // Max velocity of 10 radians per second // Max acceleration of 20 radians per second squared frc :: TrapezoidProfile < units :: radians >:: Constraints { 10 _rad_per_s , 20 __rad_per_s / 1 _s }; For more detailed documentation, please visit the official GitHub page for the units library.",
      "content_preview": "The C++ Units Library WPILib is coupled with a Units library for C++ teams. This library leverages the C++ type system to enforce proper dimensionality for method parameters, automatically perform unit conversions, and even allow users to define arbitrary defined unit types."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/misc/index.html?present",
      "title": "Miscellaneous Hardware APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Miscellaneous Hardware APIs This section highlights miscellaneous hardware APIs that are standalone. Addressable LEDs",
      "content_preview": "Miscellaneous Hardware APIs This section highlights miscellaneous hardware APIs that are standalone. Addressable LEDs"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/index.html",
      "title": "Sensors",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Sensors Sensors are an integral way of having your robot hardware and software communicate with each other. This section highlights interfacing with those sensors at a software level. Sensor Overview - Software Accelerometers - Software Gyroscopes - Software Ultrasonics - Software Counters Encoders - Software Analog Inputs - Software Analog Potentiometers - Software Digital Inputs - Software Programming Limit Switches",
      "content_preview": "Sensors Sensors are an integral way of having your robot hardware and software communicate with each other. This section highlights interfacing with those sensors at a software level."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/accelerometers-software.html",
      "title": "Accelerometers",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Accelerometers - Software Note This section covers accelerometers in software. For a hardware guide to accelerometers, see Accelerometers - Hardware . An accelerometer is a device that measures acceleration. Accelerometers generally come in two types: single-axis and 3-axis. A single-axis accelerometer measures acceleration along one spatial dimension; a 3-axis accelerometer measures acceleration along all three spatial dimensions at once. WPILib supports single-axis accelerometers through the AnalogAccelerometer class. Three-axis accelerometers often require more complicated communications protocols (such as SPI or I2C) in order to send multi-dimensional data. WPILib has native support for the following 3-axis accelerometers: ADXL345_I2C ADXL345_SPI ADXL362 BuiltInAccelerometer AnalogAccelerometer The AnalogAccelerometer class ( Java , C++ ) allows users to read values from a single-axis accelerometer that is connected to one of the roboRIO’s analog inputs. JAVA // Creates an analog accelerometer on analog input 0 AnalogAccelerometer accelerometer = new AnalogAccelerometer ( 0 ); // Sets the sensitivity of the accelerometer to 1 volt per G accelerometer . setSensitivity ( 1 ); // Sets the zero voltage of the accelerometer to 3 volts accelerometer . setZero ( 3 ); // Gets the current acceleration double accel = accelerometer . getAcceleration (); C++ // Creates an analog accelerometer on analog input 0 frc :: AnalogAccelerometer accelerometer { 0 }; // Sets the sensitivity of the accelerometer to 1 volt per G accelerometer . SetSensitivity ( 1 ); // Sets the zero voltage of the accelerometer to 3 volts accelerometer . SetZero ( 3 ); // Gets the current acceleration double accel = accelerometer . GetAcceleration (); If users have a 3-axis analog accelerometer, they can use three instances of this class, one for each axis. There are getters for the acceleration along each cardinal direction (x, y, and z), as well as a setter for the range of accelerations the accelerometer will measure. JAVA // Sets the accelerometer to measure between -8 and 8 G's accelerometer . setRange ( BuiltInAccelerometer . Range . k8G ); C++ // Sets the accelerometer to measure between -8 and 8 G's accelerometer . SetRange ( BuiltInAccelerometer :: Range :: kRange_8G ); ADXL345_I2C The ADXL345_I2C class ( Java , C++ ) provides support for the ADXL345 accelerometer over the I2C communications bus. JAVA // Creates an ADXL345 accelerometer object on the MXP I2C port // with a measurement range from -8 to 8 G's ADXL345_I2C accelerometer = new ADXL345_I2C ( I2C . Port . kMXP , ADXL345_I2C . Range . k8G ); C++ // Creates an ADXL345 accelerometer object on the MXP I2C port // with a measurement range from -8 to 8 G's frc :: ADXL345_I2C accelerometer { I2C :: Port :: kMXP , frc :: ADXL345_I2C :: Range :: kRange_8G }; ADXL345_SPI The ADXL345_SPI class ( Java , C++ ) provides support for the ADXL345 accelerometer over the SPI communications bus. JAVA // Creates an ADXL345 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's ADXL345_SPI accelerometer = new ADXL345_SPI ( SPI . Port . kMXP , ADXL345_SPI . Range . k8G ); C++ // Creates an ADXL345 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's frc :: ADXL345_SPI accelerometer { SPI :: Port :: kMXP , frc :: ADXL345_SPI :: Range :: kRange_8G }; ADXL362 The ADXL362 class ( Java , C++ ) provides support for the ADXL362 accelerometer over the SPI communications bus. JAVA // Creates an ADXL362 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's ADXL362 accelerometer = new ADXL362 ( SPI . Port . kMXP , ADXL362 . Range . k8G ); C++ // Creates an ADXL362 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's frc :: ADXL362 accelerometer { SPI :: Port :: kMXP , frc :: ADXL362 :: Range :: kRange_8G }; BuiltInAccelerometer The BuiltInAccelerometer class ( Java , C++ ) provides access to the roboRIO’s own built-in accelerometer: JAVA // Creates an object for the built-in accelerometer // Range defaults to +- 8 G's BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); C++ // Creates an object for the built-in accelerometer // Range defaults to +- 8 G's frc :: BuiltInAccelerometer accelerometer ; Third-party accelerometers While WPILib provides native support for a number of accelerometers that are available in the kit of parts or through FIRST Choice, there are a few popular AHRS (Attitude and Heading Reference System) devices commonly used in FRC that include accelerometers. These are generally controlled through vendor libraries, though if they have a simple analog output they can be used with the AnalogAccelerometer class. Using accelerometers in code Note Accelerometers, as their name suggests, measure acceleration. Precise accelerometers can be used to determine position through double-integration (since acceleration is the second derivative of position), much in the way that gyroscopes are used to determine heading. However, the accelerometers available for use in FRC are not nearly high-enough quality to be used this way. It is recommended to use accelerometers in FRC® for any application which needs a rough measurement of the current acceleration. This can include detecting collisions with other robots or field elements, so that vulnerable mechanisms can be automatically retracted. They may also be used to determine when the robot is passing over rough terrain for an autonomous routine (such as traversing the defenses in FIRST Stronghold). For detecting collisions, it is often more robust to measure the jerk than the acceleration. The jerk is the derivative (or rate of change) of acceleration, and indicates how rapidly the forces on the robot are changing - the sudden impulse from a collision causes a sharp spike in the jerk. Jerk can be determined by simply taking the difference of subsequent acceleration measurements, and dividing by the time between them: JAVA double prevXAccel = 0.0 ; double prevYAccel = 0.0 ; BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); @Override public void robotPeriodic () { // Gets the current accelerations in the X and Y directions double xAccel = accelerometer . getX (); double yAccel = accelerometer . getY (); // Calculates the jerk in the X and Y directions // Divides by .02 because default loop timing is 20ms double xJerk = ( xAccel - prevXAccel ) / 0.02 ; double yJerk = ( yAccel - prevYAccel ) / 0.02 ; prevXAccel = xAccel ; prevYAccel = yAccel ; } C++ double prevXAccel = 0.0 ; double prevYAccel = 0.0 ; frc :: BuiltInAccelerometer accelerometer ; void Robot::RobotPeriodic () { // Gets the current accelerations in the X and Y directions double xAccel = accelerometer . GetX (); double yAccel = accelerometer . GetY (); // Calculates the jerk in the X and Y directions // Divides by .02 because default loop timing is 20ms double xJerk = ( xAccel - prevXAccel ) / 0.02 ; double yJerk = ( yAccel - prevYAccel ) / 0.02 ; prevXAccel = xAccel ; prevYAccel = yAccel ; } Most accelerometers legal for FRC use are quite noisy, and it is often a good idea to combine them with the LinearFilter class ( Java , C++ ) to reduce the noise: JAVA BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); // Create a LinearFilter that will calculate a moving average of the measured X acceleration over the past 10 iterations of the main loop LinearFilter xAccelFilter = LinearFilter . movingAverage ( 10 ); @Override public void robotPeriodic () { // Get the filtered X acceleration double filteredXAccel = xAccelFilter . calculate ( accelerometer . getX ()); } C++ frc :: BuiltInAccelerometer accelerometer ; // Create a LinearFilter that will calculate a moving average of the measured X acceleration over the past 10 iterations of the main loop auto xAccelFilter = frc :: LinearFilter :: MovingAverage ( 10 ); void Robot::RobotPeriodic () { // Get the filtered X acceleration double filteredXAccel = xAccelFilter . Calculate ( accelerometer . GetX ()); }",
      "content_preview": "Accelerometers - Software Note This section covers accelerometers in software. For a hardware guide to accelerometers, see Accelerometers - Hardware . An accelerometer is a device that measures acceleration. Accelerometers generally come in two types: single-axis and 3-axis."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/accelerometers-software.html?present",
      "title": "Accelerometers",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Accelerometers - Software Note This section covers accelerometers in software. For a hardware guide to accelerometers, see Accelerometers - Hardware . An accelerometer is a device that measures acceleration. Accelerometers generally come in two types: single-axis and 3-axis. A single-axis accelerometer measures acceleration along one spatial dimension; a 3-axis accelerometer measures acceleration along all three spatial dimensions at once. WPILib supports single-axis accelerometers through the AnalogAccelerometer class. Three-axis accelerometers often require more complicated communications protocols (such as SPI or I2C) in order to send multi-dimensional data. WPILib has native support for the following 3-axis accelerometers: ADXL345_I2C ADXL345_SPI ADXL362 BuiltInAccelerometer AnalogAccelerometer The AnalogAccelerometer class ( Java , C++ ) allows users to read values from a single-axis accelerometer that is connected to one of the roboRIO’s analog inputs. JAVA // Creates an analog accelerometer on analog input 0 AnalogAccelerometer accelerometer = new AnalogAccelerometer ( 0 ); // Sets the sensitivity of the accelerometer to 1 volt per G accelerometer . setSensitivity ( 1 ); // Sets the zero voltage of the accelerometer to 3 volts accelerometer . setZero ( 3 ); // Gets the current acceleration double accel = accelerometer . getAcceleration (); C++ // Creates an analog accelerometer on analog input 0 frc :: AnalogAccelerometer accelerometer { 0 }; // Sets the sensitivity of the accelerometer to 1 volt per G accelerometer . SetSensitivity ( 1 ); // Sets the zero voltage of the accelerometer to 3 volts accelerometer . SetZero ( 3 ); // Gets the current acceleration double accel = accelerometer . GetAcceleration (); If users have a 3-axis analog accelerometer, they can use three instances of this class, one for each axis. There are getters for the acceleration along each cardinal direction (x, y, and z), as well as a setter for the range of accelerations the accelerometer will measure. JAVA // Sets the accelerometer to measure between -8 and 8 G's accelerometer . setRange ( BuiltInAccelerometer . Range . k8G ); C++ // Sets the accelerometer to measure between -8 and 8 G's accelerometer . SetRange ( BuiltInAccelerometer :: Range :: kRange_8G ); ADXL345_I2C The ADXL345_I2C class ( Java , C++ ) provides support for the ADXL345 accelerometer over the I2C communications bus. JAVA // Creates an ADXL345 accelerometer object on the MXP I2C port // with a measurement range from -8 to 8 G's ADXL345_I2C accelerometer = new ADXL345_I2C ( I2C . Port . kMXP , ADXL345_I2C . Range . k8G ); C++ // Creates an ADXL345 accelerometer object on the MXP I2C port // with a measurement range from -8 to 8 G's frc :: ADXL345_I2C accelerometer { I2C :: Port :: kMXP , frc :: ADXL345_I2C :: Range :: kRange_8G }; ADXL345_SPI The ADXL345_SPI class ( Java , C++ ) provides support for the ADXL345 accelerometer over the SPI communications bus. JAVA // Creates an ADXL345 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's ADXL345_SPI accelerometer = new ADXL345_SPI ( SPI . Port . kMXP , ADXL345_SPI . Range . k8G ); C++ // Creates an ADXL345 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's frc :: ADXL345_SPI accelerometer { SPI :: Port :: kMXP , frc :: ADXL345_SPI :: Range :: kRange_8G }; ADXL362 The ADXL362 class ( Java , C++ ) provides support for the ADXL362 accelerometer over the SPI communications bus. JAVA // Creates an ADXL362 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's ADXL362 accelerometer = new ADXL362 ( SPI . Port . kMXP , ADXL362 . Range . k8G ); C++ // Creates an ADXL362 accelerometer object on the MXP SPI port // with a measurement range from -8 to 8 G's frc :: ADXL362 accelerometer { SPI :: Port :: kMXP , frc :: ADXL362 :: Range :: kRange_8G }; BuiltInAccelerometer The BuiltInAccelerometer class ( Java , C++ ) provides access to the roboRIO’s own built-in accelerometer: JAVA // Creates an object for the built-in accelerometer // Range defaults to +- 8 G's BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); C++ // Creates an object for the built-in accelerometer // Range defaults to +- 8 G's frc :: BuiltInAccelerometer accelerometer ; Third-party accelerometers While WPILib provides native support for a number of accelerometers that are available in the kit of parts or through FIRST Choice, there are a few popular AHRS (Attitude and Heading Reference System) devices commonly used in FRC that include accelerometers. These are generally controlled through vendor libraries, though if they have a simple analog output they can be used with the AnalogAccelerometer class. Using accelerometers in code Note Accelerometers, as their name suggests, measure acceleration. Precise accelerometers can be used to determine position through double-integration (since acceleration is the second derivative of position), much in the way that gyroscopes are used to determine heading. However, the accelerometers available for use in FRC are not nearly high-enough quality to be used this way. It is recommended to use accelerometers in FRC® for any application which needs a rough measurement of the current acceleration. This can include detecting collisions with other robots or field elements, so that vulnerable mechanisms can be automatically retracted. They may also be used to determine when the robot is passing over rough terrain for an autonomous routine (such as traversing the defenses in FIRST Stronghold). For detecting collisions, it is often more robust to measure the jerk than the acceleration. The jerk is the derivative (or rate of change) of acceleration, and indicates how rapidly the forces on the robot are changing - the sudden impulse from a collision causes a sharp spike in the jerk. Jerk can be determined by simply taking the difference of subsequent acceleration measurements, and dividing by the time between them: JAVA double prevXAccel = 0.0 ; double prevYAccel = 0.0 ; BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); @Override public void robotPeriodic () { // Gets the current accelerations in the X and Y directions double xAccel = accelerometer . getX (); double yAccel = accelerometer . getY (); // Calculates the jerk in the X and Y directions // Divides by .02 because default loop timing is 20ms double xJerk = ( xAccel - prevXAccel ) / 0.02 ; double yJerk = ( yAccel - prevYAccel ) / 0.02 ; prevXAccel = xAccel ; prevYAccel = yAccel ; } C++ double prevXAccel = 0.0 ; double prevYAccel = 0.0 ; frc :: BuiltInAccelerometer accelerometer ; void Robot::RobotPeriodic () { // Gets the current accelerations in the X and Y directions double xAccel = accelerometer . GetX (); double yAccel = accelerometer . GetY (); // Calculates the jerk in the X and Y directions // Divides by .02 because default loop timing is 20ms double xJerk = ( xAccel - prevXAccel ) / 0.02 ; double yJerk = ( yAccel - prevYAccel ) / 0.02 ; prevXAccel = xAccel ; prevYAccel = yAccel ; } Most accelerometers legal for FRC use are quite noisy, and it is often a good idea to combine them with the LinearFilter class ( Java , C++ ) to reduce the noise: JAVA BuiltInAccelerometer accelerometer = new BuiltInAccelerometer (); // Create a LinearFilter that will calculate a moving average of the measured X acceleration over the past 10 iterations of the main loop LinearFilter xAccelFilter = LinearFilter . movingAverage ( 10 ); @Override public void robotPeriodic () { // Get the filtered X acceleration double filteredXAccel = xAccelFilter . calculate ( accelerometer . getX ()); } C++ frc :: BuiltInAccelerometer accelerometer ; // Create a LinearFilter that will calculate a moving average of the measured X acceleration over the past 10 iterations of the main loop auto xAccelFilter = frc :: LinearFilter :: MovingAverage ( 10 ); void Robot::RobotPeriodic () { // Get the filtered X acceleration double filteredXAccel = xAccelFilter . Calculate ( accelerometer . GetX ()); }",
      "content_preview": "Accelerometers - Software Note This section covers accelerometers in software. For a hardware guide to accelerometers, see Accelerometers - Hardware . An accelerometer is a device that measures acceleration. Accelerometers generally come in two types: single-axis and 3-axis."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/encoders-software.html",
      "title": "Encoders",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Encoders - Software Note This section covers encoders in software. For a hardware guide to encoders, see Encoders - Hardware . Encoders are devices used to measure motion (usually, the rotation of a shaft). Important The classes in this document are only used for encoders that are plugged directly into the roboRIO! Please reference the appropriate vendors’ documentation for using encoders plugged into motor controllers. Quadrature Encoders - The Encoder Class WPILib provides support for quadrature encoders through the Encoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from encoders. These encoders produce square-wave signals on two channels that are a quarter-period out-of-phase (hence the term, “quadrature”). The pulses are used to measure the rotation, and the direction of motion can be determined from which channel “leads” the other. The FPGA handles quadrature encoders either through a counter module or an encoder module, depending on the decoding type - the choice is handled automatically by WPILib. The FPGA contains 8 encoder modules. Examples of quadrature encoders: AMT103-V available through FIRST Choice CIMcoder CTRE Mag Encoder Grayhill 63r REV Through Bore Encoder US Digital E4T Initializing a Quadrature Encoder A quadrature encoder can be instantiated as follows: JAVA // Initializes an encoder on DIO pins 0 and 1 // Defaults to 4X decoding and non-inverted Encoder m_encoder = new Encoder ( 0 , 1 ); C++ // Initializes an encoder on DIO pins 0 and 1 // Defaults to 4X decoding and non-inverted frc :: Encoder m_encoder { 0 , 1 }; Decoding Type The WPILib Encoder class can decode encoder signals in three different modes: 1X Decoding : Increments the distance for every complete period of the encoder signal (once per four edges). 2X Decoding : Increments the distance for every half-period of the encoder signal (once per two edges). 4X Decoding : Increments the distance for every edge of the encoder signal (four times per period). 4X decoding offers the greatest precision, but at the potential cost of increased “jitter” in rate measurements. To use a different decoding type, use the following constructor: JAVA // Initializes an encoder on DIO pins 0 and 1 // 2X encoding and non-inverted Encoder m_encoder2x = new Encoder ( 0 , 1 , false , Encoder . EncodingType . k2X ); C++ // Initializes an encoder on DIO pins 0 and 1 // 2X encoding and non-inverted frc :: Encoder m_encoder2x { 0 , 1 , false , frc :: Encoder :: EncodingType :: k2X }; Configuring Quadrature Encoder Parameters Note The Encoder class does not make any assumptions about units of distance; it will return values in whatever units were used to calculate the distance-per-pulse value. Users thus have complete control over the distance units used. However, units of time are always in seconds. Note The number of pulses used in the distance-per-pulse calculation does not depend on the decoding type - each “pulse” should always be considered to be a full cycle (four edges). The Encoder class offers a number of configuration methods: JAVA // Configures the encoder to return a distance of 4 for every 256 pulses // Also changes the units of getRate m_encoder . setDistancePerPulse ( 4.0 / 256.0 ); // Configures the encoder to consider itself stopped after .1 seconds m_encoder . setMaxPeriod ( 0.1 ); // Configures the encoder to consider itself stopped when its rate is below 10 m_encoder . setMinRate ( 10 ); // Reverses the direction of the encoder m_encoder . setReverseDirection ( true ); // Configures an encoder to average its period measurement over 5 samples // Can be between 1 and 127 samples m_encoder . setSamplesToAverage ( 5 ); C++ // Configures the encoder to return a distance of 4 for every 256 pulses // Also changes the units of getRate m_encoder . SetDistancePerPulse ( 4.0 / 256.0 ); // Configures the encoder to consider itself stopped after .1 seconds m_encoder . SetMaxPeriod ( 0.1 _s ); // Configures the encoder to consider itself stopped when its rate is below // 10 m_encoder . SetMinRate ( 10 ); // Reverses the direction of the encoder m_encoder . SetReverseDirection ( true ); // Configures an encoder to average its period measurement over 5 samples // Can be between 1 and 127 samples m_encoder . SetSamplesToAverage ( 5 ); Reading information from Quadrature Encoders The Encoder class provides a wealth of information to the user about the motion of the encoder. Distance Note Quadrature encoders measure relative distance, not absolute; the distance value returned will depend on the position of the encoder when the robot was turned on or the encoder value was last reset . Users can obtain the total distance traveled by the encoder with the getDistance() method: JAVA // Gets the distance traveled m_encoder . getDistance (); C++ // Gets the distance traveled m_encoder . GetDistance (); Rate Note Units of time for the Encoder class are always in seconds. Users can obtain the current rate of change of the encoder with the getRate() method: JAVA // Gets the current rate of the encoder m_encoder . getRate (); C++ // Gets the current rate of the encoder m_encoder . GetRate (); Stopped Users can obtain whether the encoder is stationary with the getStopped() method: JAVA // Gets whether the encoder is stopped m_encoder . getStopped (); C++ // Gets whether the encoder is stopped m_encoder . GetStopped (); Direction Users can obtain the direction in which the encoder last moved with the getDirection() method: JAVA // Gets the last direction in which the encoder moved m_encoder . getDirection (); C++ // Gets the last direction in which the encoder moved m_encoder . GetDirection (); Period Users can obtain the period of the encoder pulses (in seconds) with the getPeriod() method: JAVA // Gets the current period of the encoder m_encoder . getPeriod (); C++ // Gets the current period of the encoder m_encoder . GetPeriod (); Resetting a Quadrature Encoder To reset a quadrature encoder to a distance reading of zero, call the reset() method. This is useful for ensuring that the measured distance corresponds to the actual desired physical measurement, and is often called during a homing routine: JAVA // Resets the encoder to read a distance of zero m_encoder . reset (); C++ // Resets the encoder to read a distance of zero m_encoder . Reset (); Duty Cycle Encoders - The DutyCycleEncoder class WPILib provides support for duty cycle (also marketed as PWM ) encoders through the DutyCycleEncoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from duty cycle encoders. The roboRIO’s FPGA handles duty cycle encoders automatically. Warning In 2025 the API changed to remove rollover detection as rollover detection did not work. The get() method returns the value within a rotation where the maximum value in a rotation is defined in the constructor (default 1). Examples of duty cycle encoders: AndyMark Mag Encoder CTRE Mag Encoder REV Through Bore Encoder Team 221 Lamprey2 US Digital MA3 Initializing a Duty Cycle Encoder A duty cycle encoder can be instantiated as follows: JAVA // Initializes a duty cycle encoder on DIO pins 0 DutyCycleEncoder m_encoder = new DutyCycleEncoder ( 0 ); C++ // Initializes a duty cycle encoder on DIO pins 0 frc :: DutyCycleEncoder m_encoder { 0 }; Configuring Duty Cycle Encoder Range and Zero Note The DutyCycleEncoder class does not assume specific units of rotation. It returns values in the same units used to calculate the full range of rotation, giving users complete control over the rotation units. The DutyCycleEncoder class provides an alternate constructor that allows control over the full range and the zero position of the encoder. The zero position is useful for ensuring that the measured rotation corresponds to the desired physical measurement. Unlike quadrature encoders, duty cycle encoders don’t need to be homed. The desired rotation can be read and stored to be set when the program starts. The Preferences class provides methods to save and retrieve these values on the roboRIO. JAVA // Initializes a duty cycle encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) DutyCycleEncoder m_encoderFR = new DutyCycleEncoder ( 0 , 4.0 , 2.0 ); C++ // Initializes a duty cycle encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) frc :: DutyCycleEncoder m_encoderFR { 0 , 4.0 , 2.0 }; Reading Rotation from Duty Cycle Encoders Note Duty Cycle encoders measure absolute rotation. It does not depend on the starting position of the encoder. Users can obtain the rotation measured by the encoder with the get() method: JAVA // Gets the rotation m_encoder . get (); C++ // Gets the rotation m_encoder . Get (); Detecting a Duty Cycle Encoder is Connected As duty cycle encoders output a continuous set of pulses, it is possible to detect that the encoder has been unplugged. JAVA // Gets if the encoder is connected m_encoder . isConnected (); C++ // Gets if the encoder is connected m_encoder . IsConnected (); Analog Encoders - The AnalogEncoder Class WPILib provides support for analog absolute encoders through the AnalogEncoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from analog encoders. Examples of analog encoders: Team 221 Lamprey2 Thrifty Absolute Magnetic Encoder US Digital MA3 Initializing an Analog Encoder An analog encoder can be instantiated as follows: JAVA // Initializes an analog encoder on Analog Input pin 0 AnalogEncoder m_encoder = new AnalogEncoder ( 0 ); C++ // Initializes an analog encoder on Analog Input pin 0 frc :: AnalogEncoder m_encoder { 0 }; Configuring Analog Encoder Range and Zero Note The AnalogEncoder class makes no assumptions about rotation units, returning values in the same units used to calculate the full range. This gives users complete control over the choice of rotation units. The AnalogEncoder class offers an alternate constructor that offers control over the full range of rotation and zero position of the encoder. The zero position is useful for ensuring that the measured rotation corresponds to the desired physical measurement. Unlike quadrature encoders, analog encoders don’t need to be homed. The desired rotation can be read and stored to be set when the program starts. The Preferences class provides methods to save and retrieve these values on the roboRIO. JAVA // Initializes an analog encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) AnalogEncoder m_encoderFR = new AnalogEncoder ( 0 , 4.0 , 2.0 ); C++ // Initializes an analog encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) frc :: AnalogEncoder m_encoderFR { 0 , 4.0 , 2.0 }; Reading Rotation from Analog Encoders Note Analog encoders measure absolute rotation. It does not depend on the starting position of the encoder. Users can obtain the rotation measured by the encoder with the get() method: JAVA // Gets the rotation m_encoder . get (); C++ // Gets the rotation m_encoder . Get (); Using Encoders in Code Encoders are some of the most useful sensors in FRC®; they are very nearly a requirement to make a robot capable of nontrivially-automated actuations and movement. The potential applications of encoders in robot code are too numerous to summarize fully here, but an example is provided below: Driving to a Distance Encoders can be used on a robot drive to create a simple “drive to distance” routine. This is useful in autonomous mode, but has the disadvantage that the robot’s momentum will cause it to overshoot the intended distance. Better methods include using a PID Controller or using Path Planning Note The following example uses the Encoder class, but is similar if other DutyCycleEncoder or AnalogEncoder is used. However, quadrature encoders are typically better suited for drivetrains since they roll over many times and don’t have an absolute position. JAVA // Creates an encoder on DIO ports 0 and 1 Encoder m_encoder = new Encoder ( 0 , 1 ); // Initialize motor controllers and drive Spark m_leftLeader = new Spark ( 0 ); Spark m_leftFollower = new Spark ( 1 ); Spark m_rightLeader = new Spark ( 2 ); Spark m_rightFollower = new Spark ( 3 ); DifferentialDrive m_drive = new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); /** Called once at the beginning of the robot program. */ public Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation m_encoder . setDistancePerPulse ( 1.0 / 256.0 ); // Invert the right side of the drivetrain. You might have to invert the other side m_rightLeader . setInverted ( true ); // Configure the followers to follow the leaders m_leftLeader . addFollower ( m_leftFollower ); m_rightLeader . addFollower ( m_rightFollower ); } /** Drives forward at half speed until the robot has moved 5 feet, then stops. */ @Override public void autonomousPeriodic () { if ( m_encoder . getDistance () < 5.0 ) { m_drive . tankDrive ( 0.5 , 0.5 ); } else { m_drive . tankDrive ( 0.0 , 0.0 ); } } C++ // Creates an encoder on DIO ports 0 and 1. frc :: Encoder m_encoder { 0 , 1 }; // Initialize motor controllers and drive frc :: Spark leftLeader { 0 }; frc :: Spark leftFollower { 1 }; frc :: Spark rightLeader { 2 }; frc :: Spark rightFollower { 3 }; frc :: DifferentialDrive drive {[ & ]( double output ) { leftLeader . Set ( output ); }, [ & ]( double output ) { rightLeader . Set ( output ); }}; Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation m_encoder . SetDistancePerPulse ( 1.0 / 256.0 ); // Invert the right side of the drivetrain. You might have to invert the // other side rightLeader . SetInverted ( true ); // Configure the followers to follow the leaders leftLeader . AddFollower ( leftFollower ); rightLeader . AddFollower ( rightFollower ); } void AutonomousPeriodic () override { // Drives forward at half speed until the robot has moved 5 feet, then // stops: if ( m_encoder . GetDistance () < 5 ) { drive . TankDrive ( 0.5 , 0.5 ); } else { drive . TankDrive ( 0 , 0 ); } } Homing a Mechanism Since quadrature encoders measure relative distance, it is often important to ensure that their “zero-point” is in the right place. A typical way to do this is a “homing routine,” in which a mechanism is moved until it hits a known position (usually accomplished with a limit switch), or “home,” and then the encoder is reset. The following code provides a basic example: Note Homing is not necessary for absolute encoders like duty cycle encoders and analog encoders. JAVA Encoder m_encoder = new Encoder ( 0 , 1 ); Spark m_spark = new Spark ( 0 ); // Limit switch on DIO 2 DigitalInput m_limit = new DigitalInput ( 2 ); /** * Runs the motor backwards at half speed until the limit switch is pressed then turn off the * motor and reset the encoder. */ @Override public void autonomousPeriodic () { if ( ! m_limit . get ()) { m_spark . set ( - 0.5 ); } else { m_spark . set ( 0.0 ); m_encoder . reset (); } } C++ frc :: Encoder m_encoder { 0 , 1 }; frc :: Spark m_spark { 0 }; // Limit switch on DIO 2 frc :: DigitalInput m_limit { 2 }; void AutonomousPeriodic () override { // Runs the motor backwards at half speed until the limit switch is pressed // then turn off the motor and reset the encoder if ( ! m_limit . Get ()) { m_spark . Set ( -0.5 ); } else { m_spark . Set ( 0 ); m_encoder . Reset (); } }",
      "content_preview": "Encoders - Software Note This section covers encoders in software. For a hardware guide to encoders, see Encoders - Hardware . Encoders are devices used to measure motion (usually, the rotation of a shaft)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/robot-preferences.html",
      "title": "Setting Robot Preferences",
      "section": "Basic Programming",
      "language": "All",
      "content": "Setting Robot Preferences The Robot Preferences ( Java , C++ ) class is used to store values in the flash memory on the roboRIO. The values might be for remembering preferences on the robot such as calibration settings for potentiometers, PID values, setpoints, etc. that you would like to change without having to rebuild the program. The values can be viewed on SmartDashboard or Shuffleboard and read and written by the robot program. This example shows how to utilize Preferences to change the setpoint of a PID controller and the P constant. The code examples are adapted from the Arm Simulation example ( Java , C++ ). You can run the Arm Simulation example in the Robot Simulator to see how to use the preference class and interact with it using the dashboards without needing a robot. Initializing Preferences Java public static final String kArmPositionKey = \"ArmPosition\" ; public static final String kArmPKey = \"ArmP\" ; // The P gain for the PID controller that drives this arm. public static final double kDefaultArmKp = 50.0 ; public static final double kDefaultArmSetpointDegrees = 75.0 ; // The P gain for the PID controller that drives this arm. private double m_armKp = Constants . kDefaultArmKp ; private double m_armSetpointDegrees = Constants . kDefaultArmSetpointDegrees ; public Arm () { m_encoder . setDistancePerPulse ( Constants . kArmEncoderDistPerPulse ); // Set the Arm position setpoint and P constant to Preferences if the keys don't already exist Preferences . initDouble ( Constants . kArmPositionKey , m_armSetpointDegrees ); Preferences . initDouble ( Constants . kArmPKey , m_armKp ); } C++ inline constexpr std :: string_view kArmPositionKey = \"ArmPosition\" ; inline constexpr std :: string_view kArmPKey = \"ArmP\" ; inline constexpr double kDefaultArmKp = 50.0 ; inline constexpr units :: degree_t kDefaultArmSetpoint = 75.0 _deg ; Arm :: Arm () { // Set the Arm position setpoint and P constant to Preferences if the keys // don't already exist frc :: Preferences :: InitDouble ( kArmPositionKey , m_armSetpoint . value ()); frc :: Preferences :: InitDouble ( kArmPKey , m_armKp ); } Python kArmPositionKey = \"ArmPosition\" kArmPKey = \"ArmP\" # The P gain for the PID controller that drives this arm. kDefaultArmKp = 50.0 kDefaultArmSetpointDegrees = 75.0 # The P gain for the PID controller that drives this arm. self . armKp = Constants . kDefaultArmKp self . armSetpointDegrees = Constants . kDefaultArmSetpointDegrees # Set the Arm position setpoint and P constant to Preferences if the keys don't already exist wpilib . Preferences . initDouble ( Constants . kArmPositionKey , self . armSetpointDegrees ) wpilib . Preferences . initDouble ( Constants . kArmPKey , self . armKp ) Preferences are stored using a name, the key. It’s helpful to store the key in a constant, like kArmPositionKey and kArmPKey in the code above to avoid typing it multiple times and avoid typos. We also declare variables, kArmKp and armPositionDeg to hold the data retrieved from preferences. In Arm constructor, each key is checked to see if it already exists in the Preferences database. The containsKey method takes one parameter, the key to check if data for that key already exists in the preferences database. If it doesn’t exist, a default value is written. The setDouble method takes two parameters, the key to write and the data to write. There are similar methods for other data types like booleans, ints, and strings. If using the Command Framework, this type of code could be placed in the constructor of a Subsystem or Command. Reading Preferences Java public void loadPreferences () { // Read Preferences for Arm setpoint and kP on entering Teleop m_armSetpointDegrees = Preferences . getDouble ( Constants . kArmPositionKey , m_armSetpointDegrees ); if ( m_armKp != Preferences . getDouble ( Constants . kArmPKey , m_armKp )) { m_armKp = Preferences . getDouble ( Constants . kArmPKey , m_armKp ); m_controller . setP ( m_armKp ); } } C++ void Arm::LoadPreferences () { // Read Preferences for Arm setpoint and kP on entering Teleop m_armSetpoint = units :: degree_t { frc :: Preferences :: GetDouble ( kArmPositionKey , m_armSetpoint . value ())}; if ( m_armKp != frc :: Preferences :: GetDouble ( kArmPKey , m_armKp )) { m_armKp = frc :: Preferences :: GetDouble ( kArmPKey , m_armKp ); m_controller . SetP ( m_armKp ); } } Python def loadPreferences ( self ): # Read Preferences for Arm setpoint and kP on entering Teleop self . armSetpointDegrees = wpilib . Preferences . getDouble ( Constants . kArmPositionKey , self . armSetpointDegrees ) if self . armKp != wpilib . Preferences . getDouble ( Constants . kArmPKey , self . armKp ): self . armKp = wpilib . Preferences . getDouble ( Constants . kArmPKey , self . armKp ) self . controller . setP ( self . armKp ) Reading a preference is easy. The getDouble method takes two parameters, the key to read, and a default value to use in case the preference doesn’t exist. There are similar methods for other data types like booleans, ints, and strings. Depending on the data that is stored in preferences, you can use it when you read it, such as the proportional constant above. Or you can store it in a variable and use it later, such as the setpoint, which is used in telopPeriodic below. Java @Override public void teleopPeriodic () { if ( m_joystick . getTrigger ()) { // Here, we run PID control like normal. m_arm . reachSetpoint (); } else { // Otherwise, we disable the motor. m_arm . stop (); } } /** Run the control loop to reach and maintain the setpoint from the preferences. */ public void reachSetpoint () { var pidOutput = m_controller . calculate ( m_encoder . getDistance (), Units . degreesToRadians ( m_armSetpointDegrees )); m_motor . setVoltage ( pidOutput ); } C++ void Robot::TeleopPeriodic () { if ( m_joystick . GetTrigger ()) { // Here, we run PID control like normal. m_arm . ReachSetpoint (); } else { // Otherwise, we disable the motor. m_arm . Stop (); } } void Arm::ReachSetpoint () { // Here, we run PID control like normal, with a setpoint read from // preferences in degrees. double pidOutput = m_controller . Calculate ( m_encoder . GetDistance (), ( units :: radian_t { m_armSetpoint }. value ())); m_motor . SetVoltage ( units :: volt_t { pidOutput }); } Python def teleopPeriodic ( self ): if self . joystick . getTrigger (): # Here, we run PID control like normal. self . arm . reachSetpoint () else : # Otherwise, we disable the motor. self . arm . stop () def reachSetpoint ( self ): pidOutput = self . controller . calculate ( self . encoder . getDistance (), units . degreesToRadians ( self . armSetpointDegrees ), ) self . motor . setVoltage ( pidOutput ) Using Preferences in SmartDashboard Displaying Preferences in SmartDashboard In the SmartDashboard, the Preferences display can be added to the display by selecting View then Add… then Robot Preferences . This reveals the contents of the preferences file stored in the roboRIO flash memory. Editing Preferences in SmartDashboard The values are shown here with the default values from the code. If the values need to be adjusted they can be edited here and saved. Using Preferences in Shuffleboard Displaying Preferences in Shuffleboard In Shuffleboard, the Preferences display can be added to the display by dragging the preferences field from the sources window. This reveals the contents of the preferences file stored in the roboRIO flash memory. Editing Preferences in Shuffleboard The values are shown here with the default values from the code. If the values need to be adjusted they can be edited here.",
      "content_preview": "Setting Robot Preferences The Robot Preferences ( Java , C++ ) class is used to store values in the flash memory on the roboRIO. The values might be for remembering preferences on the robot such as calibration settings for potentiometers, PID values, setpoints, etc."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/basic-programming/robot-preferences.html?present",
      "title": "Setting Robot Preferences",
      "section": "Basic Programming",
      "language": "All",
      "content": "Setting Robot Preferences The Robot Preferences ( Java , C++ ) class is used to store values in the flash memory on the roboRIO. The values might be for remembering preferences on the robot such as calibration settings for potentiometers, PID values, setpoints, etc. that you would like to change without having to rebuild the program. The values can be viewed on SmartDashboard or Shuffleboard and read and written by the robot program. This example shows how to utilize Preferences to change the setpoint of a PID controller and the P constant. The code examples are adapted from the Arm Simulation example ( Java , C++ ). You can run the Arm Simulation example in the Robot Simulator to see how to use the preference class and interact with it using the dashboards without needing a robot. Initializing Preferences Java public static final String kArmPositionKey = \"ArmPosition\" ; public static final String kArmPKey = \"ArmP\" ; // The P gain for the PID controller that drives this arm. public static final double kDefaultArmKp = 50.0 ; public static final double kDefaultArmSetpointDegrees = 75.0 ; // The P gain for the PID controller that drives this arm. private double m_armKp = Constants . kDefaultArmKp ; private double m_armSetpointDegrees = Constants . kDefaultArmSetpointDegrees ; public Arm () { m_encoder . setDistancePerPulse ( Constants . kArmEncoderDistPerPulse ); // Set the Arm position setpoint and P constant to Preferences if the keys don't already exist Preferences . initDouble ( Constants . kArmPositionKey , m_armSetpointDegrees ); Preferences . initDouble ( Constants . kArmPKey , m_armKp ); } C++ inline constexpr std :: string_view kArmPositionKey = \"ArmPosition\" ; inline constexpr std :: string_view kArmPKey = \"ArmP\" ; inline constexpr double kDefaultArmKp = 50.0 ; inline constexpr units :: degree_t kDefaultArmSetpoint = 75.0 _deg ; Arm :: Arm () { // Set the Arm position setpoint and P constant to Preferences if the keys // don't already exist frc :: Preferences :: InitDouble ( kArmPositionKey , m_armSetpoint . value ()); frc :: Preferences :: InitDouble ( kArmPKey , m_armKp ); } Python kArmPositionKey = \"ArmPosition\" kArmPKey = \"ArmP\" # The P gain for the PID controller that drives this arm. kDefaultArmKp = 50.0 kDefaultArmSetpointDegrees = 75.0 # The P gain for the PID controller that drives this arm. self . armKp = Constants . kDefaultArmKp self . armSetpointDegrees = Constants . kDefaultArmSetpointDegrees # Set the Arm position setpoint and P constant to Preferences if the keys don't already exist wpilib . Preferences . initDouble ( Constants . kArmPositionKey , self . armSetpointDegrees ) wpilib . Preferences . initDouble ( Constants . kArmPKey , self . armKp ) Preferences are stored using a name, the key. It’s helpful to store the key in a constant, like kArmPositionKey and kArmPKey in the code above to avoid typing it multiple times and avoid typos. We also declare variables, kArmKp and armPositionDeg to hold the data retrieved from preferences. In Arm constructor, each key is checked to see if it already exists in the Preferences database. The containsKey method takes one parameter, the key to check if data for that key already exists in the preferences database. If it doesn’t exist, a default value is written. The setDouble method takes two parameters, the key to write and the data to write. There are similar methods for other data types like booleans, ints, and strings. If using the Command Framework, this type of code could be placed in the constructor of a Subsystem or Command. Reading Preferences Java public void loadPreferences () { // Read Preferences for Arm setpoint and kP on entering Teleop m_armSetpointDegrees = Preferences . getDouble ( Constants . kArmPositionKey , m_armSetpointDegrees ); if ( m_armKp != Preferences . getDouble ( Constants . kArmPKey , m_armKp )) { m_armKp = Preferences . getDouble ( Constants . kArmPKey , m_armKp ); m_controller . setP ( m_armKp ); } } C++ void Arm::LoadPreferences () { // Read Preferences for Arm setpoint and kP on entering Teleop m_armSetpoint = units :: degree_t { frc :: Preferences :: GetDouble ( kArmPositionKey , m_armSetpoint . value ())}; if ( m_armKp != frc :: Preferences :: GetDouble ( kArmPKey , m_armKp )) { m_armKp = frc :: Preferences :: GetDouble ( kArmPKey , m_armKp ); m_controller . SetP ( m_armKp ); } } Python def loadPreferences ( self ): # Read Preferences for Arm setpoint and kP on entering Teleop self . armSetpointDegrees = wpilib . Preferences . getDouble ( Constants . kArmPositionKey , self . armSetpointDegrees ) if self . armKp != wpilib . Preferences . getDouble ( Constants . kArmPKey , self . armKp ): self . armKp = wpilib . Preferences . getDouble ( Constants . kArmPKey , self . armKp ) self . controller . setP ( self . armKp ) Reading a preference is easy. The getDouble method takes two parameters, the key to read, and a default value to use in case the preference doesn’t exist. There are similar methods for other data types like booleans, ints, and strings. Depending on the data that is stored in preferences, you can use it when you read it, such as the proportional constant above. Or you can store it in a variable and use it later, such as the setpoint, which is used in telopPeriodic below. Java @Override public void teleopPeriodic () { if ( m_joystick . getTrigger ()) { // Here, we run PID control like normal. m_arm . reachSetpoint (); } else { // Otherwise, we disable the motor. m_arm . stop (); } } /** Run the control loop to reach and maintain the setpoint from the preferences. */ public void reachSetpoint () { var pidOutput = m_controller . calculate ( m_encoder . getDistance (), Units . degreesToRadians ( m_armSetpointDegrees )); m_motor . setVoltage ( pidOutput ); } C++ void Robot::TeleopPeriodic () { if ( m_joystick . GetTrigger ()) { // Here, we run PID control like normal. m_arm . ReachSetpoint (); } else { // Otherwise, we disable the motor. m_arm . Stop (); } } void Arm::ReachSetpoint () { // Here, we run PID control like normal, with a setpoint read from // preferences in degrees. double pidOutput = m_controller . Calculate ( m_encoder . GetDistance (), ( units :: radian_t { m_armSetpoint }. value ())); m_motor . SetVoltage ( units :: volt_t { pidOutput }); } Python def teleopPeriodic ( self ): if self . joystick . getTrigger (): # Here, we run PID control like normal. self . arm . reachSetpoint () else : # Otherwise, we disable the motor. self . arm . stop () def reachSetpoint ( self ): pidOutput = self . controller . calculate ( self . encoder . getDistance (), units . degreesToRadians ( self . armSetpointDegrees ), ) self . motor . setVoltage ( pidOutput ) Using Preferences in SmartDashboard Displaying Preferences in SmartDashboard In the SmartDashboard, the Preferences display can be added to the display by selecting View then Add… then Robot Preferences . This reveals the contents of the preferences file stored in the roboRIO flash memory. Editing Preferences in SmartDashboard The values are shown here with the default values from the code. If the values need to be adjusted they can be edited here and saved. Using Preferences in Shuffleboard Displaying Preferences in Shuffleboard In Shuffleboard, the Preferences display can be added to the display by dragging the preferences field from the sources window. This reveals the contents of the preferences file stored in the roboRIO flash memory. Editing Preferences in Shuffleboard The values are shown here with the default values from the code. If the values need to be adjusted they can be edited here.",
      "content_preview": "Setting Robot Preferences The Robot Preferences ( Java , C++ ) class is used to store values in the flash memory on the roboRIO. The values might be for remembering preferences on the robot such as calibration settings for potentiometers, PID values, setpoints, etc."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/index.html",
      "title": "Path Planning",
      "section": "Path Planning",
      "language": "All",
      "content": "Path Planning Path Planning is the process of creating and following trajectories. These paths use the WPILib trajectory APIs for generation and a LTV Unicycle Controller for following. This section highlights the process of characterizing your robot for system identification, trajectory following, and usage of PathWeaver. Users may also want to read the generic trajectory following documents for additional information about the API and non-commandbased usage. Notice on Swerve Support Swerve support in path following has a couple of limitations that teams need to be aware of: WPILib currently does not support swerve in simulation, please see this pull request. Pathweaver and Trajectory following currently do not incorporate independent heading. Path following using the WPILib trajectory framework on swerve will be the same as a DifferentialDrive robot. Both Choreo and PathPlanner have swerve support. We are sorry for the inconvenience. Trajectory Tutorial Trajectory Tutorial Overview Step 1: Characterizing Your Robot Drive Step 2: Entering the Calculated Constants Step 3: Creating a Drive Subsystem Step 4: Creating and Following a Trajectory PathWeaver Introduction to PathWeaver Creating a Pathweaver Project Visualizing PathWeaver Trajectories Creating Autonomous Routines Importing a PathWeaver JSON Adding field images to PathWeaver Choreo",
      "content_preview": "Path Planning Path Planning is the process of creating and following trajectories. These paths use the WPILib trajectory APIs for generation and a LTV Unicycle Controller for following."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/index.html",
      "title": "Trajectory Tutorial",
      "section": "Path Planning",
      "language": "Java",
      "content": "Trajectory Tutorial This is full tutorial for implementing trajectory generation and following on a differential-drive robot. The full code used in this tutorial can be found in the RamseteCommand example project ( Java , C++ ). Trajectory Tutorial Overview Step 1: Characterizing Your Robot Drive Step 2: Entering the Calculated Constants Step 3: Creating a Drive Subsystem Step 4: Creating and Following a Trajectory",
      "content_preview": "Trajectory Tutorial This is full tutorial for implementing trajectory generation and following on a differential-drive robot. The full code used in this tutorial can be found in the RamseteCommand example project ( Java , C++ )."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/index.html?present",
      "title": "Path Planning",
      "section": "Path Planning",
      "language": "All",
      "content": "Path Planning Path Planning is the process of creating and following trajectories. These paths use the WPILib trajectory APIs for generation and a LTV Unicycle Controller for following. This section highlights the process of characterizing your robot for system identification, trajectory following, and usage of PathWeaver. Users may also want to read the generic trajectory following documents for additional information about the API and non-commandbased usage. Notice on Swerve Support Swerve support in path following has a couple of limitations that teams need to be aware of: WPILib currently does not support swerve in simulation, please see this pull request. Pathweaver and Trajectory following currently do not incorporate independent heading. Path following using the WPILib trajectory framework on swerve will be the same as a DifferentialDrive robot. Both Choreo and PathPlanner have swerve support. We are sorry for the inconvenience. Trajectory Tutorial Trajectory Tutorial Overview Step 1: Characterizing Your Robot Drive Step 2: Entering the Calculated Constants Step 3: Creating a Drive Subsystem Step 4: Creating and Following a Trajectory PathWeaver Introduction to PathWeaver Creating a Pathweaver Project Visualizing PathWeaver Trajectories Creating Autonomous Routines Importing a PathWeaver JSON Adding field images to PathWeaver Choreo",
      "content_preview": "Path Planning Path Planning is the process of creating and following trajectories. These paths use the WPILib trajectory APIs for generation and a LTV Unicycle Controller for following."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/characterizing-drive.html",
      "title": "Step 1: Characterizing Your Robot Drive",
      "section": "Path Planning",
      "language": "All",
      "content": "Step 1: Characterizing Your Robot Drive Note For detailed instructions on using the System Identification tool, see its dedicated documentation . Note The drive identification process requires ample space for the robot to drive. Be sure to have at least a 10’ stretch (ideally closer to 20’) in which the robot can drive during the identification routine. Note The identification data for this tutorial has been generously provided by Team 5190, who generated it as part of a demonstration of this functionality at the 2019 North Carolina State University P2P Workshop. Before accurately following a path with a robot, it is important to have an accurate model for how the robot moves in response to its control inputs. Determining such a model is a process called “system identification.” WPILib’s System Identification tool can accurately determine such a model. Gathering the Data We begin by gathering our drive identification data. Configure and Deploy your robot project . Run the identification Routine . Analyzing the Data Once the identification routine has been run and the data file has been saved, it is time to open it in the analysis pane . Checking Diagnostics Per the system identification guide , we first view the diagnostics to ensure that our data look reasonable: As our data look reasonably linear, and the fit metrics are within acceptable parameters, we proceed to the next step. Record Feedforward Gains Note Feedforward gains do not , in general, transfer across robots. Do not use the gains from this tutorial for your own robot. We now record the feedforward gains calculated by the tool: Since our wheel diameter was specified in meters, our feedforward gains are in the following units: kS : Volts kV : Volts * Seconds / Meters kA : Volts * Seconds^2 / Meters If you have specified your units correctly, your feedforward gains will likely be within an order of magnitude of the ones reported here (a possible exception exists for kA , which may be vanishingly small if your robot is light). If they are not, it is possible you specified one of your drive parameters incorrectly when generating your robot project. A good test for this is to calculate the “theoretical” value of kV , which is 12 volts divided by the theoretical free speed of your drivetrain (which is, in turn, the free speed of the motor times the wheel circumference divided by the gear reduction). This value should agree very closely with the kV measured by the tool - if it does not, you have likely made an error somewhere. Calculate Feedback Gains Note Feedback gains do not , in general, transfer across robots. Do not use the gains from this tutorial for your own robot. We now calculate the feedback gains for the PID control that we will use to follow the path. Trajectory following with WPILib’s RAMSETE controller uses velocity closed-loop control, so we first select Velocity mode in the identification tool: Since we will be using the WPILib PIDController for our velocity loop, we furthermore select the WPILib (2020-) option from the drop-down “presets” menu. This is very important, as the feedback gains will not be in the correct units if we do not select the correct preset: Finally, we calculate and record the feedback gains for our control loop. Since it is a velocity controller, only a P gain is required: Assuming we have done everything correctly, our proportional gain will be in units of Volts * Seconds / Meters. Thus, our calculated gain means that, for each meter per second of velocity error, the controller will output an additional 3.38 volts.",
      "content_preview": "Step 1: Characterizing Your Robot Drive Note For detailed instructions on using the System Identification tool, see its dedicated documentation . Note The drive identification process requires ample space for the robot to drive."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/drawing-pathweaver-path.html",
      "title": "Visualizing PathWeaver Trajectories",
      "section": "Path Planning",
      "language": "All",
      "content": "Visualizing PathWeaver Trajectories PathWeaver’s primary feature is to visualize trajectories. The following images depict a smooth trajectory that represents a trajectory that a robot might take during the autonomous period. Paths can have any number of waypoints that can allow more complex driving to be described. In this case there are 3 waypoints (including the start and stop) depicted with the triangle icons. Each waypoint consists of a X, Y position on the field as well as a robot heading described as the X and Y tangent lines. Creating the Initial Trajectory To start creating a trajectory, click the + (plus) button in the path window. A default trajectory will be created that probably does not have the proper start and end points that you desire. The path also shows the tangent vectors (teal lines) for the start and end points. Changing the angle of the tangent vectors changes the shape of the trajectory. Drag the start and end points of the trajectory to the desired locations. Notice that in this case, the default trajectory does not start in a legal spot for the 2019 game. We can drag the initial waypoint to make the robot start on the HAB. Changing a Waypoint Heading The robot heading can be changed by dragging the tangent vector (teal) line. Here, the final waypoint was dragged to the desired final pose and was rotated to face the rocket. Adding Additional Waypoints to Control the Robot Path Adding additional waypoints and changing their tangent vectors can affect the path that is followed. Additional waypoints can be added by dragging in the middle of the path. In this case, we added another waypoint in the middle of the path. Locking the Tangent Lines Locking tangent lines prevents them from changing when the trajectory is being manipulated. The tangent lines will also be locked when the point is moved. More Precise control of Waypoints While PathWeaver makes it simple to draw trajectories that the robot should follow, it is sometimes hard to precisely set where the waypoints should be placed. In this case, setting the waypoint locations can be done by entering the X and Y value which might come from an accurate CAD model of the field. The points can be entered in the X and Y fields when a waypoint is selected.",
      "content_preview": "Visualizing PathWeaver Trajectories PathWeaver’s primary feature is to visualize trajectories. The following images depict a smooth trajectory that represents a trajectory that a robot might take during the autonomous period."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/entering-constants.html",
      "title": "Step 2: Entering the Calculated Constants",
      "section": "Path Planning",
      "language": "All",
      "content": "Step 2: Entering the Calculated Constants Note In C++, it is important that the feedforward constants be entered as the correct unit type. For more information on C++ units, see The C++ Units Library . Now that we have our system constants, it is time to place them in our code. The recommended place for this is the Constants file of the standard command-based project structure . The relevant parts of the constants file from the RamseteCommand Example Project ( Java , C++ ) can be seen below. Feedforward/Feedback Gains Firstly, we must enter the feedforward and feedback gains which we obtained from the identification tool. Note Feedforward and feedback gains do not , in general, transfer across robots. Do not use the gains from this tutorial for your own robot. JAVA 39 // These are example values only - DO NOT USE THESE FOR YOUR OWN ROBOT! 40 // These characterization values MUST be determined either experimentally or theoretically 41 // for *your* robot's drive. 42 // The Robot Characterization Toolsuite provides a convenient tool for obtaining these 43 // values for your robot. 44 public static final double ksVolts = 0.22 ; 45 public static final double kvVoltSecondsPerMeter = 1.98 ; 46 public static final double kaVoltSecondsSquaredPerMeter = 0.2 ; 47 48 // Example value only - as above, this must be tuned for your drive! 49 public static final double kPDriveVel = 8.5 ; C++ 47 // These are example values only - DO NOT USE THESE FOR YOUR OWN ROBOT! 48 // These characterization values MUST be determined either experimentally or 49 // theoretically for *your* robot's drive. The Robot Characterization 50 // Toolsuite provides a convenient tool for obtaining these values for your 51 // robot. 52 inline constexpr auto ks = 0.22 _V ; 53 inline constexpr auto kv = 1.98 * 1 _V * 1 _s / 1 _m ; 54 inline constexpr auto ka = 0.2 * 1 _V * 1 _s * 1 _s / 1 _m ; 55 56 // Example value only - as above, this must be tuned for your drive! 57 inline constexpr double kPDriveVel = 8.5 ; DifferentialDriveKinematics Additionally, we must create an instance of the DifferentialDriveKinematics class, which allows us to use the trackwidth (i.e. horizontal distance between the wheels) of the robot to convert from chassis speeds to wheel speeds. As elsewhere, we keep our units in meters. JAVA 29 public static final double kTrackwidthMeters = 0.69 ; 30 public static final DifferentialDriveKinematics kDriveKinematics = 31 new DifferentialDriveKinematics ( kTrackwidthMeters ); C++ 38 inline constexpr auto kTrackwidth = 0.69 _m ; 39 extern const frc :: DifferentialDriveKinematics kDriveKinematics ; Max Trajectory Velocity/Acceleration We must also decide on a nominal max acceleration and max velocity for the robot during path-following. The maximum velocity value should be set somewhat below the nominal free-speed of the robot. Due to the later use of the DifferentialDriveVoltageConstraint , the maximum acceleration value is not extremely crucial. Warning Max velocity and acceleration, as defined here, are applied only during trajectory generation. They do not limit the RamseteCommand itself, which may give values to the DriveSubsystem that can cause the robot to greatly exceed these velocities and accelerations. JAVA 57 public static final double kMaxSpeedMetersPerSecond = 3 ; 58 public static final double kMaxAccelerationMetersPerSecondSquared = 1 ; C++ 61 inline constexpr auto kMaxSpeed = 3 _mps ; 62 inline constexpr auto kMaxAcceleration = 1 _mps_sq ; Ramsete Parameters Finally, we must include a pair of parameters for the RAMSETE controller. The values b and zeta shown below should work well for most robots, provided distances have been correctly measured in meters. Larger values of b make convergence more aggressive like a proportional term whereas larger values of zeta provide more damping in the response. These controller gains only dictate how the controller will output adjusted velocities. It does NOT affect the actual velocity tracking of the robot. This means that these controller gains are generally robot-agnostic. Note Gains of 2.0 and 0.7 for b and zeta have been tested repeatedly to produce desirable results when all units were in meters. As such, a zero-argument constructor for RamseteController exists with gains defaulted to these values. JAVA 60 // Reasonable baseline values for a RAMSETE follower in units of meters and seconds 61 public static final double kRamseteB = 2 ; 62 public static final double kRamseteZeta = 0.7 ; C++ 64 // Reasonable baseline values for a RAMSETE follower in units of meters and 65 // seconds 66 inline constexpr auto kRamseteB = 2.0 * 1 _rad * 1 _rad / ( 1 _m * 1 _m ); 67 inline constexpr auto kRamseteZeta = 0.7 / 1 _rad ;",
      "content_preview": "Step 2: Entering the Calculated Constants Note In C++, it is important that the feedforward constants be entered as the correct unit type. For more information on C++ units, see The C++ Units Library . Now that we have our system constants, it is time to place them in our code."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/introduction.html",
      "title": "Introduction to PathWeaver",
      "section": "Path Planning",
      "language": "All",
      "content": "Introduction to PathWeaver Warning PathWeaver is deprecated and will be removed for 2027. Users may find Choreo or PathPlanner more useful. They both have an intuitive user interface and swerve support. Autonomous is an important section of the match; it is exciting when robots do impressive things in autonomous. In order to score, the robot usually need to go somewhere. The faster the robot arrives at that location, the sooner it can score points! The traditional method for autonomous is driving in a straight line, turning to a certain angle, and driving in a straight line again. This approach works fine, but the robot spends a non-negligible amount of time stopping and starting again after each straight line and turn. A more advanced approach to autonomous is called “path planning”. Instead of driving in a straight line and turning once the line is complete, the robot continuously moves, driving with a curve-like motion. This can reduce turning stoppage time. WPILib contains a trajectory generation suite that can be used by teams to generate and follow trajectories. This series of articles will go over how to generate and visualize trajectories using PathWeaver. For a comprehensive tutorial on following trajectories, please visit the end-to-end trajectory tutorial . Note Trajectory following code is required to use PathWeaver. We recommend that you start with Trajectory following and get that working with simple paths. From there you can continue on to testing more complicated paths generated by PathWeaver.",
      "content_preview": "Introduction to PathWeaver Warning PathWeaver is deprecated and will be removed for 2027. Users may find Choreo or PathPlanner more useful. They both have an intuitive user interface and swerve support."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/trajectory-tutorial-overview.html",
      "title": "Trajectory Tutorial Overview",
      "section": "Path Planning",
      "language": "All",
      "content": "Trajectory Tutorial Overview Warning This tutorial uses the Ramsete Controller which has been deprecated . The replacement is LTV Unicycle Controller which has more intuitive tuning. We are looking for volunteers to update this tutorial . Note Before following this tutorial, it is helpful (but not strictly necessary) to have a baseline familiarity with WPILib’s PID control , feedforward , and trajectory features. Note The robot code in this tutorial uses the command-based framework. The command-based framework is strongly recommended for beginning and intermediate teams. The goal of this tutorial is to provide “end-to-end” instruction on implementing a trajectory-following autonomous routine for a differential-drive robot. By following this tutorial, readers will learn how to: Accurately characterize their robot’s drivetrain to obtain accurate feedforward calculations and approximate feedback gains. Configure a drive subsystem to track the robot’s pose using WPILib’s odometry library. Generate a simple trajectory through a set of waypoints using WPILib’s TrajectoryGenerator class. Follow the generated trajectory in an autonomous routine using WPILib’s RamseteCommand class with the calculated feedforward/feedback gains and pose. This tutorial is intended to be approachable for teams without a great deal of programming expertise. While the WPILib library offers significant flexibility in the manner in which its trajectory-following features are implemented, closely following the implementation outlined in this tutorial should provide teams with a relatively-simple, clean, and repeatable solution for autonomous movement. The full robot code for this tutorial can be found in the RamseteCommand Example Project ( Java , C++ ). Why Trajectory Following? FRC® games often feature autonomous tasks that require a robot to effectively and accurately move from a known starting location to a known scoring location. Historically, the most common solution for this sort of task in FRC has been a “drive-turn-drive” approach - that is, drive forward by a known distance, turn by a known angle, and drive forward by another known distance. While the “drive-turn-drive” approach is certainly functional, in recent years teams have begun tracking smooth trajectories which require the robot to drive and turn at the same time. While this is a fundamentally more-complicated technical task, it offers significant benefits: in particular, since the robot no longer has to stop to change directions, the paths can be driven much faster, allowing a robot to score more game pieces during the autonomous period. Beginning in 2020, WPILib now supplies teams with working, advanced code solutions for trajectory generation and tracking, significantly lowering the “barrier-to-entry” for this kind of advanced and effective autonomous motion. Required Equipment To follow this tutorial, you will need ready access to the following materials: A differential-drive robot (such as the AndyMark AM14U5 ), equipped with: Quadrature encoders for measuring the wheel rotation of each side of the drive. A gyroscope for measuring robot heading. A driver-station computer configured with: FRC Driver Station . WPILib . The System Identification Toolsuite .",
      "content_preview": "Trajectory Tutorial Overview Warning This tutorial uses the Ramsete Controller which has been deprecated . The replacement is LTV Unicycle Controller which has more intuitive tuning. We are looking for volunteers to update this tutorial ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/index.html",
      "title": "PathWeaver",
      "section": "Path Planning",
      "language": "All",
      "content": "PathWeaver Warning PathWeaver is deprecated and will be removed for 2027. Users may find Choreo or PathPlanner more useful. They both have an intuitive user interface and swerve support. Introduction to PathWeaver Creating a Pathweaver Project Visualizing PathWeaver Trajectories Creating Autonomous Routines Importing a PathWeaver JSON Adding field images to PathWeaver",
      "content_preview": "PathWeaver Warning PathWeaver is deprecated and will be removed for 2027. Users may find Choreo or PathPlanner more useful. They both have an intuitive user interface and swerve support."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/creating-autonomous-routines.html",
      "title": "Creating Autonomous Routines",
      "section": "Path Planning",
      "language": "All",
      "content": "Creating Autonomous Routines Autonomous Routines (also known as Path Groups) are a way of visualizing where one path ends and the next one starts. An example is when the robot program drives one path, does something after the path has completed, drives to another location to obtain a game piece, then back again to score it. It’s important that the start and end points of each path in the routine have common end and start points. By adding all the paths to a single autonomous routine and selecting the routine, all paths in that routine will be shown. Then each path can be edited while viewing all the paths. Creating an Autonomous Routine Press the + button underneath Autonomous Routines. Then drag the Paths from the Paths section into your Autonomous Routine. Each path added to an autonomous routine will be drawn in a different color making it easy to figure out what the name is for each path. If there are multiple paths in a routine, selection works as follows: Selecting the routine displays all paths in the routine making it easy to see the relationship between them. Any waypoint on any of the paths can be edited while the routine is selected and it will only change the path containing the waypoint. Selecting on a single path in the routine will only display that path, making it easy to precisely see what all the waypoints are doing and preventing clutter in the interface if multiple paths cross over or are close to each other.",
      "content_preview": "Creating Autonomous Routines Autonomous Routines (also known as Path Groups) are a way of visualizing where one path ends and the next one starts. An example is when the robot program drives one path, does something after the path has completed, drives to another location to obtain a game piece,..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/integrating-robot-program.html",
      "title": "Importing a PathWeaver JSON",
      "section": "Path Planning",
      "language": "All",
      "content": "Importing a PathWeaver JSON The TrajectoryUtil class can be used to import a PathWeaver JSON into robot code to follow it. This article will go over importing the trajectory. Please visit the end-to-end trajectory tutorial for more information on following the trajectory. The fromPathweaverJson (Java) / FromPathweaverJson (C++) static methods in TrajectoryUtil can be used to create a trajectory from a JSON file stored on the roboRIO file system. Important To be compatible with the Field2d view in the simulator GUI, the coordinates for the exported JSON have changed. Previously (before 2021), the range of the y-coordinate was from -27 feet to 0 feet whereas now, the range of the y-coordinate is from 0 feet to 27 feet (with 0 being at the bottom of the screen and 27 feet being at the top). This should not affect teams who are correctly resetting their odometry to the starting pose of the trajectory before path following. Note PathWeaver places JSON files in src/main/deploy/paths which will automatically be placed on the roboRIO file system in /home/lvuser/deploy/paths and can be accessed using getDeployDirectory as shown below. JAVA String trajectoryJSON = \"paths/YourPath.wpilib.json\" ; Trajectory trajectory = new Trajectory (); public Robot () { try { Path trajectoryPath = Filesystem . getDeployDirectory (). toPath (). resolve ( trajectoryJSON ); trajectory = TrajectoryUtil . fromPathweaverJson ( trajectoryPath ); } catch ( IOException ex ) { DriverStation . reportError ( \"Unable to open trajectory: \" + trajectoryJSON , ex . getStackTrace ()); } } C++ #include <frc/Filesystem.h> #include <frc/trajectory/TrajectoryUtil.h> #include <wpi/fs.h> frc :: Trajectory trajectory ; Robot :: Robot ()) { fs :: path deployDirectory = frc :: filesystem :: GetDeployDirectory (); deployDirectory = deployDirectory / \"paths\" / \"YourPath.wpilib.json\" ; trajectory = frc :: TrajectoryUtil :: FromPathweaverJson ( deployDirectory . string ()); } In the examples above, YourPath should be replaced with the name of your path. Warning Loading a PathWeaver JSON from file in Java can take more than one loop iteration so it is highly recommended that the robot load these paths on startup.",
      "content_preview": "Importing a PathWeaver JSON The TrajectoryUtil class can be used to import a PathWeaver JSON into robot code to follow it. This article will go over importing the trajectory. Please visit the end-to-end trajectory tutorial for more information on following the trajectory."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/trajectory-tutorial/creating-drive-subsystem.html",
      "title": "Step 3: Creating a Drive Subsystem",
      "section": "Path Planning",
      "language": "All",
      "content": "Step 3: Creating a Drive Subsystem Now that our drive is characterized, it is time to start writing our robot code proper . As mentioned before, we will use the command-based framework for our robot code. Accordingly, our first step is to write a suitable drive subsystem class. The full drive class from the RamseteCommand Example Project ( Java , C++ ) can be seen below. The rest of the article will describe the steps involved in writing this class. Java 5 package edu.wpi.first.wpilibj.examples.ramsetecommand.subsystems ; 6 7 import edu.wpi.first.math.geometry.Pose2d ; 8 import edu.wpi.first.math.kinematics.DifferentialDriveOdometry ; 9 import edu.wpi.first.math.kinematics.DifferentialDriveWheelSpeeds ; 10 import edu.wpi.first.util.sendable.SendableRegistry ; 11 import edu.wpi.first.wpilibj.ADXRS450_Gyro ; 12 import edu.wpi.first.wpilibj.Encoder ; 13 import edu.wpi.first.wpilibj.drive.DifferentialDrive ; 14 import edu.wpi.first.wpilibj.examples.ramsetecommand.Constants.DriveConstants ; 15 import edu.wpi.first.wpilibj.motorcontrol.PWMSparkMax ; 16 import edu.wpi.first.wpilibj2.command.SubsystemBase ; 17 18 public class DriveSubsystem extends SubsystemBase { 19 // The motors on the left side of the drive. 20 private final PWMSparkMax m_leftLeader = new PWMSparkMax ( DriveConstants . kLeftMotor1Port ); 21 private final PWMSparkMax m_leftFollower = new PWMSparkMax ( DriveConstants . kLeftMotor2Port ); 22 23 // The motors on the right side of the drive. 24 private final PWMSparkMax m_rightLeader = new PWMSparkMax ( DriveConstants . kRightMotor1Port ); 25 private final PWMSparkMax m_rightFollower = new PWMSparkMax ( DriveConstants . kRightMotor2Port ); 26 27 // The robot's drive 28 private final DifferentialDrive m_drive = 29 new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); 30 31 // The left-side drive encoder 32 private final Encoder m_leftEncoder = 33 new Encoder ( 34 DriveConstants . kLeftEncoderPorts [ 0 ] , 35 DriveConstants . kLeftEncoderPorts [ 1 ] , 36 DriveConstants . kLeftEncoderReversed ); 37 38 // The right-side drive encoder 39 private final Encoder m_rightEncoder = 40 new Encoder ( 41 DriveConstants . kRightEncoderPorts [ 0 ] , 42 DriveConstants . kRightEncoderPorts [ 1 ] , 43 DriveConstants . kRightEncoderReversed ); 44 45 // The gyro sensor 46 private final ADXRS450_Gyro m_gyro = new ADXRS450_Gyro (); 47 48 // Odometry class for tracking robot pose 49 private final DifferentialDriveOdometry m_odometry ; 50 51 /** Creates a new DriveSubsystem. */ 52 public DriveSubsystem () { 53 SendableRegistry . addChild ( m_drive , m_leftLeader ); 54 SendableRegistry . addChild ( m_drive , m_rightLeader ); 55 56 m_leftLeader . addFollower ( m_leftFollower ); 57 m_rightLeader . addFollower ( m_rightFollower ); 58 59 // We need to invert one side of the drivetrain so that positive voltages 60 // result in both sides moving forward. Depending on how your robot's 61 // gearbox is constructed, you might have to invert the left side instead. 62 m_rightLeader . setInverted ( true ); 63 64 // Sets the distance per pulse for the encoders 65 m_leftEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 66 m_rightEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 67 68 resetEncoders (); 69 m_odometry = 70 new DifferentialDriveOdometry ( 71 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); 72 } 73 74 @Override 75 public void periodic () { 76 // Update the odometry in the periodic block 77 m_odometry . update ( 78 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); 79 } 80 81 /** 82 * Returns the currently-estimated pose of the robot. 83 * 84 * @return The pose. 85 */ 86 public Pose2d getPose () { 87 return m_odometry . getPoseMeters (); 88 } 89 90 /** 91 * Returns the current wheel speeds of the robot. 92 * 93 * @return The current wheel speeds. 94 */ 95 public DifferentialDriveWheelSpeeds getWheelSpeeds () { 96 return new DifferentialDriveWheelSpeeds ( m_leftEncoder . getRate (), m_rightEncoder . getRate ()); 97 } 98 99 /** 100 * Resets the odometry to the specified pose. 101 * 102 * @param pose The pose to which to set the odometry. 103 */ 104 public void resetOdometry ( Pose2d pose ) { 105 m_odometry . resetPosition ( 106 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance (), pose ); 107 } 108 109 /** 110 * Drives the robot using arcade controls. 111 * 112 * @param fwd the commanded forward movement 113 * @param rot the commanded rotation 114 */ 115 public void arcadeDrive ( double fwd , double rot ) { 116 m_drive . arcadeDrive ( fwd , rot ); 117 } 118 119 /** 120 * Controls the left and right sides of the drive directly with voltages. 121 * 122 * @param leftVolts the commanded left output 123 * @param rightVolts the commanded right output 124 */ 125 public void tankDriveVolts ( double leftVolts , double rightVolts ) { 126 m_leftLeader . setVoltage ( leftVolts ); 127 m_rightLeader . setVoltage ( rightVolts ); 128 m_drive . feed (); 129 } 130 131 /** Resets the drive encoders to currently read a position of 0. */ 132 public void resetEncoders () { 133 m_leftEncoder . reset (); 134 m_rightEncoder . reset (); 135 } 136 137 /** 138 * Gets the average distance of the two encoders. 139 * 140 * @return the average of the two encoder readings 141 */ 142 public double getAverageEncoderDistance () { 143 return ( m_leftEncoder . getDistance () + m_rightEncoder . getDistance ()) / 2.0 ; 144 } 145 146 /** 147 * Gets the left drive encoder. 148 * 149 * @return the left drive encoder 150 */ 151 public Encoder getLeftEncoder () { 152 return m_leftEncoder ; 153 } 154 155 /** 156 * Gets the right drive encoder. 157 * 158 * @return the right drive encoder 159 */ 160 public Encoder getRightEncoder () { 161 return m_rightEncoder ; 162 } 163 164 /** 165 * Sets the max output of the drive. Useful for scaling the drive to drive more slowly. 166 * 167 * @param maxOutput the maximum output to which the drive will be constrained 168 */ 169 public void setMaxOutput ( double maxOutput ) { 170 m_drive . setMaxOutput ( maxOutput ); 171 } 172 173 /** Zeroes the heading of the robot. */ 174 public void zeroHeading () { 175 m_gyro . reset (); 176 } 177 178 /** 179 * Returns the heading of the robot. 180 * 181 * @return the robot's heading in degrees, from -180 to 180 182 */ 183 public double getHeading () { 184 return m_gyro . getRotation2d (). getDegrees (); 185 } 186 187 /** 188 * Returns the turn rate of the robot. 189 * 190 * @return The turn rate of the robot, in degrees per second 191 */ 192 public double getTurnRate () { 193 return - m_gyro . getRate (); 194 } 195 } C++ (Header) 5 #pragma once 6 7 #include <frc/ADXRS450_Gyro.h> 8 #include <frc/Encoder.h> 9 #include <frc/drive/DifferentialDrive.h> 10 #include <frc/geometry/Pose2d.h> 11 #include <frc/kinematics/DifferentialDriveOdometry.h> 12 #include <frc/motorcontrol/PWMSparkMax.h> 13 #include <frc2/command/SubsystemBase.h> 14 #include <units/voltage.h> 15 16 #include \"Constants.h\" 17 18 class DriveSubsystem : public frc2 :: SubsystemBase { 19 public : 20 DriveSubsystem (); 21 22 /** 23 * Will be called periodically whenever the CommandScheduler runs. 24 */ 25 void Periodic () override ; 26 27 // Subsystem methods go here. 28 29 /** 30 * Drives the robot using arcade controls. 31 * 32 * @param fwd the commanded forward movement 33 * @param rot the commanded rotation 34 */ 35 void ArcadeDrive ( double fwd , double rot ); 36 37 /** 38 * Controls each side of the drive directly with a voltage. 39 * 40 * @param left the commanded left output 41 * @param right the commanded right output 42 */ 43 void TankDriveVolts ( units :: volt_t left , units :: volt_t right ); 44 45 /** 46 * Resets the drive encoders to currently read a position of 0. 47 */ 48 void ResetEncoders (); 49 50 /** 51 * Gets the average distance of the TWO encoders. 52 * 53 * @return the average of the TWO encoder readings 54 */ 55 double GetAverageEncoderDistance (); 56 57 /** 58 * Gets the left drive encoder. 59 * 60 * @return the left drive encoder 61 */ 62 frc :: Encoder & GetLeftEncoder (); 63 64 /** 65 * Gets the right drive encoder. 66 * 67 * @return the right drive encoder 68 */ 69 frc :: Encoder & GetRightEncoder (); 70 71 /** 72 * Sets the max output of the drive. Useful for scaling the drive to drive 73 * more slowly. 74 * 75 * @param maxOutput the maximum output to which the drive will be constrained 76 */ 77 void SetMaxOutput ( double maxOutput ); 78 79 /** 80 * Returns the heading of the robot. 81 * 82 * @return the robot's heading in degrees, from -180 to 180 83 */ 84 units :: degree_t GetHeading () const ; 85 86 /** 87 * Returns the turn rate of the robot. 88 * 89 * @return The turn rate of the robot, in degrees per second 90 */ 91 double GetTurnRate (); 92 93 /** 94 * Returns the currently-estimated pose of the robot. 95 * 96 * @return The pose. 97 */ 98 frc :: Pose2d GetPose (); 99 100 /** 101 * Returns the current wheel speeds of the robot. 102 * 103 * @return The current wheel speeds. 104 */ 105 frc :: DifferentialDriveWheelSpeeds GetWheelSpeeds (); 106 107 /** 108 * Resets the odometry to the specified pose. 109 * 110 * @param pose The pose to which to set the odometry. 111 */ 112 void ResetOdometry ( frc :: Pose2d pose ); 113 114 private : 115 // Components (e.g. motor controllers and sensors) should generally be 116 // declared private and exposed only through public methods. 117 118 // The motor controllers 119 frc :: PWMSparkMax m_left1 ; 120 frc :: PWMSparkMax m_left2 ; 121 frc :: PWMSparkMax m_right1 ; 122 frc :: PWMSparkMax m_right2 ; 123 124 // The robot's drive 125 frc :: DifferentialDrive m_drive {[ & ]( double output ) { m_left1 . Set ( output ); }, 126 [ & ]( double output ) { m_right1 . Set ( output ); }}; 127 128 // The left-side drive encoder 129 frc :: Encoder m_leftEncoder ; 130 131 // The right-side drive encoder 132 frc :: Encoder m_rightEncoder ; 133 134 // The gyro sensor 135 frc :: ADXRS450_Gyro m_gyro ; 136 137 // Odometry class for tracking robot pose 138 frc :: DifferentialDriveOdometry m_odometry ; 139 }; C++ (Source) 5 #include \"subsystems/DriveSubsystem.h\" 6 7 #include <frc/geometry/Rotation2d.h> 8 #include <frc/kinematics/DifferentialDriveWheelSpeeds.h> 9 10 using namespace DriveConstants ; 11 12 DriveSubsystem :: DriveSubsystem () 13 : m_left1 { kLeftMotor1Port }, 14 m_left2 { kLeftMotor2Port }, 15 m_right1 { kRightMotor1Port }, 16 m_right2 { kRightMotor2Port }, 17 m_leftEncoder { kLeftEncoderPorts [ 0 ], kLeftEncoderPorts [ 1 ]}, 18 m_rightEncoder { kRightEncoderPorts [ 0 ], kRightEncoderPorts [ 1 ]}, 19 m_odometry { m_gyro . GetRotation2d (), units :: meter_t { 0 }, units :: meter_t { 0 }} { 20 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_left1 ); 21 wpi :: SendableRegistry :: AddChild ( & m_drive , & m_right1 ); 22 23 m_left1 . AddFollower ( m_left2 ); 24 m_right1 . AddFollower ( m_right2 ); 25 26 // We need to invert one side of the drivetrain so that positive voltages 27 // result in both sides moving forward. Depending on how your robot's 28 // gearbox is constructed, you might have to invert the left side instead. 29 m_right1 . SetInverted ( true ); 30 31 // Set the distance per pulse for the encoders 32 m_leftEncoder . SetDistancePerPulse ( kEncoderDistancePerPulse . value ()); 33 m_rightEncoder . SetDistancePerPulse ( kEncoderDistancePerPulse . value ()); 34 35 ResetEncoders (); 36 } 37 38 void DriveSubsystem :: Periodic () { 39 // Implementation of subsystem periodic method goes here. 40 m_odometry . Update ( m_gyro . GetRotation2d (), 41 units :: meter_t { m_leftEncoder . GetDistance ()}, 42 units :: meter_t { m_rightEncoder . GetDistance ()}); 43 } 44 45 void DriveSubsystem :: ArcadeDrive ( double fwd , double rot ) { 46 m_drive . ArcadeDrive ( fwd , rot ); 47 } 48 49 void DriveSubsystem :: TankDriveVolts ( units :: volt_t left , units :: volt_t right ) { 50 m_left1 . SetVoltage ( left ); 51 m_right1 . SetVoltage ( right ); 52 m_drive . Feed (); 53 } 54 55 void DriveSubsystem :: ResetEncoders () { 56 m_leftEncoder . Reset (); 57 m_rightEncoder . Reset (); 58 } 59 60 double DriveSubsystem :: GetAverageEncoderDistance () { 61 return ( m_leftEncoder . GetDistance () + m_rightEncoder . GetDistance ()) / 2.0 ; 62 } 63 64 frc :: Encoder & DriveSubsystem :: GetLeftEncoder () { 65 return m_leftEncoder ; 66 } 67 68 frc :: Encoder & DriveSubsystem :: GetRightEncoder () { 69 return m_rightEncoder ; 70 } 71 72 void DriveSubsystem :: SetMaxOutput ( double maxOutput ) { 73 m_drive . SetMaxOutput ( maxOutput ); 74 } 75 76 units :: degree_t DriveSubsystem :: GetHeading () const { 77 return m_gyro . GetRotation2d (). Degrees (); 78 } 79 80 double DriveSubsystem :: GetTurnRate () { 81 return - m_gyro . GetRate (); 82 } 83 84 frc :: Pose2d DriveSubsystem :: GetPose () { 85 return m_odometry . GetPose (); 86 } 87 88 frc :: DifferentialDriveWheelSpeeds DriveSubsystem :: GetWheelSpeeds () { 89 return { units :: meters_per_second_t { m_leftEncoder . GetRate ()}, 90 units :: meters_per_second_t { m_rightEncoder . GetRate ()}}; 91 } 92 93 void DriveSubsystem :: ResetOdometry ( frc :: Pose2d pose ) { 94 m_odometry . ResetPosition ( m_gyro . GetRotation2d (), 95 units :: meter_t { m_leftEncoder . GetDistance ()}, 96 units :: meter_t { m_rightEncoder . GetDistance ()}, pose ); 97 } Configuring the Drive Encoders The drive encoders measure the rotation of the wheels on each side of the drive. To properly configure the encoders, we need to specify two things: the ports the encoders are plugged into, and the distance per encoder pulse. Then, we need to write methods allowing access to the encoder values from code that uses the subsystem. Encoder Ports The encoder ports are specified in the encoder’s constructor, like so: Java 31 // The left-side drive encoder 32 private final Encoder m_leftEncoder = 33 new Encoder ( 34 DriveConstants . kLeftEncoderPorts [ 0 ] , 35 DriveConstants . kLeftEncoderPorts [ 1 ] , 36 DriveConstants . kLeftEncoderReversed ); 37 38 // The right-side drive encoder 39 private final Encoder m_rightEncoder = 40 new Encoder ( 41 DriveConstants . kRightEncoderPorts [ 0 ] , 42 DriveConstants . kRightEncoderPorts [ 1 ] , 43 DriveConstants . kRightEncoderReversed ); C++ (Source) 17 m_leftEncoder { kLeftEncoderPorts [ 0 ], kLeftEncoderPorts [ 1 ]}, 18 m_rightEncoder { kRightEncoderPorts [ 0 ], kRightEncoderPorts [ 1 ]}, Encoder Distance per Pulse The distance per pulse is specified by calling the encoder’s setDistancePerPulse method. Note that for the WPILib Encoder class, “pulse” refers to a full encoder cycle (i.e. four edges), and thus will be 1/4 the value that was specified in the SysId config. Remember, as well, that the distance should be measured in meters! Java 65 m_leftEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); 66 m_rightEncoder . setDistancePerPulse ( DriveConstants . kEncoderDistancePerPulse ); C++ (Source) 32 m_leftEncoder . SetDistancePerPulse ( kEncoderDistancePerPulse . value ()); 33 m_rightEncoder . SetDistancePerPulse ( kEncoderDistancePerPulse . value ()); Encoder Accessor Method To access the values measured by the encoders, we include the following method: Important The returned velocities must be in meters! Because we configured the distance per pulse on the encoders above, calling getRate() will automatically apply the conversion factor from encoder units to meters. If you are not using WPILib’s Encoder class, you must perform this conversion either through the respective vendor’s API or by manually multiplying by a conversion factor. Java 90 /** 91 * Returns the current wheel speeds of the robot. 92 * 93 * @return The current wheel speeds. 94 */ 95 public DifferentialDriveWheelSpeeds getWheelSpeeds () { 96 return new DifferentialDriveWheelSpeeds ( m_leftEncoder . getRate (), m_rightEncoder . getRate ()); 97 } C++ (Source) 88 frc :: DifferentialDriveWheelSpeeds DriveSubsystem::GetWheelSpeeds () { 89 return { units :: meters_per_second_t { m_leftEncoder . GetRate ()}, 90 units :: meters_per_second_t { m_rightEncoder . GetRate ()}}; 91 } We wrap the measured encoder values in a DifferentialDriveWheelSpeeds object for easier integration with the RamseteCommand class later on. Configuring the Gyroscope The gyroscope measures the rate of change of the robot’s heading (which can then be integrated to provide a measurement of the robot’s heading relative to when it first turned on). In our example, we use the Analog Devices ADXRS450 FRC Gyro Board , which was included in the kit of parts for several years: Java 45 // The gyro sensor 46 private final ADXRS450_Gyro m_gyro = new ADXRS450_Gyro (); C++ (Header) 134 // The gyro sensor 135 frc :: ADXRS450_Gyro m_gyro ; Gyroscope Accessor Method To access the current heading measured by the gyroscope, we include the following method: Java 178 /** 179 * Returns the heading of the robot. 180 * 181 * @return the robot's heading in degrees, from -180 to 180 182 */ 183 public double getHeading () { 184 return m_gyro . getRotation2d (). getDegrees (); 185 } C++ (Source) 76 units :: degree_t DriveSubsystem::GetHeading () const { 77 return m_gyro . GetRotation2d (). Degrees (); 78 } Configuring the Odometry Now that we have our encoders and gyroscope configured, it is time to set up our drive subsystem to automatically compute its position from the encoder and gyroscope readings. First, we create a member instance of the DifferentialDriveOdometry class: Java 48 // Odometry class for tracking robot pose 49 private final DifferentialDriveOdometry m_odometry ; C++ (Header) 137 // Odometry class for tracking robot pose 138 frc :: DifferentialDriveOdometry m_odometry ; Then we initialize the DifferentialDriveOdometry . Java 69 m_odometry = 70 new DifferentialDriveOdometry ( 71 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); C++ (Source) 19 m_odometry { m_gyro . GetRotation2d (), units :: meter_t { 0 }, units :: meter_t { 0 }} { Updating the Odometry The odometry class must be regularly updated to incorporate new readings from the encoder and gyroscope. We accomplish this inside the subsystem’s periodic method, which is automatically called once per main loop iteration: Java 74 @Override 75 public void periodic () { 76 // Update the odometry in the periodic block 77 m_odometry . update ( 78 m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); 79 } C++ (Source) 38 void DriveSubsystem::Periodic () { 39 // Implementation of subsystem periodic method goes here. 40 m_odometry . Update ( m_gyro . GetRotation2d (), 41 units :: meter_t { m_leftEncoder . GetDistance ()}, 42 units :: meter_t { m_rightEncoder . GetDistance ()}); 43 } Odometry Accessor Method To access the robot’s current computed pose, we include the following method: Java 81 /** 82 * Returns the currently-estimated pose of the robot. 83 * 84 * @return The pose. 85 */ 86 public Pose2d getPose () { 87 return m_odometry . getPoseMeters (); 88 } C++ (Source) 84 frc :: Pose2d DriveSubsystem::GetPose () { 85 return m_odometry . GetPose (); 86 } Important Before running a RamseteCommand , teams are strongly encouraged to deploy and test the odometry code alone, with values sent to the SmartDashboard or Shuffleboard during the DriveSubsystem ’s periodic() . This odometry must be correct for a RamseteCommand to successfully work, as sign or unit errors can cause a robot to move at high speeds in unpredictable directions. Voltage-Based Drive Method Finally, we must include one additional method - a method that allows us to set the voltage to each side of the drive using the setVoltage() method of the MotorController interface. The default WPILib drive class does not include this functionality, so we must write it ourselves: Java 119 /** 120 * Controls the left and right sides of the drive directly with voltages. 121 * 122 * @param leftVolts the commanded left output 123 * @param rightVolts the commanded right output 124 */ 125 public void tankDriveVolts ( double leftVolts , double rightVolts ) { 126 m_leftLeader . setVoltage ( leftVolts ); 127 m_rightLeader . setVoltage ( rightVolts ); 128 m_drive . feed (); 129 } C++ (Source) 49 void DriveSubsystem::TankDriveVolts ( units :: volt_t left , units :: volt_t right ) { 50 m_left1 . SetVoltage ( left ); 51 m_right1 . SetVoltage ( right ); 52 m_drive . Feed (); 53 } It is very important to use the setVoltage() method rather than the ordinary set() method, as this will automatically compensate for battery “voltage sag” during operation. Since our feedforward voltages are physically-meaningful (as they are based on measured identification data), this is essential to ensuring their accuracy. Warning RamseteCommand itself does not internally enforce any speed or acceleration limits before providing motor voltage parameters to this method. During initial code development, teams are strongly encouraged to apply both maximum and minimum bounds on the input variables before passing these values to setVoltage() while ensuring the trajectory velocity and acceleration are achievable. For example, generate a trajectory with a little less than half of the Robot’s maximum velocity and limit voltage to 6 volts.",
      "content_preview": "Step 3: Creating a Drive Subsystem Now that our drive is characterized, it is time to start writing our robot code proper . As mentioned before, we will use the command-based framework for our robot code. Accordingly, our first step is to write a suitable drive subsystem class."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/adding-field-images.html",
      "title": "Adding field images to PathWeaver",
      "section": "Path Planning",
      "language": "All",
      "content": "Adding field images to PathWeaver Here are instructions for adding your own field image using the 2019 game as an example. Games are loaded from the ~/PathWeaver/Games on Linux and macOS or %USERPROFILE%/PathWeaver/Games directory on Windows. The files can be in either a game-specific subdirectory, or in a zip file in the Games directory. The ZIP file must follow the same layout as a game directory; the JSON file must be in the root of the ZIP file (cannot be in a subdirectory). Download the example FIRST Destination Deep Space field definition here . Other field definitions are available in the allwpilib GitHub repository . File Layout ~/PathWeaver /Games /Custom Game custom-game.json field-image.png OtherGame.zip JSON Format { \"game\": \"game name\", \"field-image\": \"relative/path/to/img.png\", \"field-corners\": { \"top-left\": [x, y], \"bottom-right\": [x, y] }, \"field-size\": [width, length], \"field-unit\": \"unit name\" } The path to the field image is relative to the JSON file. For simplicity, the image file should be in the same directory as the JSON file. The field corners are the X and Y coordinates of the top-left and bottom-right pixels defining the rectangular boundary of the playable area in the field image. Non-rectangular playing areas are not supported. The field size is the width and length of the playable area of the field in the provided units. The field units are case-insensitive and can be in meters, cm, mm, inches, feet, yards, or miles. Singular, plural, and abbreviations are supported (e.g. “meter”,”meters”, and”m”are all valid for specifying meters) Note When making a new field image, a border (minimum of 20 pixels is recommended) should be left around the outside so that waypoints on the field edge are accessible.",
      "content_preview": "Adding field images to PathWeaver Here are instructions for adding your own field image using the 2019 game as an example. Games are loaded from the ~/PathWeaver/Games on Linux and macOS or %USERPROFILE%/PathWeaver/Games directory on Windows."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/choreo/index.html",
      "title": "Choreo",
      "section": "Path Planning",
      "language": "All",
      "content": "Choreo Choreo is a tool for calculating time optimal autonomous trajectories. This allows simple and efficient creation of autonomous routines. Note Detailed documentation for Choreo can be found here . The capabilities of Choreo include creating trajectories with a variety of different constraints scheduling commands at different events on your path support for different drivebases, including swerve and tank",
      "content_preview": "Choreo Choreo is a tool for calculating time optimal autonomous trajectories. This allows simple and efficient creation of autonomous routines. Note Detailed documentation for Choreo can be found here ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/pathplanning/pathweaver/creating-pathweaver-project.html",
      "title": "Creating a Pathweaver Project",
      "section": "Path Planning",
      "language": "All",
      "content": "Creating a Pathweaver Project PathWeaver is the tool used to draw the paths for a robot to follow. The paths for a single program are stored in a PathWeaver project. Starting PathWeaver PathWeaver is started by clicking on the ellipsis icon in the top right of the corner of the Visual Studio Code interface. You must select a source file from the WPILib project to see the icon. Then click on “Start tool” and then click on “PathWeaver” as shown below. Creating the Project To create a PathWeaver project, click on “Create project” and then fill out the project creation form. Notice that hovering over any of the fields in the form will display more information about what is required. Project Directory: This is normally the top level project directory that contains the build.gradle and src files for your robot program. Choosing this directory is the expected way to use PathWeaver and will cause it to locate all the output files in the correct directories for automatic path deployment to your robot. Output directory: The directory where the paths are stored for deployment to your robot. If you specified the top level project folder of our robot project in the previous step (as recommended) filling in the output directory is optional. Game: The game (which FRC® game is being used) will cause the correct field image overlay to be used. You can also create your own field images and the procedure will be described later in this series. Length Unit: The units to be used in describing your robot and for the field measurements when visualizing trajectories using PathWeaver. Export Unit: The units to be used when exporting the paths and waypoints. If you are planning to use WPILib Trajectories, then you should choose Always Meters . Choosing Same as Project will export in the same units as Length Unit above. Max Velocity: The max speed of the robot for trajectory tracking. The kitbot runs at ~10 \\(ft/sec\\) which is ~3 \\(m/sec\\) . Max Acceleration: The max acceleration of the robot for trajectory tracking. Using a conservative 1 \\(m/sec^2\\) is a good place to start if you don’t know your drivetain’s characteristics. Wheel Base: The distance between the left and right wheels of your robot. This is used to ensure that no wheel on a differential drive will go over the specified max velocity around turns. PathWeaver User Interface The PathWeaver user interface consists of the following: The field area in the top left corner, which takes up most of the PathWeaver window. Trajectories are drawn on this part of the program. The properties of the currently selected waypoint are displayed in the bottom pane. These properties include the X and Y, along with the tangents at each point. A group of paths (or an “autonomous” mode) is displayed on the upper right side of the window. This is a convenient way of seeing all of the trajectories in a single auto mode. The individual paths that a robot might follow are displayed in the lower right side of the window. The “Build Paths” button will export the trajectories in a JSON format. These JSON files can be used from the robot code to follow the trajectory. The “Edit Project” button allows you to edit the project properties.",
      "content_preview": "Creating a Pathweaver Project PathWeaver is the tool used to draw the paths for a robot to follow. The paths for a single program are stored in a PathWeaver project."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/encoders-software.html?present",
      "title": "Encoders",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Encoders - Software Note This section covers encoders in software. For a hardware guide to encoders, see Encoders - Hardware . Encoders are devices used to measure motion (usually, the rotation of a shaft). Important The classes in this document are only used for encoders that are plugged directly into the roboRIO! Please reference the appropriate vendors’ documentation for using encoders plugged into motor controllers. Quadrature Encoders - The Encoder Class WPILib provides support for quadrature encoders through the Encoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from encoders. These encoders produce square-wave signals on two channels that are a quarter-period out-of-phase (hence the term, “quadrature”). The pulses are used to measure the rotation, and the direction of motion can be determined from which channel “leads” the other. The FPGA handles quadrature encoders either through a counter module or an encoder module, depending on the decoding type - the choice is handled automatically by WPILib. The FPGA contains 8 encoder modules. Examples of quadrature encoders: AMT103-V available through FIRST Choice CIMcoder CTRE Mag Encoder Grayhill 63r REV Through Bore Encoder US Digital E4T Initializing a Quadrature Encoder A quadrature encoder can be instantiated as follows: JAVA // Initializes an encoder on DIO pins 0 and 1 // Defaults to 4X decoding and non-inverted Encoder m_encoder = new Encoder ( 0 , 1 ); C++ // Initializes an encoder on DIO pins 0 and 1 // Defaults to 4X decoding and non-inverted frc :: Encoder m_encoder { 0 , 1 }; Decoding Type The WPILib Encoder class can decode encoder signals in three different modes: 1X Decoding : Increments the distance for every complete period of the encoder signal (once per four edges). 2X Decoding : Increments the distance for every half-period of the encoder signal (once per two edges). 4X Decoding : Increments the distance for every edge of the encoder signal (four times per period). 4X decoding offers the greatest precision, but at the potential cost of increased “jitter” in rate measurements. To use a different decoding type, use the following constructor: JAVA // Initializes an encoder on DIO pins 0 and 1 // 2X encoding and non-inverted Encoder m_encoder2x = new Encoder ( 0 , 1 , false , Encoder . EncodingType . k2X ); C++ // Initializes an encoder on DIO pins 0 and 1 // 2X encoding and non-inverted frc :: Encoder m_encoder2x { 0 , 1 , false , frc :: Encoder :: EncodingType :: k2X }; Configuring Quadrature Encoder Parameters Note The Encoder class does not make any assumptions about units of distance; it will return values in whatever units were used to calculate the distance-per-pulse value. Users thus have complete control over the distance units used. However, units of time are always in seconds. Note The number of pulses used in the distance-per-pulse calculation does not depend on the decoding type - each “pulse” should always be considered to be a full cycle (four edges). The Encoder class offers a number of configuration methods: JAVA // Configures the encoder to return a distance of 4 for every 256 pulses // Also changes the units of getRate m_encoder . setDistancePerPulse ( 4.0 / 256.0 ); // Configures the encoder to consider itself stopped after .1 seconds m_encoder . setMaxPeriod ( 0.1 ); // Configures the encoder to consider itself stopped when its rate is below 10 m_encoder . setMinRate ( 10 ); // Reverses the direction of the encoder m_encoder . setReverseDirection ( true ); // Configures an encoder to average its period measurement over 5 samples // Can be between 1 and 127 samples m_encoder . setSamplesToAverage ( 5 ); C++ // Configures the encoder to return a distance of 4 for every 256 pulses // Also changes the units of getRate m_encoder . SetDistancePerPulse ( 4.0 / 256.0 ); // Configures the encoder to consider itself stopped after .1 seconds m_encoder . SetMaxPeriod ( 0.1 _s ); // Configures the encoder to consider itself stopped when its rate is below // 10 m_encoder . SetMinRate ( 10 ); // Reverses the direction of the encoder m_encoder . SetReverseDirection ( true ); // Configures an encoder to average its period measurement over 5 samples // Can be between 1 and 127 samples m_encoder . SetSamplesToAverage ( 5 ); Reading information from Quadrature Encoders The Encoder class provides a wealth of information to the user about the motion of the encoder. Distance Note Quadrature encoders measure relative distance, not absolute; the distance value returned will depend on the position of the encoder when the robot was turned on or the encoder value was last reset . Users can obtain the total distance traveled by the encoder with the getDistance() method: JAVA // Gets the distance traveled m_encoder . getDistance (); C++ // Gets the distance traveled m_encoder . GetDistance (); Rate Note Units of time for the Encoder class are always in seconds. Users can obtain the current rate of change of the encoder with the getRate() method: JAVA // Gets the current rate of the encoder m_encoder . getRate (); C++ // Gets the current rate of the encoder m_encoder . GetRate (); Stopped Users can obtain whether the encoder is stationary with the getStopped() method: JAVA // Gets whether the encoder is stopped m_encoder . getStopped (); C++ // Gets whether the encoder is stopped m_encoder . GetStopped (); Direction Users can obtain the direction in which the encoder last moved with the getDirection() method: JAVA // Gets the last direction in which the encoder moved m_encoder . getDirection (); C++ // Gets the last direction in which the encoder moved m_encoder . GetDirection (); Period Users can obtain the period of the encoder pulses (in seconds) with the getPeriod() method: JAVA // Gets the current period of the encoder m_encoder . getPeriod (); C++ // Gets the current period of the encoder m_encoder . GetPeriod (); Resetting a Quadrature Encoder To reset a quadrature encoder to a distance reading of zero, call the reset() method. This is useful for ensuring that the measured distance corresponds to the actual desired physical measurement, and is often called during a homing routine: JAVA // Resets the encoder to read a distance of zero m_encoder . reset (); C++ // Resets the encoder to read a distance of zero m_encoder . Reset (); Duty Cycle Encoders - The DutyCycleEncoder class WPILib provides support for duty cycle (also marketed as PWM ) encoders through the DutyCycleEncoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from duty cycle encoders. The roboRIO’s FPGA handles duty cycle encoders automatically. Warning In 2025 the API changed to remove rollover detection as rollover detection did not work. The get() method returns the value within a rotation where the maximum value in a rotation is defined in the constructor (default 1). Examples of duty cycle encoders: AndyMark Mag Encoder CTRE Mag Encoder REV Through Bore Encoder Team 221 Lamprey2 US Digital MA3 Initializing a Duty Cycle Encoder A duty cycle encoder can be instantiated as follows: JAVA // Initializes a duty cycle encoder on DIO pins 0 DutyCycleEncoder m_encoder = new DutyCycleEncoder ( 0 ); C++ // Initializes a duty cycle encoder on DIO pins 0 frc :: DutyCycleEncoder m_encoder { 0 }; Configuring Duty Cycle Encoder Range and Zero Note The DutyCycleEncoder class does not assume specific units of rotation. It returns values in the same units used to calculate the full range of rotation, giving users complete control over the rotation units. The DutyCycleEncoder class provides an alternate constructor that allows control over the full range and the zero position of the encoder. The zero position is useful for ensuring that the measured rotation corresponds to the desired physical measurement. Unlike quadrature encoders, duty cycle encoders don’t need to be homed. The desired rotation can be read and stored to be set when the program starts. The Preferences class provides methods to save and retrieve these values on the roboRIO. JAVA // Initializes a duty cycle encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) DutyCycleEncoder m_encoderFR = new DutyCycleEncoder ( 0 , 4.0 , 2.0 ); C++ // Initializes a duty cycle encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) frc :: DutyCycleEncoder m_encoderFR { 0 , 4.0 , 2.0 }; Reading Rotation from Duty Cycle Encoders Note Duty Cycle encoders measure absolute rotation. It does not depend on the starting position of the encoder. Users can obtain the rotation measured by the encoder with the get() method: JAVA // Gets the rotation m_encoder . get (); C++ // Gets the rotation m_encoder . Get (); Detecting a Duty Cycle Encoder is Connected As duty cycle encoders output a continuous set of pulses, it is possible to detect that the encoder has been unplugged. JAVA // Gets if the encoder is connected m_encoder . isConnected (); C++ // Gets if the encoder is connected m_encoder . IsConnected (); Analog Encoders - The AnalogEncoder Class WPILib provides support for analog absolute encoders through the AnalogEncoder class ( Java , C++ ). This class provides a simple API for configuring and reading data from analog encoders. Examples of analog encoders: Team 221 Lamprey2 Thrifty Absolute Magnetic Encoder US Digital MA3 Initializing an Analog Encoder An analog encoder can be instantiated as follows: JAVA // Initializes an analog encoder on Analog Input pin 0 AnalogEncoder m_encoder = new AnalogEncoder ( 0 ); C++ // Initializes an analog encoder on Analog Input pin 0 frc :: AnalogEncoder m_encoder { 0 }; Configuring Analog Encoder Range and Zero Note The AnalogEncoder class makes no assumptions about rotation units, returning values in the same units used to calculate the full range. This gives users complete control over the choice of rotation units. The AnalogEncoder class offers an alternate constructor that offers control over the full range of rotation and zero position of the encoder. The zero position is useful for ensuring that the measured rotation corresponds to the desired physical measurement. Unlike quadrature encoders, analog encoders don’t need to be homed. The desired rotation can be read and stored to be set when the program starts. The Preferences class provides methods to save and retrieve these values on the roboRIO. JAVA // Initializes an analog encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) AnalogEncoder m_encoderFR = new AnalogEncoder ( 0 , 4.0 , 2.0 ); C++ // Initializes an analog encoder on DIO pins 0 to return a value of 4 for // a full rotation, with the encoder reporting 0 half way through rotation (2 // out of 4) frc :: AnalogEncoder m_encoderFR { 0 , 4.0 , 2.0 }; Reading Rotation from Analog Encoders Note Analog encoders measure absolute rotation. It does not depend on the starting position of the encoder. Users can obtain the rotation measured by the encoder with the get() method: JAVA // Gets the rotation m_encoder . get (); C++ // Gets the rotation m_encoder . Get (); Using Encoders in Code Encoders are some of the most useful sensors in FRC®; they are very nearly a requirement to make a robot capable of nontrivially-automated actuations and movement. The potential applications of encoders in robot code are too numerous to summarize fully here, but an example is provided below: Driving to a Distance Encoders can be used on a robot drive to create a simple “drive to distance” routine. This is useful in autonomous mode, but has the disadvantage that the robot’s momentum will cause it to overshoot the intended distance. Better methods include using a PID Controller or using Path Planning Note The following example uses the Encoder class, but is similar if other DutyCycleEncoder or AnalogEncoder is used. However, quadrature encoders are typically better suited for drivetrains since they roll over many times and don’t have an absolute position. JAVA // Creates an encoder on DIO ports 0 and 1 Encoder m_encoder = new Encoder ( 0 , 1 ); // Initialize motor controllers and drive Spark m_leftLeader = new Spark ( 0 ); Spark m_leftFollower = new Spark ( 1 ); Spark m_rightLeader = new Spark ( 2 ); Spark m_rightFollower = new Spark ( 3 ); DifferentialDrive m_drive = new DifferentialDrive ( m_leftLeader :: set , m_rightLeader :: set ); /** Called once at the beginning of the robot program. */ public Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation m_encoder . setDistancePerPulse ( 1.0 / 256.0 ); // Invert the right side of the drivetrain. You might have to invert the other side m_rightLeader . setInverted ( true ); // Configure the followers to follow the leaders m_leftLeader . addFollower ( m_leftFollower ); m_rightLeader . addFollower ( m_rightFollower ); } /** Drives forward at half speed until the robot has moved 5 feet, then stops. */ @Override public void autonomousPeriodic () { if ( m_encoder . getDistance () < 5.0 ) { m_drive . tankDrive ( 0.5 , 0.5 ); } else { m_drive . tankDrive ( 0.0 , 0.0 ); } } C++ // Creates an encoder on DIO ports 0 and 1. frc :: Encoder m_encoder { 0 , 1 }; // Initialize motor controllers and drive frc :: Spark leftLeader { 0 }; frc :: Spark leftFollower { 1 }; frc :: Spark rightLeader { 2 }; frc :: Spark rightFollower { 3 }; frc :: DifferentialDrive drive {[ & ]( double output ) { leftLeader . Set ( output ); }, [ & ]( double output ) { rightLeader . Set ( output ); }}; Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation m_encoder . SetDistancePerPulse ( 1.0 / 256.0 ); // Invert the right side of the drivetrain. You might have to invert the // other side rightLeader . SetInverted ( true ); // Configure the followers to follow the leaders leftLeader . AddFollower ( leftFollower ); rightLeader . AddFollower ( rightFollower ); } void AutonomousPeriodic () override { // Drives forward at half speed until the robot has moved 5 feet, then // stops: if ( m_encoder . GetDistance () < 5 ) { drive . TankDrive ( 0.5 , 0.5 ); } else { drive . TankDrive ( 0 , 0 ); } } Homing a Mechanism Since quadrature encoders measure relative distance, it is often important to ensure that their “zero-point” is in the right place. A typical way to do this is a “homing routine,” in which a mechanism is moved until it hits a known position (usually accomplished with a limit switch), or “home,” and then the encoder is reset. The following code provides a basic example: Note Homing is not necessary for absolute encoders like duty cycle encoders and analog encoders. JAVA Encoder m_encoder = new Encoder ( 0 , 1 ); Spark m_spark = new Spark ( 0 ); // Limit switch on DIO 2 DigitalInput m_limit = new DigitalInput ( 2 ); /** * Runs the motor backwards at half speed until the limit switch is pressed then turn off the * motor and reset the encoder. */ @Override public void autonomousPeriodic () { if ( ! m_limit . get ()) { m_spark . set ( - 0.5 ); } else { m_spark . set ( 0.0 ); m_encoder . reset (); } } C++ frc :: Encoder m_encoder { 0 , 1 }; frc :: Spark m_spark { 0 }; // Limit switch on DIO 2 frc :: DigitalInput m_limit { 2 }; void AutonomousPeriodic () override { // Runs the motor backwards at half speed until the limit switch is pressed // then turn off the motor and reset the encoder if ( ! m_limit . Get ()) { m_spark . Set ( -0.5 ); } else { m_spark . Set ( 0 ); m_encoder . Reset (); } }",
      "content_preview": "Encoders - Software Note This section covers encoders in software. For a hardware guide to encoders, see Encoders - Hardware . Encoders are devices used to measure motion (usually, the rotation of a shaft)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/limit-switch.html",
      "title": "Programming Limit Switches",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Programming Limit Switches Limit switches are often used to control mechanisms on robots. While limit switches are simple to use, they only can sense a single position of a moving part. This makes them ideal for ensuring that movement doesn’t exceed some limit but not so good at controlling the speed of the movement as it approaches the limit. For example, a rotational shoulder joint on a robot arm would best be controlled using a potentiometer or an absolute encoder. A limit switch could make sure that if the potentiometer ever failed, the limit switch would stop the robot from going too far and causing damage. Limit switches can have “normally open” or “normally closed” outputs. This will control if a high signal means the switch is opened or closed. To learn more about limit switch hardware see this article . Controlling a Motor with Two Limit Switches JAVA DigitalInput m_toplimitSwitch = new DigitalInput ( 0 ); DigitalInput m_bottomlimitSwitch = new DigitalInput ( 1 ); PWMVictorSPX m_motor = new PWMVictorSPX ( 0 ); Joystick m_joystick = new Joystick ( 0 ); @Override public void teleopPeriodic () { setMotorSpeed ( m_joystick . getRawAxis ( 2 )); } /** * Sets the motor speed based on joystick input while respecting limit switches. * * @param speed the desired speed of the motor, positive for up and negative for down */ public void setMotorSpeed ( double speed ) { if ( speed > 0 ) { if ( m_toplimitSwitch . get ()) { // We are going up and top limit is tripped so stop m_motor . set ( 0 ); } else { // We are going up but top limit is not tripped so go at commanded speed m_motor . set ( speed ); } } else { if ( m_bottomlimitSwitch . get ()) { // We are going down and bottom limit is tripped so stop m_motor . set ( 0 ); } else { // We are going down but bottom limit is not tripped so go at commanded speed m_motor . set ( speed ); } } } C++ frc :: DigitalInput m_toplimitSwitch { 0 }; frc :: DigitalInput m_bottomlimitSwitch { 1 }; frc :: PWMVictorSPX m_motor { 0 }; frc :: Joystick m_joystick { 0 }; void TeleopPeriodic () override { SetMotorSpeed ( m_joystick . GetRawAxis ( 2 )); } void SetMotorSpeed ( double speed ) { if ( speed > 0 ) { if ( m_toplimitSwitch . Get ()) { // We are going up and top limit is tripped so stop m_motor . Set ( 0 ); } else { // We are going up but top limit is not tripped so go at commanded speed m_motor . Set ( speed ); } } else { if ( m_bottomlimitSwitch . Get ()) { // We are going down and bottom limit is tripped so stop m_motor . Set ( 0 ); } else { // We are going down but bottom limit is not tripped so go at commanded // speed m_motor . Set ( speed ); } } }",
      "content_preview": "Programming Limit Switches Limit switches are often used to control mechanisms on robots. While limit switches are simple to use, they only can sense a single position of a moving part."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/limit-switch.html?present",
      "title": "Programming Limit Switches",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Programming Limit Switches Limit switches are often used to control mechanisms on robots. While limit switches are simple to use, they only can sense a single position of a moving part. This makes them ideal for ensuring that movement doesn’t exceed some limit but not so good at controlling the speed of the movement as it approaches the limit. For example, a rotational shoulder joint on a robot arm would best be controlled using a potentiometer or an absolute encoder. A limit switch could make sure that if the potentiometer ever failed, the limit switch would stop the robot from going too far and causing damage. Limit switches can have “normally open” or “normally closed” outputs. This will control if a high signal means the switch is opened or closed. To learn more about limit switch hardware see this article . Controlling a Motor with Two Limit Switches JAVA DigitalInput m_toplimitSwitch = new DigitalInput ( 0 ); DigitalInput m_bottomlimitSwitch = new DigitalInput ( 1 ); PWMVictorSPX m_motor = new PWMVictorSPX ( 0 ); Joystick m_joystick = new Joystick ( 0 ); @Override public void teleopPeriodic () { setMotorSpeed ( m_joystick . getRawAxis ( 2 )); } /** * Sets the motor speed based on joystick input while respecting limit switches. * * @param speed the desired speed of the motor, positive for up and negative for down */ public void setMotorSpeed ( double speed ) { if ( speed > 0 ) { if ( m_toplimitSwitch . get ()) { // We are going up and top limit is tripped so stop m_motor . set ( 0 ); } else { // We are going up but top limit is not tripped so go at commanded speed m_motor . set ( speed ); } } else { if ( m_bottomlimitSwitch . get ()) { // We are going down and bottom limit is tripped so stop m_motor . set ( 0 ); } else { // We are going down but bottom limit is not tripped so go at commanded speed m_motor . set ( speed ); } } } C++ frc :: DigitalInput m_toplimitSwitch { 0 }; frc :: DigitalInput m_bottomlimitSwitch { 1 }; frc :: PWMVictorSPX m_motor { 0 }; frc :: Joystick m_joystick { 0 }; void TeleopPeriodic () override { SetMotorSpeed ( m_joystick . GetRawAxis ( 2 )); } void SetMotorSpeed ( double speed ) { if ( speed > 0 ) { if ( m_toplimitSwitch . Get ()) { // We are going up and top limit is tripped so stop m_motor . Set ( 0 ); } else { // We are going up but top limit is not tripped so go at commanded speed m_motor . Set ( speed ); } } else { if ( m_bottomlimitSwitch . Get ()) { // We are going down and bottom limit is tripped so stop m_motor . Set ( 0 ); } else { // We are going down but bottom limit is not tripped so go at commanded // speed m_motor . Set ( speed ); } } }",
      "content_preview": "Programming Limit Switches Limit switches are often used to control mechanisms on robots. While limit switches are simple to use, they only can sense a single position of a moving part."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/analog-potentiometers-software.html",
      "title": "Analog Potentiometers",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Analog Potentiometers - Software Note This section covers analog potentiometers in software. For a hardware guide to analog potentiometers, see Analog Potentiometers - Hardware . Potentiometers are variable resistors that allow information about position to be converted into an analog voltage signal. This signal can be read by the roboRIO to control whatever device is attached to the potentiometer. While it is possible to read information from a potentiometer directly with an Analog Inputs - Software , WPILib provides an AnalogPotentiometer class ( Java , C++ ) that handles re-scaling the values into meaningful units for the user. It is strongly encouraged to use this class. In fact, the AnalogPotentiometer name is something of a misnomer - this class should be used for the vast majority of sensors that return their signal as a simple, linearly-scaled analog voltage. The AnalogPotentiometer class Note The “full range” or “scale” parameters in the AnalogPotentiometer constructor are scale factors from a range of 0-1 to the actual range, not from 0-5. That is, they represent a native fractional scale, rather than a voltage scale. An AnalogPotentiometer can be initialized as follows: JAVA // Initializes an AnalogPotentiometer on analog port 0 // The full range of motion (in meaningful external units) is 0-180 (this could be degrees, for // instance) // The \"starting point\" of the motion, i.e. where the mechanism is located when the potentiometer // reads 0v, is 30. AnalogPotentiometer m_pot = new AnalogPotentiometer ( 0 , 180 , 30 ); C++ // Initializes an AnalogPotentiometer on analog port 0 // The full range of motion (in meaningful external units) is 0-180 (this // could be degrees, for instance) The \"starting point\" of the motion, i.e. // where the mechanism is located when the potentiometer reads 0v, is 30. frc :: AnalogPotentiometer m_pot { 0 , 180 , 30 }; Customizing the underlying AnalogInput Note If the user changes the scaling of the AnalogInput with oversampling, this must be reflected in the scale setting passed to the AnalogPotentiometer . If the user would like to apply custom settings to the underlying AnalogInput used by the AnalogPotentiometer , an alternative constructor may be used in which the AnalogInput is injected: JAVA // Initializes an AnalogInput on port 1 AnalogInput m_input = new AnalogInput ( 0 ); // Initializes an AnalogPotentiometer with the given AnalogInput // The full range of motion (in meaningful external units) is 0-180 (this could be degrees, for // instance) // The \"starting point\" of the motion, i.e. where the mechanism is located when the potentiometer // reads 0v, is 30. AnalogPotentiometer m_pot1 = new AnalogPotentiometer ( m_input , 180 , 30 ); C++ // Initializes an AnalogInput on port 1 frc :: AnalogInput m_input { 1 }; // Initializes an AnalogPotentiometer with the given AnalogInput // The full range of motion (in meaningful external units) is 0-180 (this // could be degrees, for instance) The \"starting point\" of the motion, i.e. // where the mechanism is located when the potentiometer reads 0v, is 30. frc :: AnalogPotentiometer m_pot1 { & m_input , 180 , 30 }; Reading values from the AnalogPotentiometer The scaled value can be read by simply calling the get method: JAVA // Get the value of the potentiometer m_pot . get (); C++ // Get the value of the potentiometer m_pot . Get (); Using AnalogPotentiometers in code Analog sensors can be used in code much in the way other sensors that measure the same thing can be. If the analog sensor is a potentiometer measuring an arm angle, it can be used similarly to an encoder . If it is an ultrasonic sensor, it can be used similarly to other ultrasonics . It is very important to keep in mind that actual, physical potentiometers generally have a limited range of motion. Safeguards should be present in both the physical mechanism and the code to ensure that the mechanism does not break the sensor by traveling past its maximum throw.",
      "content_preview": "Analog Potentiometers - Software Note This section covers analog potentiometers in software. For a hardware guide to analog potentiometers, see Analog Potentiometers - Hardware ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/analog-potentiometers-software.html?present",
      "title": "Analog Potentiometers",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Analog Potentiometers - Software Note This section covers analog potentiometers in software. For a hardware guide to analog potentiometers, see Analog Potentiometers - Hardware . Potentiometers are variable resistors that allow information about position to be converted into an analog voltage signal. This signal can be read by the roboRIO to control whatever device is attached to the potentiometer. While it is possible to read information from a potentiometer directly with an Analog Inputs - Software , WPILib provides an AnalogPotentiometer class ( Java , C++ ) that handles re-scaling the values into meaningful units for the user. It is strongly encouraged to use this class. In fact, the AnalogPotentiometer name is something of a misnomer - this class should be used for the vast majority of sensors that return their signal as a simple, linearly-scaled analog voltage. The AnalogPotentiometer class Note The “full range” or “scale” parameters in the AnalogPotentiometer constructor are scale factors from a range of 0-1 to the actual range, not from 0-5. That is, they represent a native fractional scale, rather than a voltage scale. An AnalogPotentiometer can be initialized as follows: JAVA // Initializes an AnalogPotentiometer on analog port 0 // The full range of motion (in meaningful external units) is 0-180 (this could be degrees, for // instance) // The \"starting point\" of the motion, i.e. where the mechanism is located when the potentiometer // reads 0v, is 30. AnalogPotentiometer m_pot = new AnalogPotentiometer ( 0 , 180 , 30 ); C++ // Initializes an AnalogPotentiometer on analog port 0 // The full range of motion (in meaningful external units) is 0-180 (this // could be degrees, for instance) The \"starting point\" of the motion, i.e. // where the mechanism is located when the potentiometer reads 0v, is 30. frc :: AnalogPotentiometer m_pot { 0 , 180 , 30 }; Customizing the underlying AnalogInput Note If the user changes the scaling of the AnalogInput with oversampling, this must be reflected in the scale setting passed to the AnalogPotentiometer . If the user would like to apply custom settings to the underlying AnalogInput used by the AnalogPotentiometer , an alternative constructor may be used in which the AnalogInput is injected: JAVA // Initializes an AnalogInput on port 1 AnalogInput m_input = new AnalogInput ( 0 ); // Initializes an AnalogPotentiometer with the given AnalogInput // The full range of motion (in meaningful external units) is 0-180 (this could be degrees, for // instance) // The \"starting point\" of the motion, i.e. where the mechanism is located when the potentiometer // reads 0v, is 30. AnalogPotentiometer m_pot1 = new AnalogPotentiometer ( m_input , 180 , 30 ); C++ // Initializes an AnalogInput on port 1 frc :: AnalogInput m_input { 1 }; // Initializes an AnalogPotentiometer with the given AnalogInput // The full range of motion (in meaningful external units) is 0-180 (this // could be degrees, for instance) The \"starting point\" of the motion, i.e. // where the mechanism is located when the potentiometer reads 0v, is 30. frc :: AnalogPotentiometer m_pot1 { & m_input , 180 , 30 }; Reading values from the AnalogPotentiometer The scaled value can be read by simply calling the get method: JAVA // Get the value of the potentiometer m_pot . get (); C++ // Get the value of the potentiometer m_pot . Get (); Using AnalogPotentiometers in code Analog sensors can be used in code much in the way other sensors that measure the same thing can be. If the analog sensor is a potentiometer measuring an arm angle, it can be used similarly to an encoder . If it is an ultrasonic sensor, it can be used similarly to other ultrasonics . It is very important to keep in mind that actual, physical potentiometers generally have a limited range of motion. Safeguards should be present in both the physical mechanism and the code to ensure that the mechanism does not break the sensor by traveling past its maximum throw.",
      "content_preview": "Analog Potentiometers - Software Note This section covers analog potentiometers in software. For a hardware guide to analog potentiometers, see Analog Potentiometers - Hardware ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/analog-inputs-software.html",
      "title": "Analog Inputs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Analog Inputs - Software Note This section covers analog inputs in software. For a hardware guide to analog inputs, see Analog Inputs - Hardware . The roboRIO’s FPGA supports up to 8 analog input channels that can be used to read the value of an analog voltage from a sensor. Analog inputs may be used for any sensor that outputs a simple voltage. Analog inputs from the FPGA by default return a 12-bit integer proportional to the voltage, from 0 to 5 volts. The AnalogInput class Note It is often more convenient to use the Analog Potentiometers wrapper class than to use AnalogInput directly, as it supports scaling to meaningful units. Support for reading the voltages on the FPGA analog inputs is provided through the AnalogInput class ( Java , C++ ). Initializing an AnalogInput An AnalogInput may be initialized as follows: JAVA // Initializes an AnalogInput on port 0 AnalogInput m_analog = new AnalogInput ( 0 ); C++ // Initializes an AnalogInput on port 0 frc :: AnalogInput m_analog { 0 }; Oversampling and Averaging The FPGA’s analog input modules supports both oversampling and averaging. These behaviors are highly similar, but differ in a few important ways. Both may be used at the same time. Oversampling When oversampling is enabled, the FPGA will add multiple consecutive samples together, and return the accumulated value. Users may specify the number of bits of oversampling - for \\(n\\) bits of oversampling, the number of samples added together is \\(2^{n}\\) : JAVA // Sets the AnalogInput to 4-bit oversampling. 16 samples will be added together. // Thus, the reported values will increase by about a factor of 16, and the update // rate will decrease by a similar amount. m_analog . setOversampleBits ( 4 ); C++ // Sets the AnalogInput to 4-bit oversampling. 16 samples will be added // together. // Thus, the reported values will increase by about a factor of 16, and the // update rate will decrease by a similar amount. m_analog . SetOversampleBits ( 4 ); Averaging Averaging behaves much like oversampling, except the accumulated values are divided by the number of samples so that the scaling of the returned values does not change. This is often more-convenient, but occasionally the additional roundoff error introduced by the rounding is undesirable. JAVA // Sets the AnalogInput to 4-bit averaging. 16 samples will be averaged together. // The update rate will decrease by a factor of 16. m_analog . setAverageBits ( 4 ); C++ // Sets the AnalogInput to 4-bit averaging. 16 samples will be averaged // together. The update rate will decrease by a factor of 16. m_analog . SetAverageBits ( 4 ); Note When oversampling and averaging are used at the same time, the oversampling is applied first, and then the oversampled values are averaged. Thus, 2-bit oversampling and 2-bit averaging used at the same time will increase the scale of the returned values by approximately a factor of 2, and decrease the update rate by approximately a factor of 4. Reading values from an AnalogInput Values can be read from an AnalogInput with one of four different methods: getValue The getValue method returns the raw instantaneous measured value from the analog input, without applying any calibration and ignoring oversampling and averaging settings. The returned value is an integer. JAVA // Gets the raw instantaneous measured value from the analog input, without // applying any calibration and ignoring oversampling and averaging // settings. m_analog . getValue (); C++ // Gets the raw instantaneous measured value from the analog input, without // applying any calibration and ignoring oversampling and averaging // settings. m_analog . GetValue (); getVoltage The getVoltage method returns the instantaneous measured voltage from the analog input. Oversampling and averaging settings are ignored, but the value is rescaled to represent a voltage. The returned value is a double. JAVA // Gets the instantaneous measured voltage from the analog input. // Oversampling and averaging settings are ignored m_analog . getVoltage (); C++ // Gets the instantaneous measured voltage from the analog input. // Oversampling and averaging settings are ignored m_analog . GetVoltage (); getAverageValue The getAverageValue method returns the averaged value from the analog input. The value is not rescaled, but oversampling and averaging are both applied. The returned value is an integer. JAVA // Gets the averaged value from the analog input. The value is not // rescaled, but oversampling and averaging are both applied. m_analog . getAverageValue (); C++ // Gets the averaged value from the analog input. The value is not // rescaled, but oversampling and averaging are both applied. m_analog . GetAverageValue (); getAverageVoltage The getAverageVoltage method returns the averaged voltage from the analog input. Rescaling, oversampling, and averaging are all applied. The returned value is a double. JAVA // Gets the averaged value from the analog input. The value is not // rescaled, but oversampling and averaging are both applied. m_analog . getAverageValue (); C++ // Gets the averaged voltage from the analog input. Rescaling, // oversampling, and averaging are all applied. m_analog . GetAverageVoltage (); Accumulator Note The accumulator methods do not currently support returning a value in units of volts - the returned value will always be an integer (specifically, a long ). Analog input channels 0 and 1 additionally support an accumulator, which integrates (adds up) the signal indefinitely, so that the returned value is the sum of all past measured values. Oversampling and averaging are applied prior to accumulation. JAVA // Gets the instantaneous measured voltage from the analog input. // Oversampling and averaging settings are ignored m_analog . getVoltage (); C++ // Sets the initial value of the accumulator to 0 // This is the \"starting point\" from which the value will change over time m_analog . SetAccumulatorInitialValue ( 0 ); // Sets the \"center\" of the accumulator to 0. This value is subtracted from // all measured values prior to accumulation. m_analog . SetAccumulatorCenter ( 0 ); // Returns the number of accumulated samples since the accumulator was last // started/reset m_analog . GetAccumulatorCount (); // Returns the value of the accumulator. Return type is long. m_analog . GetAccumulatorValue (); // Resets the accumulator to the initial value m_analog . ResetAccumulator (); Obtaining synchronized count and value Sometimes, it is necessarily to obtain matched measurements of the count and the value. This can be done using the getAccumulatorOutput method: JAVA // Instantiate an AccumulatorResult object to hold the matched measurements AccumulatorResult m_result = new AccumulatorResult (); // Fill the AccumulatorResult with the matched measurements m_analog . getAccumulatorOutput ( m_result ); // Read the values from the AccumulatorResult long count = m_result . count ; long value = m_result . value ; C++ // The count and value variables to fill int64_t count ; int64_t value ; // Fill the count and value variables with the matched measurements m_analog . GetAccumulatorOutput ( count , value ); Using analog inputs in code The AnalogInput class can be used to write code for a wide variety of sensors (including potentiometers, accelerometers, gyroscopes, ultrasonics, and more) that return their data as an analog voltage. However, if possible it is almost always more convenient to use one of the other existing WPILib classes that handles the lower-level code (reading the analog voltages and converting them to meaningful units) for you. Users should only directly use AnalogInput as a “last resort.” Accordingly, for examples of how to effectively use analog sensors in code, users should refer to the other pages of this chapter that deal with more-specific classes.",
      "content_preview": "Analog Inputs - Software Note This section covers analog inputs in software. For a hardware guide to analog inputs, see Analog Inputs - Hardware . The roboRIO’s FPGA supports up to 8 analog input channels that can be used to read the value of an analog voltage from a sensor."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/ultrasonics-software.html",
      "title": "Ultrasonics",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Ultrasonics - Software Note This section covers ultrasonics in software. For a hardware guide to ultrasonics, see Ultrasonics - Hardware . An ultrasonic sensor is commonly used to measure distance to an object using high-frequency sound. Generally, ultrasonics measure the distance to the closest object within their “field of view.” There are two primary types of ultrasonics supported natively by WPILib: Ping-response ultrasonics Analog ultrasonics Ping-response ultrasonics The Ultrasonic class ( Java , C++ ) provides support for ping-response ultrasonics. As ping-response ultrasonics (per the name) require separate pins for both sending the ping and measuring the response, users must specify DIO pin numbers for both output and input when constructing an Ultrasonic instance: Java // Creates a ping-response Ultrasonic object on DIO 1 and 2. Ultrasonic m_rangeFinder = new Ultrasonic ( 1 , 2 ); C++ // Creates a ping-response Ultrasonic object on DIO 1 and 2. frc :: Ultrasonic m_rangeFinder { 1 , 2 }; The measurement can then be retrieved in either inches or millimeters in Java; in C++ the units library is used to automatically convert to any desired length unit: Java // We can read the distance in millimeters double distanceMillimeters = m_rangeFinder . getRangeMM (); // ... or in inches double distanceInches = m_rangeFinder . getRangeInches (); C++ // We can read the distance units :: meter_t distance = m_rangeFinder . GetRange (); // units auto-convert units :: millimeter_t distanceMillimeters = distance ; units :: inch_t distanceInches = distance ; Analog ultrasonics Some ultrasonic sensors simply return an analog voltage corresponding to the measured distance. These sensors can may simply be used with the AnalogPotentiometer class. Third-party ultrasonics Other ultrasonic sensors offered by third-parties may use more complicated communications protocols (such as I2C or SPI). WPILib does not provide native support for any such ultrasonics; they will typically be controlled with vendor libraries. Using ultrasonics in code Ultrasonic sensors are very useful for determining spacing during autonomous routines. For example, the following code from the UltrasonicPID example project ( Java , C++ ) will move the robot to 1 meter away from the nearest object the sensor detects: Java public class Robot extends TimedRobot { // distance the robot wants to stay from an object // (one meter) static final double kHoldDistanceMillimeters = 1.0e3 ; // proportional speed constant private static final double kP = 0.001 ; // integral speed constant private static final double kI = 0.0 ; // derivative speed constant private static final double kD = 0.0 ; static final int kLeftMotorPort = 0 ; static final int kRightMotorPort = 1 ; static final int kUltrasonicPingPort = 0 ; static final int kUltrasonicEchoPort = 1 ; // Ultrasonic sensors tend to be quite noisy and susceptible to sudden outliers, // so measurements are filtered with a 5-sample median filter private final MedianFilter m_filter = new MedianFilter ( 5 ); private final Ultrasonic m_ultrasonic = new Ultrasonic ( kUltrasonicPingPort , kUltrasonicEchoPort ); private final PWMSparkMax m_leftMotor = new PWMSparkMax ( kLeftMotorPort ); private final PWMSparkMax m_rightMotor = new PWMSparkMax ( kRightMotorPort ); private final DifferentialDrive m_robotDrive = new DifferentialDrive ( m_leftMotor :: set , m_rightMotor :: set ); private final PIDController m_pidController = new PIDController ( kP , kI , kD ); public Robot () { SendableRegistry . addChild ( m_robotDrive , m_leftMotor ); SendableRegistry . addChild ( m_robotDrive , m_rightMotor ); } @Override public void autonomousInit () { // Set setpoint of the pid controller m_pidController . setSetpoint ( kHoldDistanceMillimeters ); } @Override public void autonomousPeriodic () { double measurement = m_ultrasonic . getRangeMM (); double filteredMeasurement = m_filter . calculate ( measurement ); double pidOutput = m_pidController . calculate ( filteredMeasurement ); // disable input squaring -- PID output is linear m_robotDrive . arcadeDrive ( pidOutput , 0 , false ); } } C++ (Header) class Robot : public frc :: TimedRobot { public : Robot (); void AutonomousInit () override ; void AutonomousPeriodic () override ; // distance the robot wants to stay from an object static constexpr units :: millimeter_t kHoldDistance = 1 _m ; static constexpr int kLeftMotorPort = 0 ; static constexpr int kRightMotorPort = 1 ; static constexpr int kUltrasonicPingPort = 0 ; static constexpr int kUltrasonicEchoPort = 1 ; private : // proportional speed constant static constexpr double kP = 0.001 ; // integral speed constant static constexpr double kI = 0.0 ; // derivative speed constant static constexpr double kD = 0.0 ; // Ultrasonic sensors tend to be quite noisy and susceptible to sudden // outliers, so measurements are filtered with a 5-sample median filter frc :: MedianFilter < units :: millimeter_t > m_filter { 5 }; frc :: Ultrasonic m_ultrasonic { kUltrasonicPingPort , kUltrasonicEchoPort }; frc :: PWMSparkMax m_left { kLeftMotorPort }; frc :: PWMSparkMax m_right { kRightMotorPort }; frc :: DifferentialDrive m_robotDrive { [ & ]( double output ) { m_left . Set ( output ); }, [ & ]( double output ) { m_right . Set ( output ); }}; frc :: PIDController m_pidController { kP , kI , kD }; }; C++ (Source) void Robot::AutonomousInit () { // Set setpoint of the pid controller m_pidController . SetSetpoint ( kHoldDistance . value ()); } void Robot::AutonomousPeriodic () { units :: millimeter_t measurement = m_ultrasonic . GetRange (); units :: millimeter_t filteredMeasurement = m_filter . Calculate ( measurement ); double pidOutput = m_pidController . Calculate ( filteredMeasurement . value ()); // disable input squaring -- PID output is linear m_robotDrive . ArcadeDrive ( pidOutput , 0 , false ); } Additionally, ping-response ultrasonics can be sent to Shuffleboard , where they will be displayed with their own widgets: Java // Add the ultrasonic on the \"Sensors\" tab of the dashboard // Data will update automatically Shuffleboard . getTab ( \"Sensors\" ). add ( m_rangeFinder ); C++ // Add the ultrasonic on the \"Sensors\" tab of the dashboard // Data will update automatically frc :: Shuffleboard :: GetTab ( \"Sensors\" ). Add ( m_rangeFinder );",
      "content_preview": "Ultrasonics - Software Note This section covers ultrasonics in software. For a hardware guide to ultrasonics, see Ultrasonics - Hardware . An ultrasonic sensor is commonly used to measure distance to an object using high-frequency sound."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/index.html?present",
      "title": "Sensors",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Sensors Sensors are an integral way of having your robot hardware and software communicate with each other. This section highlights interfacing with those sensors at a software level. Sensor Overview - Software Accelerometers - Software Gyroscopes - Software Ultrasonics - Software Counters Encoders - Software Analog Inputs - Software Analog Potentiometers - Software Digital Inputs - Software Programming Limit Switches",
      "content_preview": "Sensors Sensors are an integral way of having your robot hardware and software communicate with each other. This section highlights interfacing with those sensors at a software level."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/gyros-software.html",
      "title": "Gyroscopes",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Gyroscopes - Software Note This section covers gyros in software. For a hardware guide to gyros, see Gyroscopes - Hardware . A gyroscope, or “gyro,” is an angular rate sensor typically used in robotics to measure and/or stabilize robot headings. WPILib natively provides specific support for the ADXRS450 gyro available in the kit of parts, as well as more general support for a wider variety of analog gyros through the AnalogGyro class. There are getters the current angular rate and heading and functions for zeroing the current heading and calibrating the gyro. Note It is crucial that the robot remain stationary while calibrating a gyro. ADIS16448 The ADIS16448 uses the ADIS16448_IMU class ( Java , C++ , Python ). See the Analog Devices ADIS16448 documentation for additional information and examples. Warning The Analog Devices documentation linked above contains outdated instructions for software installation as the ADIS16448 is now built into WPILib. JAVA // ADIS16448 plugged into the MXP port ADIS16448_IMU gyro = new ADIS16448_IMU (); C++ // ADIS16448 plugged into the MXP port ADIS16448_IMU gyro ; PYTHON from wpilib import ADIS16448_IMU # ADIS16448 plugged into the MXP port self . gyro = ADIS16448_IMU () ADIS16470 The ADIS16470 uses the ADIS16470_IMU class ( Java , C++ , Python ). See the Analog Devices ADIS16470 documentation for additional information and examples. Warning The Analog Devices documentation linked above contains outdated instructions for software installation as the ADIS16470 is now built into WPILib. JAVA // ADIS16470 plugged into the SPI port ADIS16470_IMU gyro = new ADIS16470_IMU (); C++ // ADIS16470 plugged into the SPI port ADIS16470_IMU gyro ; PYTHON # ADIS16470 plugged into the SPI port self . gyro = ADIS16470_IMU () ADXRS450_Gyro The ADXRS450_Gyro class ( Java , C++ , Python ) provides support for the Analog Devices ADXRS450 gyro available in the kit of parts, which connects over the SPI bus. Note ADXRS450 Gyro accumulation is handled through special circuitry in the FPGA; accordingly only a single instance of ADXRS450_Gyro may be used. JAVA // Creates an ADXRS450_Gyro object on the onboard SPI port ADXRS450_Gyro gyro = new ADXRS450_Gyro (); C++ // Creates an ADXRS450_Gyro object on the onboard SPI port frc :: ADXRS450_Gyro gyro ; PYTHON # Creates an ADXRS450_Gyro object on the onboard SPI port self . gyro = ADXRS450_Gyro () AnalogGyro The AnalogGyro class ( Java , C++ , Python ) provides support for any single-axis gyro with an analog output. Note Gyro accumulation is handled through special circuitry in the FPGA; accordingly, AnalogGyro `s may only be used on analog ports 0 and 1. JAVA // Creates an AnalogGyro object on port 0 AnalogGyro gyro = new AnalogGyro ( 0 ); C++ // Creates an AnalogGyro object on port 0 frc :: AnalogGyro gyro { 0 }; PYTHON # Creates an AnalogGyro object on port 0 self . gyro = AnalogGyro ( 0 ) navX The navX uses the AHRS class. See the navX documentation for additional connection types. JAVA // navX MXP using SPI AHRS gyro = new AHRS ( NavXComType . kMXP_SPI ); C++ // navX MXP using SPI studica :: AHRS navx { studica :: AHRS :: NavXComType :: kMXP_SPI }; PYTHON import navx # navX MXP using SPI self . gyro = navx . AHRS ( NavXComType . kMXP_SPI ) Pigeon 2 The Pigeon should use the Pigeon2 class. The Pigeon can either be connected with CAN or by data cable to a TalonSRX. The Pigeon IMU User’s Guide contains full details on using the Pigeon. JAVA private final Pigeon2 pidgey = new Pigeon2 ( 1 , \"rio\" ); // Pigeon is on roboRIO CAN Bus with device ID 1 C++ ctre :: phoenix6 :: hardware :: Pigeon2 pidgey { 1 , \"rio\" }; // Pigeon is on roboRIO CAN Bus with device ID 1 PYTHON import phoenix5 import ctre.sensors self . gyro = ctre . WPI_PigeonIMU ( 0 ); # Pigeon is on CAN Bus with device ID 0 # OR (choose one or the other based on your connection) talon = ctre . TalonSRX ( 0 ); # TalonSRX is on CAN Bus with device ID 0 self . gyro = ctre . WPI_PigeonIMU ( talon ) # Pigeon uses the talon created above Using gyros in code Note As gyros measure rate rather than position, position is inferred by integrating (adding up) the rate signal to get the total change in angle. Thus, gyro angle measurements are always relative to some arbitrary zero angle (determined by the angle of the gyro when either the robot was turned on or a zeroing method was called), and are also subject to accumulated errors (called “drift”) that increase in magnitude the longer the gyro is used. The amount of drift varies with the type of gyro. Gyros are extremely useful in FRC for both measuring and controlling robot heading. Since FRC matches are generally short, total gyro drift over the course of an FRC match tends to be manageably small (on the order of a couple of degrees for a good-quality gyro). Moreover, not all useful gyro applications require the absolute heading measurement to remain accurate over the course of the entire match. Displaying the robot heading on the dashboard Shuffleboard includes a widget for displaying heading data from a gyro in the form of a compass. This can be helpful for viewing the robot heading when sight lines to the robot are obscured: JAVA // Use gyro declaration from above here public Robot () { // Places a compass indicator for the gyro heading on the dashboard Shuffleboard . getTab ( \"Example tab\" ). add ( gyro ); } C++ // Use gyro declaration from above here Robot :: Robot () { // Places a compass indicator for the gyro heading on the dashboard frc :: Shuffleboard . GetTab ( \"Example tab\" ). Add ( gyro ); } PYTHON from wpilib.shuffleboard import Shuffleboard def robotInit ( self ): # Use gyro declaration from above here # Places a compass indicator for the gyro heading on the dashboard Shuffleboard . getTab ( \"Example tab\" ) . add ( self . gyro ) Stabilizing heading while driving A very common use for a gyro is to stabilize robot heading while driving, so that the robot drives straight. This is especially important for holonomic drives such as mecanum and swerve, but is extremely useful for tank drives as well. This is typically achieved by closing a PID controller on either the turn rate or the heading, and piping the output of the loop to one’s turning control (for a tank drive, this would be a speed differential between the two sides of the drive). Warning Like with all control loops, users should be careful to ensure that the sensor direction and the turning direction are consistent. If they are not, the loop will be unstable and the robot will turn wildly. Example: Tank drive stabilization using turn rate The following example shows how to stabilize heading using a simple P loop closed on the turn rate. Since a robot that is not turning should have a turn rate of zero, the setpoint for the loop is implicitly zero, making this method very simple. JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // Initialize motor controllers and drive Spark leftLeader = new Spark ( 0 ); Spark leftFollower = new Spark ( 1 ); Spark rightLeader = new Spark ( 2 ); Spark rightFollower = new Spark ( 3 ); DifferentialDrive drive = new DifferentialDrive ( leftLeader :: set , rightLeader :: set ); public Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation encoder . setDistancePerPulse ( 1. / 256. ); // Invert the right side of the drivetrain. You might have to invert the other side rightLeader . setInverted ( true ); // Configure the followers to follow the leaders leftLeader . addFollower ( leftFollower ); rightLeader . addFollower ( rightFollower ); } @Override public void autonomousPeriodic () { // Setpoint is implicitly 0, since we don't want the heading to change double error = - gyro . getRate (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . tankDrive ( .5 + kP * error , .5 - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // Initialize motor controllers and drive frc :: Spark leftLeader { 0 }; frc :: Spark leftFollower { 1 }; frc :: Spark rightLeader { 2 }; frc :: Spark rightFollower { 3 }; frc :: DifferentialDrive drive {[ & ]( double output ) { leftLeader . Set ( output ); }, [ & ]( double output ) { rightLeader . Set ( output ); }}; Robot :: Robot () { // Invert the right side of the drivetrain. You might have to invert the other side rightLeader . SetInverted ( true ); // Configure the followers to follow the leaders leftLeader . AddFollower ( leftFollower ); rightLeader . AddFollower ( rightFollower ); } void Robot :: AutonomousPeriodic () { // Setpoint is implicitly 0, since we don't want the heading to change double error = - gyro . GetRate (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . TankDrive ( .5 + kP * error , .5 - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 1 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , rightLeader ) rightLeader . setInverted ( True ) def autonomousPeriodic ( self ): # Setpoint is implicitly 0, since we don't want the heading to change error = - self . gyro . getRate () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( 0.5 + self . kP * error , 0.5 - self . kP * error ) More-advanced implementations can use a more-complicated control loop. When closing the loop on the turn rate for heading stabilization, PI loops are particularly effective. Example: Tank drive stabilization using heading The following example shows how to stabilize heading using a simple P loop closed on the heading. Unlike in the turn rate example, we will need to set the setpoint to the current heading before starting motion, making this method slightly more-complicated. JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // The heading of the robot when starting the motion double heading ; // Initialize motor controllers and drive Spark left1 = new Spark ( 0 ); Spark left2 = new Spark ( 1 ); Spark right1 = new Spark ( 2 ); Spark right2 = new Spark ( 3 ); MotorControllerGroup leftMotors = new MotorControllerGroup ( left1 , left2 ); MotorControllerGroup rightMotors = new MotorControllerGroup ( right1 , right2 ); DifferentialDrive drive = new DifferentialDrive ( leftMotors , rightMotors ); public Robot () { rightMotors . setInverted ( true ); } @Override public void autonomousInit () { // Set setpoint to current heading at start of auto heading = gyro . getAngle (); } @Override public void autonomousPeriodic () { double error = heading - gyro . getAngle (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . tankDrive ( .5 + kP * error , .5 - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // The heading of the robot when starting the motion double heading ; // Initialize motor controllers and drive frc :: Spark left1 { 0 }; frc :: Spark left2 { 1 }; frc :: Spark right1 { 2 }; frc :: Spark right2 { 3 }; frc :: MotorControllerGroup leftMotors { left1 , left2 }; frc :: MotorControllerGroup rightMotors { right1 , right2 }; frc :: DifferentialDrive drive { leftMotors , rightMotors }; Robot :: Robot () { rightMotors . SetInverted ( true ); } void Robot :: AutonomousInit () { // Set setpoint to current heading at start of auto heading = gyro . GetAngle (); } void Robot :: AutonomousPeriodic () { double error = heading - gyro . GetAngle (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . TankDrive ( .5 + kP * error , .5 - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 1 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , leftFollower ) rightLeader . setInverted ( True ) def autonomousInit ( self ): # Set setpoint to current heading at start of auto self . heading = self . gyro . getAngle () def autonomousPeriodic ( self ): error = self . heading - self . gyro . getAngle () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( 0.5 + self . kP * error , 0.5 - self . kP * error ) More-advanced implementations can use a more-complicated control loop. When closing the loop on the heading for heading stabilization, PD loops are particularly effective. Turning to a set heading Another common and highly-useful application for a gyro is turning a robot to face a specified direction. This can be a component of an autonomous driving routine, or can be used during teleoperated control to help align a robot with field elements. Much like with heading stabilization, this is often accomplished with a PID loop - unlike with stabilization, however, the loop can only be closed on the heading. The following example code will turn the robot to face 90 degrees with a simple P loop: JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 0.05 ; // Initialize motor controllers and drive Spark left1 = new Spark ( 0 ); Spark left2 = new Spark ( 1 ); Spark right1 = new Spark ( 2 ); Spark right2 = new Spark ( 3 ); MotorControllerGroup leftMotors = new MotorControllerGroup ( left1 , left2 ); MotorControllerGroup rightMotors = new MotorControllerGroup ( right1 , right2 ); DifferentialDrive drive = new DifferentialDrive ( leftMotors , rightMotors ); public Robot () { rightMotors . setInverted ( true ); } @Override public void autonomousPeriodic () { // Find the heading error; setpoint is 90 double error = 90 - gyro . getAngle (); // Turns the robot to face the desired direction drive . tankDrive ( kP * error , - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 0.05 ; // Initialize motor controllers and drive frc :: Spark left1 { 0 }; frc :: Spark left2 { 1 }; frc :: Spark right1 { 2 }; frc :: Spark right2 { 3 }; frc :: MotorControllerGroup leftMotors { left1 , left2 }; frc :: MotorControllerGroup rightMotors { right1 , right2 }; frc :: DifferentialDrive drive { leftMotors , rightMotors }; Robot :: Robot () { rightMotors . SetInverted ( true ); } void Robot :: AutonomousPeriodic () { // Find the heading error; setpoint is 90 double error = 90 - gyro . GetAngle (); // Turns the robot to face the desired direction drive . TankDrive ( kP * error , - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 0.05 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , rightLeader ) rightLeader . setInverted ( True ) def autonomousPeriodic ( self ): # Find the heading error; setpoint is 90 error = 90 - self . gyro . getAngle () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( self . kP * error , - self . kP * error ) As before, more-advanced implementations can use more-complicated control loops. Note Turn-to-angle loops can be tricky to tune correctly due to static friction in the drivetrain, especially if a simple P loop is used. There are a number of ways to account for this; one of the most common/effective is to add a “minimum output” to the output of the control loop. Another effective strategy is to cascade to well-tuned velocity controllers on each side of the drive.",
      "content_preview": "Gyroscopes - Software Note This section covers gyros in software. For a hardware guide to gyros, see Gyroscopes - Hardware . A gyroscope, or “gyro,” is an angular rate sensor typically used in robotics to measure and/or stabilize robot headings."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/dashboards/shuffleboard/getting-started/shuffleboard-tour.html",
      "title": "Tour of Shuffleboard",
      "section": "General",
      "language": "All",
      "content": "Tour of Shuffleboard Warning Shuffleboard is deprecated and will be removed for 2027 due to its lack of a maintainer and resource utilization issues. Users can find additional modern dashboard options here Shuffleboard is a dashboard for FRC® based on newer technologies such as JavaFX that are available to Java programs. It is designed to be used for creating dashboards for C++, Java, and Python programs. If you’ve used SmartDashboard in the past then you are already familiar with many of the features of Shuffleboard since they fundamentally work the same way. But Shuffleboard has many features that aren’t in SmartDashboard. Here are some of the highlights: Graphics is based on JavaFX , the Java graphics standard. Each of the components has an associated style sheet so it becomes possible to have different “skins” or “themes” for Shuffleboard. We supply default light and dark themes. Shuffleboard supports multiple sheets for the display of your data . In fact you can create a new sheet (shown as a tab in the Shuffleboard window) and indicate if and which data should be autopopulated on it. By default there is a Test tab and a SmartDashboard tab that are autopopulated as data arrives. Other tabs might be for robot debugging vs. driving. Graphical display elements (widgets) are laid out on a grid to keep the interface clean and easy to read. You can change the grid size to have more or less resolution in your layouts and visual cues are provided to help you change your layout using drag and drop. Or you can choose to turn off the grid lines although the grid layout is preserved. Layouts are saved and the previous layout is instantiated by default when you run shuffleboard again. There is a record and playback feature that lets you review the data sent by your robot program after it finishes. That way you can carefully review the actions of the robot if something goes wrong. Graph widgets are available for numeric data and you can drag data onto a graph to see multiple points at the same time and on the same scale. You can extend Shuffleboard by writing your own widgets that are specific to your team’s requirements. Documentation on extending it can be found in Custom Widgets . Sources area: Here are data sources from which you can choose values from NetworkTables or other sources to display by dragging a value into one of the tabs Tab panes: This is where you data is displayed from the robot or other sources. In this example it is Test-mode subsystems that are shown here in the LiveWindow tab. This area can show any number of tabbed windows, and each window has it’s own set of properties like grid size and auto-populate. Record/playback controls: set of media-like controls where you can playback the current session to see historical data Starting Shuffleboard You can start Shuffleboard in one of four ways: You can automatically start it when the Driver Station starts by setting the “Dashboard Type” to Shuffleboard in the settings tab as shown in the picture above. You can run it by double-clicking the Shuffleboard icon in the YEAR WPILib tools folder on the Windows Desktop. You can start from with Visual Studio Code by pressing Ctrl + Shift + P and type “WPILib” or click the WPILib logo in the top right to launch the WPILib Command Palette. Select Start Tool , then select Shuffleboard . You can run it by double-clicking on the shuffleboard.XXX file (where XXX is .vbs on Windows and .py on Linux or macOS) in ~/WPILib/YYYY/tools/ (where YYYY is the year and ~ is C:\\Users\\Public on Windows). This is useful on a development system that does not have the Driver Station installed such as a macOS or Linux system. You can start it from the command line by typing the command: shuffleboard on Windows or python shuffleboard.py on macOS or Linux from ~/WPILib/YYYY/tools directory (where YYYY is the year and ~ is C:\\Users\\Public on Windows). This is often easiest on a development system that doesn’t have the Driver Station installed. Note The .vbs (Windows) and .py (macOS/Linux) scripts help launch the tools using the correct JDK. Getting robot data onto the dashboard The easiest way to get data displayed on the dashboard is simply to use methods in the SmartDashboard class. For example to write a number to Shuffleboard write: JAVA SmartDashboard . putNumber ( \"Joystick X value\" , joystick1 . getX ()); C++ frc :: SmartDashboard :: PutNumber ( \"Joystick X value\" , joystick1 . getX ()); PYTHON from wpilib import SmartDashboard SmartDashboard . putNumber ( \"Joystick X value\" , joystick1 . getX ()) to see a field displayed with the label “Joystick X value” and a value of the X value of the joystick. Each time this line of code is executed, a new joystick value will be sent to Shuffleboard. Remember: you must write the joystick value whenever you want to see an updated value. Executing this line once at the start of the program will only display the value once at the time the line of code was executed.",
      "content_preview": "Tour of Shuffleboard Warning Shuffleboard is deprecated and will be removed for 2027 due to its lack of a maintainer and resource utilization issues. Users can find additional modern dashboard options here Shuffleboard is a dashboard for FRC® based on newer technologies such as JavaFX that are..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/gyros-software.html?present",
      "title": "Gyroscopes",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Gyroscopes - Software Note This section covers gyros in software. For a hardware guide to gyros, see Gyroscopes - Hardware . A gyroscope, or “gyro,” is an angular rate sensor typically used in robotics to measure and/or stabilize robot headings. WPILib natively provides specific support for the ADXRS450 gyro available in the kit of parts, as well as more general support for a wider variety of analog gyros through the AnalogGyro class. There are getters the current angular rate and heading and functions for zeroing the current heading and calibrating the gyro. Note It is crucial that the robot remain stationary while calibrating a gyro. ADIS16448 The ADIS16448 uses the ADIS16448_IMU class ( Java , C++ , Python ). See the Analog Devices ADIS16448 documentation for additional information and examples. Warning The Analog Devices documentation linked above contains outdated instructions for software installation as the ADIS16448 is now built into WPILib. JAVA // ADIS16448 plugged into the MXP port ADIS16448_IMU gyro = new ADIS16448_IMU (); C++ // ADIS16448 plugged into the MXP port ADIS16448_IMU gyro ; PYTHON from wpilib import ADIS16448_IMU # ADIS16448 plugged into the MXP port self . gyro = ADIS16448_IMU () ADIS16470 The ADIS16470 uses the ADIS16470_IMU class ( Java , C++ , Python ). See the Analog Devices ADIS16470 documentation for additional information and examples. Warning The Analog Devices documentation linked above contains outdated instructions for software installation as the ADIS16470 is now built into WPILib. JAVA // ADIS16470 plugged into the SPI port ADIS16470_IMU gyro = new ADIS16470_IMU (); C++ // ADIS16470 plugged into the SPI port ADIS16470_IMU gyro ; PYTHON # ADIS16470 plugged into the SPI port self . gyro = ADIS16470_IMU () ADXRS450_Gyro The ADXRS450_Gyro class ( Java , C++ , Python ) provides support for the Analog Devices ADXRS450 gyro available in the kit of parts, which connects over the SPI bus. Note ADXRS450 Gyro accumulation is handled through special circuitry in the FPGA; accordingly only a single instance of ADXRS450_Gyro may be used. JAVA // Creates an ADXRS450_Gyro object on the onboard SPI port ADXRS450_Gyro gyro = new ADXRS450_Gyro (); C++ // Creates an ADXRS450_Gyro object on the onboard SPI port frc :: ADXRS450_Gyro gyro ; PYTHON # Creates an ADXRS450_Gyro object on the onboard SPI port self . gyro = ADXRS450_Gyro () AnalogGyro The AnalogGyro class ( Java , C++ , Python ) provides support for any single-axis gyro with an analog output. Note Gyro accumulation is handled through special circuitry in the FPGA; accordingly, AnalogGyro `s may only be used on analog ports 0 and 1. JAVA // Creates an AnalogGyro object on port 0 AnalogGyro gyro = new AnalogGyro ( 0 ); C++ // Creates an AnalogGyro object on port 0 frc :: AnalogGyro gyro { 0 }; PYTHON # Creates an AnalogGyro object on port 0 self . gyro = AnalogGyro ( 0 ) navX The navX uses the AHRS class. See the navX documentation for additional connection types. JAVA // navX MXP using SPI AHRS gyro = new AHRS ( NavXComType . kMXP_SPI ); C++ // navX MXP using SPI studica :: AHRS navx { studica :: AHRS :: NavXComType :: kMXP_SPI }; PYTHON import navx # navX MXP using SPI self . gyro = navx . AHRS ( NavXComType . kMXP_SPI ) Pigeon 2 The Pigeon should use the Pigeon2 class. The Pigeon can either be connected with CAN or by data cable to a TalonSRX. The Pigeon IMU User’s Guide contains full details on using the Pigeon. JAVA private final Pigeon2 pidgey = new Pigeon2 ( 1 , \"rio\" ); // Pigeon is on roboRIO CAN Bus with device ID 1 C++ ctre :: phoenix6 :: hardware :: Pigeon2 pidgey { 1 , \"rio\" }; // Pigeon is on roboRIO CAN Bus with device ID 1 PYTHON import phoenix5 import ctre.sensors self . gyro = ctre . WPI_PigeonIMU ( 0 ); # Pigeon is on CAN Bus with device ID 0 # OR (choose one or the other based on your connection) talon = ctre . TalonSRX ( 0 ); # TalonSRX is on CAN Bus with device ID 0 self . gyro = ctre . WPI_PigeonIMU ( talon ) # Pigeon uses the talon created above Using gyros in code Note As gyros measure rate rather than position, position is inferred by integrating (adding up) the rate signal to get the total change in angle. Thus, gyro angle measurements are always relative to some arbitrary zero angle (determined by the angle of the gyro when either the robot was turned on or a zeroing method was called), and are also subject to accumulated errors (called “drift”) that increase in magnitude the longer the gyro is used. The amount of drift varies with the type of gyro. Gyros are extremely useful in FRC for both measuring and controlling robot heading. Since FRC matches are generally short, total gyro drift over the course of an FRC match tends to be manageably small (on the order of a couple of degrees for a good-quality gyro). Moreover, not all useful gyro applications require the absolute heading measurement to remain accurate over the course of the entire match. Displaying the robot heading on the dashboard Shuffleboard includes a widget for displaying heading data from a gyro in the form of a compass. This can be helpful for viewing the robot heading when sight lines to the robot are obscured: JAVA // Use gyro declaration from above here public Robot () { // Places a compass indicator for the gyro heading on the dashboard Shuffleboard . getTab ( \"Example tab\" ). add ( gyro ); } C++ // Use gyro declaration from above here Robot :: Robot () { // Places a compass indicator for the gyro heading on the dashboard frc :: Shuffleboard . GetTab ( \"Example tab\" ). Add ( gyro ); } PYTHON from wpilib.shuffleboard import Shuffleboard def robotInit ( self ): # Use gyro declaration from above here # Places a compass indicator for the gyro heading on the dashboard Shuffleboard . getTab ( \"Example tab\" ) . add ( self . gyro ) Stabilizing heading while driving A very common use for a gyro is to stabilize robot heading while driving, so that the robot drives straight. This is especially important for holonomic drives such as mecanum and swerve, but is extremely useful for tank drives as well. This is typically achieved by closing a PID controller on either the turn rate or the heading, and piping the output of the loop to one’s turning control (for a tank drive, this would be a speed differential between the two sides of the drive). Warning Like with all control loops, users should be careful to ensure that the sensor direction and the turning direction are consistent. If they are not, the loop will be unstable and the robot will turn wildly. Example: Tank drive stabilization using turn rate The following example shows how to stabilize heading using a simple P loop closed on the turn rate. Since a robot that is not turning should have a turn rate of zero, the setpoint for the loop is implicitly zero, making this method very simple. JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // Initialize motor controllers and drive Spark leftLeader = new Spark ( 0 ); Spark leftFollower = new Spark ( 1 ); Spark rightLeader = new Spark ( 2 ); Spark rightFollower = new Spark ( 3 ); DifferentialDrive drive = new DifferentialDrive ( leftLeader :: set , rightLeader :: set ); public Robot () { // Configures the encoder's distance-per-pulse // The robot moves forward 1 foot per encoder rotation // There are 256 pulses per encoder rotation encoder . setDistancePerPulse ( 1. / 256. ); // Invert the right side of the drivetrain. You might have to invert the other side rightLeader . setInverted ( true ); // Configure the followers to follow the leaders leftLeader . addFollower ( leftFollower ); rightLeader . addFollower ( rightFollower ); } @Override public void autonomousPeriodic () { // Setpoint is implicitly 0, since we don't want the heading to change double error = - gyro . getRate (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . tankDrive ( .5 + kP * error , .5 - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // Initialize motor controllers and drive frc :: Spark leftLeader { 0 }; frc :: Spark leftFollower { 1 }; frc :: Spark rightLeader { 2 }; frc :: Spark rightFollower { 3 }; frc :: DifferentialDrive drive {[ & ]( double output ) { leftLeader . Set ( output ); }, [ & ]( double output ) { rightLeader . Set ( output ); }}; Robot :: Robot () { // Invert the right side of the drivetrain. You might have to invert the other side rightLeader . SetInverted ( true ); // Configure the followers to follow the leaders leftLeader . AddFollower ( leftFollower ); rightLeader . AddFollower ( rightFollower ); } void Robot :: AutonomousPeriodic () { // Setpoint is implicitly 0, since we don't want the heading to change double error = - gyro . GetRate (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . TankDrive ( .5 + kP * error , .5 - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 1 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , rightLeader ) rightLeader . setInverted ( True ) def autonomousPeriodic ( self ): # Setpoint is implicitly 0, since we don't want the heading to change error = - self . gyro . getRate () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( 0.5 + self . kP * error , 0.5 - self . kP * error ) More-advanced implementations can use a more-complicated control loop. When closing the loop on the turn rate for heading stabilization, PI loops are particularly effective. Example: Tank drive stabilization using heading The following example shows how to stabilize heading using a simple P loop closed on the heading. Unlike in the turn rate example, we will need to set the setpoint to the current heading before starting motion, making this method slightly more-complicated. JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // The heading of the robot when starting the motion double heading ; // Initialize motor controllers and drive Spark left1 = new Spark ( 0 ); Spark left2 = new Spark ( 1 ); Spark right1 = new Spark ( 2 ); Spark right2 = new Spark ( 3 ); MotorControllerGroup leftMotors = new MotorControllerGroup ( left1 , left2 ); MotorControllerGroup rightMotors = new MotorControllerGroup ( right1 , right2 ); DifferentialDrive drive = new DifferentialDrive ( leftMotors , rightMotors ); public Robot () { rightMotors . setInverted ( true ); } @Override public void autonomousInit () { // Set setpoint to current heading at start of auto heading = gyro . getAngle (); } @Override public void autonomousPeriodic () { double error = heading - gyro . getAngle (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . tankDrive ( .5 + kP * error , .5 - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 1 ; // The heading of the robot when starting the motion double heading ; // Initialize motor controllers and drive frc :: Spark left1 { 0 }; frc :: Spark left2 { 1 }; frc :: Spark right1 { 2 }; frc :: Spark right2 { 3 }; frc :: MotorControllerGroup leftMotors { left1 , left2 }; frc :: MotorControllerGroup rightMotors { right1 , right2 }; frc :: DifferentialDrive drive { leftMotors , rightMotors }; Robot :: Robot () { rightMotors . SetInverted ( true ); } void Robot :: AutonomousInit () { // Set setpoint to current heading at start of auto heading = gyro . GetAngle (); } void Robot :: AutonomousPeriodic () { double error = heading - gyro . GetAngle (); // Drives forward continuously at half speed, using the gyro to stabilize the heading drive . TankDrive ( .5 + kP * error , .5 - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 1 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , leftFollower ) rightLeader . setInverted ( True ) def autonomousInit ( self ): # Set setpoint to current heading at start of auto self . heading = self . gyro . getAngle () def autonomousPeriodic ( self ): error = self . heading - self . gyro . getAngle () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( 0.5 + self . kP * error , 0.5 - self . kP * error ) More-advanced implementations can use a more-complicated control loop. When closing the loop on the heading for heading stabilization, PD loops are particularly effective. Turning to a set heading Another common and highly-useful application for a gyro is turning a robot to face a specified direction. This can be a component of an autonomous driving routine, or can be used during teleoperated control to help align a robot with field elements. Much like with heading stabilization, this is often accomplished with a PID loop - unlike with stabilization, however, the loop can only be closed on the heading. The following example code will turn the robot to face 90 degrees with a simple P loop: JAVA // Use gyro declaration from above here // The gain for a simple P loop double kP = 0.05 ; // Initialize motor controllers and drive Spark left1 = new Spark ( 0 ); Spark left2 = new Spark ( 1 ); Spark right1 = new Spark ( 2 ); Spark right2 = new Spark ( 3 ); MotorControllerGroup leftMotors = new MotorControllerGroup ( left1 , left2 ); MotorControllerGroup rightMotors = new MotorControllerGroup ( right1 , right2 ); DifferentialDrive drive = new DifferentialDrive ( leftMotors , rightMotors ); public Robot () { rightMotors . setInverted ( true ); } @Override public void autonomousPeriodic () { // Find the heading error; setpoint is 90 double error = 90 - gyro . getAngle (); // Turns the robot to face the desired direction drive . tankDrive ( kP * error , - kP * error ); } C++ // Use gyro declaration from above here // The gain for a simple P loop double kP = 0.05 ; // Initialize motor controllers and drive frc :: Spark left1 { 0 }; frc :: Spark left2 { 1 }; frc :: Spark right1 { 2 }; frc :: Spark right2 { 3 }; frc :: MotorControllerGroup leftMotors { left1 , left2 }; frc :: MotorControllerGroup rightMotors { right1 , right2 }; frc :: DifferentialDrive drive { leftMotors , rightMotors }; Robot :: Robot () { rightMotors . SetInverted ( true ); } void Robot :: AutonomousPeriodic () { // Find the heading error; setpoint is 90 double error = 90 - gyro . GetAngle (); // Turns the robot to face the desired direction drive . TankDrive ( kP * error , - kP * error ); } PYTHON from wpilib import Spark from wpilib.drive import DifferentialDrive def robotInit ( self ): # Use gyro declaration from above here # The gain for a simple P loop self . kP = 0.05 # Initialize motor controllers and drive leftLeader = Spark ( 0 ) leftFollower = Spark ( 1 ) rightLeader = Spark ( 2 ) rightFollower = Spark ( 3 ) leftLeader . addFollower ( leftFollower ) rightLeader . addFollower ( rightFollower ) self . drive = DifferentialDrive ( leftLeader , rightLeader ) rightLeader . setInverted ( True ) def autonomousPeriodic ( self ): # Find the heading error; setpoint is 90 error = 90 - self . gyro . getAngle () # Drives forward continuously at half speed, using the gyro to stabilize the heading self . drive . tankDrive ( self . kP * error , - self . kP * error ) As before, more-advanced implementations can use more-complicated control loops. Note Turn-to-angle loops can be tricky to tune correctly due to static friction in the drivetrain, especially if a simple P loop is used. There are a number of ways to account for this; one of the most common/effective is to add a “minimum output” to the output of the control loop. Another effective strategy is to cascade to well-tuned velocity controllers on each side of the drive.",
      "content_preview": "Gyroscopes - Software Note This section covers gyros in software. For a hardware guide to gyros, see Gyroscopes - Hardware . A gyroscope, or “gyro,” is an angular rate sensor typically used in robotics to measure and/or stabilize robot headings."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/counters.html",
      "title": "Counters",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Counters The Counter class ( Java , C++ ) is a versatile class that allows the counting of pulse edges on a digital input. Counter is used as a component in several more-complicated WPILib classes (such as Encoder and Ultrasonic ), but is also quite useful on its own. Note There are a total of 8 counter units in the roboRIO FPGA, meaning no more than 8 Counter objects may be instantiated at any one time, including those contained as resources in other WPILib objects. For detailed information on when a Counter may be used by another object, refer to the official API documentation. Configuring a counter The Counter class can be configured in a number of ways to provide differing functionalities. Counter Modes The Counter object may be configured to operate in one of four different modes: Two-pulse mode : Counts up and down based on the edges of two different channels. Semi-period mode : Measures the duration of a pulse on a single channel. Pulse-length mode : Counts up and down based on the edges of one channel, with the direction determined by the duration of the pulse on that channel. External direction mode : Counts up and down based on the edges of one channel, with a separate channel specifying the direction. Note In all modes except semi-period mode, the counter can be configured to increment either once per edge (2X decoding), or once per pulse (1X decoding). By default, counters are set to two-pulse mode, though if only one channel is specified the counter will only count up. Two-pulse mode In two-pulse mode, the Counter will count up for every edge/pulse on the specified “up channel,” and down for every edge/pulse on the specified “down channel.” A counter can be initialized in two-pulse with the following code: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . k2Pulse ); public Robot () { // Set up the input channels for the counter counter . setUpSource ( 1 ); counter . setDownSource ( 2 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); counter . setDownSourceEdge ( true , true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: k2Pulse }; Robot :: Robot () { // Set up the input channels for the counter counter . SetUpSource ( 1 ); counter . SetDownSource ( 2 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); counter . SetDownSourceEdge ( true , true ); Semi-period mode In semi-period mode, the Counter will count the duration of the pulses on a channel, either from a rising edge to the next falling edge, or from a falling edge to the next rising edge. A counter can be initialized in semi-period mode with the following code: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kSemiperiod ); public Robot () { // Set up the input channel for the counter counter . setUpSource ( 1 ); // Set the encoder to count pulse duration from rising edge to falling edge counter . setSemiPeriodMode ( true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kSemiperiod }; void Robot () { // Set up the input channel for the counter counter . SetUpSource ( 1 ); // Set the encoder to count pulse duration from rising edge to falling edge counter . SetSemiPeriodMode ( true ); To get the pulse width, call the getPeriod() method: JAVA // Return the measured pulse width in seconds counter . getPeriod (); C++ // Return the measured pulse width in seconds counter . GetPeriod (); Pulse-length mode In pulse-length mode, the counter will count either up or down depending on the length of the pulse. A pulse below the specified threshold time will be interpreted as a forward count and a pulse above the threshold is a reverse count. This is useful for some gear tooth sensors which encode direction in this manner. A counter can be initialized in this mode as follows: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kPulseLength ); public Robot () { // Set up the input channel for the counter counter . setUpSource ( 1 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); // Set the counter to count down if the pulses are longer than .05 seconds counter . setPulseLengthMode ( .05 ) } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kPulseLength }; Robot :: Robot () { // Set up the input channel for the counter counter . SetUpSource ( 1 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); // Set the counter to count down if the pulses are longer than .05 seconds counter . SetPulseLengthMode ( .05 ) External direction mode In external direction mode, the counter counts either up or down depending on the level on the second channel. If the direction source is low, the counter will increase; if the direction source is high, the counter will decrease (to reverse this, see the next section). A counter can be initialized in this mode as follows: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kExternalDirection ); public Robot () { // Set up the input channels for the counter counter . setUpSource ( 1 ); counter . setDownSource ( 2 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kExternalDirection }; void RobotInit () { // Set up the input channels for the counter counter . SetUpSource ( 1 ); counter . SetDownSource ( 2 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); Configuring counter parameters Note The Counter class does not make any assumptions about units of distance; it will return values in whatever units were used to calculate the distance-per-pulse value. Users thus have complete control over the distance units used. However, units of time are always in seconds. Note The number of pulses used in the distance-per-pulse calculation does not depend on the decoding type - each “pulse” should always be considered to be a full cycle (rising and falling). Apart from the mode-specific configurations, the Counter class offers a number of additional configuration methods: JAVA // Configures the counter to return a distance of 4 for every 256 pulses // Also changes the units of getRate counter . setDistancePerPulse ( 4. / 256. ); // Configures the counter to consider itself stopped after .1 seconds counter . setMaxPeriod ( .1 ); // Configures the counter to consider itself stopped when its rate is below 10 counter . setMinRate ( 10 ); // Reverses the direction of the counter counter . setReverseDirection ( true ); // Configures an counter to average its period measurement over 5 samples // Can be between 1 and 127 samples counter . setSamplesToAverage ( 5 ); C++ // Configures the counter to return a distance of 4 for every 256 pulses // Also changes the units of getRate counter . SetDistancePerPulse ( 4. / 256. ); // Configures the counter to consider itself stopped after .1 seconds counter . SetMaxPeriod ( .1 ); // Configures the counter to consider itself stopped when its rate is below 10 counter . SetMinRate ( 10 ); // Reverses the direction of the counter counter . SetReverseDirection ( true ); // Configures an counter to average its period measurement over 5 samples // Can be between 1 and 127 samples counter . SetSamplesToAverage ( 5 ); Reading information from counters Regardless of mode, there is some information that the Counter class always exposes to users: Count Users can obtain the current count with the get() method: JAVA // returns the current count counter . get (); C++ // returns the current count counter . Get (); Distance Note Counters measure relative distance, not absolute; the distance value returned will depend on the position of the encoder when the robot was turned on or the encoder value was last reset . If the distance per pulse has been configured, users can obtain the total distance traveled by the counted sensor with the getDistance() method: JAVA // returns the current distance counter . getDistance (); C++ // returns the current distance counter . GetDistance (); Rate Note Units of time for the Counter class are always in seconds. Users can obtain the current rate of change of the counter with the getRate() method: JAVA // Gets the current rate of the counter counter . getRate (); C++ // Gets the current rate of the counter counter . GetRate (); Stopped Users can obtain whether the counter is stationary with the getStopped() method: JAVA // Gets whether the counter is stopped counter . getStopped (); C++ // Gets whether the counter is stopped counter . GetStopped (); Direction Users can obtain the direction in which the counter last moved with the getDirection() method: JAVA // Gets the last direction in which the counter moved counter . getDirection (); C++ // Gets the last direction in which the counter moved counter . GetDirection (); Period Note In semi-period mode , this method returns the duration of the pulse, not of the period. Users can obtain the duration (in seconds) of the most-recent period with the getPeriod() method: JAVA // returns the current period in seconds counter . getPeriod (); C++ // returns the current period in seconds counter . GetPeriod (); Resetting a counter To reset a counter to a distance reading of zero, call the reset() method. This is useful for ensuring that the measured distance corresponds to the actual desired physical measurement. JAVA // Resets the encoder to read a distance of zero counter . reset (); C++ // Resets the encoder to read a distance of zero counter . Reset (); Using counters in code Counters are useful for a wide variety of robot applications - but since the Counter class is so varied, it is difficult to provide a good summary of them here. Many of these applications overlap with the Encoder class - a simple counter is often a cheaper alternative to a quadrature encoder. For a summary of potential uses for encoders in code, see Encoders - Software .",
      "content_preview": "Counters The Counter class ( Java , C++ ) is a versatile class that allows the counting of pulse edges on a digital input. Counter is used as a component in several more-complicated WPILib classes (such as Encoder and Ultrasonic ), but is also quite useful on its own."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/counters.html?present",
      "title": "Counters",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Counters The Counter class ( Java , C++ ) is a versatile class that allows the counting of pulse edges on a digital input. Counter is used as a component in several more-complicated WPILib classes (such as Encoder and Ultrasonic ), but is also quite useful on its own. Note There are a total of 8 counter units in the roboRIO FPGA, meaning no more than 8 Counter objects may be instantiated at any one time, including those contained as resources in other WPILib objects. For detailed information on when a Counter may be used by another object, refer to the official API documentation. Configuring a counter The Counter class can be configured in a number of ways to provide differing functionalities. Counter Modes The Counter object may be configured to operate in one of four different modes: Two-pulse mode : Counts up and down based on the edges of two different channels. Semi-period mode : Measures the duration of a pulse on a single channel. Pulse-length mode : Counts up and down based on the edges of one channel, with the direction determined by the duration of the pulse on that channel. External direction mode : Counts up and down based on the edges of one channel, with a separate channel specifying the direction. Note In all modes except semi-period mode, the counter can be configured to increment either once per edge (2X decoding), or once per pulse (1X decoding). By default, counters are set to two-pulse mode, though if only one channel is specified the counter will only count up. Two-pulse mode In two-pulse mode, the Counter will count up for every edge/pulse on the specified “up channel,” and down for every edge/pulse on the specified “down channel.” A counter can be initialized in two-pulse with the following code: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . k2Pulse ); public Robot () { // Set up the input channels for the counter counter . setUpSource ( 1 ); counter . setDownSource ( 2 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); counter . setDownSourceEdge ( true , true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: k2Pulse }; Robot :: Robot () { // Set up the input channels for the counter counter . SetUpSource ( 1 ); counter . SetDownSource ( 2 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); counter . SetDownSourceEdge ( true , true ); Semi-period mode In semi-period mode, the Counter will count the duration of the pulses on a channel, either from a rising edge to the next falling edge, or from a falling edge to the next rising edge. A counter can be initialized in semi-period mode with the following code: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kSemiperiod ); public Robot () { // Set up the input channel for the counter counter . setUpSource ( 1 ); // Set the encoder to count pulse duration from rising edge to falling edge counter . setSemiPeriodMode ( true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kSemiperiod }; void Robot () { // Set up the input channel for the counter counter . SetUpSource ( 1 ); // Set the encoder to count pulse duration from rising edge to falling edge counter . SetSemiPeriodMode ( true ); To get the pulse width, call the getPeriod() method: JAVA // Return the measured pulse width in seconds counter . getPeriod (); C++ // Return the measured pulse width in seconds counter . GetPeriod (); Pulse-length mode In pulse-length mode, the counter will count either up or down depending on the length of the pulse. A pulse below the specified threshold time will be interpreted as a forward count and a pulse above the threshold is a reverse count. This is useful for some gear tooth sensors which encode direction in this manner. A counter can be initialized in this mode as follows: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kPulseLength ); public Robot () { // Set up the input channel for the counter counter . setUpSource ( 1 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); // Set the counter to count down if the pulses are longer than .05 seconds counter . setPulseLengthMode ( .05 ) } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kPulseLength }; Robot :: Robot () { // Set up the input channel for the counter counter . SetUpSource ( 1 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); // Set the counter to count down if the pulses are longer than .05 seconds counter . SetPulseLengthMode ( .05 ) External direction mode In external direction mode, the counter counts either up or down depending on the level on the second channel. If the direction source is low, the counter will increase; if the direction source is high, the counter will decrease (to reverse this, see the next section). A counter can be initialized in this mode as follows: JAVA // Create a new Counter object in two-pulse mode Counter counter = new Counter ( Counter . Mode . kExternalDirection ); public Robot () { // Set up the input channels for the counter counter . setUpSource ( 1 ); counter . setDownSource ( 2 ); // Set the decoding type to 2X counter . setUpSourceEdge ( true , true ); } C++ // Create a new Counter object in two-pulse mode frc :: Counter counter { frc :: Counter :: Mode :: kExternalDirection }; void RobotInit () { // Set up the input channels for the counter counter . SetUpSource ( 1 ); counter . SetDownSource ( 2 ); // Set the decoding type to 2X counter . SetUpSourceEdge ( true , true ); Configuring counter parameters Note The Counter class does not make any assumptions about units of distance; it will return values in whatever units were used to calculate the distance-per-pulse value. Users thus have complete control over the distance units used. However, units of time are always in seconds. Note The number of pulses used in the distance-per-pulse calculation does not depend on the decoding type - each “pulse” should always be considered to be a full cycle (rising and falling). Apart from the mode-specific configurations, the Counter class offers a number of additional configuration methods: JAVA // Configures the counter to return a distance of 4 for every 256 pulses // Also changes the units of getRate counter . setDistancePerPulse ( 4. / 256. ); // Configures the counter to consider itself stopped after .1 seconds counter . setMaxPeriod ( .1 ); // Configures the counter to consider itself stopped when its rate is below 10 counter . setMinRate ( 10 ); // Reverses the direction of the counter counter . setReverseDirection ( true ); // Configures an counter to average its period measurement over 5 samples // Can be between 1 and 127 samples counter . setSamplesToAverage ( 5 ); C++ // Configures the counter to return a distance of 4 for every 256 pulses // Also changes the units of getRate counter . SetDistancePerPulse ( 4. / 256. ); // Configures the counter to consider itself stopped after .1 seconds counter . SetMaxPeriod ( .1 ); // Configures the counter to consider itself stopped when its rate is below 10 counter . SetMinRate ( 10 ); // Reverses the direction of the counter counter . SetReverseDirection ( true ); // Configures an counter to average its period measurement over 5 samples // Can be between 1 and 127 samples counter . SetSamplesToAverage ( 5 ); Reading information from counters Regardless of mode, there is some information that the Counter class always exposes to users: Count Users can obtain the current count with the get() method: JAVA // returns the current count counter . get (); C++ // returns the current count counter . Get (); Distance Note Counters measure relative distance, not absolute; the distance value returned will depend on the position of the encoder when the robot was turned on or the encoder value was last reset . If the distance per pulse has been configured, users can obtain the total distance traveled by the counted sensor with the getDistance() method: JAVA // returns the current distance counter . getDistance (); C++ // returns the current distance counter . GetDistance (); Rate Note Units of time for the Counter class are always in seconds. Users can obtain the current rate of change of the counter with the getRate() method: JAVA // Gets the current rate of the counter counter . getRate (); C++ // Gets the current rate of the counter counter . GetRate (); Stopped Users can obtain whether the counter is stationary with the getStopped() method: JAVA // Gets whether the counter is stopped counter . getStopped (); C++ // Gets whether the counter is stopped counter . GetStopped (); Direction Users can obtain the direction in which the counter last moved with the getDirection() method: JAVA // Gets the last direction in which the counter moved counter . getDirection (); C++ // Gets the last direction in which the counter moved counter . GetDirection (); Period Note In semi-period mode , this method returns the duration of the pulse, not of the period. Users can obtain the duration (in seconds) of the most-recent period with the getPeriod() method: JAVA // returns the current period in seconds counter . getPeriod (); C++ // returns the current period in seconds counter . GetPeriod (); Resetting a counter To reset a counter to a distance reading of zero, call the reset() method. This is useful for ensuring that the measured distance corresponds to the actual desired physical measurement. JAVA // Resets the encoder to read a distance of zero counter . reset (); C++ // Resets the encoder to read a distance of zero counter . Reset (); Using counters in code Counters are useful for a wide variety of robot applications - but since the Counter class is so varied, it is difficult to provide a good summary of them here. Many of these applications overlap with the Encoder class - a simple counter is often a cheaper alternative to a quadrature encoder. For a summary of potential uses for encoders in code, see Encoders - Software .",
      "content_preview": "Counters The Counter class ( Java , C++ ) is a versatile class that allows the counting of pulse edges on a digital input. Counter is used as a component in several more-complicated WPILib classes (such as Encoder and Ultrasonic ), but is also quite useful on its own."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/digital-inputs-software.html",
      "title": "Digital Inputs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Digital Inputs - Software Note This section covers digital inputs in software. For a hardware guide to digital inputs, see Digital Inputs - Hardware . The roboRIO’s FPGA supports up to 26 digital inputs. 10 of these are made available through the built-in DIO ports on the RIO itself, while the other 16 are available through the MXP breakout port. Digital inputs read one of two states - “high” or “low.” By default, the built-in ports on the RIO will read “high” due to internal pull-up resistors (for more information, see Digital Inputs - Hardware ). Accordingly, digital inputs are most-commonly used with switches of some sort. Support for this usage is provided through the DigitalInput class ( Java , C++ ). The DigitalInput class A DigitalInput can be initialized as follows: JAVA // Initializes a DigitalInput on DIO 0 DigitalInput m_input = new DigitalInput ( 0 ); C++ // Initializes a DigitalInput on DIO 0 frc :: DigitalInput m_input { 0 }; Reading the value of the DigitalInput The state of the DigitalInput can be polled with the get method: JAVA // Gets the value of the digital input. Returns true if the circuit is open. m_input . get (); C++ // Gets the value of the digital input. Returns true if the circuit is // open. m_input . Get (); Creating a DigitalInput from an AnalogInput Note An AnalogTrigger constructed with a port number argument can share that analog port with a separate AnalogInput , but two AnalogInput objects may not share the same port. Sometimes, it is desirable to use an analog input as a digital input. This can be easily achieved using the AnalogTrigger class ( Java , C++ ). An AnalogTrigger may be initialized as follows. As with AnalogPotentiometer , an AnalogInput may be passed explicitly if the user wishes to customize the sampling settings: JAVA // Initializes an AnalogTrigger on port 0 AnalogTrigger m_trigger0 = new AnalogTrigger ( 0 ); // Initializes an AnalogInput on port 1 and enables 2-bit oversampling AnalogInput m_input = new AnalogInput ( 1 ); // Initializes an AnalogTrigger using the above input AnalogTrigger m_trigger1 = new AnalogTrigger ( m_input ); C++ // Initializes an AnalogTrigger on port 0 frc :: AnalogTrigger trigger0 { 0 }; // Initializes an AnalogInput on port 1 frc :: AnalogInput input { 1 }; // Initializes an AnalogTrigger using the above input frc :: AnalogTrigger trigger1 { input }; Setting the trigger points Note For details on the scaling of “raw” AnalogInput values, see Analog Inputs - Software . To convert the analog signal to a digital one, it is necessary to specify at what values the trigger will enable and disable. These values may be different to avoid “dithering” around the transition point: JAVA // Enables 2-bit oversampling m_input . setAverageBits ( 2 ); // Sets the trigger to enable at a raw value of 3500, and disable at a value of 1000 m_trigger0 . setLimitsRaw ( 1000 , 3500 ); // Sets the trigger to enable at a voltage of 4 volts, and disable at a value of 1.5 volts m_trigger0 . setLimitsVoltage ( 1.5 , 4 ); C++ // Enables 2-bit oversampling input . SetAverageBits ( 2 ); // Sets the trigger to enable at a raw value of 3500, and disable at a value // of 1000 trigger0 . SetLimitsRaw ( 1000 , 3500 ); // Sets the trigger to enable at a voltage of 4 volts, and disable at a // value of 1.5 volts trigger0 . SetLimitsVoltage ( 1.5 , 4 ); Using DigitalInputs in code As almost all switches on the robot will be used through a DigitalInput . This class is extremely important for effective robot control. Limiting the motion of a mechanism Nearly all motorized mechanisms (such as arms and elevators) in FRC® should be given some form of “limit switch” to prevent them from damaging themselves at the end of their range of motions. For an example of this, see Programming Limit Switches . Homing a mechanism Limit switches are very important for being able to “home” a mechanism with an encoder. For an example of this, see Homing a Mechanism .",
      "content_preview": "Digital Inputs - Software Note This section covers digital inputs in software. For a hardware guide to digital inputs, see Digital Inputs - Hardware . The roboRIO’s FPGA supports up to 26 digital inputs."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/digital-inputs-software.html?present",
      "title": "Digital Inputs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Digital Inputs - Software Note This section covers digital inputs in software. For a hardware guide to digital inputs, see Digital Inputs - Hardware . The roboRIO’s FPGA supports up to 26 digital inputs. 10 of these are made available through the built-in DIO ports on the RIO itself, while the other 16 are available through the MXP breakout port. Digital inputs read one of two states - “high” or “low.” By default, the built-in ports on the RIO will read “high” due to internal pull-up resistors (for more information, see Digital Inputs - Hardware ). Accordingly, digital inputs are most-commonly used with switches of some sort. Support for this usage is provided through the DigitalInput class ( Java , C++ ). The DigitalInput class A DigitalInput can be initialized as follows: JAVA // Initializes a DigitalInput on DIO 0 DigitalInput m_input = new DigitalInput ( 0 ); C++ // Initializes a DigitalInput on DIO 0 frc :: DigitalInput m_input { 0 }; Reading the value of the DigitalInput The state of the DigitalInput can be polled with the get method: JAVA // Gets the value of the digital input. Returns true if the circuit is open. m_input . get (); C++ // Gets the value of the digital input. Returns true if the circuit is // open. m_input . Get (); Creating a DigitalInput from an AnalogInput Note An AnalogTrigger constructed with a port number argument can share that analog port with a separate AnalogInput , but two AnalogInput objects may not share the same port. Sometimes, it is desirable to use an analog input as a digital input. This can be easily achieved using the AnalogTrigger class ( Java , C++ ). An AnalogTrigger may be initialized as follows. As with AnalogPotentiometer , an AnalogInput may be passed explicitly if the user wishes to customize the sampling settings: JAVA // Initializes an AnalogTrigger on port 0 AnalogTrigger m_trigger0 = new AnalogTrigger ( 0 ); // Initializes an AnalogInput on port 1 and enables 2-bit oversampling AnalogInput m_input = new AnalogInput ( 1 ); // Initializes an AnalogTrigger using the above input AnalogTrigger m_trigger1 = new AnalogTrigger ( m_input ); C++ // Initializes an AnalogTrigger on port 0 frc :: AnalogTrigger trigger0 { 0 }; // Initializes an AnalogInput on port 1 frc :: AnalogInput input { 1 }; // Initializes an AnalogTrigger using the above input frc :: AnalogTrigger trigger1 { input }; Setting the trigger points Note For details on the scaling of “raw” AnalogInput values, see Analog Inputs - Software . To convert the analog signal to a digital one, it is necessary to specify at what values the trigger will enable and disable. These values may be different to avoid “dithering” around the transition point: JAVA // Enables 2-bit oversampling m_input . setAverageBits ( 2 ); // Sets the trigger to enable at a raw value of 3500, and disable at a value of 1000 m_trigger0 . setLimitsRaw ( 1000 , 3500 ); // Sets the trigger to enable at a voltage of 4 volts, and disable at a value of 1.5 volts m_trigger0 . setLimitsVoltage ( 1.5 , 4 ); C++ // Enables 2-bit oversampling input . SetAverageBits ( 2 ); // Sets the trigger to enable at a raw value of 3500, and disable at a value // of 1000 trigger0 . SetLimitsRaw ( 1000 , 3500 ); // Sets the trigger to enable at a voltage of 4 volts, and disable at a // value of 1.5 volts trigger0 . SetLimitsVoltage ( 1.5 , 4 ); Using DigitalInputs in code As almost all switches on the robot will be used through a DigitalInput . This class is extremely important for effective robot control. Limiting the motion of a mechanism Nearly all motorized mechanisms (such as arms and elevators) in FRC® should be given some form of “limit switch” to prevent them from damaging themselves at the end of their range of motions. For an example of this, see Programming Limit Switches . Homing a mechanism Limit switches are very important for being able to “home” a mechanism with an encoder. For an example of this, see Homing a Mechanism .",
      "content_preview": "Digital Inputs - Software Note This section covers digital inputs in software. For a hardware guide to digital inputs, see Digital Inputs - Hardware . The roboRIO’s FPGA supports up to 26 digital inputs."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/sensor-overview-software.html",
      "title": "Sensor Overview",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Sensor Overview - Software Note This section covers using sensors in software. For a guide to sensor hardware, see Sensor Overview - Hardware . Note While cameras may definitely be considered “sensors”, vision processing is a sufficiently-complicated subject that it is covered in its own section , rather than here. In order to be effective, it is often vital for robots to be able to gather information about their surroundings. Devices that provide feedback to the robot on the state of its environment are called “sensors.” WPILib innately supports a large variety of sensors through classes included in the library. This section will provide a guide to both using common sensor types through WPILib, as well as writing code for sensors without official support. What sensors does WPILIB support? The roboRIO includes an FPGA which allows accurate real-time measuring of a variety of sensor input. WPILib, in turn, provides a number of classes for accessing this functionality. WPILib provides native support for: Accelerometers Gyroscopes Ultrasonic rangefinders Potentiometers Counters Quadrature encoders Limit switches Additionally, WPILib includes lower-level classes for interfacing directly with the FPGA’s digital and analog inputs and outputs.",
      "content_preview": "Sensor Overview - Software Note This section covers using sensors in software. For a guide to sensor hardware, see Sensor Overview - Hardware . Note While cameras may definitely be considered “sensors”, vision processing is a sufficiently-complicated subject that it is covered in its own section ,..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/strategies-for-vision-programming.html",
      "title": "Strategies for Vision Programming",
      "section": "Vision Processing",
      "language": "All",
      "content": "Strategies for Vision Programming Using computer vision is a great way of making your robot be responsive to the elements on the field and make it much more autonomous. Often in FRC® games there are bonus points for autonomously shooting balls or other game pieces into goals or navigating to locations on the field. Computer vision is a great way of solving many of these problems. And if you have autonomous code that can do the challenge, then it can be used during the teleop period as well to help the human drivers. There are many options for choosing the components for vision processing and where the vision program should run. WPILib and associated tools support a number of options and give teams a lot of flexibility to decide what to do. This article will attempt to give you some insight into many of the choices and tradeoffs that are available. OpenCV Computer Vision Library OpenCV is an open source computer vision library that is widely used throughout academia and industry. It has support from hardware manufactures providing GPU accelerated processing, it has bindings for a number of languages including C++, Java, and Python. It is also well documented with many web sites, books, videos, and training courses so there are lots of resources available to help learn how to use it. The C++ and Java versions of WPILib include the OpenCV libraries, there is support in the library for capturing, processing, and viewing video, and tools to help you create your vision algorithms. For more information about OpenCV see https://opencv.org . Vision Code on roboRIO Vision code can be embedded into the main robot program on the roboRIO. Building and running the vision code is straightforward because it is built and deployed along with the robot program. The vision code can be written in C++, Java, or Python. The disadvantage of this approach is that having vision code running on the same processor as the robot program can cause performance issues. This is something you will have to evaluate depending on the requirements for your robot and vision program. In this approach, the vision code simply produces results that the robot code directly uses. Be careful about synchronization issues when writing robot code that is getting values from a vision thread. The VisionRunner class in WPILib make this easier. Using functions provided by the CameraServer class, the video stream can be sent to dashboards such as Shuffleboard so operators can see what the camera sees. In addition, annotations can be added to the images using OpenCV commands so targets or other interesting objects can be identified in the dashboard view. Vision Code on DS Computer When vision code is running on the DS computer, the video is streamed back to the Driver Station laptop for processing. Even the older Classmate laptops are substantially faster at vision processing than the roboRIO. You can write your own vision program using a language of your choosing. Python makes a good choice since there is a native NetworkTables implementation and the OpenCV bindings are very good. After the images are processed, the key values such as the target position, distance, or anything else you need can be sent back to the robot with NetworkTables. This approach generally has higher latency, as delay is added due to the images needing to be sent to the laptop. Bandwidth limitations also limit the maximum resolution and FPS of the images used for processing. The video stream can be displayed on Shuffleboard or SmartDashboard. Vision Code on Coprocessor Coprocessors such as the Raspberry Pi are ideal for supporting vision code (see Using the Raspberry Pi for FRC ). The advantage is that they can run full speed and not interfere with the robot program. In this case, the camera is probably connected to the coprocessor or (in the case of Ethernet cameras) an Ethernet switch on the robot. The program can be written in any language; Python is a good choice because of its simple bindings to OpenCV and NetworkTables. Some teams have used high performance vision coprocessors such as the Nvidia Jetson for fastest speed and highest resolution, although this approach generally requires advanced Linux and programming knowledge. This approach takes a bit more programming expertise as well as a small amount of additional weight, but otherwise it brings the best of both worlds compared to the other two approaches, as coprocessors are much faster than the roboRIO and the image processing can be performed with minimal latency or bandwidth use. Data can be sent from the vision program on the coprocessor to the robot using NetworkTables or a private protocol over a network or serial connection. Camera Options There are a number of camera options supported by WPILib. Cameras have a number of parameters that affect operation; for example, frame rate and image resolution affect the quality of the received images, but when set too high impact processing time and, if sent to the driver station, may exceed the available bandwidth on the field. The CameraServer class in C++ and Java is used to interface with cameras connected to the robot. It retrieve frames for local processing through a Source object and sends the stream to your driver station for viewing or processing there.",
      "content_preview": "Strategies for Vision Programming Using computer vision is a great way of making your robot be responsive to the elements on the field and make it much more autonomous."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/sensors/sensor-overview-software.html?present",
      "title": "Sensor Overview",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Sensor Overview - Software Note This section covers using sensors in software. For a guide to sensor hardware, see Sensor Overview - Hardware . Note While cameras may definitely be considered “sensors”, vision processing is a sufficiently-complicated subject that it is covered in its own section , rather than here. In order to be effective, it is often vital for robots to be able to gather information about their surroundings. Devices that provide feedback to the robot on the state of its environment are called “sensors.” WPILib innately supports a large variety of sensors through classes included in the library. This section will provide a guide to both using common sensor types through WPILib, as well as writing code for sensors without official support. What sensors does WPILIB support? The roboRIO includes an FPGA which allows accurate real-time measuring of a variety of sensor input. WPILib, in turn, provides a number of classes for accessing this functionality. WPILib provides native support for: Accelerometers Gyroscopes Ultrasonic rangefinders Potentiometers Counters Quadrature encoders Limit switches Additionally, WPILib includes lower-level classes for interfacing directly with the FPGA’s digital and analog inputs and outputs.",
      "content_preview": "Sensor Overview - Software Note This section covers using sensors in software. For a guide to sensor hardware, see Sensor Overview - Hardware . Note While cameras may definitely be considered “sensors”, vision processing is a sufficiently-complicated subject that it is covered in its own section ,..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/index.html",
      "title": "Motors APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Motors APIs Programming your motors are absolutely essential to a moving robot! This section showcases some helpful classes and examples for getting your robot up and moving! Using Motor Controllers in Code PWM Motor Controllers in Depth Using the WPILib Classes to Drive your Robot Repeatable Low Power Movement - Controlling Servos with WPILib",
      "content_preview": "Motors APIs Programming your motors are absolutely essential to a moving robot! This section showcases some helpful classes and examples for getting your robot up and moving! Using Motor Controllers in Code PWM Motor Controllers in Depth Using the WPILib Classes to Drive your Robot Repeatable Low..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/pwm-controllers.html",
      "title": "PWM Motor Controllers in Depth",
      "section": "Advanced Controls",
      "language": "All",
      "content": "PWM Motor Controllers in Depth Hint WPILib has extensive support for motor control. There are a number of classes that represent different types of motor controllers and servos. There are currently two classes of motor controllers, PWM based motor controllers and CAN based motor controllers. WPILib also contains composite classes (like DifferentialDrive) which allow you to control multiple motors with a single object. This article will cover the details of PWM motor controllers; CAN controllers and composite classes will be covered in separate articles. PWM Controllers, brief theory of operation The acronym PWM stands for Pulse Width Modulation. For motor controllers, PWM can refer to both the input signal and the method the controller uses to control motor speed. To control the speed of the motor the controller must vary the perceived input voltage of the motor. To do this the controller switches the full input voltage on and off very quickly, varying the amount of time it is on based on the control signal. Because of the mechanical and electrical time constants of the types of motors used in FRC® this rapid switching produces an effect equivalent to that of applying a fixed lower voltage (50% switching produces the same effect as applying ~6V). The PWM signal the controllers use for an input is a little bit different. Even at the bounds of the signal range (max forward or max reverse) the signal never approaches a duty cycle of 0% or 100%. Instead the controllers use a signal with a period of either 5ms or 10ms and a midpoint pulse width of 1.5ms. Many of the controllers use the typical hobby RC controller timing of 1ms to 2ms. Raw vs Scaled output values In general, all of the motor controller classes in WPILib take a scaled -1.0 to 1.0 value as the output to an actuator. The PWM module in the FPGA on the roboRIO is capable of generating PWM signals with periods of 5, 10, or 20ms and can vary the pulse width in 4096 steps of 1us each . The raw values sent to this module are in this 0-4096 range with 0 being a special case which holds the signal low (disabled). The class for each motor controller contains information about what the typical bound values (min, max, and each side of the deadband) are as well as the typical midpoint. WPILib can then use these values to map the scaled value into the proper range for the motor controller. This allows for the code to switch seamlessly between different types of controllers and abstracts out the details of the specific signaling. Calibrating Motor Controllers So if WPILib handles all this scaling, why would you ever need to calibrate your motor controller? The values WPILib uses for scaling are approximate based on measurement of a number of samples of each controller type. Due to a variety of factors, the timing of an individual motor controller may vary slightly. In order to definitively eliminate “humming” (midpoint signal interpreted as slight movement in one direction) and drive the controller all the way to each extreme, calibrating the controllers is still recommended. In general, the calibration procedure for each controller involves putting the controller into calibration mode then driving the input signal to each extreme, then back to the midpoint. For examples on how to use these motor controllers in your code, see Using Motor Controllers in Code/Using PWM Motor Controllers",
      "content_preview": "PWM Motor Controllers in Depth Hint WPILib has extensive support for motor control. There are a number of classes that represent different types of motor controllers and servos. There are currently two classes of motor controllers, PWM based motor controllers and CAN based motor controllers."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/pwm-controllers.html?present",
      "title": "PWM Motor Controllers in Depth",
      "section": "Advanced Controls",
      "language": "All",
      "content": "PWM Motor Controllers in Depth Hint WPILib has extensive support for motor control. There are a number of classes that represent different types of motor controllers and servos. There are currently two classes of motor controllers, PWM based motor controllers and CAN based motor controllers. WPILib also contains composite classes (like DifferentialDrive) which allow you to control multiple motors with a single object. This article will cover the details of PWM motor controllers; CAN controllers and composite classes will be covered in separate articles. PWM Controllers, brief theory of operation The acronym PWM stands for Pulse Width Modulation. For motor controllers, PWM can refer to both the input signal and the method the controller uses to control motor speed. To control the speed of the motor the controller must vary the perceived input voltage of the motor. To do this the controller switches the full input voltage on and off very quickly, varying the amount of time it is on based on the control signal. Because of the mechanical and electrical time constants of the types of motors used in FRC® this rapid switching produces an effect equivalent to that of applying a fixed lower voltage (50% switching produces the same effect as applying ~6V). The PWM signal the controllers use for an input is a little bit different. Even at the bounds of the signal range (max forward or max reverse) the signal never approaches a duty cycle of 0% or 100%. Instead the controllers use a signal with a period of either 5ms or 10ms and a midpoint pulse width of 1.5ms. Many of the controllers use the typical hobby RC controller timing of 1ms to 2ms. Raw vs Scaled output values In general, all of the motor controller classes in WPILib take a scaled -1.0 to 1.0 value as the output to an actuator. The PWM module in the FPGA on the roboRIO is capable of generating PWM signals with periods of 5, 10, or 20ms and can vary the pulse width in 4096 steps of 1us each . The raw values sent to this module are in this 0-4096 range with 0 being a special case which holds the signal low (disabled). The class for each motor controller contains information about what the typical bound values (min, max, and each side of the deadband) are as well as the typical midpoint. WPILib can then use these values to map the scaled value into the proper range for the motor controller. This allows for the code to switch seamlessly between different types of controllers and abstracts out the details of the specific signaling. Calibrating Motor Controllers So if WPILib handles all this scaling, why would you ever need to calibrate your motor controller? The values WPILib uses for scaling are approximate based on measurement of a number of samples of each controller type. Due to a variety of factors, the timing of an individual motor controller may vary slightly. In order to definitively eliminate “humming” (midpoint signal interpreted as slight movement in one direction) and drive the controller all the way to each extreme, calibrating the controllers is still recommended. In general, the calibration procedure for each controller involves putting the controller into calibration mode then driving the input signal to each extreme, then back to the midpoint. For examples on how to use these motor controllers in your code, see Using Motor Controllers in Code/Using PWM Motor Controllers",
      "content_preview": "PWM Motor Controllers in Depth Hint WPILib has extensive support for motor control. There are a number of classes that represent different types of motor controllers and servos. There are currently two classes of motor controllers, PWM based motor controllers and CAN based motor controllers."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/using-motor-controllers.html",
      "title": "Using Motor Controllers in Code",
      "section": "Advanced Controls",
      "language": "All",
      "content": "Using Motor Controllers in Code Motor controllers come in two main flavors: CAN and PWM . A CAN controller can send more detailed status information back to the roboRIO, whereas a PWM controller can only be set to a value. For information on using these motors with the WPILib drivetrain classes, see Using the WPILib Classes to Drive your Robot . Using PWM Motor Controllers For a more detailed background on how PWM motor controllers work, see PWM Motor Controllers in Depth . To use a PWM motor controller, simply use the appropriate motor controller class provided by WPILib and supply it the port the motor controller(s) are plugged into on the roboRIO. All approved motor controllers have WPILib classes provided for them. Note The Spark and VictorSP classes are used here as an example; other PWM motor controller classes have exactly the same API. Important The set() method accepts values from -1.0 to 1.0 , where: -1.0 = full speed reverse 0.0 = stopped 1.0 = full speed forward Where to Put This Code In Command-Based programs: Motor controllers should be declared as member variables in your subsystem class. Create them in the subsystem constructor, and use them in command methods. JAVA public class IntakeSubsystem extends SubsystemBase { private final Spark m_motor = new Spark ( 0 ); public void runIntake () { m_motor . set ( 0.8 ); } public void stopIntake () { m_motor . set ( 0.0 ); } } C++ class IntakeSubsystem : public frc2 :: SubsystemBase { public : IntakeSubsystem () : m_motor { 0 } {} void RunIntake () { m_motor . Set ( 0.8 ); } void StopIntake () { m_motor . Set ( 0.0 ); } private : frc :: Spark m_motor ; }; PYTHON class IntakeSubsystem ( commands2 . SubsystemBase ): def __init__ ( self ): super () . __init__ () self . motor = wpilib . Spark ( 0 ) def run_intake ( self ): self . motor . set ( 0.8 ) def stop_intake ( self ): self . motor . set ( 0.0 ) In Timed Robot programs: Motor controllers should be declared as member variables in your Robot class. Create them in robotInit() , and use them in periodic methods or autonomous/teleop methods. JAVA public class Robot extends TimedRobot { private Spark m_intakeMotor ; private Joystick m_joystick ; @Override public void robotInit () { m_intakeMotor = new Spark ( 0 ); m_joystick = new Joystick ( 0 ); } @Override public void teleopPeriodic () { // Run intake when button is pressed if ( m_joystick . getRawButton ( 1 )) { m_intakeMotor . set ( 0.8 ); } else { m_intakeMotor . set ( 0.0 ); } } } C++ class Robot : public frc :: TimedRobot { public : Robot () : m_intakeMotor { 0 }, m_joystick { 0 } {} void TeleopPeriodic () override { // Run intake when button is pressed if ( m_joystick . GetRawButton ( 1 )) { m_intakeMotor . Set ( 0.8 ); } else { m_intakeMotor . Set ( 0.0 ); } } private : frc :: Spark m_intakeMotor ; frc :: Joystick m_joystick ; }; PYTHON class MyRobot ( wpilib . TimedRobot ): def robotInit ( self ): self . intake_motor = wpilib . Spark ( 0 ) self . joystick = wpilib . Joystick ( 0 ) def teleopPeriodic ( self ): # Run intake when button is pressed if self . joystick . getRawButton ( 1 ): self . intake_motor . set ( 0.8 ) else : self . intake_motor . set ( 0.0 ) Common Use Cases Motor controllers are used throughout the robot for many mechanisms: Intakes : Spin wheels to collect game pieces Shooters : Spin flywheels to launch game pieces Conveyors : Move game pieces through the robot Arms/Elevators : Raise and lower mechanisms (often with position control) Climbers : Extend or retract climbing mechanisms For drivetrain usage, see Using the WPILib Classes to Drive your Robot . For more complete examples, see WPILib Example Projects . CAN Motor Controllers CAN motor controllers are available through vendors such as CTR Electronics (Talon FX), REV Robotics (SPARK MAX/FLEX), and others. See Third-Party CAN Devices , 3rd Party Libraries , and Third Party Example Projects for more information.",
      "content_preview": "Using Motor Controllers in Code Motor controllers come in two main flavors: CAN and PWM . A CAN controller can send more detailed status information back to the roboRIO, whereas a PWM controller can only be set to a value."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/index.html?present",
      "title": "Motors APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Motors APIs Programming your motors are absolutely essential to a moving robot! This section showcases some helpful classes and examples for getting your robot up and moving! Using Motor Controllers in Code PWM Motor Controllers in Depth Using the WPILib Classes to Drive your Robot Repeatable Low Power Movement - Controlling Servos with WPILib",
      "content_preview": "Motors APIs Programming your motors are absolutely essential to a moving robot! This section showcases some helpful classes and examples for getting your robot up and moving! Using Motor Controllers in Code PWM Motor Controllers in Depth Using the WPILib Classes to Drive your Robot Repeatable Low..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/wpi-drive-classes.html",
      "title": "Using the WPILib Classes to Drive your Robot",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Using the WPILib Classes to Drive your Robot WPILib includes many classes to help make your robot get driving faster. Standard drivetrains Differential Drive Robots These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as “skid-steer”, “tank drive”, or “West Coast Drive”. The Kit of Parts drivetrain is an example of a differential drive. These drivetrains are capable of driving forward/backward and can turn by driving the two sides in opposite directions causing the wheels to skid sideways. These drivetrains are not capable of sideways translational movement. Mecanum Drive Mecanum drive is a method of driving using specially designed wheels that allow the robot to drive in any direction without changing the orientation of the robot. A robot with a conventional drivetrain (all wheels pointing in the same direction) must turn in the direction it needs to drive. A mecanum robot can move in any direction without first turning and is called a holonomic drive. The wheels (shown on this robot) have rollers that cause the forces from driving to be applied at a 45 degree angle rather than straight forward as in the case of a conventional drive. When viewed from the top, the rollers on a mecanum drivetrain should form an ‘X’ pattern. This results in the force vectors (when driving the wheel forward) on the front two wheels pointing forward and inward and the rear two wheels pointing forward and outward. By spinning the wheels in different directions, various components of the force vectors cancel out, resulting in the desired robot movement. A quick chart of different movements has been provided below, drawing out the force vectors for each of these motions may help in understanding how these drivetrains work. By varying the speeds of the wheels in addition to the direction, movements can be combined resulting in translation in any direction and rotation, simultaneously. Drive Class Conventions Motor Inversion It is the responsibility of the user to manage proper inversions for their drivetrain. Users can invert motors by calling setInverted() / SetInverted() on their motor objects. Typically for differential drive trains, one side must be inverted to avoid spinning in circles, since the forward direction of each side of the tank drive is opposite of each other. JAVA PWMSparkMax m_motorRight = new PWMSparkMax ( 0 ); public Robot () { m_motorRight . setInverted ( true ); } C++ frc :: PWMSparkMax m_motorLeft { 0 }; public : Robot :: Robot () { m_motorRight . SetInverted ( true ); } PYTHON def robotInit ( self ): self . motorRight = wpilib . PWMSparkMax ( 0 ) self . motorRight . setInverted ( True ) Squaring Inputs When driving robots, it is often desirable to manipulate the joystick inputs such that the robot has finer control at low speeds while still using the full output range. One way to accomplish this is by squaring the joystick input, then reapplying the sign. By default the Differential Drive class will square the inputs. If this is not desired (e.g. if passing values in from a PIDController), use one of the drive methods with the squaredInputs parameter and set it to false. Input Deadband By default, the Differential Drive class applies an input deadband of 0.02. This means that input values with a magnitude below 0.02 (after any squaring as described above) will be set to 0. In most cases these small inputs result from imperfect joystick centering and are not sufficient to cause drivetrain movement, the deadband helps reduce unnecessary motor heating that may result from applying these small values to the drivetrain. To change the deadband, use the setDeadband() method. Maximum Output Sometimes drivers feel that their drivetrain is driving too fast and want to limit the output. This can be accomplished with the setMaxOutput() method. This maximum output is multiplied by result of the previous drive functions like deadband and squared inputs. Motor Safety Motor Safety is a mechanism in WPILib that takes the concept of a watchdog and breaks it out into one watchdog (Motor Safety timer) for each individual actuator. Note that this protection mechanism is in addition to the System Watchdog which is controlled by the Network Communications code and the FPGA and will disable all actuator outputs if it does not receive a valid data packet for 125ms. The purpose of the Motor Safety mechanism is the same as the purpose of a watchdog timer, to disable mechanisms which may cause harm to themselves, people, or property if the code locks up and does not properly update the actuator output. Motor Safety breaks this concept out on a per actuator basis so that you can appropriately determine where it is necessary and where it is not. Examples of mechanisms that should have motor safety enabled are systems like drive trains and arms. If these systems get latched on a particular value they could cause damage to their environment or themselves. An example of a mechanism that may not need motor safety is a spinning flywheel for a shooter. If this mechanism gets latched on a particular value it will simply continue spinning until the robot is disabled. By default Motor Safety is enabled for DifferentialDrive and MecanumDrive objects and disabled for all other motor controllers and servos. The Motor Safety feature operates by maintaining a timer that tracks how long it has been since the feed() method has been called for that actuator. Code in the Driver Station class initiates a comparison of these timers to the timeout values for any actuator with safety enabled every 5 received packets (100ms nominal). The set() methods of each motor controller class and the set() and setAngle() methods of the servo class call feed() to indicate that the output of the actuator has been updated. The Motor Safety interface of motor controllers can be interacted with by the user using the following methods: JAVA m_motorRight . setSafetyEnabled ( true ); m_motorRight . setSafetyEnabled ( false ); m_motorRight . setExpiration ( .1 ); m_motorRight . feed () C++ m_motorRight -> SetSafetyEnabled ( true ); m_motorRight -> SetSafetyEnabled ( false ); m_motorRight -> SetExpiration ( .1 ); m_motorRight -> Feed (); PYTHON m_motorRight . setSafetyEnabled ( True ) m_motorRight . setSafetyEnabled ( False ) m_motorRight . setExpiration ( .1 ) m_motorRight . feed () By default all Drive objects enable Motor Safety. Depending on the mechanism and the structure of your program, you may wish to configure the timeout length of the motor safety (in seconds). The timeout length is configured on a per actuator basis and is not a global setting. The default (and minimum useful) value is 100ms. Axis Conventions The drive classes use the NWU axes convention (North-West-Up as external reference in the world frame). The positive X axis points ahead, the positive Y axis points left, and the positive Z axis points up. We use NWU here because the rest of the library, and math in general, use NWU axes convention. Joysticks follow NED (North-East-Down) convention, where the positive X axis points ahead, the positive Y axis points right, and the positive Z axis points down. However, it’s important to note that axes values are rotations around the respective axes, not translations. When viewed with each axis pointing toward you, CCW is a positive value and CW is a negative value. Pushing forward on the joystick is a CW rotation around the Y axis, so you get a negative value. Pushing to the right is a CCW rotation around the X axis, so you get a positive value. Note See the Coordinate System section for more detail about the axis conventions and coordinate systems. Using the DifferentialDrive class to control Differential Drive robots Note WPILib provides separate Robot Drive classes for the most common drive train configurations (differential and mecanum). The DifferentialDrive class handles the differential drivetrain configuration. These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as “skid-steer”, “tank drive”, or “West Coast Drive” (WCD). The Kit of Parts drivetrain is an example of a differential drive. There are methods to control the drive with 3 different styles (“Tank”, “Arcade”, or “Curvature”), explained in the article below. DifferentialDrive is a method provided for the control of “skid-steer” or “West Coast” drivetrains, such as the Kit of Parts chassis. Instantiating a DifferentialDrive is as simple as so: Java public class Robot extends TimedRobot { private DifferentialDrive m_robotDrive ; private final PWMSparkMax m_leftMotor = new PWMSparkMax ( 0 ); private final PWMSparkMax m_rightMotor = new PWMSparkMax ( 1 ); @Override public void robotInit () { // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightMotor . setInverted ( true ); m_robotDrive = new DifferentialDrive ( m_leftMotor :: set , m_rightMotor :: set ); } C++ (Header) frc :: PWMSparkMax m_leftMotor { 0 }; frc :: PWMSparkMax m_rightMotor { 1 }; frc :: DifferentialDrive m_robotDrive { [ & ]( double output ) { m_leftMotor . Set ( output ); }, [ & ]( double output ) { m_rightMotor . Set ( output ); }}; C++ (Source) :sync: C++ (Source) void RobotInit () override { // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightMotor . SetInverted ( true ); } Python def robotInit ( self ): \"\"\"Robot initialization function\"\"\" leftMotor = wpilib . PWMSparkMax ( 0 ) rightMotor = wpilib . PWMSparkMax ( 1 ) self . robotDrive = wpilib . drive . DifferentialDrive ( leftMotor , rightMotor ) # We need to invert one side of the drivetrain so that positive voltages # result in both sides moving forward. Depending on how your robot's # gearbox is constructed, you might have to invert the left side instead. rightMotor . setInverted ( True ) Multi-Motor DifferentialDrive Many FRC® drivetrains have more than 1 motor on each side. Classes derived from PWMMotorController ( Java / C++ / Python ) have an addFollower method so that multiple follower motor controllers can be updated when the leader motor controller is commanded. CAN motor controllers have similar features, review the vendor’s documentation to see how to use them. The examples below show a 4 motor (2 per side) drivetrain. To extend to more motors, simply create the additional controllers and use additional addFollower calls. Java Class variables (e.g. in Robot.java or Subsystem): // The motors on the left side of the drive. private final PWMSparkMax m_leftLeader = new PWMSparkMax ( DriveConstants . kLeftMotor1Port ); private final PWMSparkMax m_leftFollower = new PWMSparkMax ( DriveConstants . kLeftMotor2Port ); // The motors on the right side of the drive. private final PWMSparkMax m_rightLeader = new PWMSparkMax ( DriveConstants . kRightMotor1Port ); private final PWMSparkMax m_rightFollower = new PWMSparkMax ( DriveConstants . kRightMotor2Port ); In Robot or Subsystem constructor: m_leftLeader . addFollower ( m_leftFollower ); m_rightLeader . addFollower ( m_rightFollower ); // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightLeader . setInverted ( true ); C++ (Header) private : // The motor controllers frc :: PWMSparkMax m_left1 ; frc :: PWMSparkMax m_left2 ; frc :: PWMSparkMax m_right1 ; frc :: PWMSparkMax m_right2 ; // The robot's drive frc :: DifferentialDrive m_drive {[ & ]( double output ) { m_left1 . Set ( output ); }, [ & ]( double output ) { m_right1 . Set ( output ); }}; C++ (Source) In Robot or Subsystem constructor: m_left1 . AddFollower ( m_left2 ); m_right1 . AddFollower ( m_right2 ); // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_right1 . SetInverted ( true ); Python def robotInit ( self ): leftLeader = wpilib . Spark ( 1 ) leftFollower = wpilib . Spark ( 2 ) leftLeader . addFollower ( leftFollower ) leftLeader . setInverted ( True ) # if you want to invert the entire side you can do so here rightLeader = wpilib . Spark ( 3 ) rightFollower = wpilib . Spark ( 4 ) rightLeader . addFollower ( rightFollower ) self . drive = wpilib . drive . DifferentialDrive ( leftLeader , rightLeader ) Drive Modes Note The DifferentialDrive class contains three different default modes of driving your robot’s motors. Tank Drive, which controls the left and right side independently Arcade Drive, which controls a forward and turn speed Curvature Drive, a subset of Arcade Drive, which makes your robot handle like a car with constant-curvature turns. The DifferentialDrive class contains three default methods for controlling skid-steer or WCD robots. Note that you can create your own methods of controlling the robot’s driving and have them call tankDrive() with the derived inputs for left and right motors. The Tank Drive mode is used to control each side of the drivetrain independently (usually with an individual joystick axis controlling each). This example shows how to use the Y-axis of two separate joysticks to run the drivetrain in Tank mode. Construction of the objects has been omitted, for above for drivetrain construction and here for Joystick construction. The Arcade Drive mode is used to control the drivetrain using speed/throttle and rotation rate. This is typically used either with two axes from a single joystick, or split across joysticks (often on a single gamepad) with the throttle coming from one stick and the rotation from another. This example shows how to use a single joystick with the Arcade mode. Construction of the objects has been omitted, for above for drivetrain construction and here for Joystick construction. Like Arcade Drive, the Curvature Drive mode is used to control the drivetrain using speed/throttle and rotation rate. The difference is that the rotation control input controls the radius of curvature instead of rate of heading change, much like the steering wheel of a car. This mode also supports turning in place, which is enabled when the third boolean parameter is true. JAVA public void teleopPeriodic () { // Tank drive with a given left and right rates myDrive . tankDrive ( - leftStick . getY (), - rightStick . getY ()); // Arcade drive with a given forward and turn rate myDrive . arcadeDrive ( - driveStick . getY (), - driveStick . getX ()); // Curvature drive with a given forward and turn rate, as well as a button for turning in-place. myDrive . curvatureDrive ( - driveStick . getY (), - driveStick . getX (), driveStick . getButton ( 1 )); } C++ void TeleopPeriodic () override { // Tank drive with a given left and right rates myDrive . TankDrive ( - leftStick . GetY (), - rightStick . GetY ()); // Arcade drive with a given forward and turn rate myDrive . ArcadeDrive ( - driveStick . GetY (), - driveStick . GetX ()); // Curvature drive with a given forward and turn rate, as well as a quick-turn button myDrive . CurvatureDrive ( - driveStick . GetY (), - driveStick . GetX (), driveStick . GetButton ( 1 )); } PYTHON def teleopPeriodic ( self ): # Tank drive with a given left and right rates self . myDrive . tankDrive ( - self . leftStick . getY (), - self . rightStick . getY ()) # Arcade drive with a given forward and turn rate self . myDrive . arcadeDrive ( - self . driveStick . getY (), - self . driveStick . getX ()) # Curvature drive with a given forward and turn rate, as well as a button for turning in-place. self . myDrive . curvatureDrive ( - self . driveStick . getY (), - self . driveStick . getX (), self . driveStick . getButton ( 1 )) Using the MecanumDrive class to control Mecanum Drive robots MecanumDrive is a method provided for the control of holonomic drivetrains with Mecanum wheels, such as the Kit of Parts chassis with the mecanum drive upgrade kit, as shown above. Instantiating a MecanumDrive is as simple as so: JAVA private static final int kFrontLeftChannel = 2 ; private static final int kRearLeftChannel = 3 ; private static final int kFrontRightChannel = 1 ; private static final int kRearRightChannel = 0 ; @Override public void robotInit () { PWMSparkMax frontLeft = new PWMSparkMax ( kFrontLeftChannel ); PWMSparkMax rearLeft = new PWMSparkMax ( kRearLeftChannel ); PWMSparkMax frontRight = new PWMSparkMax ( kFrontRightChannel ); PWMSparkMax rearRight = new PWMSparkMax ( kRearRightChannel ); // Invert the right side motors. // You may need to change or remove this to match your robot. frontRight . setInverted ( true ); rearRight . setInverted ( true ); m_robotDrive = new MecanumDrive ( frontLeft :: set , rearLeft :: set , frontRight :: set , rearRight :: set ); } C++ private : static constexpr int kFrontLeftChannel = 0 ; static constexpr int kRearLeftChannel = 1 ; static constexpr int kFrontRightChannel = 2 ; static constexpr int kRearRightChannel = 3 ; frc :: PWMSparkMax m_frontLeft { kFrontLeftChannel }; frc :: PWMSparkMax m_rearLeft { kRearLeftChannel }; frc :: PWMSparkMax m_frontRight { kFrontRightChannel }; frc :: PWMSparkMax m_rearRight { kRearRightChannel }; frc :: MecanumDrive m_robotDrive { [ & ]( double output ) { m_frontLeft . Set ( output ); }, [ & ]( double output ) { m_rearLeft . Set ( output ); }, [ & ]( double output ) { m_frontRight . Set ( output ); }, [ & ]( double output ) { m_rearRight . Set ( output ); }}; void RobotInit () override { // Invert the right side motors. You may need to change or remove this to // match your robot. m_frontRight . SetInverted ( true ); m_rearRight . SetInverted ( true ); } PYTHON # Channels on the roboRIO that the motor controllers are plugged in to kFrontLeftChannel = 2 kRearLeftChannel = 3 kFrontRightChannel = 1 kRearRightChannel = 0 def robotInit ( self ): self . frontLeft = wpilib . PWMSparkMax ( self . kFrontLeftChannel ) self . rearLeft = wpilib . PWMSparkMax ( self . kRearLeftChannel ) self . frontRight = wpilib . PWMSparkMax ( self . kFrontRightChannel ) self . rearRight = wpilib . PWMSparkMax ( self . kRearRightChannel ) # invert the right side motors # you may need to change or remove this to match your robot self . frontRight . setInverted ( True ) self . rearRight . setInverted ( True ) self . robotDrive = wpilib . drive . MecanumDrive ( self . frontLeft , self . rearLeft , self . frontRight , self . rearRight ) self . stick = wpilib . Joystick ( self . kJoystickChannel ) Mecanum Drive Modes Note The drive axis conventions are different from common joystick axis conventions. See the Axis Conventions above for more information. The MecanumDrive class contains two different default modes of driving your robot’s motors. driveCartesian: Angles are measured clockwise from the positive X axis. The robot’s speed is independent from its angle or rotation rate. drivePolar: Angles are measured counter-clockwise from straight ahead. The speed at which the robot drives (translation) is independent from its angle or rotation rate. JAVA public void teleopPeriodic () { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . getY (), - m_stick . getX (), - m_stick . getZ ()); // Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. m_robotDrive . drivePolar ( - m_stick . getY (), Rotation2d . fromDegrees ( 45 ), 0 ); } C++ void TeleopPeriodic () override { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . GetY (), - m_stick . GetX (), - m_stick . GetZ ()); // Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. m_robotDrive . drivePolar ( - m_stick . GetY (), 45 _deg , 0 ); } PYTHON def teleopPeriodic ( self ): # Drive using the X, Y, and Z axes of the joystick. self . robotDrive . driveCartesian ( - self . stick . getY (), - self . stick . getX (), - self . stick . getZ ()) # Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. self . robotDrive . drivePolar ( - self . stick . getY (), Rotation2d . fromDegrees ( 45 ), 0 ) Field-Oriented Driving A 4th parameter can be supplied to the driveCartesian(double ySpeed, double xSpeed, double zRotation, double gyroAngle) method, the angle returned from a Gyro sensor. This will adjust the rotation value supplied. This is particularly useful with mecanum drive since, for the purposes of steering, the robot really has no front, back, or sides. It can go in any direction. Adding the angle in degrees from a gyro object will cause the robot to move away from the drivers when the joystick is pushed forwards, and towards the drivers when it is pulled towards them, regardless of what direction the robot is facing. The use of field-oriented driving makes often makes the robot much easier to drive, especially compared to a “robot-oriented” drive system where the controls are reversed when the robot is facing the drivers. Just remember to get the gyro angle each time driveCartesian() is called. Note Many teams also like to ramp the joysticks inputs over time to promote a smooth acceleration and reduce jerk. This can be accomplished with a Slew Rate Limiter .",
      "content_preview": "Using the WPILib Classes to Drive your Robot WPILib includes many classes to help make your robot get driving faster. Standard drivetrains Differential Drive Robots These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/wpi-drive-classes.html?present",
      "title": "Using the WPILib Classes to Drive your Robot",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Using the WPILib Classes to Drive your Robot WPILib includes many classes to help make your robot get driving faster. Standard drivetrains Differential Drive Robots These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as “skid-steer”, “tank drive”, or “West Coast Drive”. The Kit of Parts drivetrain is an example of a differential drive. These drivetrains are capable of driving forward/backward and can turn by driving the two sides in opposite directions causing the wheels to skid sideways. These drivetrains are not capable of sideways translational movement. Mecanum Drive Mecanum drive is a method of driving using specially designed wheels that allow the robot to drive in any direction without changing the orientation of the robot. A robot with a conventional drivetrain (all wheels pointing in the same direction) must turn in the direction it needs to drive. A mecanum robot can move in any direction without first turning and is called a holonomic drive. The wheels (shown on this robot) have rollers that cause the forces from driving to be applied at a 45 degree angle rather than straight forward as in the case of a conventional drive. When viewed from the top, the rollers on a mecanum drivetrain should form an ‘X’ pattern. This results in the force vectors (when driving the wheel forward) on the front two wheels pointing forward and inward and the rear two wheels pointing forward and outward. By spinning the wheels in different directions, various components of the force vectors cancel out, resulting in the desired robot movement. A quick chart of different movements has been provided below, drawing out the force vectors for each of these motions may help in understanding how these drivetrains work. By varying the speeds of the wheels in addition to the direction, movements can be combined resulting in translation in any direction and rotation, simultaneously. Drive Class Conventions Motor Inversion It is the responsibility of the user to manage proper inversions for their drivetrain. Users can invert motors by calling setInverted() / SetInverted() on their motor objects. Typically for differential drive trains, one side must be inverted to avoid spinning in circles, since the forward direction of each side of the tank drive is opposite of each other. JAVA PWMSparkMax m_motorRight = new PWMSparkMax ( 0 ); public Robot () { m_motorRight . setInverted ( true ); } C++ frc :: PWMSparkMax m_motorLeft { 0 }; public : Robot :: Robot () { m_motorRight . SetInverted ( true ); } PYTHON def robotInit ( self ): self . motorRight = wpilib . PWMSparkMax ( 0 ) self . motorRight . setInverted ( True ) Squaring Inputs When driving robots, it is often desirable to manipulate the joystick inputs such that the robot has finer control at low speeds while still using the full output range. One way to accomplish this is by squaring the joystick input, then reapplying the sign. By default the Differential Drive class will square the inputs. If this is not desired (e.g. if passing values in from a PIDController), use one of the drive methods with the squaredInputs parameter and set it to false. Input Deadband By default, the Differential Drive class applies an input deadband of 0.02. This means that input values with a magnitude below 0.02 (after any squaring as described above) will be set to 0. In most cases these small inputs result from imperfect joystick centering and are not sufficient to cause drivetrain movement, the deadband helps reduce unnecessary motor heating that may result from applying these small values to the drivetrain. To change the deadband, use the setDeadband() method. Maximum Output Sometimes drivers feel that their drivetrain is driving too fast and want to limit the output. This can be accomplished with the setMaxOutput() method. This maximum output is multiplied by result of the previous drive functions like deadband and squared inputs. Motor Safety Motor Safety is a mechanism in WPILib that takes the concept of a watchdog and breaks it out into one watchdog (Motor Safety timer) for each individual actuator. Note that this protection mechanism is in addition to the System Watchdog which is controlled by the Network Communications code and the FPGA and will disable all actuator outputs if it does not receive a valid data packet for 125ms. The purpose of the Motor Safety mechanism is the same as the purpose of a watchdog timer, to disable mechanisms which may cause harm to themselves, people, or property if the code locks up and does not properly update the actuator output. Motor Safety breaks this concept out on a per actuator basis so that you can appropriately determine where it is necessary and where it is not. Examples of mechanisms that should have motor safety enabled are systems like drive trains and arms. If these systems get latched on a particular value they could cause damage to their environment or themselves. An example of a mechanism that may not need motor safety is a spinning flywheel for a shooter. If this mechanism gets latched on a particular value it will simply continue spinning until the robot is disabled. By default Motor Safety is enabled for DifferentialDrive and MecanumDrive objects and disabled for all other motor controllers and servos. The Motor Safety feature operates by maintaining a timer that tracks how long it has been since the feed() method has been called for that actuator. Code in the Driver Station class initiates a comparison of these timers to the timeout values for any actuator with safety enabled every 5 received packets (100ms nominal). The set() methods of each motor controller class and the set() and setAngle() methods of the servo class call feed() to indicate that the output of the actuator has been updated. The Motor Safety interface of motor controllers can be interacted with by the user using the following methods: JAVA m_motorRight . setSafetyEnabled ( true ); m_motorRight . setSafetyEnabled ( false ); m_motorRight . setExpiration ( .1 ); m_motorRight . feed () C++ m_motorRight -> SetSafetyEnabled ( true ); m_motorRight -> SetSafetyEnabled ( false ); m_motorRight -> SetExpiration ( .1 ); m_motorRight -> Feed (); PYTHON m_motorRight . setSafetyEnabled ( True ) m_motorRight . setSafetyEnabled ( False ) m_motorRight . setExpiration ( .1 ) m_motorRight . feed () By default all Drive objects enable Motor Safety. Depending on the mechanism and the structure of your program, you may wish to configure the timeout length of the motor safety (in seconds). The timeout length is configured on a per actuator basis and is not a global setting. The default (and minimum useful) value is 100ms. Axis Conventions The drive classes use the NWU axes convention (North-West-Up as external reference in the world frame). The positive X axis points ahead, the positive Y axis points left, and the positive Z axis points up. We use NWU here because the rest of the library, and math in general, use NWU axes convention. Joysticks follow NED (North-East-Down) convention, where the positive X axis points ahead, the positive Y axis points right, and the positive Z axis points down. However, it’s important to note that axes values are rotations around the respective axes, not translations. When viewed with each axis pointing toward you, CCW is a positive value and CW is a negative value. Pushing forward on the joystick is a CW rotation around the Y axis, so you get a negative value. Pushing to the right is a CCW rotation around the X axis, so you get a positive value. Note See the Coordinate System section for more detail about the axis conventions and coordinate systems. Using the DifferentialDrive class to control Differential Drive robots Note WPILib provides separate Robot Drive classes for the most common drive train configurations (differential and mecanum). The DifferentialDrive class handles the differential drivetrain configuration. These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as “skid-steer”, “tank drive”, or “West Coast Drive” (WCD). The Kit of Parts drivetrain is an example of a differential drive. There are methods to control the drive with 3 different styles (“Tank”, “Arcade”, or “Curvature”), explained in the article below. DifferentialDrive is a method provided for the control of “skid-steer” or “West Coast” drivetrains, such as the Kit of Parts chassis. Instantiating a DifferentialDrive is as simple as so: Java public class Robot extends TimedRobot { private DifferentialDrive m_robotDrive ; private final PWMSparkMax m_leftMotor = new PWMSparkMax ( 0 ); private final PWMSparkMax m_rightMotor = new PWMSparkMax ( 1 ); @Override public void robotInit () { // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightMotor . setInverted ( true ); m_robotDrive = new DifferentialDrive ( m_leftMotor :: set , m_rightMotor :: set ); } C++ (Header) frc :: PWMSparkMax m_leftMotor { 0 }; frc :: PWMSparkMax m_rightMotor { 1 }; frc :: DifferentialDrive m_robotDrive { [ & ]( double output ) { m_leftMotor . Set ( output ); }, [ & ]( double output ) { m_rightMotor . Set ( output ); }}; C++ (Source) :sync: C++ (Source) void RobotInit () override { // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightMotor . SetInverted ( true ); } Python def robotInit ( self ): \"\"\"Robot initialization function\"\"\" leftMotor = wpilib . PWMSparkMax ( 0 ) rightMotor = wpilib . PWMSparkMax ( 1 ) self . robotDrive = wpilib . drive . DifferentialDrive ( leftMotor , rightMotor ) # We need to invert one side of the drivetrain so that positive voltages # result in both sides moving forward. Depending on how your robot's # gearbox is constructed, you might have to invert the left side instead. rightMotor . setInverted ( True ) Multi-Motor DifferentialDrive Many FRC® drivetrains have more than 1 motor on each side. Classes derived from PWMMotorController ( Java / C++ / Python ) have an addFollower method so that multiple follower motor controllers can be updated when the leader motor controller is commanded. CAN motor controllers have similar features, review the vendor’s documentation to see how to use them. The examples below show a 4 motor (2 per side) drivetrain. To extend to more motors, simply create the additional controllers and use additional addFollower calls. Java Class variables (e.g. in Robot.java or Subsystem): // The motors on the left side of the drive. private final PWMSparkMax m_leftLeader = new PWMSparkMax ( DriveConstants . kLeftMotor1Port ); private final PWMSparkMax m_leftFollower = new PWMSparkMax ( DriveConstants . kLeftMotor2Port ); // The motors on the right side of the drive. private final PWMSparkMax m_rightLeader = new PWMSparkMax ( DriveConstants . kRightMotor1Port ); private final PWMSparkMax m_rightFollower = new PWMSparkMax ( DriveConstants . kRightMotor2Port ); In Robot or Subsystem constructor: m_leftLeader . addFollower ( m_leftFollower ); m_rightLeader . addFollower ( m_rightFollower ); // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_rightLeader . setInverted ( true ); C++ (Header) private : // The motor controllers frc :: PWMSparkMax m_left1 ; frc :: PWMSparkMax m_left2 ; frc :: PWMSparkMax m_right1 ; frc :: PWMSparkMax m_right2 ; // The robot's drive frc :: DifferentialDrive m_drive {[ & ]( double output ) { m_left1 . Set ( output ); }, [ & ]( double output ) { m_right1 . Set ( output ); }}; C++ (Source) In Robot or Subsystem constructor: m_left1 . AddFollower ( m_left2 ); m_right1 . AddFollower ( m_right2 ); // We need to invert one side of the drivetrain so that positive voltages // result in both sides moving forward. Depending on how your robot's // gearbox is constructed, you might have to invert the left side instead. m_right1 . SetInverted ( true ); Python def robotInit ( self ): leftLeader = wpilib . Spark ( 1 ) leftFollower = wpilib . Spark ( 2 ) leftLeader . addFollower ( leftFollower ) leftLeader . setInverted ( True ) # if you want to invert the entire side you can do so here rightLeader = wpilib . Spark ( 3 ) rightFollower = wpilib . Spark ( 4 ) rightLeader . addFollower ( rightFollower ) self . drive = wpilib . drive . DifferentialDrive ( leftLeader , rightLeader ) Drive Modes Note The DifferentialDrive class contains three different default modes of driving your robot’s motors. Tank Drive, which controls the left and right side independently Arcade Drive, which controls a forward and turn speed Curvature Drive, a subset of Arcade Drive, which makes your robot handle like a car with constant-curvature turns. The DifferentialDrive class contains three default methods for controlling skid-steer or WCD robots. Note that you can create your own methods of controlling the robot’s driving and have them call tankDrive() with the derived inputs for left and right motors. The Tank Drive mode is used to control each side of the drivetrain independently (usually with an individual joystick axis controlling each). This example shows how to use the Y-axis of two separate joysticks to run the drivetrain in Tank mode. Construction of the objects has been omitted, for above for drivetrain construction and here for Joystick construction. The Arcade Drive mode is used to control the drivetrain using speed/throttle and rotation rate. This is typically used either with two axes from a single joystick, or split across joysticks (often on a single gamepad) with the throttle coming from one stick and the rotation from another. This example shows how to use a single joystick with the Arcade mode. Construction of the objects has been omitted, for above for drivetrain construction and here for Joystick construction. Like Arcade Drive, the Curvature Drive mode is used to control the drivetrain using speed/throttle and rotation rate. The difference is that the rotation control input controls the radius of curvature instead of rate of heading change, much like the steering wheel of a car. This mode also supports turning in place, which is enabled when the third boolean parameter is true. JAVA public void teleopPeriodic () { // Tank drive with a given left and right rates myDrive . tankDrive ( - leftStick . getY (), - rightStick . getY ()); // Arcade drive with a given forward and turn rate myDrive . arcadeDrive ( - driveStick . getY (), - driveStick . getX ()); // Curvature drive with a given forward and turn rate, as well as a button for turning in-place. myDrive . curvatureDrive ( - driveStick . getY (), - driveStick . getX (), driveStick . getButton ( 1 )); } C++ void TeleopPeriodic () override { // Tank drive with a given left and right rates myDrive . TankDrive ( - leftStick . GetY (), - rightStick . GetY ()); // Arcade drive with a given forward and turn rate myDrive . ArcadeDrive ( - driveStick . GetY (), - driveStick . GetX ()); // Curvature drive with a given forward and turn rate, as well as a quick-turn button myDrive . CurvatureDrive ( - driveStick . GetY (), - driveStick . GetX (), driveStick . GetButton ( 1 )); } PYTHON def teleopPeriodic ( self ): # Tank drive with a given left and right rates self . myDrive . tankDrive ( - self . leftStick . getY (), - self . rightStick . getY ()) # Arcade drive with a given forward and turn rate self . myDrive . arcadeDrive ( - self . driveStick . getY (), - self . driveStick . getX ()) # Curvature drive with a given forward and turn rate, as well as a button for turning in-place. self . myDrive . curvatureDrive ( - self . driveStick . getY (), - self . driveStick . getX (), self . driveStick . getButton ( 1 )) Using the MecanumDrive class to control Mecanum Drive robots MecanumDrive is a method provided for the control of holonomic drivetrains with Mecanum wheels, such as the Kit of Parts chassis with the mecanum drive upgrade kit, as shown above. Instantiating a MecanumDrive is as simple as so: JAVA private static final int kFrontLeftChannel = 2 ; private static final int kRearLeftChannel = 3 ; private static final int kFrontRightChannel = 1 ; private static final int kRearRightChannel = 0 ; @Override public void robotInit () { PWMSparkMax frontLeft = new PWMSparkMax ( kFrontLeftChannel ); PWMSparkMax rearLeft = new PWMSparkMax ( kRearLeftChannel ); PWMSparkMax frontRight = new PWMSparkMax ( kFrontRightChannel ); PWMSparkMax rearRight = new PWMSparkMax ( kRearRightChannel ); // Invert the right side motors. // You may need to change or remove this to match your robot. frontRight . setInverted ( true ); rearRight . setInverted ( true ); m_robotDrive = new MecanumDrive ( frontLeft :: set , rearLeft :: set , frontRight :: set , rearRight :: set ); } C++ private : static constexpr int kFrontLeftChannel = 0 ; static constexpr int kRearLeftChannel = 1 ; static constexpr int kFrontRightChannel = 2 ; static constexpr int kRearRightChannel = 3 ; frc :: PWMSparkMax m_frontLeft { kFrontLeftChannel }; frc :: PWMSparkMax m_rearLeft { kRearLeftChannel }; frc :: PWMSparkMax m_frontRight { kFrontRightChannel }; frc :: PWMSparkMax m_rearRight { kRearRightChannel }; frc :: MecanumDrive m_robotDrive { [ & ]( double output ) { m_frontLeft . Set ( output ); }, [ & ]( double output ) { m_rearLeft . Set ( output ); }, [ & ]( double output ) { m_frontRight . Set ( output ); }, [ & ]( double output ) { m_rearRight . Set ( output ); }}; void RobotInit () override { // Invert the right side motors. You may need to change or remove this to // match your robot. m_frontRight . SetInverted ( true ); m_rearRight . SetInverted ( true ); } PYTHON # Channels on the roboRIO that the motor controllers are plugged in to kFrontLeftChannel = 2 kRearLeftChannel = 3 kFrontRightChannel = 1 kRearRightChannel = 0 def robotInit ( self ): self . frontLeft = wpilib . PWMSparkMax ( self . kFrontLeftChannel ) self . rearLeft = wpilib . PWMSparkMax ( self . kRearLeftChannel ) self . frontRight = wpilib . PWMSparkMax ( self . kFrontRightChannel ) self . rearRight = wpilib . PWMSparkMax ( self . kRearRightChannel ) # invert the right side motors # you may need to change or remove this to match your robot self . frontRight . setInverted ( True ) self . rearRight . setInverted ( True ) self . robotDrive = wpilib . drive . MecanumDrive ( self . frontLeft , self . rearLeft , self . frontRight , self . rearRight ) self . stick = wpilib . Joystick ( self . kJoystickChannel ) Mecanum Drive Modes Note The drive axis conventions are different from common joystick axis conventions. See the Axis Conventions above for more information. The MecanumDrive class contains two different default modes of driving your robot’s motors. driveCartesian: Angles are measured clockwise from the positive X axis. The robot’s speed is independent from its angle or rotation rate. drivePolar: Angles are measured counter-clockwise from straight ahead. The speed at which the robot drives (translation) is independent from its angle or rotation rate. JAVA public void teleopPeriodic () { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . getY (), - m_stick . getX (), - m_stick . getZ ()); // Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. m_robotDrive . drivePolar ( - m_stick . getY (), Rotation2d . fromDegrees ( 45 ), 0 ); } C++ void TeleopPeriodic () override { // Drive using the X, Y, and Z axes of the joystick. m_robotDrive . driveCartesian ( - m_stick . GetY (), - m_stick . GetX (), - m_stick . GetZ ()); // Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. m_robotDrive . drivePolar ( - m_stick . GetY (), 45 _deg , 0 ); } PYTHON def teleopPeriodic ( self ): # Drive using the X, Y, and Z axes of the joystick. self . robotDrive . driveCartesian ( - self . stick . getY (), - self . stick . getX (), - self . stick . getZ ()) # Drive at 45 degrees relative to the robot, at the speed given by the Y axis of the joystick, with no rotation. self . robotDrive . drivePolar ( - self . stick . getY (), Rotation2d . fromDegrees ( 45 ), 0 ) Field-Oriented Driving A 4th parameter can be supplied to the driveCartesian(double ySpeed, double xSpeed, double zRotation, double gyroAngle) method, the angle returned from a Gyro sensor. This will adjust the rotation value supplied. This is particularly useful with mecanum drive since, for the purposes of steering, the robot really has no front, back, or sides. It can go in any direction. Adding the angle in degrees from a gyro object will cause the robot to move away from the drivers when the joystick is pushed forwards, and towards the drivers when it is pulled towards them, regardless of what direction the robot is facing. The use of field-oriented driving makes often makes the robot much easier to drive, especially compared to a “robot-oriented” drive system where the controls are reversed when the robot is facing the drivers. Just remember to get the gyro angle each time driveCartesian() is called. Note Many teams also like to ramp the joysticks inputs over time to promote a smooth acceleration and reduce jerk. This can be accomplished with a Slew Rate Limiter .",
      "content_preview": "Using the WPILib Classes to Drive your Robot WPILib includes many classes to help make your robot get driving faster. Standard drivetrains Differential Drive Robots These drive bases typically have two or more in-line traction or omni wheels per side (e.g., 6WD or 8WD) and may also be known as..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/servos.html",
      "title": "Repeatable Low Power Movement",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Repeatable Low Power Movement - Controlling Servos with WPILib Servo motors are a type of motor which integrates positional feedback into the motor in order to allow a single motor to perform repeatable, controllable movement, taking position as the input signal. WPILib provides the capability to control servos which match the common hobby input specification (Pulse Width Modulation (PWM) signal, 0.6 ms - 2.4 ms pulse width) Constructing a Servo object JAVA Servo exampleServo = new Servo ( 1 ); C++ frc :: Servo exampleServo { 1 }; PYTHON exampleServo = wpilib . Servo ( 1 ) A servo object is constructed by passing a channel. Setting Servo Values JAVA exampleServo . set ( .5 ); exampleServo . setAngle ( 75 ); C++ exampleServo . Set ( .5 ); exampleServo . SetAngle ( 75 ); PYTHON exampleServo . set ( .5 ) exampleServo . setAngle ( 75 ) There are two methods of setting servo values in WPILib: Scaled Value - Sets the servo position using a scaled 0 to 1.0 value. 0 corresponds to one extreme of the servo and 1.0 corresponds to the other Angle - Set the servo position by specifying the angle, in degrees from 0 to 180. This method will work for servos with the same range as the Hitec HS-322HD servo . Any values passed to this method outside the specified range will be coerced to the boundary.",
      "content_preview": "Repeatable Low Power Movement - Controlling Servos with WPILib Servo motors are a type of motor which integrates positional feedback into the motor in order to allow a single motor to perform repeatable, controllable movement, taking position as the input signal."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/motors/servos.html?present",
      "title": "Repeatable Low Power Movement",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Repeatable Low Power Movement - Controlling Servos with WPILib Servo motors are a type of motor which integrates positional feedback into the motor in order to allow a single motor to perform repeatable, controllable movement, taking position as the input signal. WPILib provides the capability to control servos which match the common hobby input specification (Pulse Width Modulation (PWM) signal, 0.6 ms - 2.4 ms pulse width) Constructing a Servo object JAVA Servo exampleServo = new Servo ( 1 ); C++ frc :: Servo exampleServo { 1 }; PYTHON exampleServo = wpilib . Servo ( 1 ) A servo object is constructed by passing a channel. Setting Servo Values JAVA exampleServo . set ( .5 ); exampleServo . setAngle ( 75 ); C++ exampleServo . Set ( .5 ); exampleServo . SetAngle ( 75 ); PYTHON exampleServo . set ( .5 ) exampleServo . setAngle ( 75 ) There are two methods of setting servo values in WPILib: Scaled Value - Sets the servo position using a scaled 0 to 1.0 value. 0 corresponds to one extreme of the servo and 1.0 corresponds to the other Angle - Set the servo position by specifying the angle, in degrees from 0 to 180. This method will work for servos with the same range as the Hitec HS-322HD servo . Any values passed to this method outside the specified range will be coerced to the boundary.",
      "content_preview": "Repeatable Low Power Movement - Controlling Servos with WPILib Servo motors are a type of motor which integrates positional feedback into the motor in order to allow a single motor to perform repeatable, controllable movement, taking position as the input signal."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/index.html?present",
      "title": "Hardware APIs",
      "section": "Hardware APIs",
      "language": "Java",
      "content": "Hardware APIs This section discusses the control of motors and pneumatics through motor controllers, solenoids, and pneumatics, and their interface with Java and C++ WPILib. Motors APIs Pneumatics APIs Sensors Miscellaneous Hardware APIs Motor Controllers A motor controller is responsible on your robot for making motors move. For brushed DC motors such as the CIM or 775, the motor controller regulates the voltage that the motor receives, much like a light bulb. For brushless motor controllers such as the Spark MAX, the controller regulates the power delivered to each “phase” of the motor. Note Another name for a motor controller is a speed controller. Hint One can make a quick, non-competition-legal motor controller by removing the motor from a cordless BRUSHED drill and attaching PowerPoles or equivalents to the motor’s leads. Make sure that the voltage supplied by the drill will not damage the motor, but note that the 775 is fine at up to 24 volts. Warning Connecting a BRUSHLESS motor controller straight to power, such as to a conventional brushed motor controller, will destroy the motor! FRC Legal Motor Controllers Motor controllers come in lots of shapes, sizes, and feature sets. This is the full list of FRC® Legal motor controllers as of 2025: DMC 60/DMC 60c Motor Controller (P/N: 410-334-1, 410-334-2) Jaguar Motor Controller (P/N: MDL-BDC, MDL-BDC24, and 217-3367) connected to PWM only Koors40 Motor Controller (P/N am-5600) Nidec Dynamo BLDC Motor with Controller to control integral actuator only (P/N 840205-000, am-3740) SD540 Motor Controller (P/N: SD540x1, SD540x2, SD540x4, SD540Bx1, SD540Bx2, SD540Bx4, SD540C) Spark Flex Motor Controller (P/N REV-11-2159, am-5276) Spark Motor Controller (P/N: REV-11-1200, am-4260) Spark MAX Motor Controller (P/N: REV-11-2158, am-4261) Talon FX Motor Controller (P/N 217-6515, 19-708850, am-6515, am-6515_Short, WCP-0940) for controlling integral Falcon 500 or Kraken X60 only, Talon FXS Motor Controller (P/N 24-708883, WCP-1692) Talon Motor Controller (P/N: CTRE_Talon, CTRE_Talon_SR, and am-2195) Talon SRX Motor Controller (P/N: 217-8080, am-2854, 14-838288) Thrifty Nova (P/N TTB-0100) Venom Motor with Controller (P/N BDC-10001) for controlling integral motor only​ Victor 884 Motor Controller (P/N: VICTOR-884-12/12) Victor 888 Motor Controller (P/N: 217-2769) Victor SP Motor Controller (P/N: 217-9090, am-2855, 14-868380) Victor SPX Motor Controller (P/N: 217-9191, 17-868388, am-3748) Pneumatics Pneumatics are a quick and easy way to make something that’s in one state or another using compressed air. For information on operating pneumatics, see Pneumatics APIs . FRC Legal Pneumatics controllers Pneumatics Control Module (P/N: am-2858, 217-4243) Pneumatic Hub (P/N REV-11-1852) Relays A relay controls power to a motor or custom electronics in an On/Off fashion. FRC Legal Relay Modules Spike H-Bridge Relay (P/N: 217-0220 and SPIKE-RELAY-H) Automation Direct Relay (P/N: AD-SSR6M12-DC200D, AD-SSR6M25-DC200D, AD-SSR6M40-DC200D) Power Distribution Hub (PDH) switched channel (P/N REV-11-1850)",
      "content_preview": "Hardware APIs This section discusses the control of motors and pneumatics through motor controllers, solenoids, and pneumatics, and their interface with Java and C++ WPILib."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/index.html",
      "title": "Pneumatics APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Pneumatics APIs Operating Pneumatic Cylinders Generating and Storing Pressure Using the FRC Control System to Control Pneumatics There are two options for operating solenoids to control pneumatic cylinders, the CTRE Pneumatics Control Module and the REV Robotics Pneumatics Hub. The CTRE Pneumatics Control Module (PCM) is a CAN-based device that provides control over the compressor and up to 8 solenoids per module. The REV Pneumatic Hub (PH) is a CAN-based device that provides control over the compressor and up to 16 solenoids per module. These devices are integrated into WPILib through a series of classes that make them simple to use. The closed loop control of the Compressor and Pressure switch is handled by the PCM hardware and the Solenoids are handled by the Solenoid class that controls the solenoid channels. These modules are responsible for regulating the robot’s pressure using a pressure switch and a compressor and switching solenoids on and off. They communicate with the roboRIO over CAN. For more information, see Hardware Component Overview . Module Numbers CAN Devices are identified by their CAN ID. The default CAN ID for PCMs is 0. The default CAN ID for PHs is 1. If using a single module on the bus it is recommended to leave it at the default CAN ID. Additional modules can be used where the modules corresponding solenoids are differentiated by the module number in the constructors of the Solenoid , DoubleSolenoid and Compressor classes.",
      "content_preview": "Pneumatics APIs Operating Pneumatic Cylinders Generating and Storing Pressure Using the FRC Control System to Control Pneumatics There are two options for operating solenoids to control pneumatic cylinders, the CTRE Pneumatics Control Module and the REV Robotics Pneumatics Hub."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/pressure.html",
      "title": "Generating and Storing Pressure",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Generating and Storing Pressure Pressure is created using a pneumatic compressor and stored in pneumatic tanks. The compressor must be on the robot and powered by the robot’s pneumatics module. The “Closed Loop” mode on the Compressor is enabled by default, and it is not recommended that teams change this setting. When closed loop control is enabled the pneumatic module will automatically turn the compressor on when the digital pressure switch is closed (below the pressure threshold) and turn it off when the pressure switch is open (~120PSI). When closed loop control is disabled the compressor will not be turned on. Using the Compressor ( Java / C++ ) class, users can query the status of the compressor. The state (currently on or off), pressure switch state, and compressor current can all be queried from the Compressor object, as shown by the following code from the Solenoid example project ( Java , C++ ): Note The Compressor object is only needed if you want the ability to turn off the compressor, change the pressure sensor (PH only), or query compressor status. Construct a Compressor object: REV Pneumatic Hub (PH) Java // Compressor connected to a PH with a default CAN ID (1) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . REVPH ); C++ (Header) // Compressor connected to a PH with a default CAN ID frc :: Compressor m_compressor { frc :: PneumaticsModuleType :: REVPH }; CTRE Pneumatics Control Module (PCM) Java // Compressor connected to a PCM with a default CAN ID (0) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . CTREPCM ); C++ (Header) // Compressor connected to a PH with a default CAN ID Querying compressor current and state: Java // Get compressor current draw. return m_compressor . getCurrent (); // Get whether the compressor is active. return m_compressor . isEnabled (); // Get the digital pressure switch connected to the PCM/PH. // The switch is open when the pressure is over ~120 PSI. return m_compressor . getPressureSwitchValue (); C++ (Source) // Get compressor current draw. units :: ampere_t compressorCurrent = m_compressor . GetCurrent (); return compressorCurrent . value (); // Get whether the compressor is active. return m_compressor . IsEnabled (); // Get the digital pressure switch connected to the PCM/PH. // The switch is open when the pressure is over ~120 PSI. return m_compressor . GetPressureSwitchValue (); Enable/disable digital closed-loop compressor control (enabled by default): Java // Disable closed-loop mode on the compressor. m_compressor . disable (); // Enable closed-loop mode based on the digital pressure switch connected to the // PCM/PH. // The switch is open when the pressure is over ~120 PSI. m_compressor . enableDigital (); C++ (Source) // Disable closed-loop mode on the compressor. m_compressor . Disable (); // Enable closed-loop mode based on the digital pressure switch // connected to the PCM/PH. The switch is open when the pressure is over // ~120 PSI. m_compressor . EnableDigital (); The Pneumatic Hub also has methods for enabling compressor control using the REV Analog Pressure Sensor: Java // Enable closed-loop mode based on the analog pressure sensor connected to the PH. // The compressor will run while the pressure reported by the sensor is in the // specified range ([70 PSI, 120 PSI] in this example). // Analog mode exists only on the PH! On the PCM, this enables digital control. m_compressor . enableAnalog ( 70 , 120 ); // Enable closed-loop mode based on both the digital pressure switch AND the analog // pressure sensor connected to the PH. // The compressor will run while the pressure reported by the analog sensor is in the // specified range ([70 PSI, 120 PSI] in this example) AND the digital switch reports // that the system is not full. // Hybrid mode exists only on the PH! On the PCM, this enables digital control. m_compressor . enableHybrid ( 70 , 120 ); C++ (Source) // Enable closed-loop mode based on the analog pressure sensor connected // to the PH. The compressor will run while the pressure reported by the // sensor is in the specified range ([70 PSI, 120 PSI] in this example). // Analog mode exists only on the PH! On the PCM, this enables digital // control. m_compressor . EnableAnalog ( 70 _psi , 120 _psi ); // Enable closed-loop mode based on both the digital pressure switch AND the analog // pressure sensor connected to the PH. // The compressor will run while the pressure reported by the analog sensor is in the // specified range ([70 PSI, 120 PSI] in this example) AND the digital switch reports // that the system is not full. // Hybrid mode exists only on the PH! On the PCM, this enables digital control. m_compressor . EnableHybrid ( 70 _psi , 120 _psi ); Pressure Transducers A pressure transducer is a sensor where analog voltage is proportial to the measured pressure. Pneumatic Hub The Pneumatic Hub has analog inputs that may be used to read a pressure transducer using the Compressor class. Java // Compressor connected to a PH with a default CAN ID (1) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . REVPH ); // Get the pressure (in PSI) from the analog sensor connected to the PH. // This function is supported only on the PH! // On a PCM, this function will return 0. return m_compressor . getPressure (); C++ (Header) // Compressor connected to a PH with a default CAN ID frc :: Compressor m_compressor { frc :: PneumaticsModuleType :: REVPH }; C++ (Source) // Get the pressure (in PSI) from the analog sensor connected to the PH. // This function is supported only on the PH! // On a PCM, this function will return 0. units :: pounds_per_square_inch_t pressure = m_compressor . GetPressure (); return pressure . value (); roboRIO A pressure transducer can be connected to the Analog Input ports on the roboRIO, and can be read by the AnalogInput or AnalogPotentiometer classes in WPILib. Java // External analog pressure sensor // product-specific voltage->pressure conversion, see product manual // in this case, 250(V/5)-25 // the scale parameter in the AnalogPotentiometer constructor is scaled from 1 instead of 5, // so if r is the raw AnalogPotentiometer output, the pressure is 250r-25 static final double kScale = 250 ; static final double kOffset = - 25 ; private final AnalogPotentiometer m_pressureTransducer = new AnalogPotentiometer ( /* the AnalogIn port*/ 2 , kScale , kOffset ); // Get the pressure (in PSI) from an analog pressure sensor connected to the RIO. return m_pressureTransducer . get (); C++ (Header) // External analog pressure sensor // product-specific voltage->pressure conversion, see product manual // in this case, 250(V/5)-25 // the scale parameter in the AnalogPotentiometer constructor is scaled from // 1 instead of 5, so if r is the raw AnalogPotentiometer output, the // pressure is 250r-25 static constexpr double kScale = 250 ; static constexpr double kOffset = -25 ; frc :: AnalogPotentiometer m_pressureTransducer { /* the AnalogIn port*/ 2 , kScale , kOffset }; C++ (Source) // Get the pressure (in PSI) from an analog pressure sensor connected to // the RIO. return units :: pounds_per_square_inch_t { m_pressureTransducer . Get ()};",
      "content_preview": "Generating and Storing Pressure Pressure is created using a pneumatic compressor and stored in pneumatic tanks. The compressor must be on the robot and powered by the robot’s pneumatics module."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/pressure.html?present",
      "title": "Generating and Storing Pressure",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Generating and Storing Pressure Pressure is created using a pneumatic compressor and stored in pneumatic tanks. The compressor must be on the robot and powered by the robot’s pneumatics module. The “Closed Loop” mode on the Compressor is enabled by default, and it is not recommended that teams change this setting. When closed loop control is enabled the pneumatic module will automatically turn the compressor on when the digital pressure switch is closed (below the pressure threshold) and turn it off when the pressure switch is open (~120PSI). When closed loop control is disabled the compressor will not be turned on. Using the Compressor ( Java / C++ ) class, users can query the status of the compressor. The state (currently on or off), pressure switch state, and compressor current can all be queried from the Compressor object, as shown by the following code from the Solenoid example project ( Java , C++ ): Note The Compressor object is only needed if you want the ability to turn off the compressor, change the pressure sensor (PH only), or query compressor status. Construct a Compressor object: REV Pneumatic Hub (PH) Java // Compressor connected to a PH with a default CAN ID (1) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . REVPH ); C++ (Header) // Compressor connected to a PH with a default CAN ID frc :: Compressor m_compressor { frc :: PneumaticsModuleType :: REVPH }; CTRE Pneumatics Control Module (PCM) Java // Compressor connected to a PCM with a default CAN ID (0) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . CTREPCM ); C++ (Header) // Compressor connected to a PH with a default CAN ID Querying compressor current and state: Java // Get compressor current draw. return m_compressor . getCurrent (); // Get whether the compressor is active. return m_compressor . isEnabled (); // Get the digital pressure switch connected to the PCM/PH. // The switch is open when the pressure is over ~120 PSI. return m_compressor . getPressureSwitchValue (); C++ (Source) // Get compressor current draw. units :: ampere_t compressorCurrent = m_compressor . GetCurrent (); return compressorCurrent . value (); // Get whether the compressor is active. return m_compressor . IsEnabled (); // Get the digital pressure switch connected to the PCM/PH. // The switch is open when the pressure is over ~120 PSI. return m_compressor . GetPressureSwitchValue (); Enable/disable digital closed-loop compressor control (enabled by default): Java // Disable closed-loop mode on the compressor. m_compressor . disable (); // Enable closed-loop mode based on the digital pressure switch connected to the // PCM/PH. // The switch is open when the pressure is over ~120 PSI. m_compressor . enableDigital (); C++ (Source) // Disable closed-loop mode on the compressor. m_compressor . Disable (); // Enable closed-loop mode based on the digital pressure switch // connected to the PCM/PH. The switch is open when the pressure is over // ~120 PSI. m_compressor . EnableDigital (); The Pneumatic Hub also has methods for enabling compressor control using the REV Analog Pressure Sensor: Java // Enable closed-loop mode based on the analog pressure sensor connected to the PH. // The compressor will run while the pressure reported by the sensor is in the // specified range ([70 PSI, 120 PSI] in this example). // Analog mode exists only on the PH! On the PCM, this enables digital control. m_compressor . enableAnalog ( 70 , 120 ); // Enable closed-loop mode based on both the digital pressure switch AND the analog // pressure sensor connected to the PH. // The compressor will run while the pressure reported by the analog sensor is in the // specified range ([70 PSI, 120 PSI] in this example) AND the digital switch reports // that the system is not full. // Hybrid mode exists only on the PH! On the PCM, this enables digital control. m_compressor . enableHybrid ( 70 , 120 ); C++ (Source) // Enable closed-loop mode based on the analog pressure sensor connected // to the PH. The compressor will run while the pressure reported by the // sensor is in the specified range ([70 PSI, 120 PSI] in this example). // Analog mode exists only on the PH! On the PCM, this enables digital // control. m_compressor . EnableAnalog ( 70 _psi , 120 _psi ); // Enable closed-loop mode based on both the digital pressure switch AND the analog // pressure sensor connected to the PH. // The compressor will run while the pressure reported by the analog sensor is in the // specified range ([70 PSI, 120 PSI] in this example) AND the digital switch reports // that the system is not full. // Hybrid mode exists only on the PH! On the PCM, this enables digital control. m_compressor . EnableHybrid ( 70 _psi , 120 _psi ); Pressure Transducers A pressure transducer is a sensor where analog voltage is proportial to the measured pressure. Pneumatic Hub The Pneumatic Hub has analog inputs that may be used to read a pressure transducer using the Compressor class. Java // Compressor connected to a PH with a default CAN ID (1) private final Compressor m_compressor = new Compressor ( PneumaticsModuleType . REVPH ); // Get the pressure (in PSI) from the analog sensor connected to the PH. // This function is supported only on the PH! // On a PCM, this function will return 0. return m_compressor . getPressure (); C++ (Header) // Compressor connected to a PH with a default CAN ID frc :: Compressor m_compressor { frc :: PneumaticsModuleType :: REVPH }; C++ (Source) // Get the pressure (in PSI) from the analog sensor connected to the PH. // This function is supported only on the PH! // On a PCM, this function will return 0. units :: pounds_per_square_inch_t pressure = m_compressor . GetPressure (); return pressure . value (); roboRIO A pressure transducer can be connected to the Analog Input ports on the roboRIO, and can be read by the AnalogInput or AnalogPotentiometer classes in WPILib. Java // External analog pressure sensor // product-specific voltage->pressure conversion, see product manual // in this case, 250(V/5)-25 // the scale parameter in the AnalogPotentiometer constructor is scaled from 1 instead of 5, // so if r is the raw AnalogPotentiometer output, the pressure is 250r-25 static final double kScale = 250 ; static final double kOffset = - 25 ; private final AnalogPotentiometer m_pressureTransducer = new AnalogPotentiometer ( /* the AnalogIn port*/ 2 , kScale , kOffset ); // Get the pressure (in PSI) from an analog pressure sensor connected to the RIO. return m_pressureTransducer . get (); C++ (Header) // External analog pressure sensor // product-specific voltage->pressure conversion, see product manual // in this case, 250(V/5)-25 // the scale parameter in the AnalogPotentiometer constructor is scaled from // 1 instead of 5, so if r is the raw AnalogPotentiometer output, the // pressure is 250r-25 static constexpr double kScale = 250 ; static constexpr double kOffset = -25 ; frc :: AnalogPotentiometer m_pressureTransducer { /* the AnalogIn port*/ 2 , kScale , kOffset }; C++ (Source) // Get the pressure (in PSI) from an analog pressure sensor connected to // the RIO. return units :: pounds_per_square_inch_t { m_pressureTransducer . Get ()};",
      "content_preview": "Generating and Storing Pressure Pressure is created using a pneumatic compressor and stored in pneumatic tanks. The compressor must be on the robot and powered by the robot’s pneumatics module."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/solenoids.html",
      "title": "Operating Pneumatic Cylinders",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Operating Pneumatic Cylinders FRC teams can use a solenoid valve as part of performing a variety of tasks, including shifting gearboxes and moving robot mechanisms. A solenoid valve is used to electronically switch a pressurized air line “on” or “off”. Solenoids are controlled by a robot’s Pneumatics Control Module, or Pneumatic Hub, which is in turn connected to the robot’s roboRIO via CAN . The easiest way to see a solenoid’s state is via the LEDs on the PCM or PH (which indicates if the valve is “on” or not). When un-powered, solenoids can be manually actuated with the small button on the valve body. Single acting solenoids apply or vent pressure from a single output port. They are typically used either when an external force will provide the return action of the cylinder (spring, gravity, separate mechanism) or in pairs to act as a double solenoid. A double solenoid switches air flow between two output ports (many also have a center position where neither output is vented or connected to the input). Double solenoid valves are commonly used when you wish to control both the extend and retract actions of a cylinder using air pressure. Double solenoid valves have two electrical inputs which connect back to two separate channels on the solenoid breakout. Single Solenoids in WPILib Single solenoids in WPILib are controlled using the Solenoid class ( Java / C++ ). To construct a Solenoid object, simply pass the desired port number (assumes default CAN ID) and pneumatics module type or CAN ID, pneumatics module type, and port number to the constructor. To set the value of the solenoid call set(true) to enable or set(false) to disable the solenoid output. Java 30 // Solenoid corresponds to a single solenoid. 31 // In this case, it's connected to channel 0 of a PH with the default CAN ID. 32 private final Solenoid m_solenoid = new Solenoid ( PneumaticsModuleType . REVPH , 0 ); 72 /* 73 * The output of GetRawButton is true/false depending on whether 74 * the button is pressed; Set takes a boolean for whether 75 * to retract the solenoid (false) or extend it (true). 76 */ 77 m_solenoid . set ( m_stick . getRawButton ( kSolenoidButton )); C++ (Header) 44 // Solenoid corresponds to a single solenoid. 45 // In this case, it's connected to channel 0 of a PH with the default CAN 46 // ID. 47 frc :: Solenoid m_solenoid { frc :: PneumaticsModuleType :: REVPH , 0 }; C++ (Source) 42 /* 43 * The output of GetRawButton is true/false depending on whether 44 * the button is pressed; Set takes a boolean for whether 45 * to retract the solenoid (false) or extend it (true). 46 */ 47 m_solenoid . Set ( m_stick . GetRawButton ( kSolenoidButton )); Double Solenoids in WPILib Double solenoids are controlled by the DoubleSolenoid class in WPILib ( Java / C++ ). These are constructed similarly to the single solenoid but there are now two port numbers to pass to the constructor, a forward channel (first) and a reverse channel (second). The state of the valve can then be set to kOff (neither output activated), kForward (forward channel enabled) or kReverse (reverse channel enabled). Additionally, the CAN ID can be passed to the DoubleSolenoid if teams have a non-default CAN ID. Java 34 // DoubleSolenoid corresponds to a double solenoid. 35 // In this case, it's connected to channels 1 and 2 of a PH with the default CAN ID. 36 private final DoubleSolenoid m_doubleSolenoid = 37 new DoubleSolenoid ( PneumaticsModuleType . REVPH , 1 , 2 ); 84 m_doubleSolenoid . set ( DoubleSolenoid . Value . kForward ); 85 m_doubleSolenoid . set ( DoubleSolenoid . Value . kReverse ); C++ (Header) 49 // DoubleSolenoid corresponds to a double solenoid. 50 // In this case, it's connected to channels 1 and 2 of a PH with the default 51 // CAN ID. 52 frc :: DoubleSolenoid m_doubleSolenoid { frc :: PneumaticsModuleType :: REVPH , 1 , 2 }; C++ (Source) 54 m_doubleSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); 55 m_doubleSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); Toggling Solenoids Solenoids can be switched from one output to the other (known as toggling) by using the .toggle() method. Note Since a DoubleSolenoid defaults to off, you will have to set it before it can be toggled. JAVA Solenoid exampleSingle = new Solenoid ( PneumaticsModuleType . CTREPCM , 0 ); DoubleSolenoid exampleDouble = new DoubleSolenoid ( PneumaticsModuleType . CTREPCM , 1 , 2 ); // Initialize the DoubleSolenoid so it knows where to start. Not required for single solenoids. exampleDouble . set ( kReverse ); if ( m_controller . getYButtonPressed ()) { exampleSingle . toggle (); exampleDouble . toggle (); } C++ frc :: Solenoid exampleSingle { frc :: PneumaticsModuleType :: CTREPCM , 0 }; frc :: DoubleSolenoid exampleDouble { frc :: PneumaticsModuleType :: CTREPCM , 1 , 2 }; // Initialize the DoubleSolenoid so it knows where to start. Not required for single solenoids. exampleDouble . Set ( frc :: DoubleSolenoid :: Value :: kReverse ); if ( m_controller . GetYButtonPressed ()) { exampleSingle . Toggle (); exampleDouble . Toggle (); }",
      "content_preview": "Operating Pneumatic Cylinders FRC teams can use a solenoid valve as part of performing a variety of tasks, including shifting gearboxes and moving robot mechanisms. A solenoid valve is used to electronically switch a pressurized air line “on” or “off”."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/solenoids.html?present",
      "title": "Operating Pneumatic Cylinders",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Operating Pneumatic Cylinders FRC teams can use a solenoid valve as part of performing a variety of tasks, including shifting gearboxes and moving robot mechanisms. A solenoid valve is used to electronically switch a pressurized air line “on” or “off”. Solenoids are controlled by a robot’s Pneumatics Control Module, or Pneumatic Hub, which is in turn connected to the robot’s roboRIO via CAN . The easiest way to see a solenoid’s state is via the LEDs on the PCM or PH (which indicates if the valve is “on” or not). When un-powered, solenoids can be manually actuated with the small button on the valve body. Single acting solenoids apply or vent pressure from a single output port. They are typically used either when an external force will provide the return action of the cylinder (spring, gravity, separate mechanism) or in pairs to act as a double solenoid. A double solenoid switches air flow between two output ports (many also have a center position where neither output is vented or connected to the input). Double solenoid valves are commonly used when you wish to control both the extend and retract actions of a cylinder using air pressure. Double solenoid valves have two electrical inputs which connect back to two separate channels on the solenoid breakout. Single Solenoids in WPILib Single solenoids in WPILib are controlled using the Solenoid class ( Java / C++ ). To construct a Solenoid object, simply pass the desired port number (assumes default CAN ID) and pneumatics module type or CAN ID, pneumatics module type, and port number to the constructor. To set the value of the solenoid call set(true) to enable or set(false) to disable the solenoid output. Java 30 // Solenoid corresponds to a single solenoid. 31 // In this case, it's connected to channel 0 of a PH with the default CAN ID. 32 private final Solenoid m_solenoid = new Solenoid ( PneumaticsModuleType . REVPH , 0 ); 72 /* 73 * The output of GetRawButton is true/false depending on whether 74 * the button is pressed; Set takes a boolean for whether 75 * to retract the solenoid (false) or extend it (true). 76 */ 77 m_solenoid . set ( m_stick . getRawButton ( kSolenoidButton )); C++ (Header) 44 // Solenoid corresponds to a single solenoid. 45 // In this case, it's connected to channel 0 of a PH with the default CAN 46 // ID. 47 frc :: Solenoid m_solenoid { frc :: PneumaticsModuleType :: REVPH , 0 }; C++ (Source) 42 /* 43 * The output of GetRawButton is true/false depending on whether 44 * the button is pressed; Set takes a boolean for whether 45 * to retract the solenoid (false) or extend it (true). 46 */ 47 m_solenoid . Set ( m_stick . GetRawButton ( kSolenoidButton )); Double Solenoids in WPILib Double solenoids are controlled by the DoubleSolenoid class in WPILib ( Java / C++ ). These are constructed similarly to the single solenoid but there are now two port numbers to pass to the constructor, a forward channel (first) and a reverse channel (second). The state of the valve can then be set to kOff (neither output activated), kForward (forward channel enabled) or kReverse (reverse channel enabled). Additionally, the CAN ID can be passed to the DoubleSolenoid if teams have a non-default CAN ID. Java 34 // DoubleSolenoid corresponds to a double solenoid. 35 // In this case, it's connected to channels 1 and 2 of a PH with the default CAN ID. 36 private final DoubleSolenoid m_doubleSolenoid = 37 new DoubleSolenoid ( PneumaticsModuleType . REVPH , 1 , 2 ); 84 m_doubleSolenoid . set ( DoubleSolenoid . Value . kForward ); 85 m_doubleSolenoid . set ( DoubleSolenoid . Value . kReverse ); C++ (Header) 49 // DoubleSolenoid corresponds to a double solenoid. 50 // In this case, it's connected to channels 1 and 2 of a PH with the default 51 // CAN ID. 52 frc :: DoubleSolenoid m_doubleSolenoid { frc :: PneumaticsModuleType :: REVPH , 1 , 2 }; C++ (Source) 54 m_doubleSolenoid . Set ( frc :: DoubleSolenoid :: kForward ); 55 m_doubleSolenoid . Set ( frc :: DoubleSolenoid :: kReverse ); Toggling Solenoids Solenoids can be switched from one output to the other (known as toggling) by using the .toggle() method. Note Since a DoubleSolenoid defaults to off, you will have to set it before it can be toggled. JAVA Solenoid exampleSingle = new Solenoid ( PneumaticsModuleType . CTREPCM , 0 ); DoubleSolenoid exampleDouble = new DoubleSolenoid ( PneumaticsModuleType . CTREPCM , 1 , 2 ); // Initialize the DoubleSolenoid so it knows where to start. Not required for single solenoids. exampleDouble . set ( kReverse ); if ( m_controller . getYButtonPressed ()) { exampleSingle . toggle (); exampleDouble . toggle (); } C++ frc :: Solenoid exampleSingle { frc :: PneumaticsModuleType :: CTREPCM , 0 }; frc :: DoubleSolenoid exampleDouble { frc :: PneumaticsModuleType :: CTREPCM , 1 , 2 }; // Initialize the DoubleSolenoid so it knows where to start. Not required for single solenoids. exampleDouble . Set ( frc :: DoubleSolenoid :: Value :: kReverse ); if ( m_controller . GetYButtonPressed ()) { exampleSingle . Toggle (); exampleDouble . Toggle (); }",
      "content_preview": "Operating Pneumatic Cylinders FRC teams can use a solenoid valve as part of performing a variety of tasks, including shifting gearboxes and moving robot mechanisms. A solenoid valve is used to electronically switch a pressurized air line “on” or “off”."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/hardware-apis/pneumatics/index.html?present",
      "title": "Pneumatics APIs",
      "section": "Hardware APIs",
      "language": "All",
      "content": "Pneumatics APIs Operating Pneumatic Cylinders Generating and Storing Pressure Using the FRC Control System to Control Pneumatics There are two options for operating solenoids to control pneumatic cylinders, the CTRE Pneumatics Control Module and the REV Robotics Pneumatics Hub. The CTRE Pneumatics Control Module (PCM) is a CAN-based device that provides control over the compressor and up to 8 solenoids per module. The REV Pneumatic Hub (PH) is a CAN-based device that provides control over the compressor and up to 16 solenoids per module. These devices are integrated into WPILib through a series of classes that make them simple to use. The closed loop control of the Compressor and Pressure switch is handled by the PCM hardware and the Solenoids are handled by the Solenoid class that controls the solenoid channels. These modules are responsible for regulating the robot’s pressure using a pressure switch and a compressor and switching solenoids on and off. They communicate with the roboRIO over CAN. For more information, see Hardware Component Overview . Module Numbers CAN Devices are identified by their CAN ID. The default CAN ID for PCMs is 0. The default CAN ID for PHs is 1. If using a single module on the bus it is recommended to leave it at the default CAN ID. Additional modules can be used where the modules corresponding solenoids are differentiated by the module number in the constructors of the Solenoid , DoubleSolenoid and Compressor classes.",
      "content_preview": "Pneumatics APIs Operating Pneumatic Cylinders Generating and Storing Pressure Using the FRC Control System to Control Pneumatics There are two options for operating solenoids to control pneumatic cylinders, the CTRE Pneumatics Control Module and the REV Robotics Pneumatics Hub."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/index.html",
      "title": "Kinematics and Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Kinematics and Odometry Introduction to Kinematics and The ChassisSpeeds Class Differential Drive Kinematics Differential Drive Odometry Swerve Drive Kinematics Swerve Drive Odometry Mecanum Drive Kinematics Mecanum Drive Odometry",
      "content_preview": "Kinematics and Odometry Introduction to Kinematics and The ChassisSpeeds Class Differential Drive Kinematics Differential Drive Odometry Swerve Drive Kinematics Swerve Drive Odometry Mecanum Drive Kinematics Mecanum Drive Odometry"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/index.html?present",
      "title": "Kinematics and Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Kinematics and Odometry Introduction to Kinematics and The ChassisSpeeds Class Differential Drive Kinematics Differential Drive Odometry Swerve Drive Kinematics Swerve Drive Odometry Mecanum Drive Kinematics Mecanum Drive Odometry",
      "content_preview": "Kinematics and Odometry Introduction to Kinematics and The ChassisSpeeds Class Differential Drive Kinematics Differential Drive Odometry Swerve Drive Kinematics Swerve Drive Odometry Mecanum Drive Kinematics Mecanum Drive Odometry"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/differential-drive-kinematics.html",
      "title": "Differential Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Differential Drive Kinematics The DifferentialDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a DifferentialDriveWheelSpeeds object, which contains velocities for the left and right sides of a differential drive robot. Constructing the Kinematics Object The DifferentialDriveKinematics object accepts one constructor argument, which is the track width of the robot. This represents the distance between the two sets of wheels on a differential drive. Note In Java and Python, the track width must be in meters. In C++, the units library can be used to pass in the track width using any length unit. Converting Chassis Speeds to Wheel Speeds The toWheelSpeeds(ChassisSpeeds speeds) (Java / Python) / ToWheelSpeeds(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a DifferentialDriveWheelSpeeds object. This is useful in situations where you have to convert a linear velocity ( vx ) and an angular velocity ( omega ) to left and right wheel velocities. JAVA // Creating my kinematics object: track width of 27 inches DifferentialDriveKinematics kinematics = new DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )); // Example chassis speeds: 2 meters per second linear velocity, // 1 radian per second angular velocity. var chassisSpeeds = new ChassisSpeeds ( 2.0 , 0 , 1.0 ); // Convert to wheel speeds DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( chassisSpeeds ); // Left velocity double leftVelocity = wheelSpeeds . leftMetersPerSecond ; // Right velocity double rightVelocity = wheelSpeeds . rightMetersPerSecond ; C++ // Creating my kinematics object: track width of 27 inches frc :: DifferentialDriveKinematics kinematics { 27 _in }; // Example chassis speeds: 2 meters per second linear velocity, // 1 radian per second angular velocity. frc :: ChassisSpeeds chassisSpeeds { 2 _mps , 0 _mps , 1 _rad_per_s }; // Convert to wheel speeds. Here, we can use C++17's structured bindings // feature to automatically split the DifferentialDriveWheelSpeeds // struct into left and right velocities. auto [ left , right ] = kinematics . ToWheelSpeeds ( chassisSpeeds ); PYTHON from wpimath.kinematics import DifferentialDriveKinematics from wpimath.kinematics import ChassisSpeeds from wpimath.units import inchesToMeters # Creating my kinematics object: track width of 27 inches kinematics = DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )) # Example chassis speeds: 2 meters per second linear velocity, # 1 radian per second angular velocity. chassisSpeeds = ChassisSpeeds ( 2.0 , 0 , 1.0 ) # Convert to wheel speeds wheelSpeeds = kinematics . toWheelSpeeds ( chassisSpeeds ) # Left velocity leftVelocity = wheelSpeeds . left # Right velocity rightVelocity = wheelSpeeds . right Converting Wheel Speeds to Chassis Speeds One can also use the kinematics object to convert individual wheel speeds (left and right) to a singular ChassisSpeeds object. The toChassisSpeeds(DifferentialDriveWheelSpeeds speeds) (Java / Python) / ToChassisSpeeds(DifferentialDriveWheelSpeeds speeds) (C++) method should be used to achieve this. JAVA // Creating my kinematics object: track width of 27 inches DifferentialDriveKinematics kinematics = new DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )); // Example differential drive wheel speeds: 2 meters per second // for the left side, 3 meters per second for the right side. var wheelSpeeds = new DifferentialDriveWheelSpeeds ( 2.0 , 3.0 ); // Convert to chassis speeds. ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ); // Linear velocity double linearVelocity = chassisSpeeds . vxMetersPerSecond ; // Angular velocity double angularVelocity = chassisSpeeds . omegaRadiansPerSecond ; C++ // Creating my kinematics object: track width of 27 inches frc :: DifferentialDriveKinematics kinematics { 27 _in }; // Example differential drive wheel speeds: 2 meters per second // for the left side, 3 meters per second for the right side. frc :: DifferentialDriveWheelSpeeds wheelSpeeds { 2 _mps , 3 _mps }; // Convert to chassis speeds. Here we can use C++17's structured bindings // feature to automatically split the ChassisSpeeds struct into its 3 components. // Note that because a differential drive is non-holonomic, the vy variable // will be equal to zero. auto [ linearVelocity , vy , angularVelocity ] = kinematics . ToChassisSpeeds ( wheelSpeeds ); PYTHON from wpimath.kinematics import DifferentialDriveKinematics from wpimath.kinematics import DifferentialDriveWheelSpeeds from wpimath.units import inchesToMeters # Creating my kinematics object: track width of 27 inches kinematics = DifferentialDriveKinematics ( inchesToMeters ( 27.0 )) # Example differential drive wheel speeds: 2 meters per second # for the left side, 3 meters per second for the right side. wheelSpeeds = DifferentialDriveWheelSpeeds ( 2.0 , 3.0 ) # Convert to chassis speeds. chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ) # Linear velocity linearVelocity = chassisSpeeds . vx # Angular velocity angularVelocity = chassisSpeeds . omega",
      "content_preview": "Differential Drive Kinematics The DifferentialDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a DifferentialDriveWheelSpeeds object, which contains velocities for the left and right sides of a differential drive robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/differential-drive-kinematics.html?present",
      "title": "Differential Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Differential Drive Kinematics The DifferentialDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a DifferentialDriveWheelSpeeds object, which contains velocities for the left and right sides of a differential drive robot. Constructing the Kinematics Object The DifferentialDriveKinematics object accepts one constructor argument, which is the track width of the robot. This represents the distance between the two sets of wheels on a differential drive. Note In Java and Python, the track width must be in meters. In C++, the units library can be used to pass in the track width using any length unit. Converting Chassis Speeds to Wheel Speeds The toWheelSpeeds(ChassisSpeeds speeds) (Java / Python) / ToWheelSpeeds(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a DifferentialDriveWheelSpeeds object. This is useful in situations where you have to convert a linear velocity ( vx ) and an angular velocity ( omega ) to left and right wheel velocities. JAVA // Creating my kinematics object: track width of 27 inches DifferentialDriveKinematics kinematics = new DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )); // Example chassis speeds: 2 meters per second linear velocity, // 1 radian per second angular velocity. var chassisSpeeds = new ChassisSpeeds ( 2.0 , 0 , 1.0 ); // Convert to wheel speeds DifferentialDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( chassisSpeeds ); // Left velocity double leftVelocity = wheelSpeeds . leftMetersPerSecond ; // Right velocity double rightVelocity = wheelSpeeds . rightMetersPerSecond ; C++ // Creating my kinematics object: track width of 27 inches frc :: DifferentialDriveKinematics kinematics { 27 _in }; // Example chassis speeds: 2 meters per second linear velocity, // 1 radian per second angular velocity. frc :: ChassisSpeeds chassisSpeeds { 2 _mps , 0 _mps , 1 _rad_per_s }; // Convert to wheel speeds. Here, we can use C++17's structured bindings // feature to automatically split the DifferentialDriveWheelSpeeds // struct into left and right velocities. auto [ left , right ] = kinematics . ToWheelSpeeds ( chassisSpeeds ); PYTHON from wpimath.kinematics import DifferentialDriveKinematics from wpimath.kinematics import ChassisSpeeds from wpimath.units import inchesToMeters # Creating my kinematics object: track width of 27 inches kinematics = DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )) # Example chassis speeds: 2 meters per second linear velocity, # 1 radian per second angular velocity. chassisSpeeds = ChassisSpeeds ( 2.0 , 0 , 1.0 ) # Convert to wheel speeds wheelSpeeds = kinematics . toWheelSpeeds ( chassisSpeeds ) # Left velocity leftVelocity = wheelSpeeds . left # Right velocity rightVelocity = wheelSpeeds . right Converting Wheel Speeds to Chassis Speeds One can also use the kinematics object to convert individual wheel speeds (left and right) to a singular ChassisSpeeds object. The toChassisSpeeds(DifferentialDriveWheelSpeeds speeds) (Java / Python) / ToChassisSpeeds(DifferentialDriveWheelSpeeds speeds) (C++) method should be used to achieve this. JAVA // Creating my kinematics object: track width of 27 inches DifferentialDriveKinematics kinematics = new DifferentialDriveKinematics ( Units . inchesToMeters ( 27.0 )); // Example differential drive wheel speeds: 2 meters per second // for the left side, 3 meters per second for the right side. var wheelSpeeds = new DifferentialDriveWheelSpeeds ( 2.0 , 3.0 ); // Convert to chassis speeds. ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ); // Linear velocity double linearVelocity = chassisSpeeds . vxMetersPerSecond ; // Angular velocity double angularVelocity = chassisSpeeds . omegaRadiansPerSecond ; C++ // Creating my kinematics object: track width of 27 inches frc :: DifferentialDriveKinematics kinematics { 27 _in }; // Example differential drive wheel speeds: 2 meters per second // for the left side, 3 meters per second for the right side. frc :: DifferentialDriveWheelSpeeds wheelSpeeds { 2 _mps , 3 _mps }; // Convert to chassis speeds. Here we can use C++17's structured bindings // feature to automatically split the ChassisSpeeds struct into its 3 components. // Note that because a differential drive is non-holonomic, the vy variable // will be equal to zero. auto [ linearVelocity , vy , angularVelocity ] = kinematics . ToChassisSpeeds ( wheelSpeeds ); PYTHON from wpimath.kinematics import DifferentialDriveKinematics from wpimath.kinematics import DifferentialDriveWheelSpeeds from wpimath.units import inchesToMeters # Creating my kinematics object: track width of 27 inches kinematics = DifferentialDriveKinematics ( inchesToMeters ( 27.0 )) # Example differential drive wheel speeds: 2 meters per second # for the left side, 3 meters per second for the right side. wheelSpeeds = DifferentialDriveWheelSpeeds ( 2.0 , 3.0 ) # Convert to chassis speeds. chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ) # Linear velocity linearVelocity = chassisSpeeds . vx # Angular velocity angularVelocity = chassisSpeeds . omega",
      "content_preview": "Differential Drive Kinematics The DifferentialDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a DifferentialDriveWheelSpeeds object, which contains velocities for the left and right sides of a differential drive robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/intro-and-chassis-speeds.html",
      "title": "Introduction to Kinematics and The ChassisSpeeds Class",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Introduction to Kinematics and The ChassisSpeeds Class Note Kinematics and odometry uses a common coordinate system. You may wish to reference the Coordinate System section for details. What is kinematics? The kinematics suite contains classes for differential drive, swerve drive, and mecanum drive kinematics and odometry. The kinematics classes help convert between a universal ChassisSpeeds ( Java , C++ , Python )object, containing linear and angular velocities for a robot to usable speeds for each individual type of drivetrain i.e. left and right wheel speeds for a differential drive, four wheel speeds for a mecanum drive, or individual module states (speed and angle) for a swerve drive. What is odometry? Odometry involves using sensors on the robot to create an estimate of the position of the robot on the field. In FRC, these sensors are typically several encoders (the exact number depends on the drive type) and a gyroscope to measure robot angle. The odometry classes utilize the kinematics classes along with periodic user inputs about speeds (and angles in the case of swerve) to create an estimate of the robot’s location on the field. The ChassisSpeeds Class The ChassisSpeeds object is essential to the new WPILib kinematics and odometry suite. The ChassisSpeeds object represents the speeds of a robot chassis. This struct has three components: vx : The velocity of the robot in the x (forward) direction. vy : The velocity of the robot in the y (sideways) direction. (Positive values mean the robot is moving to the left). omega : The angular velocity of the robot in radians per second. Note A non-holonomic drivetrain (i.e. a drivetrain that cannot move sideways, ex: a differential drive) will have a vy component of zero because of its inability to move sideways. Constructing a ChassisSpeeds object The constructor for the ChassisSpeeds object is very straightforward, accepting three arguments for vx , vy , and omega . In Java and Python, vx and vy must be in meters per second. In C++, the units library may be used to provide a linear velocity using any linear velocity unit. JAVA // The robot is moving at 3 meters per second forward, 2 meters // per second to the right, and rotating at half a rotation per // second counterclockwise. var speeds = new ChassisSpeeds ( 3.0 , - 2.0 , Math . PI ); C++ // The robot is moving at 3 meters per second forward, 2 meters // per second to the right, and rotating at half a rotation per // second counterclockwise. frc :: ChassisSpeeds speeds { 3.0 _mps , -2.0 _mps , units :: radians_per_second_t ( std :: numbers :: pi )}; PYTHON import math from wpimath.kinematics import ChassisSpeeds # The robot is moving at 3 meters per second forward, 2 meters # per second to the right, and rotating at half a rotation per # second counterclockwise. speeds = ChassisSpeeds ( 3.0 , - 2.0 , math . pi ) Creating a ChassisSpeeds Object from Field-Relative Speeds A ChassisSpeeds object can also be created from a set of field-relative speeds when the robot angle is given. This converts a set of desired velocities relative to the field (for example, toward the opposite alliance station and toward the right field boundary) to a ChassisSpeeds object which represents speeds that are relative to the robot frame. This is useful for implementing field-oriented controls for a swerve or mecanum drive robot. The static ChassisSpeeds.fromFieldRelativeSpeeds (Java / Python) / ChassisSpeeds::FromFieldRelativeSpeeds (C++) method can be used to generate the ChassisSpeeds object from field-relative speeds. This method accepts the vx (relative to the field), vy (relative to the field), omega , and the robot angle. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); PYTHON import math from wpimath.kinematics import ChassisSpeeds from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) Note The angular velocity is not explicitly stated to be “relative to the field” because the angular velocity is the same as measured from a field perspective or a robot perspective.",
      "content_preview": "Introduction to Kinematics and The ChassisSpeeds Class Note Kinematics and odometry uses a common coordinate system. You may wish to reference the Coordinate System section for details."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/intro-and-chassis-speeds.html?present",
      "title": "Introduction to Kinematics and The ChassisSpeeds Class",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Introduction to Kinematics and The ChassisSpeeds Class Note Kinematics and odometry uses a common coordinate system. You may wish to reference the Coordinate System section for details. What is kinematics? The kinematics suite contains classes for differential drive, swerve drive, and mecanum drive kinematics and odometry. The kinematics classes help convert between a universal ChassisSpeeds ( Java , C++ , Python )object, containing linear and angular velocities for a robot to usable speeds for each individual type of drivetrain i.e. left and right wheel speeds for a differential drive, four wheel speeds for a mecanum drive, or individual module states (speed and angle) for a swerve drive. What is odometry? Odometry involves using sensors on the robot to create an estimate of the position of the robot on the field. In FRC, these sensors are typically several encoders (the exact number depends on the drive type) and a gyroscope to measure robot angle. The odometry classes utilize the kinematics classes along with periodic user inputs about speeds (and angles in the case of swerve) to create an estimate of the robot’s location on the field. The ChassisSpeeds Class The ChassisSpeeds object is essential to the new WPILib kinematics and odometry suite. The ChassisSpeeds object represents the speeds of a robot chassis. This struct has three components: vx : The velocity of the robot in the x (forward) direction. vy : The velocity of the robot in the y (sideways) direction. (Positive values mean the robot is moving to the left). omega : The angular velocity of the robot in radians per second. Note A non-holonomic drivetrain (i.e. a drivetrain that cannot move sideways, ex: a differential drive) will have a vy component of zero because of its inability to move sideways. Constructing a ChassisSpeeds object The constructor for the ChassisSpeeds object is very straightforward, accepting three arguments for vx , vy , and omega . In Java and Python, vx and vy must be in meters per second. In C++, the units library may be used to provide a linear velocity using any linear velocity unit. JAVA // The robot is moving at 3 meters per second forward, 2 meters // per second to the right, and rotating at half a rotation per // second counterclockwise. var speeds = new ChassisSpeeds ( 3.0 , - 2.0 , Math . PI ); C++ // The robot is moving at 3 meters per second forward, 2 meters // per second to the right, and rotating at half a rotation per // second counterclockwise. frc :: ChassisSpeeds speeds { 3.0 _mps , -2.0 _mps , units :: radians_per_second_t ( std :: numbers :: pi )}; PYTHON import math from wpimath.kinematics import ChassisSpeeds # The robot is moving at 3 meters per second forward, 2 meters # per second to the right, and rotating at half a rotation per # second counterclockwise. speeds = ChassisSpeeds ( 3.0 , - 2.0 , math . pi ) Creating a ChassisSpeeds Object from Field-Relative Speeds A ChassisSpeeds object can also be created from a set of field-relative speeds when the robot angle is given. This converts a set of desired velocities relative to the field (for example, toward the opposite alliance station and toward the right field boundary) to a ChassisSpeeds object which represents speeds that are relative to the robot frame. This is useful for implementing field-oriented controls for a swerve or mecanum drive robot. The static ChassisSpeeds.fromFieldRelativeSpeeds (Java / Python) / ChassisSpeeds::FromFieldRelativeSpeeds (C++) method can be used to generate the ChassisSpeeds object from field-relative speeds. This method accepts the vx (relative to the field), vy (relative to the field), omega , and the robot angle. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); PYTHON import math from wpimath.kinematics import ChassisSpeeds from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) Note The angular velocity is not explicitly stated to be “relative to the field” because the angular velocity is the same as measured from a field perspective or a robot perspective.",
      "content_preview": "Introduction to Kinematics and The ChassisSpeeds Class Note Kinematics and odometry uses a common coordinate system. You may wish to reference the Coordinate System section for details."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/differential-drive-odometry.html",
      "title": "Differential Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Differential Drive Odometry A user can use the differential drive kinematics classes in order to perform odometry . WPILib contains a DifferentialDriveOdometry class that can be used to track the position of a differential drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the Odometry Object The DifferentialDriveOdometry class constructor requires three mandatory arguments and one optional argument. The mandatory arguments are: The angle reported by your gyroscope (as a Rotation2d ) The initial left and right encoder readings. In Java / Python, these are a number that represents the distance traveled by each side in meters. In C++, the units library must be used to represent your wheel positions. The optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Creating my odometry object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. DifferentialDriveOdometry m_odometry = new DifferentialDriveOdometry ( m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance (), new Pose2d ( 5.0 , 13.5 , new Rotation2d ())); C++ // Creating my odometry object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: DifferentialDriveOdometry m_odometry { m_gyro . GetRotation2d (), units :: meter_t { m_leftEncoder . GetDistance ()}, units :: meter_t { m_rightEncoder . GetDistance ()}, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON from wpimath.kinematics import DifferentialDriveOdometry from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d # Creating my odometry object. Here, # our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing forward. m_odometry = DifferentialDriveOdometry ( m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance (), Pose2d ( 5.0 , 13.5 , Rotation2d ())) Updating the Robot Pose The update method can be used to update the robot’s position on the field. This method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. This method takes in the gyro angle of the robot, along with the left encoder distance and right encoder distance. Note If the robot is moving forward in a straight line, both distances (left and right) must be increasing positively – the rate of change must be positive. JAVA @Override public void periodic () { // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); } C++ void Periodic () override { // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , units :: meter_t { m_leftEncoder . GetDistance ()}, units :: meter_t { m_rightEncoder . GetDistance ()}); } PYTHON def periodic ( self ): # Get the rotation of the robot from the gyro. gyroAngle = m_gyro . getRotation2d () # Update the pose m_pose = m_odometry . update ( gyroAngle , m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts four arguments: the current gyro angle, the left and right wheel positions, and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or encoders, the resetPosition method MUST be called with the new gyro angle and wheel distances. Note A full example of a differential drive robot with odometry is available here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Differential Drive Odometry A user can use the differential drive kinematics classes in order to perform odometry . WPILib contains a DifferentialDriveOdometry class that can be used to track the position of a differential drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/differential-drive-odometry.html?present",
      "title": "Differential Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Differential Drive Odometry A user can use the differential drive kinematics classes in order to perform odometry . WPILib contains a DifferentialDriveOdometry class that can be used to track the position of a differential drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the Odometry Object The DifferentialDriveOdometry class constructor requires three mandatory arguments and one optional argument. The mandatory arguments are: The angle reported by your gyroscope (as a Rotation2d ) The initial left and right encoder readings. In Java / Python, these are a number that represents the distance traveled by each side in meters. In C++, the units library must be used to represent your wheel positions. The optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Creating my odometry object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. DifferentialDriveOdometry m_odometry = new DifferentialDriveOdometry ( m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance (), new Pose2d ( 5.0 , 13.5 , new Rotation2d ())); C++ // Creating my odometry object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: DifferentialDriveOdometry m_odometry { m_gyro . GetRotation2d (), units :: meter_t { m_leftEncoder . GetDistance ()}, units :: meter_t { m_rightEncoder . GetDistance ()}, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON from wpimath.kinematics import DifferentialDriveOdometry from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d # Creating my odometry object. Here, # our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing forward. m_odometry = DifferentialDriveOdometry ( m_gyro . getRotation2d (), m_leftEncoder . getDistance (), m_rightEncoder . getDistance (), Pose2d ( 5.0 , 13.5 , Rotation2d ())) Updating the Robot Pose The update method can be used to update the robot’s position on the field. This method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. This method takes in the gyro angle of the robot, along with the left encoder distance and right encoder distance. Note If the robot is moving forward in a straight line, both distances (left and right) must be increasing positively – the rate of change must be positive. JAVA @Override public void periodic () { // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()); } C++ void Periodic () override { // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , units :: meter_t { m_leftEncoder . GetDistance ()}, units :: meter_t { m_rightEncoder . GetDistance ()}); } PYTHON def periodic ( self ): # Get the rotation of the robot from the gyro. gyroAngle = m_gyro . getRotation2d () # Update the pose m_pose = m_odometry . update ( gyroAngle , m_leftEncoder . getDistance (), m_rightEncoder . getDistance ()) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts four arguments: the current gyro angle, the left and right wheel positions, and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or encoders, the resetPosition method MUST be called with the new gyro angle and wheel distances. Note A full example of a differential drive robot with odometry is available here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Differential Drive Odometry A user can use the differential drive kinematics classes in order to perform odometry . WPILib contains a DifferentialDriveOdometry class that can be used to track the position of a differential drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/swerve-drive-kinematics.html",
      "title": "Swerve Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Swerve Drive Kinematics The SwerveDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and several SwerveModuleState objects, which contains velocities and angles for each swerve module of a swerve drive robot. Note Swerve drive kinematics uses a common coordinate system. You may wish to reference the Coordinate System section for details. The swerve module state class The SwerveModuleState class contains information about the velocity and angle of a singular module of a swerve drive. The constructor for a SwerveModuleState takes in two arguments, the velocity of the wheel on the module, and the angle of the module. Note In Java / Python, the velocity of the wheel must be in meters per second. In C++, the units library can be used to provide the velocity using any linear velocity unit. Note An angle of 0 corresponds to the modules facing forward. Constructing the kinematics object The SwerveDriveKinematics class accepts a variable number of constructor arguments, with each argument being the location of a swerve module relative to the robot center (as a Translation2d . The number of constructor arguments corresponds to the number of swerve modules. Note A swerve drive must have 2 or more modules. Note In C++, the class is templated on the number of modules. Therefore, when constructing a SwerveDriveKinematics object as a member variable of a class, the number of modules must be passed in as a template argument. For example, for a typical swerve drive with four modules, the kinematics object must be constructed as follows: frc::SwerveDriveKinematics<4> m_kinematics{...} . The locations for the modules must be relative to the center of the robot. Positive x values represent moving toward the front of the robot whereas positive y values represent moving toward the left of the robot. JAVA // Locations for the swerve drive modules relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the module locations SwerveDriveKinematics m_kinematics = new SwerveDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); C++ // Locations for the swerve drive modules relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the module locations. frc :: SwerveDriveKinematics < 4 > m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; PYTHON # Python requires using the right class for the number of modules you have from wpimath.geometry import Translation2d from wpimath.kinematics import SwerveDrive4Kinematics # Locations for the swerve drive modules relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the module locations self . kinematics = SwerveDrive4Kinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) Converting chassis speeds to module states The toSwerveModuleStates(ChassisSpeeds speeds) (Java / Python) / ToSwerveModuleStates(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a an array of SwerveModuleState objects. This is useful in situations where you have to convert a forward velocity, sideways velocity, and an angular velocity into individual module states. The elements in the array that is returned by this method are the same order in which the kinematics object was constructed. For example, if the kinematics object was constructed with the front left module location, front right module location, back left module location, and the back right module location in that order, the elements in the array would be the front left module state, front right module state, back left module state, and back right module state in that order. JAVA // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. ChassisSpeeds speeds = new ChassisSpeeds ( 1.0 , 3.0 , 1.5 ); // Convert to module states SwerveModuleState [] moduleStates = kinematics . toSwerveModuleStates ( speeds ); // Front left module state SwerveModuleState frontLeft = moduleStates [ 0 ] ; // Front right module state SwerveModuleState frontRight = moduleStates [ 1 ] ; // Back left module state SwerveModuleState backLeft = moduleStates [ 2 ] ; // Back right module state SwerveModuleState backRight = moduleStates [ 3 ] ; C++ // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. frc :: ChassisSpeeds speeds { 1 _mps , 3 _mps , 1.5 _rad_per_s }; // Convert to module states. Here, we can use C++17's structured // bindings feature to automatically split up the array into its // individual SwerveModuleState components. auto [ fl , fr , bl , br ] = kinematics . ToSwerveModuleStates ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds # Example chassis speeds: 1 meter per second forward, 3 meters # per second to the left, and rotation at 1.5 radians per second # counterclockwise. speeds = ChassisSpeeds ( 1.0 , 3.0 , 1.5 ) # Convert to module states frontLeft , frontRight , backLeft , backRight = self . kinematics . toSwerveModuleStates ( speeds ) Module angle optimization The SwerveModuleState class contains a static optimize() (Java) / Optimize() (C++) method that is used to “optimize” the speed and angle setpoint of a given SwerveModuleState to minimize the change in heading. For example, if the angular setpoint of a certain module from inverse kinematics is 90 degrees, but your current angle is -89 degrees, this method will automatically negate the speed of the module setpoint and make the angular setpoint -90 degrees to reduce the distance the module has to travel. This method takes two parameters: the desired state (usually from the toSwerveModuleStates method) and the current angle. It will return the new optimized state which you can use as the setpoint in your feedback control loop. JAVA var frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , new Rotation2d ( m_turningEncoder . getDistance ())); C++ auto flOptimized = frc :: SwerveModuleState :: Optimize ( fl , units :: radian_t ( m_turningEncoder . GetDistance ())); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , Rotation2d ( self . m_turningEncoder . getDistance ())) Cosine compensation Cosine compensation is a technique that reduces the speed of a module when it is not pointing in the desired direction. This is done by multiplying the desired speed of the module by the cosine of the angle error. If the wheel is pointing straight in the desired direction, then the speed remains unchanged as \\(\\cos(0^\\circ) = 1\\) . If the wheel is perpendicular to the desired direction of motion, then the speed is reduced to 0 as \\(\\cos(90^\\circ) = 0\\) . Everything in between follows the cosine curve. Cosine compensation has been shown to reduce the amount of “skew” a swerve drive experiences when changing direction. JAVA var currentAngle = new Rotation2d . fromRadians ( m_turningEncoder . getDistance ()); var frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , currentAngle ); frontLeftOptimized . speedMetersPerSecond *= frontLeftOptimized . angle . minus ( currentAngle ). getCos (); C++ Rotation2d currentAngle ( m_turningEncoder . GetDistance ()); auto flOptimized = frc :: SwerveModuleState :: Optimize ( fl , currentAngle ); flOptimized . speed *= ( flOptimized . angle - currentAngle ). Cos (); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d currentAngle = Rotation2d ( self . m_turningEncoder . getDistance ()) frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , currentAngle ) frontLeftOptimized . speed *= ( frontLeftOptimized . angle - currentAngle ) . cos () Field-oriented drive Recall that a ChassisSpeeds object can be created from a set of desired field-oriented speeds. This feature can be used to get module states from a set of desired field-oriented speeds. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); // Now use this in our kinematics SwerveModuleState [] moduleStates = kinematics . toSwerveModuleStates ( speeds ); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); // Now use this in our kinematics auto [ fl , fr , bl , br ] = kinematics . ToSwerveModuleStates ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds import math from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) # Now use this in our kinematics self . moduleStates = self . kinematics . toSwerveModuleStates ( speeds ) Using custom centers of rotation Sometimes, rotating around one specific corner might be desirable for certain evasive maneuvers. This type of behavior is also supported by the WPILib classes. The same ToSwerveModuleStates() method accepts a second parameter for the center of rotation (as a Translation2d ). Just like the wheel locations, the Translation2d representing the center of rotation should be relative to the robot center. Note Because all robots are a rigid frame, the provided vx and vy velocities from the ChassisSpeeds object will still apply for the entirety of the robot. However, the omega from the ChassisSpeeds object will be measured from the center of rotation. For example, one can set the center of rotation on a certain module and if the provided ChassisSpeeds object has a vx and vy of zero and a non-zero omega , the robot will appear to rotate around that particular swerve module. Converting module states to chassis speeds One can also use the kinematics object to convert an array of SwerveModuleState objects to a singular ChassisSpeeds object. The toChassisSpeeds(SwerveModuleState... states) (Java / Python) / ToChassisSpeeds(SwerveModuleState... states) (C++) method can be used to achieve this. JAVA // Example module states var frontLeftState = new SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 140.19 )); var frontRightState = new SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 39.81 )); var backLeftState = new SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 109.44 )); var backRightState = new SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 70.56 )); // Convert to chassis speeds ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ); // Getting individual speeds double forward = chassisSpeeds . vxMetersPerSecond ; double sideways = chassisSpeeds . vyMetersPerSecond ; double angular = chassisSpeeds . omegaRadiansPerSecond ; C++ // Example module States frc :: SwerveModuleState frontLeftState { 23.43 _mps , Rotation2d ( -140.19 _deg )}; frc :: SwerveModuleState frontRightState { 23.43 _mps , Rotation2d ( -39.81 _deg )}; frc :: SwerveModuleState backLeftState { 54.08 _mps , Rotation2d ( -109.44 _deg )}; frc :: SwerveModuleState backRightState { 54.08 _mps , Rotation2d ( -70.56 _deg )}; // Convert to chassis speeds. Here, we can use C++17's structured bindings // feature to automatically break up the ChassisSpeeds struct into its // three components. auto [ forward , sideways , angular ] = kinematics . ToChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d # Example module states frontLeftState = SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 140.19 )) frontRightState = SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 39.81 )) backLeftState = SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 109.44 )) backRightState = SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 70.56 )) # Convert to chassis speeds chassisSpeeds = self . kinematics . toChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ) # Getting individual speeds forward = chassisSpeeds . vx sideways = chassisSpeeds . vy angular = chassisSpeeds . omega Module state visualization with AdvantageScope By recording a set of swerve module states using NetworkTables or WPILib data logs , AdvantageScope can be used to visualize the state of a swerve drive. The code below shows how a set of SwerveModuleState objects can be published to NetworkTables. JAVA public class Example { private final StructArrayPublisher < SwerveModuleState > publisher ; public Example () { // Start publishing an array of module states with the \"/SwerveStates\" key publisher = NetworkTableInstance . getDefault () . getStructArrayTopic ( \"/SwerveStates\" , SwerveModuleState . struct ). publish (); } public void periodic () { // Periodically send a set of module states publisher . set ( new SwerveModuleState [] { frontLeftState , frontRightState , backLeftState , backRightState }); } } C++ class Example { nt :: StructArrayPublisher < frc :: SwerveModuleState > publisher public : Example () { // Start publishing an array of module states with the \"/SwerveStates\" key publisher = nt :: NetworkTableInstance :: GetDefault () . GetStructArrayTopic < frc :: SwerveModuleState > ( \"/SwerveStates\" ). Publish (); } void Periodic () { // Periodically send a set of module states swervePublisher . Set ( std :: vector { frontLeftState , frontRightState , backLeftState , backRightState } ); } }; PYTHON import ntcore from wpimath.kinematics import SwerveModuleState # get the default instance of NetworkTables nt = ntcore . NetworkTableInstance . getDefault () # Start publishing an array of module states with the \"/SwerveStates\" key topic = nt . getStructArrayTopic ( \"/SwerveStates\" , SwerveModuleState ) self . pub = topic . publish () def periodic ( self ): # Periodically send a set of module states self . pub . set ([ frontLeftState , frontRightState , backLeftState , backRightState ]) See the documentation for the swerve tab for more details on visualizing this data using AdvantageScope.",
      "content_preview": "Swerve Drive Kinematics The SwerveDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and several SwerveModuleState objects, which contains velocities and angles for each swerve module of a swerve drive robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/swerve-drive-kinematics.html?present",
      "title": "Swerve Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Swerve Drive Kinematics The SwerveDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and several SwerveModuleState objects, which contains velocities and angles for each swerve module of a swerve drive robot. Note Swerve drive kinematics uses a common coordinate system. You may wish to reference the Coordinate System section for details. The swerve module state class The SwerveModuleState class contains information about the velocity and angle of a singular module of a swerve drive. The constructor for a SwerveModuleState takes in two arguments, the velocity of the wheel on the module, and the angle of the module. Note In Java / Python, the velocity of the wheel must be in meters per second. In C++, the units library can be used to provide the velocity using any linear velocity unit. Note An angle of 0 corresponds to the modules facing forward. Constructing the kinematics object The SwerveDriveKinematics class accepts a variable number of constructor arguments, with each argument being the location of a swerve module relative to the robot center (as a Translation2d . The number of constructor arguments corresponds to the number of swerve modules. Note A swerve drive must have 2 or more modules. Note In C++, the class is templated on the number of modules. Therefore, when constructing a SwerveDriveKinematics object as a member variable of a class, the number of modules must be passed in as a template argument. For example, for a typical swerve drive with four modules, the kinematics object must be constructed as follows: frc::SwerveDriveKinematics<4> m_kinematics{...} . The locations for the modules must be relative to the center of the robot. Positive x values represent moving toward the front of the robot whereas positive y values represent moving toward the left of the robot. JAVA // Locations for the swerve drive modules relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the module locations SwerveDriveKinematics m_kinematics = new SwerveDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); C++ // Locations for the swerve drive modules relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the module locations. frc :: SwerveDriveKinematics < 4 > m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; PYTHON # Python requires using the right class for the number of modules you have from wpimath.geometry import Translation2d from wpimath.kinematics import SwerveDrive4Kinematics # Locations for the swerve drive modules relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the module locations self . kinematics = SwerveDrive4Kinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) Converting chassis speeds to module states The toSwerveModuleStates(ChassisSpeeds speeds) (Java / Python) / ToSwerveModuleStates(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a an array of SwerveModuleState objects. This is useful in situations where you have to convert a forward velocity, sideways velocity, and an angular velocity into individual module states. The elements in the array that is returned by this method are the same order in which the kinematics object was constructed. For example, if the kinematics object was constructed with the front left module location, front right module location, back left module location, and the back right module location in that order, the elements in the array would be the front left module state, front right module state, back left module state, and back right module state in that order. JAVA // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. ChassisSpeeds speeds = new ChassisSpeeds ( 1.0 , 3.0 , 1.5 ); // Convert to module states SwerveModuleState [] moduleStates = kinematics . toSwerveModuleStates ( speeds ); // Front left module state SwerveModuleState frontLeft = moduleStates [ 0 ] ; // Front right module state SwerveModuleState frontRight = moduleStates [ 1 ] ; // Back left module state SwerveModuleState backLeft = moduleStates [ 2 ] ; // Back right module state SwerveModuleState backRight = moduleStates [ 3 ] ; C++ // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. frc :: ChassisSpeeds speeds { 1 _mps , 3 _mps , 1.5 _rad_per_s }; // Convert to module states. Here, we can use C++17's structured // bindings feature to automatically split up the array into its // individual SwerveModuleState components. auto [ fl , fr , bl , br ] = kinematics . ToSwerveModuleStates ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds # Example chassis speeds: 1 meter per second forward, 3 meters # per second to the left, and rotation at 1.5 radians per second # counterclockwise. speeds = ChassisSpeeds ( 1.0 , 3.0 , 1.5 ) # Convert to module states frontLeft , frontRight , backLeft , backRight = self . kinematics . toSwerveModuleStates ( speeds ) Module angle optimization The SwerveModuleState class contains a static optimize() (Java) / Optimize() (C++) method that is used to “optimize” the speed and angle setpoint of a given SwerveModuleState to minimize the change in heading. For example, if the angular setpoint of a certain module from inverse kinematics is 90 degrees, but your current angle is -89 degrees, this method will automatically negate the speed of the module setpoint and make the angular setpoint -90 degrees to reduce the distance the module has to travel. This method takes two parameters: the desired state (usually from the toSwerveModuleStates method) and the current angle. It will return the new optimized state which you can use as the setpoint in your feedback control loop. JAVA var frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , new Rotation2d ( m_turningEncoder . getDistance ())); C++ auto flOptimized = frc :: SwerveModuleState :: Optimize ( fl , units :: radian_t ( m_turningEncoder . GetDistance ())); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , Rotation2d ( self . m_turningEncoder . getDistance ())) Cosine compensation Cosine compensation is a technique that reduces the speed of a module when it is not pointing in the desired direction. This is done by multiplying the desired speed of the module by the cosine of the angle error. If the wheel is pointing straight in the desired direction, then the speed remains unchanged as \\(\\cos(0^\\circ) = 1\\) . If the wheel is perpendicular to the desired direction of motion, then the speed is reduced to 0 as \\(\\cos(90^\\circ) = 0\\) . Everything in between follows the cosine curve. Cosine compensation has been shown to reduce the amount of “skew” a swerve drive experiences when changing direction. JAVA var currentAngle = new Rotation2d . fromRadians ( m_turningEncoder . getDistance ()); var frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , currentAngle ); frontLeftOptimized . speedMetersPerSecond *= frontLeftOptimized . angle . minus ( currentAngle ). getCos (); C++ Rotation2d currentAngle ( m_turningEncoder . GetDistance ()); auto flOptimized = frc :: SwerveModuleState :: Optimize ( fl , currentAngle ); flOptimized . speed *= ( flOptimized . angle - currentAngle ). Cos (); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d currentAngle = Rotation2d ( self . m_turningEncoder . getDistance ()) frontLeftOptimized = SwerveModuleState . optimize ( frontLeft , currentAngle ) frontLeftOptimized . speed *= ( frontLeftOptimized . angle - currentAngle ) . cos () Field-oriented drive Recall that a ChassisSpeeds object can be created from a set of desired field-oriented speeds. This feature can be used to get module states from a set of desired field-oriented speeds. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); // Now use this in our kinematics SwerveModuleState [] moduleStates = kinematics . toSwerveModuleStates ( speeds ); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); // Now use this in our kinematics auto [ fl , fr , bl , br ] = kinematics . ToSwerveModuleStates ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds import math from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) # Now use this in our kinematics self . moduleStates = self . kinematics . toSwerveModuleStates ( speeds ) Using custom centers of rotation Sometimes, rotating around one specific corner might be desirable for certain evasive maneuvers. This type of behavior is also supported by the WPILib classes. The same ToSwerveModuleStates() method accepts a second parameter for the center of rotation (as a Translation2d ). Just like the wheel locations, the Translation2d representing the center of rotation should be relative to the robot center. Note Because all robots are a rigid frame, the provided vx and vy velocities from the ChassisSpeeds object will still apply for the entirety of the robot. However, the omega from the ChassisSpeeds object will be measured from the center of rotation. For example, one can set the center of rotation on a certain module and if the provided ChassisSpeeds object has a vx and vy of zero and a non-zero omega , the robot will appear to rotate around that particular swerve module. Converting module states to chassis speeds One can also use the kinematics object to convert an array of SwerveModuleState objects to a singular ChassisSpeeds object. The toChassisSpeeds(SwerveModuleState... states) (Java / Python) / ToChassisSpeeds(SwerveModuleState... states) (C++) method can be used to achieve this. JAVA // Example module states var frontLeftState = new SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 140.19 )); var frontRightState = new SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 39.81 )); var backLeftState = new SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 109.44 )); var backRightState = new SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 70.56 )); // Convert to chassis speeds ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ); // Getting individual speeds double forward = chassisSpeeds . vxMetersPerSecond ; double sideways = chassisSpeeds . vyMetersPerSecond ; double angular = chassisSpeeds . omegaRadiansPerSecond ; C++ // Example module States frc :: SwerveModuleState frontLeftState { 23.43 _mps , Rotation2d ( -140.19 _deg )}; frc :: SwerveModuleState frontRightState { 23.43 _mps , Rotation2d ( -39.81 _deg )}; frc :: SwerveModuleState backLeftState { 54.08 _mps , Rotation2d ( -109.44 _deg )}; frc :: SwerveModuleState backRightState { 54.08 _mps , Rotation2d ( -70.56 _deg )}; // Convert to chassis speeds. Here, we can use C++17's structured bindings // feature to automatically break up the ChassisSpeeds struct into its // three components. auto [ forward , sideways , angular ] = kinematics . ToChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ); PYTHON from wpimath.kinematics import SwerveModuleState from wpimath.geometry import Rotation2d # Example module states frontLeftState = SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 140.19 )) frontRightState = SwerveModuleState ( 23.43 , Rotation2d . fromDegrees ( - 39.81 )) backLeftState = SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 109.44 )) backRightState = SwerveModuleState ( 54.08 , Rotation2d . fromDegrees ( - 70.56 )) # Convert to chassis speeds chassisSpeeds = self . kinematics . toChassisSpeeds ( frontLeftState , frontRightState , backLeftState , backRightState ) # Getting individual speeds forward = chassisSpeeds . vx sideways = chassisSpeeds . vy angular = chassisSpeeds . omega Module state visualization with AdvantageScope By recording a set of swerve module states using NetworkTables or WPILib data logs , AdvantageScope can be used to visualize the state of a swerve drive. The code below shows how a set of SwerveModuleState objects can be published to NetworkTables. JAVA public class Example { private final StructArrayPublisher < SwerveModuleState > publisher ; public Example () { // Start publishing an array of module states with the \"/SwerveStates\" key publisher = NetworkTableInstance . getDefault () . getStructArrayTopic ( \"/SwerveStates\" , SwerveModuleState . struct ). publish (); } public void periodic () { // Periodically send a set of module states publisher . set ( new SwerveModuleState [] { frontLeftState , frontRightState , backLeftState , backRightState }); } } C++ class Example { nt :: StructArrayPublisher < frc :: SwerveModuleState > publisher public : Example () { // Start publishing an array of module states with the \"/SwerveStates\" key publisher = nt :: NetworkTableInstance :: GetDefault () . GetStructArrayTopic < frc :: SwerveModuleState > ( \"/SwerveStates\" ). Publish (); } void Periodic () { // Periodically send a set of module states swervePublisher . Set ( std :: vector { frontLeftState , frontRightState , backLeftState , backRightState } ); } }; PYTHON import ntcore from wpimath.kinematics import SwerveModuleState # get the default instance of NetworkTables nt = ntcore . NetworkTableInstance . getDefault () # Start publishing an array of module states with the \"/SwerveStates\" key topic = nt . getStructArrayTopic ( \"/SwerveStates\" , SwerveModuleState ) self . pub = topic . publish () def periodic ( self ): # Periodically send a set of module states self . pub . set ([ frontLeftState , frontRightState , backLeftState , backRightState ]) See the documentation for the swerve tab for more details on visualizing this data using AdvantageScope.",
      "content_preview": "Swerve Drive Kinematics The SwerveDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and several SwerveModuleState objects, which contains velocities and angles for each swerve module of a swerve drive robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/telemetry/datalog.html",
      "title": "On",
      "section": "General",
      "language": "All",
      "content": "On-Robot Telemetry Recording Into Data Logs By default, no telemetry data is recorded (saved) on the robot. The DataLogManager class provides a convenient wrapper around the lower-level DataLog class for on-robot recording of telemetry data into data logs. The WPILib data logs are binary for size and speed reasons. In general, the data log facilities provided by WPILib have minimal overhead to robot code, as all file I/O is performed on a separate thread–the log operation consists of mainly a mutex acquisition and copying the data. Structure of Data Logs Similar to NetworkTables, data logs have the concept of entries with string identifiers (keys) with a specified data type. Unlike NetworkTables, the data type cannot be changed after the entry is created, and entries also have metadata–an arbitrary (but typically JSON) string that can be used to convey additional information about the entry such as the data source or data schema. Also unlike NetworkTables, data log operation is unidirectional–the DataLog class can only write data logs (it does not support read-back of written values) and the DataLogReader class can only read data logs (it does not support changing values in the data log). Data logs consist of a series of timestamped records. Control records allow starting, finishing, or changing the metadata of entries, and data records record data value changes. Timestamps are stored in integer microseconds; when running on the RoboRIO, the FPGA timestamp is used (the same timestamp returned by Timer.getFPGATimestamp() ). Note For more information on the details of the data log file format, see the WPILib Data Log File Format Specification . Standard Data Logging using DataLogManager The DataLogManager class ( Java , C++ , Python ) provides a centralized data log that provides automatic data log file management. It automatically cleans up old files when disk space is low and renames the file based either on current date/time or (if available) competition match number. The data file will be saved to a USB flash drive in a folder called logs if one is attached, or to /home/lvuser/logs otherwise. Note USB flash drives need to be formatted as FAT32 to work with the roboRIO. NTFS or exFAT formatted drives will not work. Flash drives of 32GB or smaller are recommended, as Windows doesn’t format drives larger then 32GB with FAT32. Log files are initially named FRC_TBD_{random}.wpilog until the DS connects. After the DS connects, the log file is renamed to FRC_yyyyMMdd_HHmmss.wpilog (where the date/time is UTC). If the FMS is connected and provides a match number, the log file is renamed to FRC_yyyyMMdd_HHmmss_{event}_{match}.wpilog . On startup, all existing log files where a DS has not been connected will be deleted. If there is less than 50 MB of free space on the target storage, FRC_ log files are deleted (oldest to newest) until there is 50 MB free OR there are 10 files remaining. The most basic usage of DataLogManager only requires a single line of code (typically this would be called from Robot constructor). This will record all NetworkTables changes to the data log. JAVA import edu.wpi.first.wpilibj.DataLogManager ; // Starts recording to data log DataLogManager . start (); C++ #include \"frc/DataLogManager.h\" // Starts recording to data log frc :: DataLogManager :: Start (); PYTHON from wpilib import DataLogManager DataLogManager . start () DataLogManager provides a convenience function ( DataLogManager.log() ) for logging of text messages to the messages entry in the data log. The message is also printed to standard output, so this can be a replacement for System.out.println() . DataLogManager also records the current roboRIO system time (in UTC) to the data log every ~5 seconds to the systemTime entry in the data log. This can be used to (roughly) synchronize the data log with other records such as DS logs or match video. For custom logging, the managed DataLog can be accessed via DataLogManager.getLog() . Logging Joystick Data DataLogManager by default does not record joystick data. The DriverStation class provides support for logging of DS control and joystick data via the startDataLog() function: JAVA import edu.wpi.first.wpilibj.DataLogManager ; import edu.wpi.first.wpilibj.DriverStation ; // Starts recording to data log DataLogManager . start (); // Record both DS control and joystick data DriverStation . startDataLog ( DataLogManager . getLog ()); // (alternatively) Record only DS control data DriverStation . startDataLog ( DataLogManager . getLog (), false ); C++ #include \"frc/DataLogManager.h\" #include \"frc/DriverStation.h\" // Starts recording to data log frc :: DataLogManager :: Start (); // Record both DS control and joystick data DriverStation :: StartDataLog ( DataLogManager :: GetLog ()); // (alternatively) Record only DS control data DriverStation :: StartDataLog ( DataLogManager :: GetLog (), false ); PYTHON from wpilib import DataLogManager , DriverStation # Starts recording to data log DataLogManager . start () # Record both DS control and joystick data DriverStation . startDataLog ( DataLogManager . getLog ()) # (alternatively) Record only DS control data DriverStation . startDataLog ( DataLogManager . getLog (), False ) Custom Data Logging using DataLog The DataLog class ( Java , C++ , Python ) and its associated LogEntry classes (e.g. BooleanLogEntry , DoubleLogEntry , etc) provides low-level access for writing data logs. Note Unlike NetworkTables, there is no change checking performed. Every call to a LogEntry.append() function will result in a record being written to the data log. Checking for changes and only appending to the log when necessary is the responsibility of the caller. The LogEntry classes can be used in conjunction with DataLogManager to record values only to a data log and not to NetworkTables: JAVA import edu.wpi.first.util.datalog.BooleanLogEntry ; import edu.wpi.first.util.datalog.DataLog ; import edu.wpi.first.util.datalog.DoubleLogEntry ; import edu.wpi.first.util.datalog.StringLogEntry ; import edu.wpi.first.wpilibj.DataLogManager ; BooleanLogEntry myBooleanLog ; DoubleLogEntry myDoubleLog ; StringLogEntry myStringLog ; public Robot () { // Starts recording to data log DataLogManager . start (); // Set up custom log entries DataLog log = DataLogManager . getLog (); myBooleanLog = new BooleanLogEntry ( log , \"/my/boolean\" ); myDoubleLog = new DoubleLogEntry ( log , \"/my/double\" ); myStringLog = new StringLogEntry ( log , \"/my/string\" ); } public void teleopPeriodic () { if (...) { // Only log when necessary myBooleanLog . append ( true ); myDoubleLog . append ( 3.5 ); myStringLog . append ( \"wow!\" ); } } C++ #include \"frc/DataLogManager.h\" #include \"wpi/DataLog.h\" wpi :: log :: BooleanLogEntry myBooleanLog ; wpi :: log :: DoubleLogEntry myDoubleLog ; wpi :: log :: StringLogEntry myStringLog ; Robot () { // Starts recording to data log frc :: DataLogManager :: Start (); // Set up custom log entries wpi :: log :: DataLog & log = frc :: DataLogManager :: GetLog (); myBooleanLog = wpi :: log :: BooleanLogEntry ( log , \"/my/boolean\" ); myDoubleLog = wpi :: log :: DoubleLogEntry ( log , \"/my/double\" ); myStringLog = wpi :: log :: StringLogEntry ( log , \"/my/string\" ); } void TeleopPeriodic () { if (...) { // Only log when necessary myBooleanLog . Append ( true ); myDoubleLog . Append ( 3.5 ); myStringLog . Append ( \"wow!\" ); } } PYTHON from wpilib import DataLogManager , TimedRobot from wpiutil.log import ( DataLog , BooleanLogEntry , DoubleLogEntry , StringLogEntry , ) class MyRobot ( TimedRobot ): def robotInit ( self ): # Starts recording to data log DataLogManager . start () # Set up custom log entries log = DataLogManager . getLog () self . myBooleanLog = BooleanLogEntry ( log , \"/my/boolean\" ) self . myDoubleLog = DoubleLogEntry ( log , \"/my/double\" ) self . myStringLog = StringLogEntry ( log , \"/my/string\" ) def teleopPeriodic ( self ): if ... : # Only log when necessary self . myBooleanLog . append ( True ) self . myDoubleLog . append ( 3.5 ) self . myStringLog . append ( \"wow!\" )",
      "content_preview": "On-Robot Telemetry Recording Into Data Logs By default, no telemetry data is recorded (saved) on the robot. The DataLogManager class provides a convenient wrapper around the lower-level DataLog class for on-robot recording of telemetry data into data logs."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/dashboards/advantagescope.html",
      "title": "AdvantageScope",
      "section": "General",
      "language": "All",
      "content": "AdvantageScope AdvantageScope is a data visualization tool for NetworkTables , WPILib data logs , and Driver Station logs . It is a programmer’s tool (rather than a competition dashboard) and can be used to debug real or simulated robot code from a log file or live over the network. In Visual Studio Code, press Ctrl + Shift + P and type WPILib or click the WPILib logo in the top right to launch the WPILib Command Palette. Select Start Tool , then select AdvantageScope . You can also open any supported log file in AdvantageScope using a standard file browser. Note Detailed documentation for AdvantageScope can be found here . It is also available offline by clicking the book icon in the tab bar. The capabilities of AdvantageScope include: Display of numeric, textual, and boolean data in graphs and tables Visualization of pose and mechanism data in 2D and 3D, including custom 3D robot models Automatic synchronization of data sources, including various types of log files and match videos Specialized displays for joysticks, swerve module states, and console text Analysis of numeric fields using histograms and statistical measures Multiple export options, including CSV, and WPILib data logs",
      "content_preview": "AdvantageScope AdvantageScope is a data visualization tool for NetworkTables , WPILib data logs , and Driver Station logs . It is a programmer’s tool (rather than a competition dashboard) and can be used to debug real or simulated robot code from a log file or live over the network."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/networktables-intro.html",
      "title": "What is NetworkTables",
      "section": "NetworkTables",
      "language": "Java",
      "content": "What is NetworkTables NetworkTables is an implementation of a publish-subscribe messaging system . Values are published to named “topics” either on the robot, driver station, or potentially an attached coprocessor, and the values are automatically distributed to all subscribers to the topic. For example, a driver station laptop might receive camera images over the network, perform some vision processing algorithm, and come up with some values to sent back to the robot. The values might be an X, Y, and Distance. By writing these results to NetworkTables topics called “X”, “Y”, and “Distance” they can be read by the robot shortly after being written. Then the robot can act upon them. Similarly, the robot program can write sensor values to topics and those can be read and plotted in real time on a dashboard application. NetworkTables can be used by programs on the robot in Java, C++, or LabVIEW, and is built into each version of WPILib. Note NetworkTables has changed substantially in 2023. For more information on migrating pre-2023 code to use the new features, see Migrating from NetworkTables 3.0 to NetworkTables 4.0 . NetworkTables Concepts First, let’s define some terms: Topic : a named data channel. Topics have a fixed data type (for the lifetime of the topic) and mutable properties. Publisher : defines the topic and creates and sends timestamped data values. Subscriber : receives timestamped data value updates to one or more topics. Entry : a combined publisher and subscriber. The subscriber is always active, but the publisher is not created until a publish operation is performed (e.g. a value is “set”, aka published, on the entry). This may be more convenient than maintaining a separate publisher and subscriber. Property : named information (metadata) about a topic stored and updated separately from the topic’s data. A topic may have any number of properties. A property’s value can be any data type that can be represented in JSON. NetworkTables supports a range of data types, including boolean , numeric, string, and arrays of those types. Supported numeric data types are single or double precision floating point , or 64-bit integer. There is also the option of storing raw data (an array of bytes), which can be used for representing binary encoded structured data. Types are represented as strings for efficiency reasons. There is also an enumeration for the most common types in the NetworkTables API. Topics are created when the first publisher announces the topic and are removed when the last publisher stops publishing. It’s possible to subscribe to a topic that has not yet been created/published. Topics have properties. Properties are initially set by the first publisher, but may be changed at any time. Similarly to values, property changes to a topic are propagated to all subscribers to that topic. Properties are structured data (JSON), but at the top level are simply a key/value store (a JSON map). Some properties have defined behavior, but arbitrary ones can be set by the application. Publishers specify the topic’s data type; while there can be multiple publishers to a single topic, they must all be publishing the same data type. This is enforced by the NetworkTables server (the first publisher “wins”). Typically single-topic subscribers also specify what data type they’re expecting to receive on a topic and thus won’t receive value updates of other types. The Network Tables Protocol Specification contains detailed documentation on the current wire protocol. Retained and Persistent Topics While by default topics are transitory and disappear after the last publisher stops publishing, topics can be marked as retained (via setting the “retained” property to true) to prevent them from disappearing. For retained topics, the server acts as an implicit publisher of the last value, and will keep doing so as long as the server is running. This is primarily useful for configuration values; e.g. an autonomous mode selection published by a dashboard should set the topic as retained so its value is preserved in case the dashboard disconnects. Additionally, topics can be marked as persistent via setting the “persistent” property to true. These operate similarly to retained topics, but in addition, persistent topic values are automatically saved to a file on the server and when the server starts up again, the topic is created and its last value is published by the server. Value Propagation The server keeps a copy of the last published value for every topic. When a subscriber initially subscribes to a topic, the server sends the last published value. After that initial value, new value updates are communicated to subscribers each time the publisher sends a new value. NetworkTables is a client/server system; clients do not talk directly to each other, but rather communicate via the server. Typically, the robot program is the server, and other pieces of software on other computers (e.g. the driver station or a coprocessor) are clients that connect to it. Thus, when a coprocessor (client) publishes a value, the value is sent first from the coprocessor (client) to the robot program (server), and then the robot program distributes that value to any subscribers (e.g. the robot program local program, or other clients such as dashboards). The server does not send topic changes or value updates to clients that have not subscribed to the topic. By default, NetworkTables sends value updates periodically, batching the data to help limit the number of small packets being sent over the network. Also, by default, only the most recent value is transmitted; any intermediate value changes made between network transmissions are discarded. This behavior can be changed via publish/subscribe options–publishers and subscribers can indicate that all value updates should be preserved and communicated via the “send all” option. In addition, it is possible to force NetworkTables to “flush” all current updates to the network; this is useful for minimizing latency. Timestamps All NetworkTable value updates are timestamped at the time they are published. Timestamps in NetworkTables are measured in integer microseconds. NetworkTables automatically synchronizes time between the server and clients. Each client maintains an offset between the client local time and the server time, so when a client publishes a value, it stores a timestamp in local time and calculates the equivalent server timestamp. The server timestamp is what is communicated over the network to any subscribers. This makes it possible e.g. for a robot program to get a reasonable estimation of the time when a value was published on a coprocessor relative to the current time. Because of this, two timestamps are visible through the API: a server timestamp indicating the time (estimated) on the server, and a local timestamp indicating the time on the client. When the RoboRIO is the NetworkTables server, the server timestamp is the same as the FPGA timestamp returned by Timer.getFPGATimestamp() (except the units are different: NetworkTables uses microseconds, while getFPGATimestamp() returns seconds). NetworkTables Organization Data is organized in NetworkTables in a hierarchy much like a filesystem’s folders and files. There can be multiple subtables (folders) and topics (files) that may be nested in whatever way fits the data organization desired. At the top level ( NetworkTableInstance : Java , C++ , Python ), topic names are handled similar to absolute paths in a filesystem: subtables are represented as a long topic name with slashes (“/”) separating the nested subtable and value names. A NetworkTable ( Java , C++ , Python ) object represents a single subtable (folder), so topic names are relative to the NetworkTable’s base path: e.g. for a root table called “SmartDashboard” with a topic named “xValue”, the same topic can be accessed via NetworkTableInstance as a topic named “/SmartDashboard/xValue”. However, unlike a filesystem, subtables don’t really exist in the same way folders do, as there is no way to represent an empty subtable on the network–a subtable “appears” only as long as there are topics published within it. OutlineViewer is a utility for exploring the values stored in NetworkTables, and can show either a flat view (topics with absolute paths) or a nested view (subtables and topics). There are some default tables that are created automatically when a robot program starts up: Table name Use /SmartDashboard Used to store values written to the SmartDashboard or Shuffleboard using the SmartDashboard.put() set of methods. /LiveWindow Used to store Test mode (Test on the Driver Station) values. Typically these are Subsystems and the associated sensors and actuators. /FMSInfo Information about the currently running match that comes from the Driver Station and the Field Management System NetworkTables API Variants There are two major variants of the NetworkTables API. The object-oriented API (C++ and Java) is recommended for robot code and general team use, and provides classes that help ensure correct use of the API. For advanced use cases such as writing object-oriented wrappers for other programming languages, there’s also a C/C++ handle-based API. Lifetime Management Publishers, subscribers, and entries only exist as long as the objects exist. In Java, a common bug is to create a subscriber or publisher and not properly release it by calling close() , as this will result in the object lingering around for an unknown period of time and not releasing resources properly. This is less common of an issue in robot programs, as long as the publisher or subscriber object is stored in an instance variable that persists for the life of the program. In C++, publishers, subscribers, and entries are RAII , which means they are automatically destroyed when they go out of scope. NetworkTableInstance is an exception to this; it is designed to be explicitly destroyed, so it’s not necessary to maintain a global instance of it. Python is similar to Java, except that subscribers or publishers are released when they are garbage collected.",
      "content_preview": "What is NetworkTables NetworkTables is an implementation of a publish-subscribe messaging system . Values are published to named “topics” either on the robot, driver station, or potentially an attached coprocessor, and the values are automatically distributed to all subscribers to the topic."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/mecanum-drive-kinematics.html",
      "title": "Mecanum Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Mecanum Drive Kinematics The MecanumDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a MecanumDriveWheelSpeeds object, which contains velocities for each of the four wheels on a mecanum drive. Note Mecanum kinematics uses a common coordinate system. You may wish to reference the Coordinate System section for details. Constructing the Kinematics Object The MecanumDriveKinematics class accepts four constructor arguments, with each argument being the location of a wheel relative to the robot center (as a Translation2d ). The order for the arguments is front left, front right, back left, and back right. The locations for the wheels must be relative to the center of the robot. Positive x values represent moving toward the front of the robot whereas positive y values represent moving toward the left of the robot. JAVA // Locations of the wheels relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the wheel locations. MecanumDriveKinematics m_kinematics = new MecanumDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); C++ // Locations of the wheels relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the wheel locations. frc :: MecanumDriveKinematics m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; PYTHON from wpimath.geometry import Translation2d from wpimath.kinematics import MecanumDriveKinematics # Locations of the wheels relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the wheel locations. self . kinematics = MecanumDriveKinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) Converting Chassis Speeds to Wheel Speeds The toWheelSpeeds(ChassisSpeeds speeds) (Java / Python) / ToWheelSpeeds(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a MecanumDriveWheelSpeeds object. This is useful in situations where you have to convert a forward velocity, sideways velocity, and an angular velocity into individual wheel speeds. JAVA // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. ChassisSpeeds speeds = new ChassisSpeeds ( 1.0 , 3.0 , 1.5 ); // Convert to wheel speeds MecanumDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( speeds ); // Get the individual wheel speeds double frontLeft = wheelSpeeds . frontLeftMetersPerSecond double frontRight = wheelSpeeds . frontRightMetersPerSecond double backLeft = wheelSpeeds . rearLeftMetersPerSecond double backRight = wheelSpeeds . rearRightMetersPerSecond C++ // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. frc :: ChassisSpeeds speeds { 1 _mps , 3 _mps , 1.5 _rad_per_s }; // Convert to wheel speeds. Here, we can use C++17's structured // bindings feature to automatically split up the MecanumDriveWheelSpeeds // struct into it's individual components auto [ fl , fr , bl , br ] = kinematics . ToWheelSpeeds ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds # Example chassis speeds: 1 meter per second forward, 3 meters # per second to the left, and rotation at 1.5 radians per second # counterclockwise. speeds = ChassisSpeeds ( 1.0 , 3.0 , 1.5 ) # Convert to wheel speeds frontLeft , frontRight , backLeft , backRight = self . kinematics . toWheelSpeeds ( speeds ) Field-oriented drive Recall that a ChassisSpeeds object can be created from a set of desired field-oriented speeds. This feature can be used to get wheel speeds from a set of desired field-oriented speeds. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); // Now use this in our kinematics MecanumDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( speeds ); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); // Now use this in our kinematics auto [ fl , fr , bl , br ] = kinematics . ToWheelSpeeds ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds import math from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) # Now use this in our kinematics wheelSpeeds = self . kinematics . toWheelSpeeds ( speeds ) Using custom centers of rotation Sometimes, rotating around one specific corner might be desirable for certain evasive maneuvers. This type of behavior is also supported by the WPILib classes. The same ToWheelSpeeds() method accepts a second parameter for the center of rotation (as a Translation2d ). Just like the wheel locations, the Translation2d representing the center of rotation should be relative to the robot center. Note Because all robots are a rigid frame, the provided vx and vy velocities from the ChassisSpeeds object will still apply for the entirety of the robot. However, the omega from the ChassisSpeeds object will be measured from the center of rotation. For example, one can set the center of rotation on a certain wheel and if the provided ChassisSpeeds object has a vx and vy of zero and a non-zero omega , the robot will appear to rotate around that particular wheel. Converting wheel speeds to chassis speeds One can also use the kinematics object to convert a MecanumDriveWheelSpeeds object to a singular ChassisSpeeds object. The toChassisSpeeds(MecanumDriveWheelSpeeds speeds) (Java / Python) / ToChassisSpeeds(MecanumDriveWheelSpeeds speeds) (C++) method can be used to achieve this. JAVA // Example wheel speeds var wheelSpeeds = new MecanumDriveWheelSpeeds ( - 17.67 , 20.51 , - 13.44 , 16.26 ); // Convert to chassis speeds ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ); // Getting individual speeds double forward = chassisSpeeds . vxMetersPerSecond ; double sideways = chassisSpeeds . vyMetersPerSecond ; double angular = chassisSpeeds . omegaRadiansPerSecond ; C++ // Example wheel speeds frc :: MecanumDriveWheelSpeeds wheelSpeeds { -17.67 _mps , 20.51 _mps , -13.44 _mps , 16.26 _mps }; // Convert to chassis speeds. Here, we can use C++17's structured bindings // feature to automatically break up the ChassisSpeeds struct into its // three components. auto [ forward , sideways , angular ] = kinematics . ToChassisSpeeds ( wheelSpeeds ); PYTHON from wpimath.kinematics import MecanumDriveWheelSpeeds # Example wheel speeds wheelSpeeds = MecanumDriveWheelSpeeds ( - 17.67 , 20.51 , - 13.44 , 16.26 ) # Convert to chassis speeds chassisSpeeds = self . kinematics . toChassisSpeeds ( wheelSpeeds ) # Getting individual speeds forward = chassisSpeeds . vx sideways = chassisSpeeds . vy angular = chassisSpeeds . omega",
      "content_preview": "Mecanum Drive Kinematics The MecanumDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a MecanumDriveWheelSpeeds object, which contains velocities for each of the four wheels on a mecanum drive. Note Mecanum kinematics uses a common coordinate system."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/mecanum-drive-kinematics.html?present",
      "title": "Mecanum Drive Kinematics",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Mecanum Drive Kinematics The MecanumDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a MecanumDriveWheelSpeeds object, which contains velocities for each of the four wheels on a mecanum drive. Note Mecanum kinematics uses a common coordinate system. You may wish to reference the Coordinate System section for details. Constructing the Kinematics Object The MecanumDriveKinematics class accepts four constructor arguments, with each argument being the location of a wheel relative to the robot center (as a Translation2d ). The order for the arguments is front left, front right, back left, and back right. The locations for the wheels must be relative to the center of the robot. Positive x values represent moving toward the front of the robot whereas positive y values represent moving toward the left of the robot. JAVA // Locations of the wheels relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the wheel locations. MecanumDriveKinematics m_kinematics = new MecanumDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); C++ // Locations of the wheels relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the wheel locations. frc :: MecanumDriveKinematics m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; PYTHON from wpimath.geometry import Translation2d from wpimath.kinematics import MecanumDriveKinematics # Locations of the wheels relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the wheel locations. self . kinematics = MecanumDriveKinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) Converting Chassis Speeds to Wheel Speeds The toWheelSpeeds(ChassisSpeeds speeds) (Java / Python) / ToWheelSpeeds(ChassisSpeeds speeds) (C++) method should be used to convert a ChassisSpeeds object to a MecanumDriveWheelSpeeds object. This is useful in situations where you have to convert a forward velocity, sideways velocity, and an angular velocity into individual wheel speeds. JAVA // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. ChassisSpeeds speeds = new ChassisSpeeds ( 1.0 , 3.0 , 1.5 ); // Convert to wheel speeds MecanumDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( speeds ); // Get the individual wheel speeds double frontLeft = wheelSpeeds . frontLeftMetersPerSecond double frontRight = wheelSpeeds . frontRightMetersPerSecond double backLeft = wheelSpeeds . rearLeftMetersPerSecond double backRight = wheelSpeeds . rearRightMetersPerSecond C++ // Example chassis speeds: 1 meter per second forward, 3 meters // per second to the left, and rotation at 1.5 radians per second // counterclockwise. frc :: ChassisSpeeds speeds { 1 _mps , 3 _mps , 1.5 _rad_per_s }; // Convert to wheel speeds. Here, we can use C++17's structured // bindings feature to automatically split up the MecanumDriveWheelSpeeds // struct into it's individual components auto [ fl , fr , bl , br ] = kinematics . ToWheelSpeeds ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds # Example chassis speeds: 1 meter per second forward, 3 meters # per second to the left, and rotation at 1.5 radians per second # counterclockwise. speeds = ChassisSpeeds ( 1.0 , 3.0 , 1.5 ) # Convert to wheel speeds frontLeft , frontRight , backLeft , backRight = self . kinematics . toWheelSpeeds ( speeds ) Field-oriented drive Recall that a ChassisSpeeds object can be created from a set of desired field-oriented speeds. This feature can be used to get wheel speeds from a set of desired field-oriented speeds. JAVA // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. ChassisSpeeds speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , Math . PI / 2.0 , Rotation2d . fromDegrees ( 45.0 )); // Now use this in our kinematics MecanumDriveWheelSpeeds wheelSpeeds = kinematics . toWheelSpeeds ( speeds ); C++ // The desired field relative speed here is 2 meters per second // toward the opponent's alliance station wall, and 2 meters per // second toward the left field boundary. The desired rotation // is a quarter of a rotation per second counterclockwise. The current // robot angle is 45 degrees. frc :: ChassisSpeeds speeds = frc :: ChassisSpeeds :: FromFieldRelativeSpeeds ( 2 _mps , 2 _mps , units :: radians_per_second_t ( std :: numbers :: pi / 2.0 ), Rotation2d ( 45 _deg )); // Now use this in our kinematics auto [ fl , fr , bl , br ] = kinematics . ToWheelSpeeds ( speeds ); PYTHON from wpimath.kinematics import ChassisSpeeds import math from wpimath.geometry import Rotation2d # The desired field relative speed here is 2 meters per second # toward the opponent's alliance station wall, and 2 meters per # second toward the left field boundary. The desired rotation # is a quarter of a rotation per second counterclockwise. The current # robot angle is 45 degrees. speeds = ChassisSpeeds . fromFieldRelativeSpeeds ( 2.0 , 2.0 , math . pi / 2.0 , Rotation2d . fromDegrees ( 45.0 )) # Now use this in our kinematics wheelSpeeds = self . kinematics . toWheelSpeeds ( speeds ) Using custom centers of rotation Sometimes, rotating around one specific corner might be desirable for certain evasive maneuvers. This type of behavior is also supported by the WPILib classes. The same ToWheelSpeeds() method accepts a second parameter for the center of rotation (as a Translation2d ). Just like the wheel locations, the Translation2d representing the center of rotation should be relative to the robot center. Note Because all robots are a rigid frame, the provided vx and vy velocities from the ChassisSpeeds object will still apply for the entirety of the robot. However, the omega from the ChassisSpeeds object will be measured from the center of rotation. For example, one can set the center of rotation on a certain wheel and if the provided ChassisSpeeds object has a vx and vy of zero and a non-zero omega , the robot will appear to rotate around that particular wheel. Converting wheel speeds to chassis speeds One can also use the kinematics object to convert a MecanumDriveWheelSpeeds object to a singular ChassisSpeeds object. The toChassisSpeeds(MecanumDriveWheelSpeeds speeds) (Java / Python) / ToChassisSpeeds(MecanumDriveWheelSpeeds speeds) (C++) method can be used to achieve this. JAVA // Example wheel speeds var wheelSpeeds = new MecanumDriveWheelSpeeds ( - 17.67 , 20.51 , - 13.44 , 16.26 ); // Convert to chassis speeds ChassisSpeeds chassisSpeeds = kinematics . toChassisSpeeds ( wheelSpeeds ); // Getting individual speeds double forward = chassisSpeeds . vxMetersPerSecond ; double sideways = chassisSpeeds . vyMetersPerSecond ; double angular = chassisSpeeds . omegaRadiansPerSecond ; C++ // Example wheel speeds frc :: MecanumDriveWheelSpeeds wheelSpeeds { -17.67 _mps , 20.51 _mps , -13.44 _mps , 16.26 _mps }; // Convert to chassis speeds. Here, we can use C++17's structured bindings // feature to automatically break up the ChassisSpeeds struct into its // three components. auto [ forward , sideways , angular ] = kinematics . ToChassisSpeeds ( wheelSpeeds ); PYTHON from wpimath.kinematics import MecanumDriveWheelSpeeds # Example wheel speeds wheelSpeeds = MecanumDriveWheelSpeeds ( - 17.67 , 20.51 , - 13.44 , 16.26 ) # Convert to chassis speeds chassisSpeeds = self . kinematics . toChassisSpeeds ( wheelSpeeds ) # Getting individual speeds forward = chassisSpeeds . vx sideways = chassisSpeeds . vy angular = chassisSpeeds . omega",
      "content_preview": "Mecanum Drive Kinematics The MecanumDriveKinematics class is a useful tool that converts between a ChassisSpeeds object and a MecanumDriveWheelSpeeds object, which contains velocities for each of the four wheels on a mecanum drive. Note Mecanum kinematics uses a common coordinate system."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/swerve-drive-odometry.html",
      "title": "Swerve Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Swerve Drive Odometry A user can use the swerve drive kinematics classes in order to perform odometry . WPILib contains a SwerveDriveOdometry class that can be used to track the position of a swerve drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the odometry object The SwerveDriveOdometry<int NumModules> class constructor requires one template argument (only C++), three mandatory arguments, and one optional argument. The template argument (only C++) is an integer representing the number of swerve modules. The mandatory arguments are: The kinematics object that represents your swerve drive (as a SwerveDriveKinematics instance) The angle reported by your gyroscope (as a Rotation2d ) The initial positions of the swerve modules (as an array of SwerveModulePosition ). In Java, this must be constructed with each wheel position in meters. In C++, the units library must be used to represent your wheel positions. It is important that the order in which you pass the SwerveModulePosition objects is the same as the order in which you created the kinematics object. The fourth optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Locations for the swerve drive modules relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the module locations SwerveDriveKinematics m_kinematics = new SwerveDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); // Creating my odometry object from the kinematics object and the initial wheel positions. // Here, our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing the opposing alliance wall. SwerveDriveOdometry m_odometry = new SwerveDriveOdometry ( m_kinematics , m_gyro . getRotation2d (), new SwerveModulePosition [] { m_frontLeftModule . getPosition (), m_frontRightModule . getPosition (), m_backLeftModule . getPosition (), m_backRightModule . getPosition () }, new Pose2d ( 5.0 , 13.5 , new Rotation2d ())); C++ // Locations for the swerve drive modules relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the module locations. frc :: SwerveDriveKinematics < 4 > m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; // Creating my odometry object from the kinematics object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: SwerveDriveOdometry < 4 > m_odometry { m_kinematics , m_gyro . GetRotation2d (), { m_frontLeft . GetPosition (), m_frontRight . GetPosition (), m_backLeft . GetPosition (), m_backRight . GetPosition ()}, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON # Python requires using the right class for the number of modules you have # For both the Kinematics and Odometry classes from wpimath.geometry import Translation2d from wpimath.kinematics import SwerveDrive4Kinematics from wpimath.kinematics import SwerveDrive4Odometry from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d class MyRobot : def robotInit ( self ): # Locations for the swerve drive modules relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the module locations self . kinematics = SwerveDrive4Kinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) # Creating my odometry object from the kinematics object and the initial wheel positions. # Here, our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing the opposing alliance wall. self . odometry = SwerveDrive4Odometry ( self . kinematics , self . gyro . getRotation2d (), ( self . frontLeftModule . getPosition (), self . frontRightModule . getPosition (), self . backLeftModule . getPosition (), self . backRightModule . getPosition () ), Pose2d ( 5.0 , 13.5 , Rotation2d ())) Updating the robot pose The update method of the odometry class updates the robot position on the field. The update method takes in the gyro angle of the robot, along with an array of SwerveModulePosition objects. It is important that the order in which you pass the SwerveModulePosition objects is the same as the order in which you created the kinematics object. This update method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. JAVA @Override public void periodic () { // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , new SwerveModulePosition [] { m_frontLeftModule . getPosition (), m_frontRightModule . getPosition (), m_backLeftModule . getPosition (), m_backRightModule . getPosition () }); } C++ void Periodic () override { // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , { m_frontLeftModule . GetPosition (), m_frontRightModule . GetPosition (), m_backLeftModule . GetPosition (), m_backRightModule . GetPosition () }; ) } PYTHON def periodic ( self ): # Get the rotation of the robot from the gyro. self . gyroAngle = self . gyro . getRotation2d () # Update the pose self . pose = self . odometry . update ( self . gyroAngle , self . frontLeftModule . getPosition (), self . frontRightModule . getPosition (), self . backLeftModule . getPosition (), self . backRightModule . getPosition () ) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts three arguments: the current gyro angle, an array of the current module positions (as in the constructor and update method), and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or wheel encoders, the resetPosition method MUST be called with the new gyro angle and wheel encoder positions. Note The implementation of getPosition() / GetPosition() above is left to the user. The idea is to get the module position (distance and angle) from each module. For a full example, see here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Swerve Drive Odometry A user can use the swerve drive kinematics classes in order to perform odometry . WPILib contains a SwerveDriveOdometry class that can be used to track the position of a swerve drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/swerve-drive-odometry.html?present",
      "title": "Swerve Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Swerve Drive Odometry A user can use the swerve drive kinematics classes in order to perform odometry . WPILib contains a SwerveDriveOdometry class that can be used to track the position of a swerve drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the odometry object The SwerveDriveOdometry<int NumModules> class constructor requires one template argument (only C++), three mandatory arguments, and one optional argument. The template argument (only C++) is an integer representing the number of swerve modules. The mandatory arguments are: The kinematics object that represents your swerve drive (as a SwerveDriveKinematics instance) The angle reported by your gyroscope (as a Rotation2d ) The initial positions of the swerve modules (as an array of SwerveModulePosition ). In Java, this must be constructed with each wheel position in meters. In C++, the units library must be used to represent your wheel positions. It is important that the order in which you pass the SwerveModulePosition objects is the same as the order in which you created the kinematics object. The fourth optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Locations for the swerve drive modules relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the module locations SwerveDriveKinematics m_kinematics = new SwerveDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); // Creating my odometry object from the kinematics object and the initial wheel positions. // Here, our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing the opposing alliance wall. SwerveDriveOdometry m_odometry = new SwerveDriveOdometry ( m_kinematics , m_gyro . getRotation2d (), new SwerveModulePosition [] { m_frontLeftModule . getPosition (), m_frontRightModule . getPosition (), m_backLeftModule . getPosition (), m_backRightModule . getPosition () }, new Pose2d ( 5.0 , 13.5 , new Rotation2d ())); C++ // Locations for the swerve drive modules relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the module locations. frc :: SwerveDriveKinematics < 4 > m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; // Creating my odometry object from the kinematics object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: SwerveDriveOdometry < 4 > m_odometry { m_kinematics , m_gyro . GetRotation2d (), { m_frontLeft . GetPosition (), m_frontRight . GetPosition (), m_backLeft . GetPosition (), m_backRight . GetPosition ()}, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON # Python requires using the right class for the number of modules you have # For both the Kinematics and Odometry classes from wpimath.geometry import Translation2d from wpimath.kinematics import SwerveDrive4Kinematics from wpimath.kinematics import SwerveDrive4Odometry from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d class MyRobot : def robotInit ( self ): # Locations for the swerve drive modules relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the module locations self . kinematics = SwerveDrive4Kinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) # Creating my odometry object from the kinematics object and the initial wheel positions. # Here, our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing the opposing alliance wall. self . odometry = SwerveDrive4Odometry ( self . kinematics , self . gyro . getRotation2d (), ( self . frontLeftModule . getPosition (), self . frontRightModule . getPosition (), self . backLeftModule . getPosition (), self . backRightModule . getPosition () ), Pose2d ( 5.0 , 13.5 , Rotation2d ())) Updating the robot pose The update method of the odometry class updates the robot position on the field. The update method takes in the gyro angle of the robot, along with an array of SwerveModulePosition objects. It is important that the order in which you pass the SwerveModulePosition objects is the same as the order in which you created the kinematics object. This update method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. JAVA @Override public void periodic () { // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , new SwerveModulePosition [] { m_frontLeftModule . getPosition (), m_frontRightModule . getPosition (), m_backLeftModule . getPosition (), m_backRightModule . getPosition () }); } C++ void Periodic () override { // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , { m_frontLeftModule . GetPosition (), m_frontRightModule . GetPosition (), m_backLeftModule . GetPosition (), m_backRightModule . GetPosition () }; ) } PYTHON def periodic ( self ): # Get the rotation of the robot from the gyro. self . gyroAngle = self . gyro . getRotation2d () # Update the pose self . pose = self . odometry . update ( self . gyroAngle , self . frontLeftModule . getPosition (), self . frontRightModule . getPosition (), self . backLeftModule . getPosition (), self . backRightModule . getPosition () ) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts three arguments: the current gyro angle, an array of the current module positions (as in the constructor and update method), and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or wheel encoders, the resetPosition method MUST be called with the new gyro angle and wheel encoder positions. Note The implementation of getPosition() / GetPosition() above is left to the user. The idea is to get the module position (distance and angle) from each module. For a full example, see here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Swerve Drive Odometry A user can use the swerve drive kinematics classes in order to perform odometry . WPILib contains a SwerveDriveOdometry class that can be used to track the position of a swerve drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/mecanum-drive-odometry.html",
      "title": "Mecanum Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Mecanum Drive Odometry A user can use the mecanum drive kinematics classes in order to perform odometry . WPILib contains a MecanumDriveOdometry class that can be used to track the position of a mecanum drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the odometry object The MecanumDriveOdometry class constructor requires three mandatory arguments and one optional argument. The mandatory arguments are: The kinematics object that represents your mecanum drive (as a MecanumDriveKinematics instance) The angle reported by your gyroscope (as a Rotation2d ) The initial positions of the wheels (as MecanumDriveWheelPositions ). In Java / Python, this must be constructed with each wheel position in meters. In C++, the units library must be used to represent your wheel positions. The fourth optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Locations of the wheels relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the wheel locations. MecanumDriveKinematics m_kinematics = new MecanumDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); // Creating my odometry object from the kinematics object and the initial wheel positions. // Here, our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing the opposing alliance wall. MecanumDriveOdometry m_odometry = new MecanumDriveOdometry ( m_kinematics , m_gyro . getRotation2d (), new MecanumDriveWheelPositions ( m_frontLeftEncoder . getDistance (), m_frontRightEncoder . getDistance (), m_backLeftEncoder . getDistance (), m_backRightEncoder . getDistance () ), new Pose2d ( 5.0 , 13.5 , new Rotation2d ()) ); C++ // Locations of the wheels relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the wheel locations. frc :: MecanumDriveKinematics m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; // Creating my odometry object from the kinematics object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: MecanumDriveOdometry m_odometry { m_kinematics , m_gyro . GetRotation2d (), frc :: MecanumDriveWheelPositions { units :: meter_t { m_frontLeftEncoder . GetDistance ()}, units :: meter_t { m_frontRightEncoder . GetDistance ()}, units :: meter_t { m_backLeftEncoder . GetDistance ()}, units :: meter_t { m_backRightEncoder . GetDistance ()} }, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON from wpimath.geometry import Translation2d from wpimath.kinematics import MecanumDriveKinematics from wpimath.kinematics import MecanumDriveOdometry from wpimath.kinematics import MecanumDriveWheelPositions from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d # Locations of the wheels relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the wheel locations. self . kinematics = MecanumDriveKinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) # Creating my odometry object from the kinematics object and the initial wheel positions. # Here, our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing the opposing alliance wall. self . odometry = MecanumDriveOdometry ( self . kinematics , self . gyro . getRotation2d (), MecanumDriveWheelPositions ( self . frontLeftEncoder . getDistance (), self . frontRightEncoder . getDistance (), self . backLeftEncoder . getDistance (), self . backRightEncoder . getDistance () ), Pose2d ( 5.0 , 13.5 , Rotation2d ()) ) Updating the robot pose The update method of the odometry class updates the robot position on the field. The update method takes in the gyro angle of the robot, along with a MecanumDriveWheelPositions object representing the position of each of the 4 wheels on the robot. This update method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. JAVA @Override public void periodic () { // Get my wheel positions var wheelPositions = new MecanumDriveWheelPositions ( m_frontLeftEncoder . getDistance (), m_frontRightEncoder . getDistance (), m_backLeftEncoder . getDistance (), m_backRightEncoder . getDistance ()); // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , wheelPositions ); } C++ void Periodic () override { // Get my wheel positions frc :: MecanumDriveWheelPositions wheelPositions { units :: meter_t { m_frontLeftEncoder . GetDistance ()}, units :: meter_t { m_frontRightEncoder . GetDistance ()}, units :: meter_t { m_backLeftEncoder . GetDistance ()}, units :: meter_t { m_backRightEncoder . GetDistance ()}}; // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , wheelPositions ); } PYTHON from wpimath.kinematics import MecanumDriveWheelPositions def periodic ( self ): # Get my wheel positions wheelPositions = MecanumDriveWheelPositions ( self . frontLeftEncoder . getDistance (), self . frontRightEncoder . getDistance (), self . backLeftEncoder . getDistance (), self . backRightEncoder . getDistance ()) # Get the rotation of the robot from the gyro. gyroAngle = gyro . getRotation2d () # Update the pose self . pose = odometry . update ( gyroAngle , wheelPositions ) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts three arguments: the current gyro angle, the current wheel positions, and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or encoders, the resetPosition method MUST be called with the new gyro angle and wheel positions. Note A full example of a mecanum drive robot with odometry is available here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Mecanum Drive Odometry A user can use the mecanum drive kinematics classes in order to perform odometry . WPILib contains a MecanumDriveOdometry class that can be used to track the position of a mecanum drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/kinematics-and-odometry/mecanum-drive-odometry.html?present",
      "title": "Mecanum Drive Odometry",
      "section": "Kinematics and Odometry",
      "language": "All",
      "content": "Mecanum Drive Odometry A user can use the mecanum drive kinematics classes in order to perform odometry . WPILib contains a MecanumDriveOdometry class that can be used to track the position of a mecanum drive robot on the field. Note Because this method only uses encoders and a gyro, the estimate of the robot’s position on the field will drift over time, especially as your robot comes into contact with other robots during gameplay. However, odometry is usually very accurate during the autonomous period. Creating the odometry object The MecanumDriveOdometry class constructor requires three mandatory arguments and one optional argument. The mandatory arguments are: The kinematics object that represents your mecanum drive (as a MecanumDriveKinematics instance) The angle reported by your gyroscope (as a Rotation2d ) The initial positions of the wheels (as MecanumDriveWheelPositions ). In Java / Python, this must be constructed with each wheel position in meters. In C++, the units library must be used to represent your wheel positions. The fourth optional argument is the starting pose of your robot on the field (as a Pose2d ). By default, the robot will start at x = 0, y = 0, theta = 0 . Note 0 degrees / radians represents the robot angle when the robot is facing directly toward your opponent’s alliance station. As your robot turns to the left, your gyroscope angle should increase. The Gyro interface supplies getRotation2d / GetRotation2d that you can use for this purpose. See Coordinate System for more information about the coordinate system. JAVA // Locations of the wheels relative to the robot center. Translation2d m_frontLeftLocation = new Translation2d ( 0.381 , 0.381 ); Translation2d m_frontRightLocation = new Translation2d ( 0.381 , - 0.381 ); Translation2d m_backLeftLocation = new Translation2d ( - 0.381 , 0.381 ); Translation2d m_backRightLocation = new Translation2d ( - 0.381 , - 0.381 ); // Creating my kinematics object using the wheel locations. MecanumDriveKinematics m_kinematics = new MecanumDriveKinematics ( m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation ); // Creating my odometry object from the kinematics object and the initial wheel positions. // Here, our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing the opposing alliance wall. MecanumDriveOdometry m_odometry = new MecanumDriveOdometry ( m_kinematics , m_gyro . getRotation2d (), new MecanumDriveWheelPositions ( m_frontLeftEncoder . getDistance (), m_frontRightEncoder . getDistance (), m_backLeftEncoder . getDistance (), m_backRightEncoder . getDistance () ), new Pose2d ( 5.0 , 13.5 , new Rotation2d ()) ); C++ // Locations of the wheels relative to the robot center. frc :: Translation2d m_frontLeftLocation { 0.381 _m , 0.381 _m }; frc :: Translation2d m_frontRightLocation { 0.381 _m , -0.381 _m }; frc :: Translation2d m_backLeftLocation { -0.381 _m , 0.381 _m }; frc :: Translation2d m_backRightLocation { -0.381 _m , -0.381 _m }; // Creating my kinematics object using the wheel locations. frc :: MecanumDriveKinematics m_kinematics { m_frontLeftLocation , m_frontRightLocation , m_backLeftLocation , m_backRightLocation }; // Creating my odometry object from the kinematics object. Here, // our starting pose is 5 meters along the long end of the field and in the // center of the field along the short end, facing forward. frc :: MecanumDriveOdometry m_odometry { m_kinematics , m_gyro . GetRotation2d (), frc :: MecanumDriveWheelPositions { units :: meter_t { m_frontLeftEncoder . GetDistance ()}, units :: meter_t { m_frontRightEncoder . GetDistance ()}, units :: meter_t { m_backLeftEncoder . GetDistance ()}, units :: meter_t { m_backRightEncoder . GetDistance ()} }, frc :: Pose2d { 5 _m , 13.5 _m , 0 _rad }}; PYTHON from wpimath.geometry import Translation2d from wpimath.kinematics import MecanumDriveKinematics from wpimath.kinematics import MecanumDriveOdometry from wpimath.kinematics import MecanumDriveWheelPositions from wpimath.geometry import Pose2d from wpimath.geometry import Rotation2d # Locations of the wheels relative to the robot center. frontLeftLocation = Translation2d ( 0.381 , 0.381 ) frontRightLocation = Translation2d ( 0.381 , - 0.381 ) backLeftLocation = Translation2d ( - 0.381 , 0.381 ) backRightLocation = Translation2d ( - 0.381 , - 0.381 ) # Creating my kinematics object using the wheel locations. self . kinematics = MecanumDriveKinematics ( frontLeftLocation , frontRightLocation , backLeftLocation , backRightLocation ) # Creating my odometry object from the kinematics object and the initial wheel positions. # Here, our starting pose is 5 meters along the long end of the field and in the # center of the field along the short end, facing the opposing alliance wall. self . odometry = MecanumDriveOdometry ( self . kinematics , self . gyro . getRotation2d (), MecanumDriveWheelPositions ( self . frontLeftEncoder . getDistance (), self . frontRightEncoder . getDistance (), self . backLeftEncoder . getDistance (), self . backRightEncoder . getDistance () ), Pose2d ( 5.0 , 13.5 , Rotation2d ()) ) Updating the robot pose The update method of the odometry class updates the robot position on the field. The update method takes in the gyro angle of the robot, along with a MecanumDriveWheelPositions object representing the position of each of the 4 wheels on the robot. This update method must be called periodically, preferably in the periodic() method of a Subsystem . The update method returns the new updated pose of the robot. JAVA @Override public void periodic () { // Get my wheel positions var wheelPositions = new MecanumDriveWheelPositions ( m_frontLeftEncoder . getDistance (), m_frontRightEncoder . getDistance (), m_backLeftEncoder . getDistance (), m_backRightEncoder . getDistance ()); // Get the rotation of the robot from the gyro. var gyroAngle = m_gyro . getRotation2d (); // Update the pose m_pose = m_odometry . update ( gyroAngle , wheelPositions ); } C++ void Periodic () override { // Get my wheel positions frc :: MecanumDriveWheelPositions wheelPositions { units :: meter_t { m_frontLeftEncoder . GetDistance ()}, units :: meter_t { m_frontRightEncoder . GetDistance ()}, units :: meter_t { m_backLeftEncoder . GetDistance ()}, units :: meter_t { m_backRightEncoder . GetDistance ()}}; // Get the rotation of the robot from the gyro. frc :: Rotation2d gyroAngle = m_gyro . GetRotation2d (); // Update the pose m_pose = m_odometry . Update ( gyroAngle , wheelPositions ); } PYTHON from wpimath.kinematics import MecanumDriveWheelPositions def periodic ( self ): # Get my wheel positions wheelPositions = MecanumDriveWheelPositions ( self . frontLeftEncoder . getDistance (), self . frontRightEncoder . getDistance (), self . backLeftEncoder . getDistance (), self . backRightEncoder . getDistance ()) # Get the rotation of the robot from the gyro. gyroAngle = gyro . getRotation2d () # Update the pose self . pose = odometry . update ( gyroAngle , wheelPositions ) Resetting the Robot Pose The robot pose can be reset via the resetPosition method. This method accepts three arguments: the current gyro angle, the current wheel positions, and the new field-relative pose. Important If at any time, you decide to reset your gyroscope or encoders, the resetPosition method MUST be called with the new gyro angle and wheel positions. Note A full example of a mecanum drive robot with odometry is available here: C++ / Java / Python In addition, the GetPose (C++) / getPoseMeters (Java / Python) methods can be used to retrieve the current robot pose without an update.",
      "content_preview": "Mecanum Drive Odometry A user can use the mecanum drive kinematics classes in order to perform odometry . WPILib contains a MecanumDriveOdometry class that can be used to track the position of a mecanum drive robot on the field."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/index.html",
      "title": "NetworkTables",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables This section outlines the details of using the NetworkTables (v4) API to communicate information across the robot network. Important The code examples in this section are not intended for the user to copy-paste. Ensure that the following documentation is thoroughly read and the API ( Java , C++ , Python ) is consulted when necessary. What is NetworkTables NetworkTables Tables and Topics Publishing and Subscribing to a Topic NetworkTables Instances NetworkTables Networking Listening for Changes Writing a Simple NetworkTables Robot Program Creating a Client-side Program Migrating from NetworkTables 3.0 to NetworkTables 4.0 Reading Array Values Published by NetworkTables",
      "content_preview": "NetworkTables This section outlines the details of using the NetworkTables (v4) API to communicate information across the robot network. Important The code examples in this section are not intended for the user to copy-paste."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/listening-for-change.html",
      "title": "Listening for Changes",
      "section": "NetworkTables",
      "language": "All",
      "content": "Listening for Changes A common use case for NetworkTables is where a coprocessor generates values that need to be sent to the robot. For example, imagine that some image processing code running on a coprocessor computes the heading and distance to a goal and sends those values to the robot. In this case it might be desirable for the robot program to be notified when new values arrive. There are a few different ways to detect that a topic’s value has changed; the easiest way is to periodically call a subscriber’s get() , readQueue() , or readQueueValues() function from the robot’s periodic loop, as shown below: Java public class Example { final DoubleSubscriber ySub ; double prev ; public Example () { // get the default instance of NetworkTables NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); } public void periodic () { // get() can be used with simple change detection to the previous value double value = ySub . get (); if ( value != prev ) { prev = value ; // save previous value System . out . println ( \"X changed value: \" + value ); } // readQueueValues() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( double iterVal : ySub . readQueueValues ()) { System . out . println ( \"X changed value: \" + iterVal ); } // readQueue() is similar to readQueueValues(), but provides timestamps // for each change as well for ( TimestampedDouble tsValue : ySub . readQueue ()) { System . out . println ( \"X changed value: \" + tsValue . value + \" at local time \" + tsValue . timestamp ); } } // may not be necessary for robot programs if this class lives for // the length of the program public void close () { ySub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; double prev = 0 ; public : Example () { // get the default instance of NetworkTables nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable -> GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); } void Periodic () { // Get() can be used with simple change detection to the previous value double value = ySub . Get (); if ( value != prev ) { prev = value ; // save previous value fmt :: print ( \"X changed value: {} \\n \" , value ); } // ReadQueueValues() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( double iterVal : ySub . ReadQueueValues ()) { fmt :: print ( \"X changed value: {} \\n \" , iterVal ); } // ReadQueue() is similar to ReadQueueValues(), but provides timestamps // for each change as well for ( nt :: TimestampedDouble tsValue : ySub . ReadQueue ()) { fmt :: print ( \"X changed value: {} at local time {} \\n \" , tsValue . value , tsValue . timestamp ); } } }; C++ (Handle-based) class Example { NT_Subscriber ySub ; double prev = 0 ; public : Example () { // get the default instance of NetworkTables NT_Inst inst = nt :: GetDefaultInstance (); // subscribe to the topic in \"datatable\" called \"Y\" ySub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/Y\" ), NT_DOUBLE , \"double\" ); } void Periodic () { // Get() can be used with simple change detection to the previous value double value = nt :: GetDouble ( ySub , 0.0 ); if ( value != prev ) { prev = value ; // save previous value fmt :: print ( \"X changed value: {} \\n \" , value ); } // ReadQueue() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( nt :: TimestampedDouble value : nt :: ReadQueueDouble ( ySub )) { fmt :: print ( \"X changed value: {} at local time {} \\n \" , tsValue . value , tsValue . timestamp ); } } }; Python class Example : def __init__ ( self ) -> None : # get the default instance of NetworkTables inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) self . prev = 0 def periodic ( self ): # get() can be used with simple change detection to the previous value value = self . ySub . get () if value != self . prev : self . prev = value # save previous value print ( \"X changed value: \" + value ) # readQueue() provides all value changes since the last call; # this way it's not possible to miss a change by polling too slowly for tsValue in self . ySub . readQueue (): print ( f \"X changed value: { tsValue . value } at local time { tsValue . time } \" ) # may not be necessary for robot programs if this class lives for # the length of the program def close ( self ): self . ySub . close () With a command-based robot, it’s also possible to use NetworkBooleanEvent to link boolean topic changes to callback actions (e.g. running commands). While these functions suffice for value changes on a single topic, they do not provide insight into changes to topics (when a topic is published or unpublished, or when a topic’s properties change) or network connection changes (e.g. when a client connects or disconnects). They also don’t provide a way to get in-order updates for value changes across multiple topics. For these needs, NetworkTables provides an event listener facility. The easiest way to use listeners is via NetworkTableInstance . For more automatic control over listener lifetime (particularly in C++), and to operate without a background thread, NetworkTables also provides separate classes for both polled listeners ( NetworkTableListenerPoller ), which store events into an internal queue that must be periodically read to get the queued events, and threaded listeners ( NetworkTableListener ), which call a callback function from a background thread. NetworkTableEvent All listener callbacks take a single NetworkTableEvent parameter, and similarly, reading a listener poller returns an array of NetworkTableEvent . The event contains information including what kind of event it is (e.g. a value update, a new topic, a network disconnect), the handle of the listener that caused the event to be generated, and more detailed information that depends on the type of the event (connection information for connection events, topic information for topic-related events, value data for value updates, and the log message for log message events). Using NetworkTableInstance to Listen for Changes The below example listens to various kinds of events using NetworkTableInstance . The listener callback provided to any of the addListener functions will be called asynchronously from a background thread when a matching event occurs. Warning Because the listener callback is called from a separate background thread, it’s important to use thread-safe synchronization approaches such as mutexes or atomics to pass data to/from the main code and the listener callback function. The addListener functions in NetworkTableInstance return a listener handle. This can be used to remove the listener later. Java public class Example { final DoubleSubscriber ySub ; // use an AtomicReference to make updating the value thread-safe final AtomicReference < Double > yValue = new AtomicReference < Double > (); // retain listener handles for later removal int connListenerHandle ; int valueListenerHandle ; int topicListenerHandle ; public Example () { // get the default instance of NetworkTables NetworkTableInstance inst = NetworkTableInstance . getDefault (); // add a connection listener; the first parameter will cause the // callback to be called immediately for any current connections connListenerHandle = inst . addConnectionListener ( true , event -> { if ( event . is ( NetworkTableEvent . Kind . kConnected )) { System . out . println ( \"Connected to \" + event . connInfo . remote_id ); } else if ( event . is ( NetworkTableEvent . Kind . kDisconnected )) { System . out . println ( \"Disconnected from \" + event . connInfo . remote_id ); } }); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); // add a listener to only value changes on the Y subscriber valueListenerHandle = inst . addListener ( ySub , EnumSet . of ( NetworkTableEvent . Kind . kValueAll ), event -> { // can only get doubles because it's a DoubleSubscriber, but // could check value.isDouble() here too yValue . set ( event . valueData . value . getDouble ()); }); // add a listener to see when new topics are published within datatable // the string array is an array of topic name prefixes. topicListenerHandle = inst . addListener ( new String [] { datatable . getPath () + \"/\" }, EnumSet . of ( NetworkTableEvent . Kind . kTopic ), event -> { if ( event . is ( NetworkTableEvent . Kind . kPublish )) { // topicInfo.name is the full topic name, e.g. \"/datatable/X\" System . out . println ( \"newly published \" + event . topicInfo . name ); } }); } public void periodic () { // get the latest value by reading the AtomicReference; set it to null // when we read to ensure we only get value changes Double value = yValue . getAndSet ( null ); if ( value != null ) { System . out . println ( \"got new value \" + value ); } } // may not be needed for robot programs if this class exists for the // lifetime of the program public void close () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); inst . removeListener ( topicListenerHandle ); inst . removeListener ( valueListenerHandle ); inst . removeListener ( connListenerHandle ); ySub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; // use a mutex to make updating the value and flag thread-safe wpi :: mutex mutex ; double yValue ; bool yValueUpdated = false ; // retain listener handles for later removal NT_Listener connListenerHandle ; NT_Listener valueListenerHandle ; NT_Listener topicListenerHandle ; public : Example () { // get the default instance of NetworkTables nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // add a connection listener; the first parameter will cause the // callback to be called immediately for any current connections connListenerHandle = inst . AddConnectionListener ( true , [] ( const nt :: Event & event ) { if ( event . Is ( nt :: EventFlags :: kConnected )) { fmt :: print ( \"Connected to {} \\n \" , event . GetConnectionInfo () -> remote_id ); } else if ( event . Is ( nt :: EventFlags :: kDisconnected )) { fmt :: print ( \"Disconnected from {} \\n \" , event . GetConnectionInfo () -> remote_id ); } }); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); // add a listener to only value changes on the Y subscriber valueListenerHandle = inst . AddListener ( ySub , nt :: EventFlags :: kValueAll , [ this ] ( const nt :: Event & event ) { // can only get doubles because it's a DoubleSubscriber, but // could check value.IsDouble() here too std :: scoped_lock lock { mutex }; yValue = event . GetValueData () -> value . GetDouble (); yValueUpdated = true ; }); // add a listener to see when new topics are published within datatable // the string array is an array of topic name prefixes. topicListenerHandle = inst . AddListener ( {{ fmt :: format ( \"{}/\" , datatable -> GetPath ())}}, nt :: EventFlags :: kTopic , [] ( const nt :: Event & event ) { if ( event . Is ( nt :: EventFlags :: kPublish )) { // name is the full topic name, e.g. \"/datatable/X\" fmt :: print ( \"newly published {} \\n \" , event . GetTopicInfo () -> name ); } }); } void Periodic () { // get the latest value by reading the value; set it to false // when we read to ensure we only get value changes wpi :: scoped_lock lock { mutex }; if ( yValueUpdated ) { yValueUpdated = false ; fmt :: print ( \"got new value {} \\n \" , yValue ); } } ~ Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); inst . RemoveListener ( connListenerHandle ); inst . RemoveListener ( valueListenerHandle ); inst . RemoveListener ( topicListenerHandle ); } }; Python import ntcore import threading class Example : def __init__ ( self ) -> None : # get the default instance of NetworkTables inst = ntcore . NetworkTableInstance . getDefault () # Use a mutex to ensure thread safety self . lock = threading . Lock () self . yValue = None # add a connection listener; the first parameter will cause the # callback to be called immediately for any current connections def _connect_cb ( event : ntcore . Event ): if event . is_ ( ntcore . EventFlags . kConnected ): print ( \"Connected to\" , event . data . remote_id ) elif event . is_ ( ntcore . EventFlags . kDisconnected ): print ( \"Disconnected from\" , event . data . remote_id ) self . connListenerHandle = inst . addConnectionListener ( True , _connect_cb ) # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) # add a listener to only value changes on the Y subscriber def _on_ysub ( event : ntcore . Event ): # can only get doubles because it's a DoubleSubscriber, but # could check value.isDouble() here too with self . lock : self . yValue = event . data . value . getDouble () self . valueListenerHandle = inst . addListener ( self . ySub , ntcore . EventFlags . kValueAll , _on_ysub ) # add a listener to see when new topics are published within datatable # the string array is an array of topic name prefixes. def _on_pub ( event : ntcore . Event ): if event . is_ ( ntcore . EventFlags . kPublish ): # topicInfo.name is the full topic name, e.g. \"/datatable/X\" print ( \"newly published\" , event . data . name ) self . topicListenerHandle = inst . addListener ( [ datatable . getPath () + \"/\" ], ntcore . EventFlags . kTopic , _on_pub ) def periodic ( self ): # get the latest value by reading the value; set it to null # when we read to ensure we only get value changes with self . lock : value , self . yValue = self . yValue , None if value is not None : print ( \"got new value\" , value ) # may not be needed for robot programs if this class exists for the # lifetime of the program def close ( self ): inst = ntcore . NetworkTableInstance . getDefault () inst . removeListener ( self . topicListenerHandle ) inst . removeListener ( self . valueListenerHandle ) inst . removeListener ( self . connListenerHandle ) self . ySub . close ()",
      "content_preview": "Listening for Changes A common use case for NetworkTables is where a coprocessor generates values that need to be sent to the robot. For example, imagine that some image processing code running on a coprocessor computes the heading and distance to a goal and sends those values to the robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/listening-for-change.html?present",
      "title": "Listening for Changes",
      "section": "NetworkTables",
      "language": "All",
      "content": "Listening for Changes A common use case for NetworkTables is where a coprocessor generates values that need to be sent to the robot. For example, imagine that some image processing code running on a coprocessor computes the heading and distance to a goal and sends those values to the robot. In this case it might be desirable for the robot program to be notified when new values arrive. There are a few different ways to detect that a topic’s value has changed; the easiest way is to periodically call a subscriber’s get() , readQueue() , or readQueueValues() function from the robot’s periodic loop, as shown below: Java public class Example { final DoubleSubscriber ySub ; double prev ; public Example () { // get the default instance of NetworkTables NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); } public void periodic () { // get() can be used with simple change detection to the previous value double value = ySub . get (); if ( value != prev ) { prev = value ; // save previous value System . out . println ( \"X changed value: \" + value ); } // readQueueValues() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( double iterVal : ySub . readQueueValues ()) { System . out . println ( \"X changed value: \" + iterVal ); } // readQueue() is similar to readQueueValues(), but provides timestamps // for each change as well for ( TimestampedDouble tsValue : ySub . readQueue ()) { System . out . println ( \"X changed value: \" + tsValue . value + \" at local time \" + tsValue . timestamp ); } } // may not be necessary for robot programs if this class lives for // the length of the program public void close () { ySub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; double prev = 0 ; public : Example () { // get the default instance of NetworkTables nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable -> GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); } void Periodic () { // Get() can be used with simple change detection to the previous value double value = ySub . Get (); if ( value != prev ) { prev = value ; // save previous value fmt :: print ( \"X changed value: {} \\n \" , value ); } // ReadQueueValues() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( double iterVal : ySub . ReadQueueValues ()) { fmt :: print ( \"X changed value: {} \\n \" , iterVal ); } // ReadQueue() is similar to ReadQueueValues(), but provides timestamps // for each change as well for ( nt :: TimestampedDouble tsValue : ySub . ReadQueue ()) { fmt :: print ( \"X changed value: {} at local time {} \\n \" , tsValue . value , tsValue . timestamp ); } } }; C++ (Handle-based) class Example { NT_Subscriber ySub ; double prev = 0 ; public : Example () { // get the default instance of NetworkTables NT_Inst inst = nt :: GetDefaultInstance (); // subscribe to the topic in \"datatable\" called \"Y\" ySub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/Y\" ), NT_DOUBLE , \"double\" ); } void Periodic () { // Get() can be used with simple change detection to the previous value double value = nt :: GetDouble ( ySub , 0.0 ); if ( value != prev ) { prev = value ; // save previous value fmt :: print ( \"X changed value: {} \\n \" , value ); } // ReadQueue() provides all value changes since the last call; // this way it's not possible to miss a change by polling too slowly for ( nt :: TimestampedDouble value : nt :: ReadQueueDouble ( ySub )) { fmt :: print ( \"X changed value: {} at local time {} \\n \" , tsValue . value , tsValue . timestamp ); } } }; Python class Example : def __init__ ( self ) -> None : # get the default instance of NetworkTables inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) self . prev = 0 def periodic ( self ): # get() can be used with simple change detection to the previous value value = self . ySub . get () if value != self . prev : self . prev = value # save previous value print ( \"X changed value: \" + value ) # readQueue() provides all value changes since the last call; # this way it's not possible to miss a change by polling too slowly for tsValue in self . ySub . readQueue (): print ( f \"X changed value: { tsValue . value } at local time { tsValue . time } \" ) # may not be necessary for robot programs if this class lives for # the length of the program def close ( self ): self . ySub . close () With a command-based robot, it’s also possible to use NetworkBooleanEvent to link boolean topic changes to callback actions (e.g. running commands). While these functions suffice for value changes on a single topic, they do not provide insight into changes to topics (when a topic is published or unpublished, or when a topic’s properties change) or network connection changes (e.g. when a client connects or disconnects). They also don’t provide a way to get in-order updates for value changes across multiple topics. For these needs, NetworkTables provides an event listener facility. The easiest way to use listeners is via NetworkTableInstance . For more automatic control over listener lifetime (particularly in C++), and to operate without a background thread, NetworkTables also provides separate classes for both polled listeners ( NetworkTableListenerPoller ), which store events into an internal queue that must be periodically read to get the queued events, and threaded listeners ( NetworkTableListener ), which call a callback function from a background thread. NetworkTableEvent All listener callbacks take a single NetworkTableEvent parameter, and similarly, reading a listener poller returns an array of NetworkTableEvent . The event contains information including what kind of event it is (e.g. a value update, a new topic, a network disconnect), the handle of the listener that caused the event to be generated, and more detailed information that depends on the type of the event (connection information for connection events, topic information for topic-related events, value data for value updates, and the log message for log message events). Using NetworkTableInstance to Listen for Changes The below example listens to various kinds of events using NetworkTableInstance . The listener callback provided to any of the addListener functions will be called asynchronously from a background thread when a matching event occurs. Warning Because the listener callback is called from a separate background thread, it’s important to use thread-safe synchronization approaches such as mutexes or atomics to pass data to/from the main code and the listener callback function. The addListener functions in NetworkTableInstance return a listener handle. This can be used to remove the listener later. Java public class Example { final DoubleSubscriber ySub ; // use an AtomicReference to make updating the value thread-safe final AtomicReference < Double > yValue = new AtomicReference < Double > (); // retain listener handles for later removal int connListenerHandle ; int valueListenerHandle ; int topicListenerHandle ; public Example () { // get the default instance of NetworkTables NetworkTableInstance inst = NetworkTableInstance . getDefault (); // add a connection listener; the first parameter will cause the // callback to be called immediately for any current connections connListenerHandle = inst . addConnectionListener ( true , event -> { if ( event . is ( NetworkTableEvent . Kind . kConnected )) { System . out . println ( \"Connected to \" + event . connInfo . remote_id ); } else if ( event . is ( NetworkTableEvent . Kind . kDisconnected )) { System . out . println ( \"Disconnected from \" + event . connInfo . remote_id ); } }); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); // add a listener to only value changes on the Y subscriber valueListenerHandle = inst . addListener ( ySub , EnumSet . of ( NetworkTableEvent . Kind . kValueAll ), event -> { // can only get doubles because it's a DoubleSubscriber, but // could check value.isDouble() here too yValue . set ( event . valueData . value . getDouble ()); }); // add a listener to see when new topics are published within datatable // the string array is an array of topic name prefixes. topicListenerHandle = inst . addListener ( new String [] { datatable . getPath () + \"/\" }, EnumSet . of ( NetworkTableEvent . Kind . kTopic ), event -> { if ( event . is ( NetworkTableEvent . Kind . kPublish )) { // topicInfo.name is the full topic name, e.g. \"/datatable/X\" System . out . println ( \"newly published \" + event . topicInfo . name ); } }); } public void periodic () { // get the latest value by reading the AtomicReference; set it to null // when we read to ensure we only get value changes Double value = yValue . getAndSet ( null ); if ( value != null ) { System . out . println ( \"got new value \" + value ); } } // may not be needed for robot programs if this class exists for the // lifetime of the program public void close () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); inst . removeListener ( topicListenerHandle ); inst . removeListener ( valueListenerHandle ); inst . removeListener ( connListenerHandle ); ySub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; // use a mutex to make updating the value and flag thread-safe wpi :: mutex mutex ; double yValue ; bool yValueUpdated = false ; // retain listener handles for later removal NT_Listener connListenerHandle ; NT_Listener valueListenerHandle ; NT_Listener topicListenerHandle ; public : Example () { // get the default instance of NetworkTables nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // add a connection listener; the first parameter will cause the // callback to be called immediately for any current connections connListenerHandle = inst . AddConnectionListener ( true , [] ( const nt :: Event & event ) { if ( event . Is ( nt :: EventFlags :: kConnected )) { fmt :: print ( \"Connected to {} \\n \" , event . GetConnectionInfo () -> remote_id ); } else if ( event . Is ( nt :: EventFlags :: kDisconnected )) { fmt :: print ( \"Disconnected from {} \\n \" , event . GetConnectionInfo () -> remote_id ); } }); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" ySub = datatable . GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); // add a listener to only value changes on the Y subscriber valueListenerHandle = inst . AddListener ( ySub , nt :: EventFlags :: kValueAll , [ this ] ( const nt :: Event & event ) { // can only get doubles because it's a DoubleSubscriber, but // could check value.IsDouble() here too std :: scoped_lock lock { mutex }; yValue = event . GetValueData () -> value . GetDouble (); yValueUpdated = true ; }); // add a listener to see when new topics are published within datatable // the string array is an array of topic name prefixes. topicListenerHandle = inst . AddListener ( {{ fmt :: format ( \"{}/\" , datatable -> GetPath ())}}, nt :: EventFlags :: kTopic , [] ( const nt :: Event & event ) { if ( event . Is ( nt :: EventFlags :: kPublish )) { // name is the full topic name, e.g. \"/datatable/X\" fmt :: print ( \"newly published {} \\n \" , event . GetTopicInfo () -> name ); } }); } void Periodic () { // get the latest value by reading the value; set it to false // when we read to ensure we only get value changes wpi :: scoped_lock lock { mutex }; if ( yValueUpdated ) { yValueUpdated = false ; fmt :: print ( \"got new value {} \\n \" , yValue ); } } ~ Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); inst . RemoveListener ( connListenerHandle ); inst . RemoveListener ( valueListenerHandle ); inst . RemoveListener ( topicListenerHandle ); } }; Python import ntcore import threading class Example : def __init__ ( self ) -> None : # get the default instance of NetworkTables inst = ntcore . NetworkTableInstance . getDefault () # Use a mutex to ensure thread safety self . lock = threading . Lock () self . yValue = None # add a connection listener; the first parameter will cause the # callback to be called immediately for any current connections def _connect_cb ( event : ntcore . Event ): if event . is_ ( ntcore . EventFlags . kConnected ): print ( \"Connected to\" , event . data . remote_id ) elif event . is_ ( ntcore . EventFlags . kDisconnected ): print ( \"Disconnected from\" , event . data . remote_id ) self . connListenerHandle = inst . addConnectionListener ( True , _connect_cb ) # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) # add a listener to only value changes on the Y subscriber def _on_ysub ( event : ntcore . Event ): # can only get doubles because it's a DoubleSubscriber, but # could check value.isDouble() here too with self . lock : self . yValue = event . data . value . getDouble () self . valueListenerHandle = inst . addListener ( self . ySub , ntcore . EventFlags . kValueAll , _on_ysub ) # add a listener to see when new topics are published within datatable # the string array is an array of topic name prefixes. def _on_pub ( event : ntcore . Event ): if event . is_ ( ntcore . EventFlags . kPublish ): # topicInfo.name is the full topic name, e.g. \"/datatable/X\" print ( \"newly published\" , event . data . name ) self . topicListenerHandle = inst . addListener ( [ datatable . getPath () + \"/\" ], ntcore . EventFlags . kTopic , _on_pub ) def periodic ( self ): # get the latest value by reading the value; set it to null # when we read to ensure we only get value changes with self . lock : value , self . yValue = self . yValue , None if value is not None : print ( \"got new value\" , value ) # may not be needed for robot programs if this class exists for the # lifetime of the program def close ( self ): inst = ntcore . NetworkTableInstance . getDefault () inst . removeListener ( self . topicListenerHandle ) inst . removeListener ( self . valueListenerHandle ) inst . removeListener ( self . connListenerHandle ) self . ySub . close ()",
      "content_preview": "Listening for Changes A common use case for NetworkTables is where a coprocessor generates values that need to be sent to the robot. For example, imagine that some image processing code running on a coprocessor computes the heading and distance to a goal and sends those values to the robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/index.html?present",
      "title": "NetworkTables",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables This section outlines the details of using the NetworkTables (v4) API to communicate information across the robot network. Important The code examples in this section are not intended for the user to copy-paste. Ensure that the following documentation is thoroughly read and the API ( Java , C++ , Python ) is consulted when necessary. What is NetworkTables NetworkTables Tables and Topics Publishing and Subscribing to a Topic NetworkTables Instances NetworkTables Networking Listening for Changes Writing a Simple NetworkTables Robot Program Creating a Client-side Program Migrating from NetworkTables 3.0 to NetworkTables 4.0 Reading Array Values Published by NetworkTables",
      "content_preview": "NetworkTables This section outlines the details of using the NetworkTables (v4) API to communicate information across the robot network. Important The code examples in this section are not intended for the user to copy-paste."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/publish-and-subscribe.html",
      "title": "Publishing and Subscribing to a Topic",
      "section": "NetworkTables",
      "language": "All",
      "content": "Publishing and Subscribing to a Topic Publishing to a Topic In order to create a topic and publish values to it, it’s necessary to create a publisher . NetworkTable publishers are represented as type-specific Publisher objects (e.g. BooleanPublisher : Java , C++ , Python ). Publishers are only active as long as the Publisher object exists. Typically you want to keep publishing longer than the local scope of a function, so it’s necessary to store the Publisher object somewhere longer term, e.g. in an instance variable. In Java, the close() method needs be called to stop publishing; in C++ this is handled by the destructor. C++ publishers are moveable and non-copyable. In Python the close() method should be called to stop publishing, but it will also be closed when the object is garbage collected. In the handle-based APIs, there is only the non-type-specific NT_Publisher handle; the user is responsible for keeping track of the type of the publisher and using the correct type-specific set methods. Publishing values is done via a set() operation. By default, this operation uses the current time, but a timestamp may optionally be specified. Specifying a timestamp can be useful when multiple values should have the same update timestamp. The timestamp units are integer microseconds (see example code for how to get a current timestamp that is consistent with the library). Java public class Example { // the publisher is an instance variable so its lifetime matches that of the class final DoublePublisher dblPub ; public Example ( DoubleTopic dblTopic ) { // start publishing; the return value must be retained (in this case, via // an instance variable) dblPub = dblTopic . publish (); // publish options may be specified using PubSubOption dblPub = dblTopic . publish ( PubSubOption . keepDuplicates ( true )); // publishEx provides additional options such as setting initial // properties and using a custom type string. Using a custom type string for // types other than raw and string is not recommended. The properties string // must be a JSON map. dblPub = dblTopic . publishEx ( \"double\" , \"{\\\"myprop\\\": 5}\" ); } public void periodic () { // publish a default value dblPub . setDefault ( 0.0 ); // publish a value with current timestamp dblPub . set ( 1.0 ); dblPub . set ( 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; NetworkTablesJNI.now() can // be used to get the current time. On the roboRIO, this is the same as // the FPGA timestamp (e.g. RobotController.getFPGATime()) long time = NetworkTablesJNI . now (); dblPub . set ( 3.0 , time ); // publishers also implement the appropriate Consumer functional interface; // this example assumes void myFunc(DoubleConsumer func) exists myFunc ( dblPub ); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop publishing public void close () { // stop publishing dblPub . close (); } } C++ class Example { // the publisher is an instance variable so its lifetime matches that of the class // publishing is automatically stopped when dblPub is destroyed by the class destructor nt :: DoublePublisher dblPub ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start publishing; the return value must be retained (in this case, via // an instance variable) dblPub = dblTopic . Publish (); // publish options may be specified using PubSubOptions dblPub = dblTopic . Publish ({. keepDuplicates = true }); // PublishEx provides additional options such as setting initial // properties and using a custom type string. Using a custom type string for // types other than raw and string is not recommended. The properties must // be a JSON map. dblPub = dblTopic . PublishEx ( \"double\" , {{ \"myprop\" , 5 }}); } void Periodic () { // publish a default value dblPub . SetDefault ( 0.0 ); // publish a value with current timestamp dblPub . Set ( 1.0 ); dblPub . Set ( 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; nt::Now() can // be used to get the current time. int64_t time = nt :: Now (); dblPub . Set ( 3.0 , time ); } }; C++ (Handle-based) class Example { // the publisher is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Publisher dblPub ; public : explicit Example ( NT_Topic dblTopic ) { // start publishing. It's recommended that the type string be standard // for all types except string and raw. dblPub = nt :: Publish ( dblTopic , NT_DOUBLE , \"double\" ); // publish options may be specified using PubSubOptions dblPub = nt :: Publish ( dblTopic , NT_DOUBLE , \"double\" , {. keepDuplicates = true }); // PublishEx allows setting initial properties. The // properties must be a JSON map. dblPub = nt :: PublishEx ( dblTopic , NT_DOUBLE , \"double\" , {{ \"myprop\" , 5 }}); } void Periodic () { // publish a default value nt :: SetDefaultDouble ( dblPub , 0.0 ); // publish a value with current timestamp nt :: SetDouble ( dblPub , 1.0 ); nt :: SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; nt::Now() can // be used to get the current time. int64_t time = nt :: Now (); nt :: SetDouble ( dblPub , 3.0 , time ); } ~ Example () { // stop publishing nt :: Unpublish ( dblPub ); } }; C // This code assumes that a NT_Topic dblTopic variable already exists // start publishing. It's recommended that the type string be standard // for all types except string and raw. NT_Publisher dblPub = NT_Publish ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // publish options may be specified struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true NT_Publisher dblPub = NT_Publish ( dblTopic , NT_DOUBLE , \"double\" , & options ); // PublishEx allows setting initial properties. The properties string must // be a JSON map. NT_Publisher dblPub = NT_PublishEx ( dblTopic , NT_DOUBLE , \"double\" , \"{ \\\" myprop \\\" , 5}\" , NULL , 0 ); // publish a default value NT_SetDefaultDouble ( dblPub , 0.0 ); // publish a value with current timestamp NT_SetDouble ( dblPub , 1.0 ); NT_SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; NT_Now() can // be used to get the current time. int64_t time = NT_Now (); NT_SetDouble ( dblPub , 3.0 , time ); // stop publishing NT_Unpublish ( dblPub ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start publishing; the return value must be retained (in this case, via # an instance variable) self . dblPub = dblTopic . publish () # publish options may be specified using PubSubOption self . dblPub = dblTopic . publish ( ntcore . PubSubOptions ( keepDuplicates = True )) # publishEx provides additional options such as setting initial # properties and using a custom type string. Using a custom type string for # types other than raw and string is not recommended. The properties string # must be a JSON map. self . dblPub = dblTopic . publishEx ( \"double\" , '{\"myprop\": 5}' ) def periodic ( self ): # publish a default value self . dblPub . setDefault ( 0.0 ) # publish a value with current timestamp self . dblPub . set ( 1.0 ) self . dblPub . set ( 2.0 , 0 ) # 0 = use current time # publish a value with a specific timestamp with microsecond resolution. # On the roboRIO, this is the same as the FPGA timestamp (e.g. # RobotController.getFPGATime()) self . dblPub . set ( 3.0 , ntcore . _now ()) # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop publishing def close ( self ): # stop publishing self . dblPub . close () Subscribing to a Topic A subscriber receives value updates made to a topic. Similar to publishers, NetworkTable subscribers are represented as type-specific Subscriber classes (e.g. BooleanSubscriber : Java , C++ , Python ) that must be stored somewhere to continue subscribing. Subscribers have a range of different ways to read received values. It’s possible to just read the most recent value using get() , read the most recent value, along with its timestamp, using getAtomic() , or get an array of all value changes since the last call using readQueue() or readQueueValues() . Java public class Example { // the subscriber is an instance variable so its lifetime matches that of the class final DoubleSubscriber dblSub ; public Example ( DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblSub = dblTopic . subscribe ( 0.0 ); // subscribe options may be specified using PubSubOption dblSub = dblTopic . subscribe ( 0.0 , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // subscribeEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . subscribeEx ( \"double\" , 0.0 ); } public void periodic () { // simple get of most recent value; if no value has been published, // returns the default value passed to the subscribe() function double val = dblSub . get (); // get the most recent value; if no value has been published, returns // the passed-in default value double val = dblSub . get ( - 1.0 ); // subscribers also implement the appropriate Supplier interface, e.g. DoubleSupplier double val = dblSub . getAsDouble (); // get the most recent value, along with its timestamp TimestampedDouble tsVal = dblSub . getAtomic (); // read all value changes since the last call to readQueue/readQueueValues // readQueue() returns timestamps; readQueueValues() does not. TimestampedDouble [] tsUpdates = dblSub . readQueue (); double [] valUpdates = dblSub . readQueueValues (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // stop subscribing dblSub . close (); } } C++ class Example { // the subscriber is an instance variable so its lifetime matches that of the class // subscribing is automatically stopped when dblSub is destroyed by the class destructor nt :: DoubleSubscriber dblSub ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblSub = dblTopic . Subscribe ( 0.0 ); // subscribe options may be specified using PubSubOptions dblSub = dblTopic . subscribe ( 0.0 , {. pollStorage = 10 , . keepDuplicates = true }); // SubscribeEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . SubscribeEx ( \"double\" , 0.0 ); } void Periodic () { // simple get of most recent value; if no value has been published, // returns the default value passed to the Subscribe() function double val = dblSub . Get (); // get the most recent value; if no value has been published, returns // the passed-in default value double val = dblSub . Get ( -1.0 ); // get the most recent value, along with its timestamp nt :: TimestampedDouble tsVal = dblSub . GetAtomic (); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. std :: vector < nt :: TimestampedDouble > tsUpdates = dblSub . ReadQueue (); std :: vector < double > valUpdates = dblSub . ReadQueueValues (); } }; C++ (Handle-based) class Example { // the subscriber is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Subscriber dblSub ; public : explicit Example ( NT_Topic dblTopic ) { // start subscribing // Using a custom type string for types other than raw and string is not recommended. dblSub = nt :: Subscribe ( dblTopic , NT_DOUBLE , \"double\" ); // subscribe options may be specified using PubSubOptions dblSub = nt :: Subscribe ( dblTopic , NT_DOUBLE , \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // get the most recent value; if no value has been published, returns // the passed-in default value double val = nt :: GetDouble ( dblSub , 0.0 ); // get the most recent value, along with its timestamp nt :: TimestampedDouble tsVal = nt :: GetAtomic ( dblSub , 0.0 ); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. std :: vector < nt :: TimestampedDouble > tsUpdates = nt :: ReadQueueDouble ( dblSub ); std :: vector < double > valUpdates = nt :: ReadQueueValuesDouble ( dblSub ); } ~ Example () { // stop subscribing nt :: Unsubscribe ( dblSub ); } C // This code assumes that a NT_Topic dblTopic variable already exists // start subscribing // Using a custom type string for types other than raw and string is not recommended. NT_Subscriber dblSub = NT_Subscribe ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true options . pollStorage = 10 ; NT_Subscriber dblSub = NT_Subscribe ( dblTopic , NT_DOUBLE , \"double\" , & options ); // get the most recent value; if no value has been published, returns // the passed-in default value double val = NT_GetDouble ( dblSub , 0.0 ); // get the most recent value, along with its timestamp struct NT_TimestampedDouble tsVal ; NT_GetAtomic ( dblSub , 0.0 , & tsVal ); NT_DisposeTimestamped ( & tsVal ); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. size_t tsUpdatesLen ; struct NT_TimestampedDouble * tsUpdates = NT_ReadQueueDouble ( dblSub , & tsUpdatesLen ); NT_FreeQueueDouble ( tsUpdates , tsUpdatesLen ); size_t valUpdatesLen ; double * valUpdates = NT_ReadQueueValuesDouble ( dblSub , & valUpdatesLen ); NT_FreeDoubleArray ( valUpdates , valUpdatesLen ); // stop subscribing NT_Unsubscribe ( dblSub ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start subscribing; the return value must be retained. # the parameter is the default value if no value is available when get() is called self . dblSub = dblTopic . subscribe ( 0.0 ) # subscribe options may be specified using PubSubOption self . dblSub = dblTopic . subscribe ( 0.0 , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # subscribeEx provides the options of using a custom type string. # Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . subscribeEx ( \"double\" , 0.0 ) def periodic ( self ): # simple get of most recent value; if no value has been published, # returns the default value passed to the subscribe() function val = self . dblSub . get () # get the most recent value; if no value has been published, returns # the passed-in default value val = self . dblSub . get ( - 1.0 ) # get the most recent value, along with its timestamp tsVal = self . dblSub . getAtomic () # read all value changes since the last call to readQueue # readQueue() returns timestamps tsUpdates = self . dblSub . readQueue () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # stop subscribing self . dblSub . close () Using Entry to Both Subscribe and Publish An entry is a combined publisher and subscriber. The subscriber is always active, but the publisher is not created until a publish operation is performed (e.g. a value is “set”, aka published, on the entry). This may be more convenient than maintaining a separate publisher and subscriber. Similar to publishers and subscribers, NetworkTable entries are represented as type-specific Entry classes (e.g. BooleanEntry : Java , C++ , Python ) that must be retained to continue subscribing (and publishing). Java public class Example { // the entry is an instance variable so its lifetime matches that of the class final DoubleEntry dblEntry ; public Example ( DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblEntry = dblTopic . getEntry ( 0.0 ); // publish and subscribe options may be specified using PubSubOption dblEntry = dblTopic . getEntry ( 0.0 , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // getEntryEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblEntry = dblTopic . getEntryEx ( \"double\" , 0.0 ); } public void periodic () { // entries support all the same methods as subscribers: double val = dblEntry . get (); double val = dblEntry . get ( - 1.0 ); double val = dblEntry . getAsDouble (); TimestampedDouble tsVal = dblEntry . getAtomic (); TimestampedDouble [] tsUpdates = dblEntry . readQueue (); double [] valUpdates = dblEntry . readQueueValues (); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created dblEntry . setDefault ( 0.0 ); dblEntry . set ( 1.0 ); dblEntry . set ( 2.0 , 0 ); // 0 = use current time long time = NetworkTablesJNI . now (); dblEntry . set ( 3.0 , time ); myFunc ( dblEntry ); } public void unpublish () { // you can stop publishing while keeping the subscriber alive dblEntry . unpublish (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // stop subscribing/publishing dblEntry . close (); } } C++ class Example { // the entry is an instance variable so its lifetime matches that of the class // subscribing/publishing is automatically stopped when dblEntry is destroyed by // the class destructor nt :: DoubleEntry dblEntry ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblEntry = dblTopic . GetEntry ( 0.0 ); // publish and subscribe options may be specified using PubSubOptions dblEntry = dblTopic . GetEntry ( 0.0 , {. pollStorage = 10 , . keepDuplicates = true }); // GetEntryEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblEntry = dblTopic . GetEntryEx ( \"double\" , 0.0 ); } void Periodic () { // entries support all the same methods as subscribers: double val = dblEntry . Get (); double val = dblEntry . Get ( -1.0 ); nt :: TimestampedDouble tsVal = dblEntry . GetAtomic (); std :: vector < nt :: TimestampedDouble > tsUpdates = dblEntry . ReadQueue (); std :: vector < double > valUpdates = dblEntry . ReadQueueValues (); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created dblEntry . SetDefault ( 0.0 ); dblEntry . Set ( 1.0 ); dblEntry . Set ( 2.0 , 0 ); // 0 = use current time int64_t time = nt :: Now (); dblEntry . Set ( 3.0 , time ); } void Unpublish () { // you can stop publishing while keeping the subscriber alive dblEntry . Unpublish (); } }; C++ (Handle-based) class Example { // the entry is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Entry dblEntry ; public : explicit Example ( NT_Topic dblTopic ) { // start subscribing // Using a custom type string for types other than raw and string is not recommended. dblEntry = nt :: GetEntry ( dblTopic , NT_DOUBLE , \"double\" ); // publish and subscribe options may be specified using PubSubOptions dblEntry = nt :: GetEntry ( dblTopic , NT_DOUBLE , \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // entries support all the same methods as subscribers: double val = nt :: GetDouble ( dblEntry , 0.0 ); nt :: TimestampedDouble tsVal = nt :: GetAtomic ( dblEntry , 0.0 ); std :: vector < nt :: TimestampedDouble > tsUpdates = nt :: ReadQueueDouble ( dblEntry ); std :: vector < double > valUpdates = nt :: ReadQueueValuesDouble ( dblEntry ); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created nt :: SetDefaultDouble ( dblPub , 0.0 ); nt :: SetDouble ( dblPub , 1.0 ); nt :: SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time int64_t time = nt :: Now (); nt :: SetDouble ( dblPub , 3.0 , time ); } void Unpublish () { // you can stop publishing while keeping the subscriber alive nt :: Unpublish ( dblEntry ); } ~ Example () { // stop publishing and subscribing nt :: ReleaseEntry ( dblEntry ); } C // This code assumes that a NT_Topic dblTopic variable already exists // start subscribing // Using a custom type string for types other than raw and string is not recommended. NT_Entry dblEntry = NT_GetEntryEx ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // publish and subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true options . pollStorage = 10 ; NT_Entry dblEntry = NT_GetEntryEx ( dblTopic , NT_DOUBLE , \"double\" , & options ); // entries support all the same methods as subscribers: double val = NT_GetDouble ( dblEntry , 0.0 ); struct NT_TimestampedDouble tsVal ; NT_GetAtomic ( dblEntry , 0.0 , & tsVal ); NT_DisposeTimestamped ( & tsVal ); size_t tsUpdatesLen ; struct NT_TimestampedDouble * tsUpdates = NT_ReadQueueDouble ( dblEntry , & tsUpdatesLen ); NT_FreeQueueDouble ( tsUpdates , tsUpdatesLen ); size_t valUpdatesLen ; double * valUpdates = NT_ReadQueueValuesDouble ( dblEntry , & valUpdatesLen ); NT_FreeDoubleArray ( valUpdates , valUpdatesLen ); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created NT_SetDefaultDouble ( dblPub , 0.0 ); NT_SetDouble ( dblPub , 1.0 ); NT_SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time int64_t time = NT_Now (); NT_SetDouble ( dblPub , 3.0 , time ); // you can stop publishing while keeping the subscriber alive // it's not necessary to call this before NT_ReleaseEntry() NT_Unpublish ( dblEntry ); // stop subscribing NT_ReleaseEntry ( dblEntry ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start subscribing; the return value must be retained. # the parameter is the default value if no value is available when get() is called self . dblEntry = dblTopic . getEntry ( 0.0 ) # publish and subscribe options may be specified using PubSubOption self . dblEntry = dblTopic . getEntry ( 0.0 , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # getEntryEx provides the options of using a custom type string. # Using a custom type string for types other than raw and string is not recommended. self . dblEntry = dblTopic . getEntryEx ( \"double\" , 0.0 ) def periodic ( self ): # entries support all the same methods as subscribers: val = self . dblEntry . get () val = self . dblEntry . get ( - 1.0 ) val = self . dblEntry . getAsDouble () tsVal = self . dblEntry . getAtomic () tsUpdates = self . dblEntry . readQueue () # entries also support all the same methods as publishers; the first time # one of these is called, an internal publisher is automatically created self . dblEntry . setDefault ( 0.0 ) self . dblEntry . set ( 1.0 ) self . dblEntry . set ( 2.0 , 0 ) # 0 = use current time time = ntcore . _now () self . dblEntry . set ( 3.0 , time ) def unpublish ( self ): # you can stop publishing while keeping the subscriber alive self . dblEntry . unpublish () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # stop subscribing/publishing self . dblEntry . close () Using GenericEntry, GenericPublisher, and GenericSubscriber For the most robust code, using the type-specific Publisher, Subscriber, and Entry classes is recommended, but in some cases it may be easier to write code that uses type-specific get and set function calls instead of having the NetworkTables type be exposed via the class (object) type. The GenericPublisher ( Java , C++ , Python ), GenericSubscriber ( Java , C++ , Python ), and GenericEntry ( Java , C++ , Python ) classes enable this approach. Java public class Example { // the entry is an instance variable so its lifetime matches that of the class final GenericPublisher pub ; final GenericSubscriber sub ; final GenericEntry entry ; public Example ( Topic topic ) { // start subscribing; the return value must be retained. // when publishing, a type string must be provided pub = topic . genericPublish ( \"double\" ); // subscribing can optionally include a type string // unlike type-specific subscribers, no default value is provided sub = topic . genericSubscribe (); sub = topic . genericSubscribe ( \"double\" ); // when getting an entry, the type string is also optional; if not provided // the publisher data type will be determined by the first publisher-creating call entry = topic . getGenericEntry (); entry = topic . getGenericEntry ( \"double\" ); // publish and subscribe options may be specified using PubSubOption pub = topic . genericPublish ( \"double\" , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); sub = topic . genericSubscribe ( PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); entry = topic . getGenericEntry ( PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // genericPublishEx provides the option of setting initial properties. pub = topic . genericPublishEx ( \"double\" , \"{\\\"retained\\\": true}\" , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); } public void periodic () { // generic subscribers and entries have typed get operations; a default must be provided double val = sub . getDouble ( - 1.0 ); double val = entry . getDouble ( - 1.0 ); // they also support an untyped get (also meets Supplier<NetworkTableValue> interface) NetworkTableValue val = sub . get (); NetworkTableValue val = entry . get (); // they also support readQueue NetworkTableValue [] updates = sub . readQueue (); NetworkTableValue [] updates = entry . readQueue (); // publishers and entries have typed set operations; these return false if the // topic already exists with a mismatched type boolean success = pub . setDefaultDouble ( 1.0 ); boolean success = pub . setBoolean ( true ); // they also implement a generic set and Consumer<NetworkTableValue> interface boolean success = entry . set ( NetworkTableValue . makeDouble (...)); boolean success = entry . accept ( NetworkTableValue . makeDouble (...)); } public void unpublish () { // you can stop publishing an entry while keeping the subscriber alive entry . unpublish (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing/publishing public void close () { pub . close (); sub . close (); entry . close (); } } C++ class Example { // the entry is an instance variable so its lifetime matches that of the class // subscribing/publishing is automatically stopped when dblEntry is destroyed by // the class destructor nt :: GenericPublisher pub ; nt :: GenericSubscriber sub ; nt :: GenericEntry entry ; public : Example ( nt :: Topic topic ) { // start subscribing; the return value must be retained. // when publishing, a type string must be provided pub = topic . GenericPublish ( \"double\" ); // subscribing can optionally include a type string // unlike type-specific subscribers, no default value is provided sub = topic . GenericSubscribe (); sub = topic . GenericSubscribe ( \"double\" ); // when getting an entry, the type string is also optional; if not provided // the publisher data type will be determined by the first publisher-creating call entry = topic . GetEntry (); entry = topic . GetEntry ( \"double\" ); // publish and subscribe options may be specified using PubSubOptions pub = topic . GenericPublish ( \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); sub = topic . GenericSubscribe ( {. pollStorage = 10 , . keepDuplicates = true }); entry = topic . GetGenericEntry ( {. pollStorage = 10 , . keepDuplicates = true }); // genericPublishEx provides the option of setting initial properties. pub = topic . genericPublishEx ( \"double\" , {{ \"myprop\" , 5 }}, {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // generic subscribers and entries have typed get operations; a default must be provided double val = sub . GetDouble ( -1.0 ); double val = entry . GetDouble ( -1.0 ); // they also support an untyped get nt :: NetworkTableValue val = sub . Get (); nt :: NetworkTableValue val = entry . Get (); // they also support readQueue std :: vector < nt :: NetworkTableValue > updates = sub . ReadQueue (); std :: vector < nt :: NetworkTableValue > updates = entry . ReadQueue (); // publishers and entries have typed set operations; these return false if the // topic already exists with a mismatched type bool success = pub . SetDefaultDouble ( 1.0 ); bool success = pub . SetBoolean ( true ); // they also implement a generic set and Consumer<NetworkTableValue> interface bool success = entry . Set ( nt :: NetworkTableValue :: MakeDouble (...)); } void Unpublish () { // you can stop publishing an entry while keeping the subscriber alive entry . Unpublish (); } }; Python class Example : def __init__ ( self , topic : ntcore . Topic ): # start subscribing; the return value must be retained. # when publishing, a type string must be provided self . pub = topic . genericPublish ( \"double\" ) # subscribing can optionally include a type string # unlike type-specific subscribers, no default value is provided self . sub = topic . genericSubscribe () self . sub = topic . genericSubscribe ( \"double\" ) # when getting an entry, the type string is also optional; if not provided # the publisher data type will be determined by the first publisher-creating call self . entry = topic . getGenericEntry () self . entry = topic . getGenericEntry ( \"double\" ) # publish and subscribe options may be specified using PubSubOption self . pub = topic . genericPublish ( \"double\" , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) self . sub = topic . genericSubscribe ( ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) self . entry = topic . getGenericEntry ( ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # genericPublishEx provides the option of setting initial properties. self . pub = topic . genericPublishEx ( \"double\" , '{\"retained\": true}' , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ), ) def periodic ( self ): # generic subscribers and entries have typed get operations; a default must be provided val = self . sub . getDouble ( - 1.0 ) val = self . entry . getDouble ( - 1.0 ) # they also support an untyped get (also meets Supplier<NetworkTableValue> interface) val = self . sub . get () val = self . entry . get () # they also support readQueue updates = self . sub . readQueue () updates = self . entry . readQueue () # publishers and entries have typed set operations; these return false if the # topic already exists with a mismatched type success = self . pub . setDefaultDouble ( 1.0 ) success = self . pub . setBoolean ( True ) # they also implement a generic set success = self . entry . set ( ntcore . Value . makeDouble ( ... )) def unpublish ( self ): # you can stop publishing an entry while keeping the subscriber alive self . entry . unpublish () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing/publishing def close ( self ): self . pub . close () self . sub . close () self . entry . close () Subscribing to Multiple Topics While in most cases it’s only necessary to subscribe to individual topics, it is sometimes useful (e.g. in dashboard applications) to subscribe and get value updates for changes to multiple topics. Listeners (see Listening for Changes ) can be used directly, but creating a MultiSubscriber ( Java , C++ ) allows specifying subscription options and reusing the same subscriber for multiple listeners. Java public class Example { // the subscriber is an instance variable so its lifetime matches that of the class final MultiSubscriber multiSub ; final NetworkTableListenerPoller poller ; public Example ( NetworkTableInstance inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = new MultiSubscriber ( inst , new String [] { \"/table1/\" , \"/table2/\" }); // subscribe options may be specified using PubSubOption multiSub = new MultiSubscriber ( inst , new String [] { \"/table1/\" , \"/table2/\" }, PubSubOption . keepDuplicates ( true )); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = new NetworkTableListenerPoller ( inst ); poller . addListener ( multiSub , EnumSet . of ( NetworkTableEvent . Kind . kValueAll )); } public void periodic () { // read value events NetworkTableEvent [] events = poller . readQueue (); for ( NetworkTableEvent event : events ) { NetworkTableValue value = event . valueData . value ; } } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // close listener poller . close (); // stop subscribing multiSub . close (); } } C++ class Example { // the subscriber is an instance variable so its lifetime matches that of the class // subscribing is automatically stopped when multiSub is destroyed by the class destructor nt :: MultiSubscriber multiSub ; nt :: NetworkTableListenerPoller poller ; public : explicit Example ( nt :: NetworkTableInstance inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = nt :: MultiSubscriber { inst , {{ \"/table1/\" , \"/table2/\" }}}; // subscribe options may be specified using PubSubOption multiSub = nt :: MultiSubscriber { inst , {{ \"/table1/\" , \"/table2/\" }}, {. keepDuplicates = true }}; // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = nt :: NetworkTableListenerPoller { inst }; poller . AddListener ( multiSub , nt :: EventFlags :: kValueAll ); } void Periodic () { // read value events std :: vector < nt :: Event > events = poller . ReadQueue (); for ( auto && event : events ) { nt :: NetworkTableValue value = event . GetValueEventData () -> value ; } } }; C++ (Handle-based) class Example { // the subscriber is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_MultiSubscriber multiSub ; NT_ListenerPoller poller ; public : explicit Example ( NT_Inst inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = nt :: SubscribeMultiple ( inst , {{ \"/table1/\" , \"/table2/\" }}); // subscribe options may be specified using PubSubOption multiSub = nt :: SubscribeMultiple ( inst , {{ \"/table1/\" , \"/table2/\" }}, {. keepDuplicates = true }); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = nt :: CreateListenerPoller ( inst ); nt :: AddPolledListener ( poller , multiSub , nt :: EventFlags :: kValueAll ); } void Periodic () { // read value events std :: vector < nt :: Event > events = nt :: ReadListenerQueue ( poller ); for ( auto && event : events ) { nt :: NetworkTableValue value = event . GetValueEventData () -> value ; } } ~ Example () { // close listener nt :: DestroyListenerPoller ( poller ); // stop subscribing nt :: UnsubscribeMultiple ( multiSub ); } C // This code assumes that a NT_Inst inst variable already exists // start subscribing // provide an array of topic name prefixes struct NT_String prefixes [ 2 ]; prefixes [ 0 ]. str = \"/table1/\" ; prefixes [ 0 ]. len = 8 ; prefixes [ 1 ]. str = \"/table2/\" ; prefixes [ 1 ]. len = 8 ; NT_MultiSubscriber multiSub = NT_SubscribeMultiple ( inst , prefixes , 2 , NULL , 0 ); // subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true NT_MultiSubscriber multiSub = NT_SubscribeMultiple ( inst , prefixes , 2 , & options ); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) NT_ListenerPoller poller = NT_CreateListenerPoller ( inst ); NT_AddPolledListener ( poller , multiSub , NT_EVENT_VALUE_ALL ); // read value events size_t eventsLen ; struct NT_Event * events = NT_ReadListenerQueue ( poller , & eventsLen ); for ( size_t i = 0 ; i < eventsLen ; i ++ ) { NT_Value * value = & events [ i ]. data . valueData . value ; } NT_DisposeEventArray ( events , eventsLen ); // close listener NT_DestroyListenerPoller ( poller ); // stop subscribing NT_UnsubscribeMultiple ( multiSub ); Python class Example : def __init__ ( self , inst : ntcore . NetworkTableInstance ): # start subscribing; the return value must be retained. # provide an array of topic name prefixes self . multiSub = ntcore . MultiSubscriber ( inst , [ \"/table1/\" , \"/table2/\" ]) # subscribe options may be specified using PubSubOption self . multiSub = ntcore . MultiSubscriber ( inst , [ \"/table1/\" , \"/table2/\" ], ntcore . PubSubOptions ( keepDuplicates = True ) ) # to get value updates from a MultiSubscriber, it's necessary to create a listener # (see the listener documentation for more details) self . poller = ntcore . NetworkTableListenerPoller ( inst ) self . poller . addListener ( self . multiSub , ntcore . EventFlags . kValueAlls ) def periodic ( self ): # read value events events = self . poller . readQueue () for event in events : value : ntcore . Value = event . data . value # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # close listener self . poller . close () # stop subscribing self . multiSub . close () Publish/Subscribe Options Publishers and subscribers have various options that affect their behavior. Options can only be set at the creation of the publisher, subscriber, or entry. Options set on an entry affect both the publisher and subscriber portions of the entry. The above examples show how options can be set when creating a publisher or subscriber. Subscriber options: pollStorage : Polling storage size for a subscription. Specifies the maximum number of updates NetworkTables should store between calls to the subscriber’s readQueue() function. If zero, defaults to 1 if sendAll is false, 20 if sendAll is true. topicsOnly : Don’t send value changes, only topic announcements. Defaults to false. As a client doesn’t get topic announcements for topics it is not subscribed to, this option may be used with MultiSubscriber to get topic announcements for a particular topic name prefix, without also getting all value changes. excludePublisher : Used to exclude a single publisher’s updates from being queued to the subscriber’s readQueue() function. This is primarily useful in scenarios where you don’t want local value updates to be “echoed back” to a local subscriber. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. disableRemote : If true, remote value updates are not queued for readQueue() . Defaults to false. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. disableLocal : If true, local value updates are not queued for readQueue() . Defaults to false. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. Subscriber and publisher options: periodic : How frequently changes will be sent over the network, in seconds. NetworkTables may send more frequently than this (e.g. use a combined minimum period for all values) or apply a restricted range to this value. The default is 0.1 seconds. For publishers, it specifies how frequently local changes should be sent over the network; for subscribers, it is a request to the server to send server changes at the requested rate. Note that regardless of the setting of this option, only value changes are sent, unless the keepDuplicates option is set. sendAll : If true, send all value changes over the network. Defaults to false. As with periodic , this is a request to the server for subscribers and a behavior change for publishers. keepDuplicates : If true, preserves duplicate value changes (rather than ignoring them). Defaults to false. As with periodic , this is a request to the server for subscribers and a behavior change for publishers. Entry options: excludeSelf : Provides the same behavior as excludePublisher for the entry’s internal publisher. Defaults to false. NetworkTableEntry NetworkTableEntry ( Java , C++ , Python ) is a class that exists for backwards compatibility. New code should prefer using type-specific Publisher and Subscriber classes, or GenericEntry if non-type-specific access is needed. It is similar to GenericEntry in that it supports both publishing and subscribing in a single object. However, unlike GenericEntry , NetworkTableEntry is not released (e.g. unsubscribes/unpublishes) if close() is called (in Java) or the object is destroyed (in C++); instead, it operates similar to Topic , in that only a single NetworkTableEntry exists for each topic and it lasts for the lifetime of the instance.",
      "content_preview": "Publishing and Subscribing to a Topic Publishing to a Topic In order to create a topic and publish values to it, it’s necessary to create a publisher . NetworkTable publishers are represented as type-specific Publisher objects (e.g. BooleanPublisher : Java , C++ , Python )."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/publish-and-subscribe.html?present",
      "title": "Publishing and Subscribing to a Topic",
      "section": "NetworkTables",
      "language": "All",
      "content": "Publishing and Subscribing to a Topic Publishing to a Topic In order to create a topic and publish values to it, it’s necessary to create a publisher . NetworkTable publishers are represented as type-specific Publisher objects (e.g. BooleanPublisher : Java , C++ , Python ). Publishers are only active as long as the Publisher object exists. Typically you want to keep publishing longer than the local scope of a function, so it’s necessary to store the Publisher object somewhere longer term, e.g. in an instance variable. In Java, the close() method needs be called to stop publishing; in C++ this is handled by the destructor. C++ publishers are moveable and non-copyable. In Python the close() method should be called to stop publishing, but it will also be closed when the object is garbage collected. In the handle-based APIs, there is only the non-type-specific NT_Publisher handle; the user is responsible for keeping track of the type of the publisher and using the correct type-specific set methods. Publishing values is done via a set() operation. By default, this operation uses the current time, but a timestamp may optionally be specified. Specifying a timestamp can be useful when multiple values should have the same update timestamp. The timestamp units are integer microseconds (see example code for how to get a current timestamp that is consistent with the library). Java public class Example { // the publisher is an instance variable so its lifetime matches that of the class final DoublePublisher dblPub ; public Example ( DoubleTopic dblTopic ) { // start publishing; the return value must be retained (in this case, via // an instance variable) dblPub = dblTopic . publish (); // publish options may be specified using PubSubOption dblPub = dblTopic . publish ( PubSubOption . keepDuplicates ( true )); // publishEx provides additional options such as setting initial // properties and using a custom type string. Using a custom type string for // types other than raw and string is not recommended. The properties string // must be a JSON map. dblPub = dblTopic . publishEx ( \"double\" , \"{\\\"myprop\\\": 5}\" ); } public void periodic () { // publish a default value dblPub . setDefault ( 0.0 ); // publish a value with current timestamp dblPub . set ( 1.0 ); dblPub . set ( 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; NetworkTablesJNI.now() can // be used to get the current time. On the roboRIO, this is the same as // the FPGA timestamp (e.g. RobotController.getFPGATime()) long time = NetworkTablesJNI . now (); dblPub . set ( 3.0 , time ); // publishers also implement the appropriate Consumer functional interface; // this example assumes void myFunc(DoubleConsumer func) exists myFunc ( dblPub ); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop publishing public void close () { // stop publishing dblPub . close (); } } C++ class Example { // the publisher is an instance variable so its lifetime matches that of the class // publishing is automatically stopped when dblPub is destroyed by the class destructor nt :: DoublePublisher dblPub ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start publishing; the return value must be retained (in this case, via // an instance variable) dblPub = dblTopic . Publish (); // publish options may be specified using PubSubOptions dblPub = dblTopic . Publish ({. keepDuplicates = true }); // PublishEx provides additional options such as setting initial // properties and using a custom type string. Using a custom type string for // types other than raw and string is not recommended. The properties must // be a JSON map. dblPub = dblTopic . PublishEx ( \"double\" , {{ \"myprop\" , 5 }}); } void Periodic () { // publish a default value dblPub . SetDefault ( 0.0 ); // publish a value with current timestamp dblPub . Set ( 1.0 ); dblPub . Set ( 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; nt::Now() can // be used to get the current time. int64_t time = nt :: Now (); dblPub . Set ( 3.0 , time ); } }; C++ (Handle-based) class Example { // the publisher is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Publisher dblPub ; public : explicit Example ( NT_Topic dblTopic ) { // start publishing. It's recommended that the type string be standard // for all types except string and raw. dblPub = nt :: Publish ( dblTopic , NT_DOUBLE , \"double\" ); // publish options may be specified using PubSubOptions dblPub = nt :: Publish ( dblTopic , NT_DOUBLE , \"double\" , {. keepDuplicates = true }); // PublishEx allows setting initial properties. The // properties must be a JSON map. dblPub = nt :: PublishEx ( dblTopic , NT_DOUBLE , \"double\" , {{ \"myprop\" , 5 }}); } void Periodic () { // publish a default value nt :: SetDefaultDouble ( dblPub , 0.0 ); // publish a value with current timestamp nt :: SetDouble ( dblPub , 1.0 ); nt :: SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; nt::Now() can // be used to get the current time. int64_t time = nt :: Now (); nt :: SetDouble ( dblPub , 3.0 , time ); } ~ Example () { // stop publishing nt :: Unpublish ( dblPub ); } }; C // This code assumes that a NT_Topic dblTopic variable already exists // start publishing. It's recommended that the type string be standard // for all types except string and raw. NT_Publisher dblPub = NT_Publish ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // publish options may be specified struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true NT_Publisher dblPub = NT_Publish ( dblTopic , NT_DOUBLE , \"double\" , & options ); // PublishEx allows setting initial properties. The properties string must // be a JSON map. NT_Publisher dblPub = NT_PublishEx ( dblTopic , NT_DOUBLE , \"double\" , \"{ \\\" myprop \\\" , 5}\" , NULL , 0 ); // publish a default value NT_SetDefaultDouble ( dblPub , 0.0 ); // publish a value with current timestamp NT_SetDouble ( dblPub , 1.0 ); NT_SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time // publish a value with a specific timestamp; NT_Now() can // be used to get the current time. int64_t time = NT_Now (); NT_SetDouble ( dblPub , 3.0 , time ); // stop publishing NT_Unpublish ( dblPub ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start publishing; the return value must be retained (in this case, via # an instance variable) self . dblPub = dblTopic . publish () # publish options may be specified using PubSubOption self . dblPub = dblTopic . publish ( ntcore . PubSubOptions ( keepDuplicates = True )) # publishEx provides additional options such as setting initial # properties and using a custom type string. Using a custom type string for # types other than raw and string is not recommended. The properties string # must be a JSON map. self . dblPub = dblTopic . publishEx ( \"double\" , '{\"myprop\": 5}' ) def periodic ( self ): # publish a default value self . dblPub . setDefault ( 0.0 ) # publish a value with current timestamp self . dblPub . set ( 1.0 ) self . dblPub . set ( 2.0 , 0 ) # 0 = use current time # publish a value with a specific timestamp with microsecond resolution. # On the roboRIO, this is the same as the FPGA timestamp (e.g. # RobotController.getFPGATime()) self . dblPub . set ( 3.0 , ntcore . _now ()) # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop publishing def close ( self ): # stop publishing self . dblPub . close () Subscribing to a Topic A subscriber receives value updates made to a topic. Similar to publishers, NetworkTable subscribers are represented as type-specific Subscriber classes (e.g. BooleanSubscriber : Java , C++ , Python ) that must be stored somewhere to continue subscribing. Subscribers have a range of different ways to read received values. It’s possible to just read the most recent value using get() , read the most recent value, along with its timestamp, using getAtomic() , or get an array of all value changes since the last call using readQueue() or readQueueValues() . Java public class Example { // the subscriber is an instance variable so its lifetime matches that of the class final DoubleSubscriber dblSub ; public Example ( DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblSub = dblTopic . subscribe ( 0.0 ); // subscribe options may be specified using PubSubOption dblSub = dblTopic . subscribe ( 0.0 , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // subscribeEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . subscribeEx ( \"double\" , 0.0 ); } public void periodic () { // simple get of most recent value; if no value has been published, // returns the default value passed to the subscribe() function double val = dblSub . get (); // get the most recent value; if no value has been published, returns // the passed-in default value double val = dblSub . get ( - 1.0 ); // subscribers also implement the appropriate Supplier interface, e.g. DoubleSupplier double val = dblSub . getAsDouble (); // get the most recent value, along with its timestamp TimestampedDouble tsVal = dblSub . getAtomic (); // read all value changes since the last call to readQueue/readQueueValues // readQueue() returns timestamps; readQueueValues() does not. TimestampedDouble [] tsUpdates = dblSub . readQueue (); double [] valUpdates = dblSub . readQueueValues (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // stop subscribing dblSub . close (); } } C++ class Example { // the subscriber is an instance variable so its lifetime matches that of the class // subscribing is automatically stopped when dblSub is destroyed by the class destructor nt :: DoubleSubscriber dblSub ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblSub = dblTopic . Subscribe ( 0.0 ); // subscribe options may be specified using PubSubOptions dblSub = dblTopic . subscribe ( 0.0 , {. pollStorage = 10 , . keepDuplicates = true }); // SubscribeEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . SubscribeEx ( \"double\" , 0.0 ); } void Periodic () { // simple get of most recent value; if no value has been published, // returns the default value passed to the Subscribe() function double val = dblSub . Get (); // get the most recent value; if no value has been published, returns // the passed-in default value double val = dblSub . Get ( -1.0 ); // get the most recent value, along with its timestamp nt :: TimestampedDouble tsVal = dblSub . GetAtomic (); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. std :: vector < nt :: TimestampedDouble > tsUpdates = dblSub . ReadQueue (); std :: vector < double > valUpdates = dblSub . ReadQueueValues (); } }; C++ (Handle-based) class Example { // the subscriber is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Subscriber dblSub ; public : explicit Example ( NT_Topic dblTopic ) { // start subscribing // Using a custom type string for types other than raw and string is not recommended. dblSub = nt :: Subscribe ( dblTopic , NT_DOUBLE , \"double\" ); // subscribe options may be specified using PubSubOptions dblSub = nt :: Subscribe ( dblTopic , NT_DOUBLE , \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // get the most recent value; if no value has been published, returns // the passed-in default value double val = nt :: GetDouble ( dblSub , 0.0 ); // get the most recent value, along with its timestamp nt :: TimestampedDouble tsVal = nt :: GetAtomic ( dblSub , 0.0 ); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. std :: vector < nt :: TimestampedDouble > tsUpdates = nt :: ReadQueueDouble ( dblSub ); std :: vector < double > valUpdates = nt :: ReadQueueValuesDouble ( dblSub ); } ~ Example () { // stop subscribing nt :: Unsubscribe ( dblSub ); } C // This code assumes that a NT_Topic dblTopic variable already exists // start subscribing // Using a custom type string for types other than raw and string is not recommended. NT_Subscriber dblSub = NT_Subscribe ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true options . pollStorage = 10 ; NT_Subscriber dblSub = NT_Subscribe ( dblTopic , NT_DOUBLE , \"double\" , & options ); // get the most recent value; if no value has been published, returns // the passed-in default value double val = NT_GetDouble ( dblSub , 0.0 ); // get the most recent value, along with its timestamp struct NT_TimestampedDouble tsVal ; NT_GetAtomic ( dblSub , 0.0 , & tsVal ); NT_DisposeTimestamped ( & tsVal ); // read all value changes since the last call to ReadQueue/ReadQueueValues // ReadQueue() returns timestamps; ReadQueueValues() does not. size_t tsUpdatesLen ; struct NT_TimestampedDouble * tsUpdates = NT_ReadQueueDouble ( dblSub , & tsUpdatesLen ); NT_FreeQueueDouble ( tsUpdates , tsUpdatesLen ); size_t valUpdatesLen ; double * valUpdates = NT_ReadQueueValuesDouble ( dblSub , & valUpdatesLen ); NT_FreeDoubleArray ( valUpdates , valUpdatesLen ); // stop subscribing NT_Unsubscribe ( dblSub ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start subscribing; the return value must be retained. # the parameter is the default value if no value is available when get() is called self . dblSub = dblTopic . subscribe ( 0.0 ) # subscribe options may be specified using PubSubOption self . dblSub = dblTopic . subscribe ( 0.0 , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # subscribeEx provides the options of using a custom type string. # Using a custom type string for types other than raw and string is not recommended. dblSub = dblTopic . subscribeEx ( \"double\" , 0.0 ) def periodic ( self ): # simple get of most recent value; if no value has been published, # returns the default value passed to the subscribe() function val = self . dblSub . get () # get the most recent value; if no value has been published, returns # the passed-in default value val = self . dblSub . get ( - 1.0 ) # get the most recent value, along with its timestamp tsVal = self . dblSub . getAtomic () # read all value changes since the last call to readQueue # readQueue() returns timestamps tsUpdates = self . dblSub . readQueue () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # stop subscribing self . dblSub . close () Using Entry to Both Subscribe and Publish An entry is a combined publisher and subscriber. The subscriber is always active, but the publisher is not created until a publish operation is performed (e.g. a value is “set”, aka published, on the entry). This may be more convenient than maintaining a separate publisher and subscriber. Similar to publishers and subscribers, NetworkTable entries are represented as type-specific Entry classes (e.g. BooleanEntry : Java , C++ , Python ) that must be retained to continue subscribing (and publishing). Java public class Example { // the entry is an instance variable so its lifetime matches that of the class final DoubleEntry dblEntry ; public Example ( DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblEntry = dblTopic . getEntry ( 0.0 ); // publish and subscribe options may be specified using PubSubOption dblEntry = dblTopic . getEntry ( 0.0 , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // getEntryEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblEntry = dblTopic . getEntryEx ( \"double\" , 0.0 ); } public void periodic () { // entries support all the same methods as subscribers: double val = dblEntry . get (); double val = dblEntry . get ( - 1.0 ); double val = dblEntry . getAsDouble (); TimestampedDouble tsVal = dblEntry . getAtomic (); TimestampedDouble [] tsUpdates = dblEntry . readQueue (); double [] valUpdates = dblEntry . readQueueValues (); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created dblEntry . setDefault ( 0.0 ); dblEntry . set ( 1.0 ); dblEntry . set ( 2.0 , 0 ); // 0 = use current time long time = NetworkTablesJNI . now (); dblEntry . set ( 3.0 , time ); myFunc ( dblEntry ); } public void unpublish () { // you can stop publishing while keeping the subscriber alive dblEntry . unpublish (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // stop subscribing/publishing dblEntry . close (); } } C++ class Example { // the entry is an instance variable so its lifetime matches that of the class // subscribing/publishing is automatically stopped when dblEntry is destroyed by // the class destructor nt :: DoubleEntry dblEntry ; public : explicit Example ( nt :: DoubleTopic dblTopic ) { // start subscribing; the return value must be retained. // the parameter is the default value if no value is available when get() is called dblEntry = dblTopic . GetEntry ( 0.0 ); // publish and subscribe options may be specified using PubSubOptions dblEntry = dblTopic . GetEntry ( 0.0 , {. pollStorage = 10 , . keepDuplicates = true }); // GetEntryEx provides the options of using a custom type string. // Using a custom type string for types other than raw and string is not recommended. dblEntry = dblTopic . GetEntryEx ( \"double\" , 0.0 ); } void Periodic () { // entries support all the same methods as subscribers: double val = dblEntry . Get (); double val = dblEntry . Get ( -1.0 ); nt :: TimestampedDouble tsVal = dblEntry . GetAtomic (); std :: vector < nt :: TimestampedDouble > tsUpdates = dblEntry . ReadQueue (); std :: vector < double > valUpdates = dblEntry . ReadQueueValues (); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created dblEntry . SetDefault ( 0.0 ); dblEntry . Set ( 1.0 ); dblEntry . Set ( 2.0 , 0 ); // 0 = use current time int64_t time = nt :: Now (); dblEntry . Set ( 3.0 , time ); } void Unpublish () { // you can stop publishing while keeping the subscriber alive dblEntry . Unpublish (); } }; C++ (Handle-based) class Example { // the entry is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_Entry dblEntry ; public : explicit Example ( NT_Topic dblTopic ) { // start subscribing // Using a custom type string for types other than raw and string is not recommended. dblEntry = nt :: GetEntry ( dblTopic , NT_DOUBLE , \"double\" ); // publish and subscribe options may be specified using PubSubOptions dblEntry = nt :: GetEntry ( dblTopic , NT_DOUBLE , \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // entries support all the same methods as subscribers: double val = nt :: GetDouble ( dblEntry , 0.0 ); nt :: TimestampedDouble tsVal = nt :: GetAtomic ( dblEntry , 0.0 ); std :: vector < nt :: TimestampedDouble > tsUpdates = nt :: ReadQueueDouble ( dblEntry ); std :: vector < double > valUpdates = nt :: ReadQueueValuesDouble ( dblEntry ); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created nt :: SetDefaultDouble ( dblPub , 0.0 ); nt :: SetDouble ( dblPub , 1.0 ); nt :: SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time int64_t time = nt :: Now (); nt :: SetDouble ( dblPub , 3.0 , time ); } void Unpublish () { // you can stop publishing while keeping the subscriber alive nt :: Unpublish ( dblEntry ); } ~ Example () { // stop publishing and subscribing nt :: ReleaseEntry ( dblEntry ); } C // This code assumes that a NT_Topic dblTopic variable already exists // start subscribing // Using a custom type string for types other than raw and string is not recommended. NT_Entry dblEntry = NT_GetEntryEx ( dblTopic , NT_DOUBLE , \"double\" , NULL , 0 ); // publish and subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true options . pollStorage = 10 ; NT_Entry dblEntry = NT_GetEntryEx ( dblTopic , NT_DOUBLE , \"double\" , & options ); // entries support all the same methods as subscribers: double val = NT_GetDouble ( dblEntry , 0.0 ); struct NT_TimestampedDouble tsVal ; NT_GetAtomic ( dblEntry , 0.0 , & tsVal ); NT_DisposeTimestamped ( & tsVal ); size_t tsUpdatesLen ; struct NT_TimestampedDouble * tsUpdates = NT_ReadQueueDouble ( dblEntry , & tsUpdatesLen ); NT_FreeQueueDouble ( tsUpdates , tsUpdatesLen ); size_t valUpdatesLen ; double * valUpdates = NT_ReadQueueValuesDouble ( dblEntry , & valUpdatesLen ); NT_FreeDoubleArray ( valUpdates , valUpdatesLen ); // entries also support all the same methods as publishers; the first time // one of these is called, an internal publisher is automatically created NT_SetDefaultDouble ( dblPub , 0.0 ); NT_SetDouble ( dblPub , 1.0 ); NT_SetDouble ( dblPub , 2.0 , 0 ); // 0 = use current time int64_t time = NT_Now (); NT_SetDouble ( dblPub , 3.0 , time ); // you can stop publishing while keeping the subscriber alive // it's not necessary to call this before NT_ReleaseEntry() NT_Unpublish ( dblEntry ); // stop subscribing NT_ReleaseEntry ( dblEntry ); Python class Example : def __init__ ( self , dblTopic : ntcore . DoubleTopic ): # start subscribing; the return value must be retained. # the parameter is the default value if no value is available when get() is called self . dblEntry = dblTopic . getEntry ( 0.0 ) # publish and subscribe options may be specified using PubSubOption self . dblEntry = dblTopic . getEntry ( 0.0 , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # getEntryEx provides the options of using a custom type string. # Using a custom type string for types other than raw and string is not recommended. self . dblEntry = dblTopic . getEntryEx ( \"double\" , 0.0 ) def periodic ( self ): # entries support all the same methods as subscribers: val = self . dblEntry . get () val = self . dblEntry . get ( - 1.0 ) val = self . dblEntry . getAsDouble () tsVal = self . dblEntry . getAtomic () tsUpdates = self . dblEntry . readQueue () # entries also support all the same methods as publishers; the first time # one of these is called, an internal publisher is automatically created self . dblEntry . setDefault ( 0.0 ) self . dblEntry . set ( 1.0 ) self . dblEntry . set ( 2.0 , 0 ) # 0 = use current time time = ntcore . _now () self . dblEntry . set ( 3.0 , time ) def unpublish ( self ): # you can stop publishing while keeping the subscriber alive self . dblEntry . unpublish () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # stop subscribing/publishing self . dblEntry . close () Using GenericEntry, GenericPublisher, and GenericSubscriber For the most robust code, using the type-specific Publisher, Subscriber, and Entry classes is recommended, but in some cases it may be easier to write code that uses type-specific get and set function calls instead of having the NetworkTables type be exposed via the class (object) type. The GenericPublisher ( Java , C++ , Python ), GenericSubscriber ( Java , C++ , Python ), and GenericEntry ( Java , C++ , Python ) classes enable this approach. Java public class Example { // the entry is an instance variable so its lifetime matches that of the class final GenericPublisher pub ; final GenericSubscriber sub ; final GenericEntry entry ; public Example ( Topic topic ) { // start subscribing; the return value must be retained. // when publishing, a type string must be provided pub = topic . genericPublish ( \"double\" ); // subscribing can optionally include a type string // unlike type-specific subscribers, no default value is provided sub = topic . genericSubscribe (); sub = topic . genericSubscribe ( \"double\" ); // when getting an entry, the type string is also optional; if not provided // the publisher data type will be determined by the first publisher-creating call entry = topic . getGenericEntry (); entry = topic . getGenericEntry ( \"double\" ); // publish and subscribe options may be specified using PubSubOption pub = topic . genericPublish ( \"double\" , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); sub = topic . genericSubscribe ( PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); entry = topic . getGenericEntry ( PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); // genericPublishEx provides the option of setting initial properties. pub = topic . genericPublishEx ( \"double\" , \"{\\\"retained\\\": true}\" , PubSubOption . keepDuplicates ( true ), PubSubOption . pollStorage ( 10 )); } public void periodic () { // generic subscribers and entries have typed get operations; a default must be provided double val = sub . getDouble ( - 1.0 ); double val = entry . getDouble ( - 1.0 ); // they also support an untyped get (also meets Supplier<NetworkTableValue> interface) NetworkTableValue val = sub . get (); NetworkTableValue val = entry . get (); // they also support readQueue NetworkTableValue [] updates = sub . readQueue (); NetworkTableValue [] updates = entry . readQueue (); // publishers and entries have typed set operations; these return false if the // topic already exists with a mismatched type boolean success = pub . setDefaultDouble ( 1.0 ); boolean success = pub . setBoolean ( true ); // they also implement a generic set and Consumer<NetworkTableValue> interface boolean success = entry . set ( NetworkTableValue . makeDouble (...)); boolean success = entry . accept ( NetworkTableValue . makeDouble (...)); } public void unpublish () { // you can stop publishing an entry while keeping the subscriber alive entry . unpublish (); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing/publishing public void close () { pub . close (); sub . close (); entry . close (); } } C++ class Example { // the entry is an instance variable so its lifetime matches that of the class // subscribing/publishing is automatically stopped when dblEntry is destroyed by // the class destructor nt :: GenericPublisher pub ; nt :: GenericSubscriber sub ; nt :: GenericEntry entry ; public : Example ( nt :: Topic topic ) { // start subscribing; the return value must be retained. // when publishing, a type string must be provided pub = topic . GenericPublish ( \"double\" ); // subscribing can optionally include a type string // unlike type-specific subscribers, no default value is provided sub = topic . GenericSubscribe (); sub = topic . GenericSubscribe ( \"double\" ); // when getting an entry, the type string is also optional; if not provided // the publisher data type will be determined by the first publisher-creating call entry = topic . GetEntry (); entry = topic . GetEntry ( \"double\" ); // publish and subscribe options may be specified using PubSubOptions pub = topic . GenericPublish ( \"double\" , {. pollStorage = 10 , . keepDuplicates = true }); sub = topic . GenericSubscribe ( {. pollStorage = 10 , . keepDuplicates = true }); entry = topic . GetGenericEntry ( {. pollStorage = 10 , . keepDuplicates = true }); // genericPublishEx provides the option of setting initial properties. pub = topic . genericPublishEx ( \"double\" , {{ \"myprop\" , 5 }}, {. pollStorage = 10 , . keepDuplicates = true }); } void Periodic () { // generic subscribers and entries have typed get operations; a default must be provided double val = sub . GetDouble ( -1.0 ); double val = entry . GetDouble ( -1.0 ); // they also support an untyped get nt :: NetworkTableValue val = sub . Get (); nt :: NetworkTableValue val = entry . Get (); // they also support readQueue std :: vector < nt :: NetworkTableValue > updates = sub . ReadQueue (); std :: vector < nt :: NetworkTableValue > updates = entry . ReadQueue (); // publishers and entries have typed set operations; these return false if the // topic already exists with a mismatched type bool success = pub . SetDefaultDouble ( 1.0 ); bool success = pub . SetBoolean ( true ); // they also implement a generic set and Consumer<NetworkTableValue> interface bool success = entry . Set ( nt :: NetworkTableValue :: MakeDouble (...)); } void Unpublish () { // you can stop publishing an entry while keeping the subscriber alive entry . Unpublish (); } }; Python class Example : def __init__ ( self , topic : ntcore . Topic ): # start subscribing; the return value must be retained. # when publishing, a type string must be provided self . pub = topic . genericPublish ( \"double\" ) # subscribing can optionally include a type string # unlike type-specific subscribers, no default value is provided self . sub = topic . genericSubscribe () self . sub = topic . genericSubscribe ( \"double\" ) # when getting an entry, the type string is also optional; if not provided # the publisher data type will be determined by the first publisher-creating call self . entry = topic . getGenericEntry () self . entry = topic . getGenericEntry ( \"double\" ) # publish and subscribe options may be specified using PubSubOption self . pub = topic . genericPublish ( \"double\" , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) self . sub = topic . genericSubscribe ( ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) self . entry = topic . getGenericEntry ( ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ) ) # genericPublishEx provides the option of setting initial properties. self . pub = topic . genericPublishEx ( \"double\" , '{\"retained\": true}' , ntcore . PubSubOptions ( keepDuplicates = True , pollStorage = 10 ), ) def periodic ( self ): # generic subscribers and entries have typed get operations; a default must be provided val = self . sub . getDouble ( - 1.0 ) val = self . entry . getDouble ( - 1.0 ) # they also support an untyped get (also meets Supplier<NetworkTableValue> interface) val = self . sub . get () val = self . entry . get () # they also support readQueue updates = self . sub . readQueue () updates = self . entry . readQueue () # publishers and entries have typed set operations; these return false if the # topic already exists with a mismatched type success = self . pub . setDefaultDouble ( 1.0 ) success = self . pub . setBoolean ( True ) # they also implement a generic set success = self . entry . set ( ntcore . Value . makeDouble ( ... )) def unpublish ( self ): # you can stop publishing an entry while keeping the subscriber alive self . entry . unpublish () # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing/publishing def close ( self ): self . pub . close () self . sub . close () self . entry . close () Subscribing to Multiple Topics While in most cases it’s only necessary to subscribe to individual topics, it is sometimes useful (e.g. in dashboard applications) to subscribe and get value updates for changes to multiple topics. Listeners (see Listening for Changes ) can be used directly, but creating a MultiSubscriber ( Java , C++ ) allows specifying subscription options and reusing the same subscriber for multiple listeners. Java public class Example { // the subscriber is an instance variable so its lifetime matches that of the class final MultiSubscriber multiSub ; final NetworkTableListenerPoller poller ; public Example ( NetworkTableInstance inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = new MultiSubscriber ( inst , new String [] { \"/table1/\" , \"/table2/\" }); // subscribe options may be specified using PubSubOption multiSub = new MultiSubscriber ( inst , new String [] { \"/table1/\" , \"/table2/\" }, PubSubOption . keepDuplicates ( true )); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = new NetworkTableListenerPoller ( inst ); poller . addListener ( multiSub , EnumSet . of ( NetworkTableEvent . Kind . kValueAll )); } public void periodic () { // read value events NetworkTableEvent [] events = poller . readQueue (); for ( NetworkTableEvent event : events ) { NetworkTableValue value = event . valueData . value ; } } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { // close listener poller . close (); // stop subscribing multiSub . close (); } } C++ class Example { // the subscriber is an instance variable so its lifetime matches that of the class // subscribing is automatically stopped when multiSub is destroyed by the class destructor nt :: MultiSubscriber multiSub ; nt :: NetworkTableListenerPoller poller ; public : explicit Example ( nt :: NetworkTableInstance inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = nt :: MultiSubscriber { inst , {{ \"/table1/\" , \"/table2/\" }}}; // subscribe options may be specified using PubSubOption multiSub = nt :: MultiSubscriber { inst , {{ \"/table1/\" , \"/table2/\" }}, {. keepDuplicates = true }}; // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = nt :: NetworkTableListenerPoller { inst }; poller . AddListener ( multiSub , nt :: EventFlags :: kValueAll ); } void Periodic () { // read value events std :: vector < nt :: Event > events = poller . ReadQueue (); for ( auto && event : events ) { nt :: NetworkTableValue value = event . GetValueEventData () -> value ; } } }; C++ (Handle-based) class Example { // the subscriber is an instance variable, but since it's a handle, it's // not automatically released, so we need a destructor NT_MultiSubscriber multiSub ; NT_ListenerPoller poller ; public : explicit Example ( NT_Inst inst ) { // start subscribing; the return value must be retained. // provide an array of topic name prefixes multiSub = nt :: SubscribeMultiple ( inst , {{ \"/table1/\" , \"/table2/\" }}); // subscribe options may be specified using PubSubOption multiSub = nt :: SubscribeMultiple ( inst , {{ \"/table1/\" , \"/table2/\" }}, {. keepDuplicates = true }); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) poller = nt :: CreateListenerPoller ( inst ); nt :: AddPolledListener ( poller , multiSub , nt :: EventFlags :: kValueAll ); } void Periodic () { // read value events std :: vector < nt :: Event > events = nt :: ReadListenerQueue ( poller ); for ( auto && event : events ) { nt :: NetworkTableValue value = event . GetValueEventData () -> value ; } } ~ Example () { // close listener nt :: DestroyListenerPoller ( poller ); // stop subscribing nt :: UnsubscribeMultiple ( multiSub ); } C // This code assumes that a NT_Inst inst variable already exists // start subscribing // provide an array of topic name prefixes struct NT_String prefixes [ 2 ]; prefixes [ 0 ]. str = \"/table1/\" ; prefixes [ 0 ]. len = 8 ; prefixes [ 1 ]. str = \"/table2/\" ; prefixes [ 1 ]. len = 8 ; NT_MultiSubscriber multiSub = NT_SubscribeMultiple ( inst , prefixes , 2 , NULL , 0 ); // subscribe options may be specified using NT_PubSubOptions struct NT_PubSubOptions options ; memset ( & options , 0 , sizeof ( options )); options . structSize = sizeof ( options ); options . keepDuplicates = 1 ; // true NT_MultiSubscriber multiSub = NT_SubscribeMultiple ( inst , prefixes , 2 , & options ); // to get value updates from a MultiSubscriber, it's necessary to create a listener // (see the listener documentation for more details) NT_ListenerPoller poller = NT_CreateListenerPoller ( inst ); NT_AddPolledListener ( poller , multiSub , NT_EVENT_VALUE_ALL ); // read value events size_t eventsLen ; struct NT_Event * events = NT_ReadListenerQueue ( poller , & eventsLen ); for ( size_t i = 0 ; i < eventsLen ; i ++ ) { NT_Value * value = & events [ i ]. data . valueData . value ; } NT_DisposeEventArray ( events , eventsLen ); // close listener NT_DestroyListenerPoller ( poller ); // stop subscribing NT_UnsubscribeMultiple ( multiSub ); Python class Example : def __init__ ( self , inst : ntcore . NetworkTableInstance ): # start subscribing; the return value must be retained. # provide an array of topic name prefixes self . multiSub = ntcore . MultiSubscriber ( inst , [ \"/table1/\" , \"/table2/\" ]) # subscribe options may be specified using PubSubOption self . multiSub = ntcore . MultiSubscriber ( inst , [ \"/table1/\" , \"/table2/\" ], ntcore . PubSubOptions ( keepDuplicates = True ) ) # to get value updates from a MultiSubscriber, it's necessary to create a listener # (see the listener documentation for more details) self . poller = ntcore . NetworkTableListenerPoller ( inst ) self . poller . addListener ( self . multiSub , ntcore . EventFlags . kValueAlls ) def periodic ( self ): # read value events events = self . poller . readQueue () for event in events : value : ntcore . Value = event . data . value # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): # close listener self . poller . close () # stop subscribing self . multiSub . close () Publish/Subscribe Options Publishers and subscribers have various options that affect their behavior. Options can only be set at the creation of the publisher, subscriber, or entry. Options set on an entry affect both the publisher and subscriber portions of the entry. The above examples show how options can be set when creating a publisher or subscriber. Subscriber options: pollStorage : Polling storage size for a subscription. Specifies the maximum number of updates NetworkTables should store between calls to the subscriber’s readQueue() function. If zero, defaults to 1 if sendAll is false, 20 if sendAll is true. topicsOnly : Don’t send value changes, only topic announcements. Defaults to false. As a client doesn’t get topic announcements for topics it is not subscribed to, this option may be used with MultiSubscriber to get topic announcements for a particular topic name prefix, without also getting all value changes. excludePublisher : Used to exclude a single publisher’s updates from being queued to the subscriber’s readQueue() function. This is primarily useful in scenarios where you don’t want local value updates to be “echoed back” to a local subscriber. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. disableRemote : If true, remote value updates are not queued for readQueue() . Defaults to false. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. disableLocal : If true, local value updates are not queued for readQueue() . Defaults to false. Regardless of this setting, the topic value is updated–this only affects readQueue() on this subscriber. Subscriber and publisher options: periodic : How frequently changes will be sent over the network, in seconds. NetworkTables may send more frequently than this (e.g. use a combined minimum period for all values) or apply a restricted range to this value. The default is 0.1 seconds. For publishers, it specifies how frequently local changes should be sent over the network; for subscribers, it is a request to the server to send server changes at the requested rate. Note that regardless of the setting of this option, only value changes are sent, unless the keepDuplicates option is set. sendAll : If true, send all value changes over the network. Defaults to false. As with periodic , this is a request to the server for subscribers and a behavior change for publishers. keepDuplicates : If true, preserves duplicate value changes (rather than ignoring them). Defaults to false. As with periodic , this is a request to the server for subscribers and a behavior change for publishers. Entry options: excludeSelf : Provides the same behavior as excludePublisher for the entry’s internal publisher. Defaults to false. NetworkTableEntry NetworkTableEntry ( Java , C++ , Python ) is a class that exists for backwards compatibility. New code should prefer using type-specific Publisher and Subscriber classes, or GenericEntry if non-type-specific access is needed. It is similar to GenericEntry in that it supports both publishing and subscribing in a single object. However, unlike GenericEntry , NetworkTableEntry is not released (e.g. unsubscribes/unpublishes) if close() is called (in Java) or the object is destroyed (in C++); instead, it operates similar to Topic , in that only a single NetworkTableEntry exists for each topic and it lasts for the lifetime of the instance.",
      "content_preview": "Publishing and Subscribing to a Topic Publishing to a Topic In order to create a topic and publish values to it, it’s necessary to create a publisher . NetworkTable publishers are represented as type-specific Publisher objects (e.g. BooleanPublisher : Java , C++ , Python )."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/networktables-networking.html",
      "title": "NetworkTables Networking",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Networking The advantage of the robot program being the server is that it’s at a known network name (and typically at a known address) that is based on the team number. This is why it’s possible in both the NetworkTables client API and in most dashboards to simply provide the team number, rather than a server address. As the robot program is the server, note this means the NetworkTables server is running on the local computer when running in simulation. Starting a NetworkTables Server Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); inst . startServer (); C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); inst . StartServer (); C++ (Handle-based) NT_Inst inst = nt :: GetDefaultInstance (); nt :: StartServer ( inst , \"networktables.json\" , \"\" , NT_DEFAULT_PORT3 , NT_DEFAULT_PORT4 ); C NT_Inst inst = NT_GetDefaultInstance (); NT_StartServer ( inst , \"networktables.json\" , \"\" , NT_DEFAULT_PORT3 , NT_DEFAULT_PORT4 ); Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () inst . startServer () Starting a NetworkTables Client Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); // start a NT4 client inst . startClient4 ( \"example client\" ); // connect to a roboRIO with team number TEAM inst . setServerTeam ( TEAM ); // starting a DS client will try to get the roboRIO address from the DS application inst . startDSClient (); // connect to a specific host/port inst . setServer ( \"host\" , NetworkTableInstance . kDefaultPort4 ) C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // start a NT4 client inst . StartClient4 ( \"example client\" ); // connect to a roboRIO with team number TEAM inst . SetServerTeam ( TEAM ); // starting a DS client will try to get the roboRIO address from the DS application inst . StartDSClient (); // connect to a specific host/port inst . SetServer ( \"host\" , NT_DEFAULT_PORT4 ) C++ (Handle-based) NT_Inst inst = nt :: GetDefaultInstance (); // start a NT4 client nt :: StartClient4 ( inst , \"example client\" ); // connect to a roboRIO with team number TEAM nt :: SetServerTeam ( inst , TEAM ); // starting a DS client will try to get the roboRIO address from the DS application nt :: StartDSClient ( inst ); // connect to a specific host/port nt :: SetServer ( inst , \"host\" , NT_DEFAULT_PORT4 ) C NT_Inst inst = NT_GetDefaultInstance (); // start a NT4 client NT_StartClient4 ( inst , \"example client\" ); // connect to a roboRIO with team number TEAM NT_SetServerTeam ( inst , TEAM ); // starting a DS client will try to get the roboRIO address from the DS application NT_StartDSClient ( inst ); // connect to a specific host/port NT_SetServer ( inst , \"host\" , NT_DEFAULT_PORT4 ) Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () # start a NT4 client inst . startClient4 ( \"example client\" ) # connect to a roboRIO with team number TEAM inst . setServerTeam ( TEAM ) # starting a DS client will try to get the roboRIO address from the DS application inst . startDSClient () # connect to a specific host/port inst . setServer ( \"host\" , ntcore . NetworkTableInstance . kDefaultPort4 )",
      "content_preview": "NetworkTables Networking The advantage of the robot program being the server is that it’s at a known network name (and typically at a known address) that is based on the team number."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/networktables-networking.html?present",
      "title": "NetworkTables Networking",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Networking The advantage of the robot program being the server is that it’s at a known network name (and typically at a known address) that is based on the team number. This is why it’s possible in both the NetworkTables client API and in most dashboards to simply provide the team number, rather than a server address. As the robot program is the server, note this means the NetworkTables server is running on the local computer when running in simulation. Starting a NetworkTables Server Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); inst . startServer (); C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); inst . StartServer (); C++ (Handle-based) NT_Inst inst = nt :: GetDefaultInstance (); nt :: StartServer ( inst , \"networktables.json\" , \"\" , NT_DEFAULT_PORT3 , NT_DEFAULT_PORT4 ); C NT_Inst inst = NT_GetDefaultInstance (); NT_StartServer ( inst , \"networktables.json\" , \"\" , NT_DEFAULT_PORT3 , NT_DEFAULT_PORT4 ); Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () inst . startServer () Starting a NetworkTables Client Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); // start a NT4 client inst . startClient4 ( \"example client\" ); // connect to a roboRIO with team number TEAM inst . setServerTeam ( TEAM ); // starting a DS client will try to get the roboRIO address from the DS application inst . startDSClient (); // connect to a specific host/port inst . setServer ( \"host\" , NetworkTableInstance . kDefaultPort4 ) C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // start a NT4 client inst . StartClient4 ( \"example client\" ); // connect to a roboRIO with team number TEAM inst . SetServerTeam ( TEAM ); // starting a DS client will try to get the roboRIO address from the DS application inst . StartDSClient (); // connect to a specific host/port inst . SetServer ( \"host\" , NT_DEFAULT_PORT4 ) C++ (Handle-based) NT_Inst inst = nt :: GetDefaultInstance (); // start a NT4 client nt :: StartClient4 ( inst , \"example client\" ); // connect to a roboRIO with team number TEAM nt :: SetServerTeam ( inst , TEAM ); // starting a DS client will try to get the roboRIO address from the DS application nt :: StartDSClient ( inst ); // connect to a specific host/port nt :: SetServer ( inst , \"host\" , NT_DEFAULT_PORT4 ) C NT_Inst inst = NT_GetDefaultInstance (); // start a NT4 client NT_StartClient4 ( inst , \"example client\" ); // connect to a roboRIO with team number TEAM NT_SetServerTeam ( inst , TEAM ); // starting a DS client will try to get the roboRIO address from the DS application NT_StartDSClient ( inst ); // connect to a specific host/port NT_SetServer ( inst , \"host\" , NT_DEFAULT_PORT4 ) Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () # start a NT4 client inst . startClient4 ( \"example client\" ) # connect to a roboRIO with team number TEAM inst . setServerTeam ( TEAM ) # starting a DS client will try to get the roboRIO address from the DS application inst . startDSClient () # connect to a specific host/port inst . setServer ( \"host\" , ntcore . NetworkTableInstance . kDefaultPort4 )",
      "content_preview": "NetworkTables Networking The advantage of the robot program being the server is that it’s at a known network name (and typically at a known address) that is based on the team number."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/tables-and-topics.html",
      "title": "NetworkTables Tables and Topics",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Tables and Topics Using the NetworkTable Class The NetworkTable ( Java , C++ , Python ) class is an API abstraction that represents a single “folder” (or “table”) of topics as described in NetworkTables Organization . The NetworkTable class stores the base path to the table and provides functions to get topics within the table, automatically prepending the table path. Getting a Topic A Topic ( Java , C++ , Python ) object (or NT_Topic handle) represents a topic . This has a 1:1 correspondence with the topic’s name, and will not change as long as the instance exists. Unlike publishers and subscribers, it is not necessary to store a Topic object. Having a Topic object or handle does not mean the topic exists or is of the correct type. For convenience when creating publishers and subscribers, there are type-specific Topic classes (e.g. BooleanTopic : Java , C++ , Python ), but there is no check at the Topic level to ensure that the topic’s type actually matches. The preferred method to get a type-specific topic to call the appropriate type-specific getter, but it’s also possible to directly convert a generic Topic into a type-specific Topic class. Note: the handle-based API does not have a concept of type-specific classes. Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); NetworkTable table = inst . getTable ( \"datatable\" ); // get a topic from a NetworkTableInstance // the topic name in this case is the full name DoubleTopic dblTopic = inst . getDoubleTopic ( \"/datatable/X\" ); // get a topic from a NetworkTable // the topic name in this case is the name within the table; // this line and the one above reference the same topic DoubleTopic dblTopic = table . getDoubleTopic ( \"X\" ); // get a type-specific topic from a generic Topic Topic genericTopic = inst . getTopic ( \"/datatable/X\" ); DoubleTopic dblTopic = new DoubleTopic ( genericTopic ); C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); std :: shared_ptr < nt :: NetworkTable > table = inst . GetTable ( \"datatable\" ); // get a topic from a NetworkTableInstance // the topic name in this case is the full name nt :: DoubleTopic dblTopic = inst . GetDoubleTopic ( \"/datatable/X\" ); // get a topic from a NetworkTable // the topic name in this case is the name within the table; // this line and the one above reference the same topic nt :: DoubleTopic dblTopic = table -> GetDoubleTopic ( \"X\" ); // get a type-specific topic from a generic Topic nt :: Topic genericTopic = inst . GetTopic ( \"/datatable/X\" ); nt :: DoubleTopic dblTopic { genericTopic }; C++ (Handle-based) NT_Instance inst = nt :: GetDefaultInstance (); // get a topic from a NetworkTableInstance NT_Topic topic = nt :: GetTopic ( inst , \"/datatable/X\" ); C NT_Instance inst = NT_GetDefaultInstance (); // get a topic from a NetworkTableInstance NT_Topic topic = NT_GetTopic ( inst , \"/datatable/X\" ); Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () table = inst . getTable ( \"datatable\" ) # get a topic from a NetworkTableInstance # the topic name in this case is the full name dblTopic = inst . getDoubleTopic ( \"/datatable/X\" ) # get a topic from a NetworkTable # the topic name in this case is the name within the table; # this line and the one above reference the same topic dblTopic = table . getDoubleTopic ( \"X\" ) # get a type-specific topic from a generic Topic genericTopic = inst . getTopic ( \"/datatable/X\" ) dblTopic = ntcore . DoubleTopic ( genericTopic )",
      "content_preview": "NetworkTables Tables and Topics Using the NetworkTable Class The NetworkTable ( Java , C++ , Python ) class is an API abstraction that represents a single “folder” (or “table”) of topics as described in NetworkTables Organization ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/tables-and-topics.html?present",
      "title": "NetworkTables Tables and Topics",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Tables and Topics Using the NetworkTable Class The NetworkTable ( Java , C++ , Python ) class is an API abstraction that represents a single “folder” (or “table”) of topics as described in NetworkTables Organization . The NetworkTable class stores the base path to the table and provides functions to get topics within the table, automatically prepending the table path. Getting a Topic A Topic ( Java , C++ , Python ) object (or NT_Topic handle) represents a topic . This has a 1:1 correspondence with the topic’s name, and will not change as long as the instance exists. Unlike publishers and subscribers, it is not necessary to store a Topic object. Having a Topic object or handle does not mean the topic exists or is of the correct type. For convenience when creating publishers and subscribers, there are type-specific Topic classes (e.g. BooleanTopic : Java , C++ , Python ), but there is no check at the Topic level to ensure that the topic’s type actually matches. The preferred method to get a type-specific topic to call the appropriate type-specific getter, but it’s also possible to directly convert a generic Topic into a type-specific Topic class. Note: the handle-based API does not have a concept of type-specific classes. Java NetworkTableInstance inst = NetworkTableInstance . getDefault (); NetworkTable table = inst . getTable ( \"datatable\" ); // get a topic from a NetworkTableInstance // the topic name in this case is the full name DoubleTopic dblTopic = inst . getDoubleTopic ( \"/datatable/X\" ); // get a topic from a NetworkTable // the topic name in this case is the name within the table; // this line and the one above reference the same topic DoubleTopic dblTopic = table . getDoubleTopic ( \"X\" ); // get a type-specific topic from a generic Topic Topic genericTopic = inst . getTopic ( \"/datatable/X\" ); DoubleTopic dblTopic = new DoubleTopic ( genericTopic ); C++ nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); std :: shared_ptr < nt :: NetworkTable > table = inst . GetTable ( \"datatable\" ); // get a topic from a NetworkTableInstance // the topic name in this case is the full name nt :: DoubleTopic dblTopic = inst . GetDoubleTopic ( \"/datatable/X\" ); // get a topic from a NetworkTable // the topic name in this case is the name within the table; // this line and the one above reference the same topic nt :: DoubleTopic dblTopic = table -> GetDoubleTopic ( \"X\" ); // get a type-specific topic from a generic Topic nt :: Topic genericTopic = inst . GetTopic ( \"/datatable/X\" ); nt :: DoubleTopic dblTopic { genericTopic }; C++ (Handle-based) NT_Instance inst = nt :: GetDefaultInstance (); // get a topic from a NetworkTableInstance NT_Topic topic = nt :: GetTopic ( inst , \"/datatable/X\" ); C NT_Instance inst = NT_GetDefaultInstance (); // get a topic from a NetworkTableInstance NT_Topic topic = NT_GetTopic ( inst , \"/datatable/X\" ); Python import ntcore inst = ntcore . NetworkTableInstance . getDefault () table = inst . getTable ( \"datatable\" ) # get a topic from a NetworkTableInstance # the topic name in this case is the full name dblTopic = inst . getDoubleTopic ( \"/datatable/X\" ) # get a topic from a NetworkTable # the topic name in this case is the name within the table; # this line and the one above reference the same topic dblTopic = table . getDoubleTopic ( \"X\" ) # get a type-specific topic from a generic Topic genericTopic = inst . getTopic ( \"/datatable/X\" ) dblTopic = ntcore . DoubleTopic ( genericTopic )",
      "content_preview": "NetworkTables Tables and Topics Using the NetworkTable Class The NetworkTable ( Java , C++ , Python ) class is an API abstraction that represents a single “folder” (or “table”) of topics as described in NetworkTables Organization ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/nt4-migration-guide.html",
      "title": "Migrating from NetworkTables 3.0 to NetworkTables 4.0",
      "section": "NetworkTables",
      "language": "All",
      "content": "Migrating from NetworkTables 3.0 to NetworkTables 4.0 NetworkTables 4.0 (new for 2023) has a number of significant API breaking changes from NetworkTables 3.0, the version of NetworkTables used from 2016-2022. NetworkTableEntry While NetworkTableEntry can still be used (for backwards compatibility), users are encouraged to migrate to use of type-specific Publisher/Subscriber/Entry classes as appropriate, or if necessary, GenericEntry (see Publishing and Subscribing to a Topic . It’s important to note that unlike NetworkTableEntry , these classes need to have appropriate lifetime management. Some functionality (e.g. persistent settings) has also moved to Topic properties (see NetworkTables Tables and Topics ). NT3 code (was): JAVA public class Example { final NetworkTableEntry yEntry ; final NetworkTableEntry outEntry ; public Example () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // get the entry in \"datatable\" called \"Y\" yEntry = datatable . getEntry ( \"Y\" ); // get the entry in \"datatable\" called \"Out\" outEntry = datatable . getEntry ( \"Out\" ); } public void periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = yEntry . getDouble ( 0.0 ); // default to 0 outEntry . setDouble ( value * 2 ); } } C++ class Example { nt :: NetworkTableEntry yEntry ; nt :: NetworkTableEntry outEntry ; public : Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // get the entry in \"datatable\" called \"Y\" yEntry = datatable -> GetEntry ( \"Y\" ); // get the entry in \"datatable\" called \"Out\" outEntry = datatable -> GetEntry ( \"Out\" ); } void Periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = yEntry . GetDouble ( 0.0 ); // default to 0 outEntry . SetDouble ( value * 2 ); } }; PYTHON class Example : def __init__ ( self ): inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # get the entry in \"datatable\" called \"Y\" self . yEntry = datatable . getEntry ( \"Y\" ) # get the entry in \"datatable\" called \"Out\" self . outEntry = datatable . getEntry ( \"Out\" ) def periodic ( self ): # read a double value from Y, and set Out to that value multiplied by 2 value = self . yEntry . getDouble ( 0.0 ) # default to 0 self . outEntry . setDouble ( value * 2 ) Recommended NT4 equivalent (should be): JAVA public class Example { final DoubleSubscriber ySub ; final DoublePublisher outPub ; public Example () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" // default value is 0 ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); // publish to the topic in \"datatable\" called \"Out\" outPub = datatable . getDoubleTopic ( \"Out\" ). publish (); } public void periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = ySub . get (); outPub . set ( value * 2 ); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { ySub . close (); outPub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; nt :: DoublePublisher outPub ; public : Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" // default value is 0 ySub = datatable -> GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); // publish to the topic in \"datatable\" called \"Out\" outPub = datatable -> GetDoubleTopic ( \"Out\" ). Publish (); } void Periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = ySub . Get (); outPub . Set ( value * 2 ); } }; PYTHON class Example : def __init__ ( self ) -> None : inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" # default value is 0 self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) # publish to the topic in \"datatable\" called \"Out\" self . outPub = datatable . getDoubleTopic ( \"Out\" ) . publish () def periodic ( self ): # read a double value from Y, and set Out to that value multiplied by 2 value = self . ySub . get () self . outPub . set ( value * 2 ) # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): self . ySub . close () self . outPub . close () Shuffleboard In WPILib’s Shuffleboard classes, usage of NetworkTableEntry has been replaced with use of GenericEntry . In C++, since GenericEntry is non-copyable, return values now return a reference rather than a value. Force Set Operations Force set operations have been removed, as it’s no longer possible to change a topic’s type once it’s been published. In most cases calls to forceSet can simply be replaced with set , but more complex scenarios may require a different design approach (e.g. splitting into different topics). Listeners The separate connection, value, and log listeners/events have been unified into a single listener/event. The NetworkTable-level listeners have also been removed. Listeners in many cases can be replaced with subscriber readQueue() calls, but if listeners are still required, they can be used via NetworkTableInstance (see Listening for Changes for more information). While NetworkTable-level listeners were removed, table-specific listening functionality can be achieved by using NetworkTableInstance.addListener() with a topic name prefix filter. By passing an array of topic name prefixes (such as [\"/datatable/\"] ), the listener will only receive events for topics within that table. This is demonstrated in the Using NetworkTableInstance to Listen for Changes section. Client/Server Operations Starting a NetworkTable server now requires specifying both the NT3 port and the NT4 port. For a NT4-only server, the NT3 port can be specified as 0. A NetworkTable client can only operate in NT3 mode or NT4 mode, not both (there is no provision for automatic fallback). As such, the startClient() call has been replaced by startClient3() and startClient4() . The client must also specify a unique name for itself–the server will reject connection attempts with duplicate names. C++ Changes C++ values are now returned/used as value objects (plain nt::Value ) instead of shared pointers to them ( std::shared_ptr<nt::Value> ).",
      "content_preview": "Migrating from NetworkTables 3.0 to NetworkTables 4.0 NetworkTables 4.0 (new for 2023) has a number of significant API breaking changes from NetworkTables 3.0, the version of NetworkTables used from 2016-2022."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/nt4-migration-guide.html?present",
      "title": "Migrating from NetworkTables 3.0 to NetworkTables 4.0",
      "section": "NetworkTables",
      "language": "All",
      "content": "Migrating from NetworkTables 3.0 to NetworkTables 4.0 NetworkTables 4.0 (new for 2023) has a number of significant API breaking changes from NetworkTables 3.0, the version of NetworkTables used from 2016-2022. NetworkTableEntry While NetworkTableEntry can still be used (for backwards compatibility), users are encouraged to migrate to use of type-specific Publisher/Subscriber/Entry classes as appropriate, or if necessary, GenericEntry (see Publishing and Subscribing to a Topic . It’s important to note that unlike NetworkTableEntry , these classes need to have appropriate lifetime management. Some functionality (e.g. persistent settings) has also moved to Topic properties (see NetworkTables Tables and Topics ). NT3 code (was): JAVA public class Example { final NetworkTableEntry yEntry ; final NetworkTableEntry outEntry ; public Example () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // get the entry in \"datatable\" called \"Y\" yEntry = datatable . getEntry ( \"Y\" ); // get the entry in \"datatable\" called \"Out\" outEntry = datatable . getEntry ( \"Out\" ); } public void periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = yEntry . getDouble ( 0.0 ); // default to 0 outEntry . setDouble ( value * 2 ); } } C++ class Example { nt :: NetworkTableEntry yEntry ; nt :: NetworkTableEntry outEntry ; public : Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // get the entry in \"datatable\" called \"Y\" yEntry = datatable -> GetEntry ( \"Y\" ); // get the entry in \"datatable\" called \"Out\" outEntry = datatable -> GetEntry ( \"Out\" ); } void Periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = yEntry . GetDouble ( 0.0 ); // default to 0 outEntry . SetDouble ( value * 2 ); } }; PYTHON class Example : def __init__ ( self ): inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # get the entry in \"datatable\" called \"Y\" self . yEntry = datatable . getEntry ( \"Y\" ) # get the entry in \"datatable\" called \"Out\" self . outEntry = datatable . getEntry ( \"Out\" ) def periodic ( self ): # read a double value from Y, and set Out to that value multiplied by 2 value = self . yEntry . getDouble ( 0.0 ) # default to 0 self . outEntry . setDouble ( value * 2 ) Recommended NT4 equivalent (should be): JAVA public class Example { final DoubleSubscriber ySub ; final DoublePublisher outPub ; public Example () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); // get the subtable called \"datatable\" NetworkTable datatable = inst . getTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" // default value is 0 ySub = datatable . getDoubleTopic ( \"Y\" ). subscribe ( 0.0 ); // publish to the topic in \"datatable\" called \"Out\" outPub = datatable . getDoubleTopic ( \"Out\" ). publish (); } public void periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = ySub . get (); outPub . set ( value * 2 ); } // often not required in robot code, unless this class doesn't exist for // the lifetime of the entire robot program, in which case close() needs to be // called to stop subscribing public void close () { ySub . close (); outPub . close (); } } C++ class Example { nt :: DoubleSubscriber ySub ; nt :: DoublePublisher outPub ; public : Example () { nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: GetDefault (); // get the subtable called \"datatable\" auto datatable = inst . GetTable ( \"datatable\" ); // subscribe to the topic in \"datatable\" called \"Y\" // default value is 0 ySub = datatable -> GetDoubleTopic ( \"Y\" ). Subscribe ( 0.0 ); // publish to the topic in \"datatable\" called \"Out\" outPub = datatable -> GetDoubleTopic ( \"Out\" ). Publish (); } void Periodic () { // read a double value from Y, and set Out to that value multiplied by 2 double value = ySub . Get (); outPub . Set ( value * 2 ); } }; PYTHON class Example : def __init__ ( self ) -> None : inst = ntcore . NetworkTableInstance . getDefault () # get the subtable called \"datatable\" datatable = inst . getTable ( \"datatable\" ) # subscribe to the topic in \"datatable\" called \"Y\" # default value is 0 self . ySub = datatable . getDoubleTopic ( \"Y\" ) . subscribe ( 0.0 ) # publish to the topic in \"datatable\" called \"Out\" self . outPub = datatable . getDoubleTopic ( \"Out\" ) . publish () def periodic ( self ): # read a double value from Y, and set Out to that value multiplied by 2 value = self . ySub . get () self . outPub . set ( value * 2 ) # often not required in robot code, unless this class doesn't exist for # the lifetime of the entire robot program, in which case close() needs to be # called to stop subscribing def close ( self ): self . ySub . close () self . outPub . close () Shuffleboard In WPILib’s Shuffleboard classes, usage of NetworkTableEntry has been replaced with use of GenericEntry . In C++, since GenericEntry is non-copyable, return values now return a reference rather than a value. Force Set Operations Force set operations have been removed, as it’s no longer possible to change a topic’s type once it’s been published. In most cases calls to forceSet can simply be replaced with set , but more complex scenarios may require a different design approach (e.g. splitting into different topics). Listeners The separate connection, value, and log listeners/events have been unified into a single listener/event. The NetworkTable-level listeners have also been removed. Listeners in many cases can be replaced with subscriber readQueue() calls, but if listeners are still required, they can be used via NetworkTableInstance (see Listening for Changes for more information). While NetworkTable-level listeners were removed, table-specific listening functionality can be achieved by using NetworkTableInstance.addListener() with a topic name prefix filter. By passing an array of topic name prefixes (such as [\"/datatable/\"] ), the listener will only receive events for topics within that table. This is demonstrated in the Using NetworkTableInstance to Listen for Changes section. Client/Server Operations Starting a NetworkTable server now requires specifying both the NT3 port and the NT4 port. For a NT4-only server, the NT3 port can be specified as 0. A NetworkTable client can only operate in NT3 mode or NT4 mode, not both (there is no provision for automatic fallback). As such, the startClient() call has been replaced by startClient3() and startClient4() . The client must also specify a unique name for itself–the server will reject connection attempts with duplicate names. C++ Changes C++ values are now returned/used as value objects (plain nt::Value ) instead of shared pointers to them ( std::shared_ptr<nt::Value> ).",
      "content_preview": "Migrating from NetworkTables 3.0 to NetworkTables 4.0 NetworkTables 4.0 (new for 2023) has a number of significant API breaking changes from NetworkTables 3.0, the version of NetworkTables used from 2016-2022."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/client-side-program.html",
      "title": "Creating a Client",
      "section": "NetworkTables",
      "language": "All",
      "content": "Creating a Client-side Program If all you need to do is have your robot program communicate with a COTS coprocessor or a dashboard running on the Driver Station laptop, then the previous examples of writing robot programs are sufficient. But if you would like to write some custom client code that would run on the drivers station or on a coprocessor then you need to know how to build NetworkTables programs for those (non-roboRIO) platforms. A basic client program looks like the following example. Java import edu.wpi.first.networktables.DoubleSubscriber ; import edu.wpi.first.networktables.NetworkTable ; import edu.wpi.first.networktables.NetworkTableInstance ; import edu.wpi.first.networktables.NetworkTablesJNI ; import edu.wpi.first.util.CombinedRuntimeLoader ; import java.io.IOException ; import edu.wpi.first.cscore.CameraServerJNI ; import edu.wpi.first.math.WPIMathJNI ; import edu.wpi.first.util.WPIUtilJNI ; public class Program { public static void main ( String [] args ) throws IOException { NetworkTablesJNI . Helper . setExtractOnStaticLoad ( false ); WPIUtilJNI . Helper . setExtractOnStaticLoad ( false ); WPIMathJNI . Helper . setExtractOnStaticLoad ( false ); CameraServerJNI . Helper . setExtractOnStaticLoad ( false ); CombinedRuntimeLoader . loadLibraries ( Program . class , \"wpiutiljni\" , \"wpimathjni\" , \"ntcorejni\" , Core . NATIVE_LIBRARY_NAME , \"cscorejni\" ); new Program (). run (); } public void run () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); NetworkTable table = inst . getTable ( \"datatable\" ); DoubleSubscriber xSub = table . getDoubleTopic ( \"x\" ). subscribe ( 0.0 ); DoubleSubscriber ySub = table . getDoubleTopic ( \"y\" ). subscribe ( 0.0 ); inst . startClient4 ( \"example client\" ); inst . setServerTeam ( TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . startDSClient (); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { try { Thread . sleep ( 1000 ); } catch ( InterruptedException ex ) { System . out . println ( \"interrupted\" ); return ; } double x = xSub . get (); double y = ySub . get (); System . out . println ( \"X: \" + x + \" Y: \" + y ); } } } C++ #include <chrono> #include <thread> #include <fmt/format.h> #include <networktables/NetworkTableInstance.h> #include <networktables/NetworkTable.h> #include <networktables/DoubleTopic.h> int main () { auto inst = nt :: NetworkTableInstance :: GetDefault (); auto table = inst . GetTable ( \"datatable\" ); auto xSub = table -> GetDoubleTopic ( \"x\" ). Subscribe ( 0.0 ); auto ySub = table -> GetDoubleTopic ( \"y\" ). Subscribe ( 0.0 ); inst . StartClient4 ( \"example client\" ); inst . SetServerTeam ( TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . StartDSClient (); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { using namespace std :: chrono_literals ; std :: this_thread :: sleep_for ( 1 s ); double x = xSub . Get (); double y = ySub . Get (); fmt :: print ( \"X: {} Y: {} \\n \" , x , y ); } } C++ (Handle-based) #include <chrono> #include <thread> #include <fmt/format.h> #include <ntcore_cpp.h> int main () { NT_Inst inst = nt :: GetDefaultInstance (); NT_Subscriber xSub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/x\" ), NT_DOUBLE , \"double\" ); NT_Subscriber ySub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/y\" ), NT_DOUBLE , \"double\" ); nt :: StartClient4 ( inst , \"example client\" ); nt :: SetServerTeam ( inst , TEAM , 0 ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar nt :: StartDSClient ( inst , 0 ); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { using namespace std :: chrono_literals ; std :: this_thread :: sleep_for ( 1 s ); double x = nt :: GetDouble ( xSub , 0.0 ); double y = nt :: GetDouble ( ySub , 0.0 ); fmt :: print ( \"X: {} Y: {} \\n \" , x , y ); } } C #include <stdio.h> #include <threads.h> #include <time.h> #include <networktables/ntcore.h> int main () { NT_Instance inst = NT_GetDefaultInstance (); NT_Subscriber xSub = NT_Subscribe ( NT_GetTopic ( inst , \"/datatable/x\" ), NT_DOUBLE , \"double\" , NULL , 0 ); NT_Subscriber ySub = NT_Subscribe ( NT_GetTopic ( inst , \"/datatable/y\" ), NT_DOUBLE , \"double\" , NULL , 0 ); NT_StartClient4 ( inst , \"example client\" ); NT_SetServerTeam ( inst , TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar NT_StartDSClient ( inst ); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { thrd_sleep ( & ( struct timespec ){. tv_sec = 1 }, NULL ); double x = NT_GetDouble ( xSub , 0.0 ); double y = NT_GetDouble ( ySub , 0.0 ); printf ( \"X: %f Y: %f \\n \" , x , y ); } } Python #!/usr/bin/env python3 import ntcore import time if __name__ == \"__main__\" : inst = ntcore . NetworkTableInstance . getDefault () table = inst . getTable ( \"datatable\" ) xSub = table . getDoubleTopic ( \"x\" ) . subscribe ( 0 ) ySub = table . getDoubleTopic ( \"y\" ) . subscribe ( 0 ) inst . startClient4 ( \"example client\" ) inst . setServerTeam ( TEAM ) # where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . startDSClient () # recommended if running on DS computer; this gets the robot IP from the DS while True : time . sleep ( 1 ) x = xSub . get () y = ySub . get () print ( f \"X: { x } Y: { y } \" ) In this example an instance of NetworkTables is created and subscribers are created to reference the values of “x” and “y” from a table called “datatable”. Then this instance is started as a NetworkTables client with the team number (the roboRIO is always the server). Additionally, if the program is running on the Driver Station computer, by using the startDSClient() method, NetworkTables will get the robot IP address from the Driver Station. Then this sample program simply loops once a second and gets the values for x and y and prints them on the console. In a more realistic program, the client might be processing or generating values for the robot to consume. Building using Gradle Example build.gradle files are provided in the StandaloneAppSamples Repository Update the GradleRIO version to correspond to the desired WPILib version. Java 1 plugins { 2 id \"java\" 3 id 'application' 4 id 'com.gradleup.shadow' version '8.3.5' 5 id \"edu.wpi.first.GradleRIO\" version \"2025.1.1\" 6 id 'edu.wpi.first.WpilibTools' version '2.1.0' 7 } 8 9 application { 10 mainClass = 'Program' 11 } 12 13 wpilibTools . deps . wpilibVersion = wpi . versions . wpilibVersion . get () 14 15 def nativeConfigName = 'wpilibNatives' 16 def nativeConfig = configurations . create ( nativeConfigName ) 17 18 def nativeTasks = wpilibTools . createExtractionTasks { 19 configurationName = nativeConfigName 20 } 21 22 nativeTasks . addToSourceSetResources ( sourceSets . main ) 23 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpimath\" ) 24 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpinet\" ) 25 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpiutil\" ) 26 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"ntcore\" ) 27 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"cscore\" ) 28 nativeConfig . dependencies . add wpilibTools . deps . wpilibOpenCv ( \"frc\" + wpi . frcYear . get (), wpi . versions . opencvVersion . get ()) 29 30 dependencies { 31 implementation wpilibTools . deps . wpilibJava ( \"wpiutil\" ) 32 implementation wpilibTools . deps . wpilibJava ( \"wpimath\" ) 33 implementation wpilibTools . deps . wpilibJava ( \"wpinet\" ) 34 implementation wpilibTools . deps . wpilibJava ( \"ntcore\" ) 35 implementation wpilibTools . deps . wpilibJava ( \"cscore\" ) 36 implementation wpilibTools . deps . wpilibJava ( \"cameraserver\" ) 37 implementation wpilibTools . deps . wpilibOpenCvJava ( \"frc\" + wpi . frcYear . get (), wpi . versions . opencvVersion . get ()) 38 39 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-annotations\" , version: wpi . versions . jacksonVersion . get () 40 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-core\" , version: wpi . versions . jacksonVersion . get () 41 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-databind\" , version: wpi . versions . jacksonVersion . get () 42 43 implementation group: \"org.ejml\" , name: \"ejml-simple\" , version: wpi . versions . ejmlVersion . get () 44 implementation group: \"us.hebi.quickbuf\" , name: \"quickbuf-runtime\" , version: wpi . versions . quickbufVersion . get (); 45 } 46 47 shadowJar { 48 archiveBaseName = \"TestApplication\" 49 archiveVersion = \"\" 50 exclude ( \"module-info.class\" ) 51 archiveClassifier . set ( wpilibTools . currentPlatform . platformName ) 52 } 53 54 wrapper { 55 gradleVersion = '8.11' 56 } C++ Uncomment the appropriate platform as highlighted. 1 plugins { 2 id \"cpp\" 3 id \"edu.wpi.first.GradleRIO\" version \"2025.1.1\" 4 } 5 6 // Disable local cache, as it won't have the cross artifact necessary 7 wpi . maven . useLocal = false 8 9 // Set to true to run simulation in debug mode 10 wpi . cpp . debugSimulation = false 11 12 def appName = \"TestApplication\" 13 14 //nativeUtils.withCrossLinuxArm64() // Uncomment to build for Linux Arm 64. targetPlatform below also needs to be fixed 15 //nativeUtils.withCrossLinuxArm32() // Uncomment to build for Linux Arm 32. targetPlatform below also needs to be fixed 16 17 model { 18 components { 19 \"${appName}\" ( NativeExecutableSpec ) { 20 targetPlatform wpi . platforms . desktop // Uncomment to build on whatever the native platform currently is 21 //targetPlatform wpi.platforms.linuxarm64 // Uncomment to build for Linux Arm 64 22 //targetPlatform wpi.platforms.linuxarm32 // Uncomment to build for Linux Arm 32 23 24 sources . cpp { 25 source { 26 srcDir 'src/main/cpp' 27 include '**/*.cpp' , '**/*.cc' 28 } 29 exportedHeaders { 30 srcDir 'src/main/include' 31 } 32 } 33 34 // Enable run tasks for this component 35 wpi . cpp . enableExternalTasks ( it ) 36 37 wpi . cpp . deps . wpilibStatic ( it ) 38 } 39 } 40 } 41 42 wrapper { 43 gradleVersion = '8.11' 44 } Building Python For Python, refer to the RobotPy install documentation .",
      "content_preview": "Creating a Client-side Program If all you need to do is have your robot program communicate with a COTS coprocessor or a dashboard running on the Driver Station laptop, then the previous examples of writing robot programs are sufficient."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/client-side-program.html?present",
      "title": "Creating a Client",
      "section": "NetworkTables",
      "language": "All",
      "content": "Creating a Client-side Program If all you need to do is have your robot program communicate with a COTS coprocessor or a dashboard running on the Driver Station laptop, then the previous examples of writing robot programs are sufficient. But if you would like to write some custom client code that would run on the drivers station or on a coprocessor then you need to know how to build NetworkTables programs for those (non-roboRIO) platforms. A basic client program looks like the following example. Java import edu.wpi.first.networktables.DoubleSubscriber ; import edu.wpi.first.networktables.NetworkTable ; import edu.wpi.first.networktables.NetworkTableInstance ; import edu.wpi.first.networktables.NetworkTablesJNI ; import edu.wpi.first.util.CombinedRuntimeLoader ; import java.io.IOException ; import edu.wpi.first.cscore.CameraServerJNI ; import edu.wpi.first.math.WPIMathJNI ; import edu.wpi.first.util.WPIUtilJNI ; public class Program { public static void main ( String [] args ) throws IOException { NetworkTablesJNI . Helper . setExtractOnStaticLoad ( false ); WPIUtilJNI . Helper . setExtractOnStaticLoad ( false ); WPIMathJNI . Helper . setExtractOnStaticLoad ( false ); CameraServerJNI . Helper . setExtractOnStaticLoad ( false ); CombinedRuntimeLoader . loadLibraries ( Program . class , \"wpiutiljni\" , \"wpimathjni\" , \"ntcorejni\" , Core . NATIVE_LIBRARY_NAME , \"cscorejni\" ); new Program (). run (); } public void run () { NetworkTableInstance inst = NetworkTableInstance . getDefault (); NetworkTable table = inst . getTable ( \"datatable\" ); DoubleSubscriber xSub = table . getDoubleTopic ( \"x\" ). subscribe ( 0.0 ); DoubleSubscriber ySub = table . getDoubleTopic ( \"y\" ). subscribe ( 0.0 ); inst . startClient4 ( \"example client\" ); inst . setServerTeam ( TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . startDSClient (); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { try { Thread . sleep ( 1000 ); } catch ( InterruptedException ex ) { System . out . println ( \"interrupted\" ); return ; } double x = xSub . get (); double y = ySub . get (); System . out . println ( \"X: \" + x + \" Y: \" + y ); } } } C++ #include <chrono> #include <thread> #include <fmt/format.h> #include <networktables/NetworkTableInstance.h> #include <networktables/NetworkTable.h> #include <networktables/DoubleTopic.h> int main () { auto inst = nt :: NetworkTableInstance :: GetDefault (); auto table = inst . GetTable ( \"datatable\" ); auto xSub = table -> GetDoubleTopic ( \"x\" ). Subscribe ( 0.0 ); auto ySub = table -> GetDoubleTopic ( \"y\" ). Subscribe ( 0.0 ); inst . StartClient4 ( \"example client\" ); inst . SetServerTeam ( TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . StartDSClient (); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { using namespace std :: chrono_literals ; std :: this_thread :: sleep_for ( 1 s ); double x = xSub . Get (); double y = ySub . Get (); fmt :: print ( \"X: {} Y: {} \\n \" , x , y ); } } C++ (Handle-based) #include <chrono> #include <thread> #include <fmt/format.h> #include <ntcore_cpp.h> int main () { NT_Inst inst = nt :: GetDefaultInstance (); NT_Subscriber xSub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/x\" ), NT_DOUBLE , \"double\" ); NT_Subscriber ySub = nt :: Subscribe ( nt :: GetTopic ( inst , \"/datatable/y\" ), NT_DOUBLE , \"double\" ); nt :: StartClient4 ( inst , \"example client\" ); nt :: SetServerTeam ( inst , TEAM , 0 ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar nt :: StartDSClient ( inst , 0 ); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { using namespace std :: chrono_literals ; std :: this_thread :: sleep_for ( 1 s ); double x = nt :: GetDouble ( xSub , 0.0 ); double y = nt :: GetDouble ( ySub , 0.0 ); fmt :: print ( \"X: {} Y: {} \\n \" , x , y ); } } C #include <stdio.h> #include <threads.h> #include <time.h> #include <networktables/ntcore.h> int main () { NT_Instance inst = NT_GetDefaultInstance (); NT_Subscriber xSub = NT_Subscribe ( NT_GetTopic ( inst , \"/datatable/x\" ), NT_DOUBLE , \"double\" , NULL , 0 ); NT_Subscriber ySub = NT_Subscribe ( NT_GetTopic ( inst , \"/datatable/y\" ), NT_DOUBLE , \"double\" , NULL , 0 ); NT_StartClient4 ( inst , \"example client\" ); NT_SetServerTeam ( inst , TEAM ); // where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar NT_StartDSClient ( inst ); // recommended if running on DS computer; this gets the robot IP from the DS while ( true ) { thrd_sleep ( & ( struct timespec ){. tv_sec = 1 }, NULL ); double x = NT_GetDouble ( xSub , 0.0 ); double y = NT_GetDouble ( ySub , 0.0 ); printf ( \"X: %f Y: %f \\n \" , x , y ); } } Python #!/usr/bin/env python3 import ntcore import time if __name__ == \"__main__\" : inst = ntcore . NetworkTableInstance . getDefault () table = inst . getTable ( \"datatable\" ) xSub = table . getDoubleTopic ( \"x\" ) . subscribe ( 0 ) ySub = table . getDoubleTopic ( \"y\" ) . subscribe ( 0 ) inst . startClient4 ( \"example client\" ) inst . setServerTeam ( TEAM ) # where TEAM=190, 294, etc, or use inst.setServer(\"hostname\") or similar inst . startDSClient () # recommended if running on DS computer; this gets the robot IP from the DS while True : time . sleep ( 1 ) x = xSub . get () y = ySub . get () print ( f \"X: { x } Y: { y } \" ) In this example an instance of NetworkTables is created and subscribers are created to reference the values of “x” and “y” from a table called “datatable”. Then this instance is started as a NetworkTables client with the team number (the roboRIO is always the server). Additionally, if the program is running on the Driver Station computer, by using the startDSClient() method, NetworkTables will get the robot IP address from the Driver Station. Then this sample program simply loops once a second and gets the values for x and y and prints them on the console. In a more realistic program, the client might be processing or generating values for the robot to consume. Building using Gradle Example build.gradle files are provided in the StandaloneAppSamples Repository Update the GradleRIO version to correspond to the desired WPILib version. Java 1 plugins { 2 id \"java\" 3 id 'application' 4 id 'com.gradleup.shadow' version '8.3.5' 5 id \"edu.wpi.first.GradleRIO\" version \"2025.1.1\" 6 id 'edu.wpi.first.WpilibTools' version '2.1.0' 7 } 8 9 application { 10 mainClass = 'Program' 11 } 12 13 wpilibTools . deps . wpilibVersion = wpi . versions . wpilibVersion . get () 14 15 def nativeConfigName = 'wpilibNatives' 16 def nativeConfig = configurations . create ( nativeConfigName ) 17 18 def nativeTasks = wpilibTools . createExtractionTasks { 19 configurationName = nativeConfigName 20 } 21 22 nativeTasks . addToSourceSetResources ( sourceSets . main ) 23 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpimath\" ) 24 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpinet\" ) 25 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"wpiutil\" ) 26 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"ntcore\" ) 27 nativeConfig . dependencies . add wpilibTools . deps . wpilib ( \"cscore\" ) 28 nativeConfig . dependencies . add wpilibTools . deps . wpilibOpenCv ( \"frc\" + wpi . frcYear . get (), wpi . versions . opencvVersion . get ()) 29 30 dependencies { 31 implementation wpilibTools . deps . wpilibJava ( \"wpiutil\" ) 32 implementation wpilibTools . deps . wpilibJava ( \"wpimath\" ) 33 implementation wpilibTools . deps . wpilibJava ( \"wpinet\" ) 34 implementation wpilibTools . deps . wpilibJava ( \"ntcore\" ) 35 implementation wpilibTools . deps . wpilibJava ( \"cscore\" ) 36 implementation wpilibTools . deps . wpilibJava ( \"cameraserver\" ) 37 implementation wpilibTools . deps . wpilibOpenCvJava ( \"frc\" + wpi . frcYear . get (), wpi . versions . opencvVersion . get ()) 38 39 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-annotations\" , version: wpi . versions . jacksonVersion . get () 40 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-core\" , version: wpi . versions . jacksonVersion . get () 41 implementation group: \"com.fasterxml.jackson.core\" , name: \"jackson-databind\" , version: wpi . versions . jacksonVersion . get () 42 43 implementation group: \"org.ejml\" , name: \"ejml-simple\" , version: wpi . versions . ejmlVersion . get () 44 implementation group: \"us.hebi.quickbuf\" , name: \"quickbuf-runtime\" , version: wpi . versions . quickbufVersion . get (); 45 } 46 47 shadowJar { 48 archiveBaseName = \"TestApplication\" 49 archiveVersion = \"\" 50 exclude ( \"module-info.class\" ) 51 archiveClassifier . set ( wpilibTools . currentPlatform . platformName ) 52 } 53 54 wrapper { 55 gradleVersion = '8.11' 56 } C++ Uncomment the appropriate platform as highlighted. 1 plugins { 2 id \"cpp\" 3 id \"edu.wpi.first.GradleRIO\" version \"2025.1.1\" 4 } 5 6 // Disable local cache, as it won't have the cross artifact necessary 7 wpi . maven . useLocal = false 8 9 // Set to true to run simulation in debug mode 10 wpi . cpp . debugSimulation = false 11 12 def appName = \"TestApplication\" 13 14 //nativeUtils.withCrossLinuxArm64() // Uncomment to build for Linux Arm 64. targetPlatform below also needs to be fixed 15 //nativeUtils.withCrossLinuxArm32() // Uncomment to build for Linux Arm 32. targetPlatform below also needs to be fixed 16 17 model { 18 components { 19 \"${appName}\" ( NativeExecutableSpec ) { 20 targetPlatform wpi . platforms . desktop // Uncomment to build on whatever the native platform currently is 21 //targetPlatform wpi.platforms.linuxarm64 // Uncomment to build for Linux Arm 64 22 //targetPlatform wpi.platforms.linuxarm32 // Uncomment to build for Linux Arm 32 23 24 sources . cpp { 25 source { 26 srcDir 'src/main/cpp' 27 include '**/*.cpp' , '**/*.cc' 28 } 29 exportedHeaders { 30 srcDir 'src/main/include' 31 } 32 } 33 34 // Enable run tasks for this component 35 wpi . cpp . enableExternalTasks ( it ) 36 37 wpi . cpp . deps . wpilibStatic ( it ) 38 } 39 } 40 } 41 42 wrapper { 43 gradleVersion = '8.11' 44 } Building Python For Python, refer to the RobotPy install documentation .",
      "content_preview": "Creating a Client-side Program If all you need to do is have your robot program communicate with a COTS coprocessor or a dashboard running on the Driver Station laptop, then the previous examples of writing robot programs are sufficient."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/robot-program.html",
      "title": "Writing a Simple NetworkTables Robot Program",
      "section": "NetworkTables",
      "language": "All",
      "content": "Writing a Simple NetworkTables Robot Program In a robot program, a NetworkTables server is automatically started on the default instance. So it’s only necessary to get the default instance to start publishing or subscribing and have it visible over the network. The example robot program below publishes incrementing X and Y values to a table named datatable . The values for X and Y can be easily viewed using the OutlineViewer program that shows the NetworkTables hierarchy and all the values associated with each topic. JAVA package edu.wpi.first.wpilibj.templates ; import edu.wpi.first.wpilibj.TimedRobot ; import edu.wpi.first.networktables.DoublePublisher ; import edu.wpi.first.networktables.NetworkTable ; import edu.wpi.first.networktables.NetworkTableInstance ; public class EasyNetworkTableExample extends TimedRobot { DoublePublisher xPub ; DoublePublisher yPub ; public Robot () { // Get the default instance of NetworkTables that was created automatically // when the robot program starts NetworkTableInstance inst = NetworkTableInstance . getDefault (); // Get the table within that instance that contains the data. There can // be as many tables as you like and exist to make it easier to organize // your data. In this case, it's a table called datatable. NetworkTable table = inst . getTable ( \"datatable\" ); // Start publishing topics within that table that correspond to the X and Y values // for some operation in your program. // The topic names are actually \"/datatable/x\" and \"/datatable/y\". xPub = table . getDoubleTopic ( \"x\" ). publish (); yPub = table . getDoubleTopic ( \"y\" ). publish (); } double x = 0 ; double y = 0 ; public void teleopPeriodic () { // Publish values that are constantly increasing. xPub . set ( x ); yPub . set ( y ); x += 0.05 ; y += 1.0 ; } } C++ #include <frc/TimedRobot.h> #include <networktables/DoubleTopic.h> #include <networktables/NetworkTable.h> #include <networktables/NetworkTableInstance.h> class EasyNetworkExample : public frc :: TimedRobot { public : nt :: DoublePublisher xPub ; nt :: DoublePublisher yPub ; Robot () { // Get the default instance of NetworkTables that was created automatically // when the robot program starts auto inst = nt :: NetworkTableInstance :: GetDefault (); // Get the table within that instance that contains the data. There can // be as many tables as you like and exist to make it easier to organize // your data. In this case, it's a table called datatable. auto table = inst . GetTable ( \"datatable\" ); // Start publishing topics within that table that correspond to the X and Y values // for some operation in your program. // The topic names are actually \"/datatable/x\" and \"/datatable/y\". xPub = table -> GetDoubleTopic ( \"x\" ). Publish (); yPub = table -> GetDoubleTopic ( \"y\" ). Publish (); } double x = 0 ; double y = 0 ; void TeleopPeriodic () { // Publish values that are constantly increasing. xPub . Set ( x ); yPub . Set ( y ); x += 0.05 ; y += 0.05 ; } } START_ROBOT_CLASS ( EasyNetworkExample ) PYTHON import ntcore import wpilib class EasyNetworkTableExample ( wpilib . TimedRobot ): def robotInit ( self ) -> None : # Get the default instance of NetworkTables that was created automatically # when the robot program starts inst = ntcore . NetworkTableInstance . getDefault () # Get the table within that instance that contains the data. There can # be as many tables as you like and exist to make it easier to organize # your data. In this case, it's a table called datatable. table = inst . getTable ( \"datatable\" ) # Start publishing topics within that table that correspond to the X and Y values # for some operation in your program. # The topic names are actually \"/datatable/x\" and \"/datatable/y\". self . xPub = table . getDoubleTopic ( \"x\" ) . publish () self . yPub = table . getDoubleTopic ( \"y\" ) . publish () self . x = 0 self . y = 0 def teleopPeriodic ( self ) -> None : # Publish values that are constantly increasing. self . xPub . set ( self . x ) self . yPub . set ( self . y ) self . x += 0.05 self . y += 1.0",
      "content_preview": "Writing a Simple NetworkTables Robot Program In a robot program, a NetworkTables server is automatically started on the default instance. So it’s only necessary to get the default instance to start publishing or subscribing and have it visible over the network."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/robot-program.html?present",
      "title": "Writing a Simple NetworkTables Robot Program",
      "section": "NetworkTables",
      "language": "All",
      "content": "Writing a Simple NetworkTables Robot Program In a robot program, a NetworkTables server is automatically started on the default instance. So it’s only necessary to get the default instance to start publishing or subscribing and have it visible over the network. The example robot program below publishes incrementing X and Y values to a table named datatable . The values for X and Y can be easily viewed using the OutlineViewer program that shows the NetworkTables hierarchy and all the values associated with each topic. JAVA package edu.wpi.first.wpilibj.templates ; import edu.wpi.first.wpilibj.TimedRobot ; import edu.wpi.first.networktables.DoublePublisher ; import edu.wpi.first.networktables.NetworkTable ; import edu.wpi.first.networktables.NetworkTableInstance ; public class EasyNetworkTableExample extends TimedRobot { DoublePublisher xPub ; DoublePublisher yPub ; public Robot () { // Get the default instance of NetworkTables that was created automatically // when the robot program starts NetworkTableInstance inst = NetworkTableInstance . getDefault (); // Get the table within that instance that contains the data. There can // be as many tables as you like and exist to make it easier to organize // your data. In this case, it's a table called datatable. NetworkTable table = inst . getTable ( \"datatable\" ); // Start publishing topics within that table that correspond to the X and Y values // for some operation in your program. // The topic names are actually \"/datatable/x\" and \"/datatable/y\". xPub = table . getDoubleTopic ( \"x\" ). publish (); yPub = table . getDoubleTopic ( \"y\" ). publish (); } double x = 0 ; double y = 0 ; public void teleopPeriodic () { // Publish values that are constantly increasing. xPub . set ( x ); yPub . set ( y ); x += 0.05 ; y += 1.0 ; } } C++ #include <frc/TimedRobot.h> #include <networktables/DoubleTopic.h> #include <networktables/NetworkTable.h> #include <networktables/NetworkTableInstance.h> class EasyNetworkExample : public frc :: TimedRobot { public : nt :: DoublePublisher xPub ; nt :: DoublePublisher yPub ; Robot () { // Get the default instance of NetworkTables that was created automatically // when the robot program starts auto inst = nt :: NetworkTableInstance :: GetDefault (); // Get the table within that instance that contains the data. There can // be as many tables as you like and exist to make it easier to organize // your data. In this case, it's a table called datatable. auto table = inst . GetTable ( \"datatable\" ); // Start publishing topics within that table that correspond to the X and Y values // for some operation in your program. // The topic names are actually \"/datatable/x\" and \"/datatable/y\". xPub = table -> GetDoubleTopic ( \"x\" ). Publish (); yPub = table -> GetDoubleTopic ( \"y\" ). Publish (); } double x = 0 ; double y = 0 ; void TeleopPeriodic () { // Publish values that are constantly increasing. xPub . Set ( x ); yPub . Set ( y ); x += 0.05 ; y += 0.05 ; } } START_ROBOT_CLASS ( EasyNetworkExample ) PYTHON import ntcore import wpilib class EasyNetworkTableExample ( wpilib . TimedRobot ): def robotInit ( self ) -> None : # Get the default instance of NetworkTables that was created automatically # when the robot program starts inst = ntcore . NetworkTableInstance . getDefault () # Get the table within that instance that contains the data. There can # be as many tables as you like and exist to make it easier to organize # your data. In this case, it's a table called datatable. table = inst . getTable ( \"datatable\" ) # Start publishing topics within that table that correspond to the X and Y values # for some operation in your program. # The topic names are actually \"/datatable/x\" and \"/datatable/y\". self . xPub = table . getDoubleTopic ( \"x\" ) . publish () self . yPub = table . getDoubleTopic ( \"y\" ) . publish () self . x = 0 self . y = 0 def teleopPeriodic ( self ) -> None : # Publish values that are constantly increasing. self . xPub . set ( self . x ) self . yPub . set ( self . y ) self . x += 0.05 self . y += 1.0",
      "content_preview": "Writing a Simple NetworkTables Robot Program In a robot program, a NetworkTables server is automatically started on the default instance. So it’s only necessary to get the default instance to start publishing or subscribing and have it visible over the network."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/reading-array-values-published-by-networktables.html",
      "title": "Reading Array Values Published by NetworkTables",
      "section": "NetworkTables",
      "language": "All",
      "content": "Reading Array Values Published by NetworkTables This article describes how to read values published by NetworkTables using a program running on the robot. This is useful when using computer vision where the images are processed on your driver station laptop and the results stored into NetworkTables possibly using a separate vision processor like a raspberry pi, or a tool on the robot like a python program to do the image processing. Very often the values are for one or more areas of interest such as goals or game pieces and multiple instances are returned. In the example below, several x, y, width, height, and areas are returned by the image processor and the robot program can sort out which of the returned values are interesting through further processing. Verify the NetworkTables Topics Being Published You can verify the names of the NetworkTables topics used for publishing the values by using the Outline Viewer application. It is a C++ program in your user directory in the wpilib/<YEAR>/tools folder. The application is started by selecting the “WPILib” menu in Visual Studio Code then Start Tool then “OutlineViewer”. In this case the values are stored in a table called GRIP and a sub-table called myContoursReport. You can see that the values are in brackets and there are 2 values in this case for each topic. The NetworkTables topic names are centerX, centerY, area, height, and width. Both of the following examples are extremely simplified programs that just illustrate the use of NetworkTables. All the code is in the robotInit() method so it’s only run when the program starts up. In your programs, you would more likely get the values in code that is evaluating which direction to aim the robot in a command or a control loop during the autonomous or teleop periods. Writing a Program to Access the Topics JAVA DoubleArraySubscriber areasSub ; public Robot () { NetworkTable table = NetworkTableInstance . getDefault (). getTable ( \"GRIP/mycontoursReport\" ); areasSub = table . getDoubleArrayTopic ( \"area\" ). subscribe ( new double [] {}); } @Override public void teleopPeriodic () { double [] areas = areasSub . get (); System . out . print ( \"areas: \" ); for ( double area : areas ) { System . out . print ( area + \" \" ); } System . out . println (); } C++ nt :: DoubleArraySubscriber areasSub ; Robot :: Robot () { auto table = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"GRIP/myContoursReport\" ); areasSub = table -> GetDoubleArrayTopic ( \"area\" ). Subscribe ({}); } void Robot :: TeleopPeriodic () override { std :: cout << \"Areas: \" ; std :: vector < double > arr = areasSub . Get (); for ( double val : arr ) { std :: cout << val << \" \" ; } std :: cout << std :: endl ; } PYTHON def robotInit ( self ): table = ntcore . NetworkTableInstance . getDefault () . getTable ( \"GRIP/mycontoursReport\" ) self . areasSub = table . getDoubleArrayTopic ( \"area\" ) . subscribe ([]) def teleopPeriodic ( self ): areas = self . areasSub . get () print ( \"Areas:\" , areas ) The steps to getting the values and, in this program, printing them are: Declare the table variable that will hold the instance of the subtable that have the values. Initialize the subtable instance so that it can be used later for retrieving the values. Read the array of values from NetworkTables. In the case of a communicating programs, it’s possible that the program producing the output being read here might not yet be available when the robot program starts up. To avoid issues of the data not being ready, a default array of values is supplied. This default value will be returned if the NetworkTables topic hasn’t yet been published. This code will loop over the value of areas every 20ms. Program Output In this case the program is only looking at the array of areas, but in a real example all the values would more likely be used. Using the Riolog in VS Code or the Driver Station log you can see the values as they are retrieved. This program is using a sample static image so they areas don’t change, but you can imagine with a camera on your robot, the values would be changing constantly.",
      "content_preview": "Reading Array Values Published by NetworkTables This article describes how to read values published by NetworkTables using a program running on the robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/reading-array-values-published-by-networktables.html?present",
      "title": "Reading Array Values Published by NetworkTables",
      "section": "NetworkTables",
      "language": "All",
      "content": "Reading Array Values Published by NetworkTables This article describes how to read values published by NetworkTables using a program running on the robot. This is useful when using computer vision where the images are processed on your driver station laptop and the results stored into NetworkTables possibly using a separate vision processor like a raspberry pi, or a tool on the robot like a python program to do the image processing. Very often the values are for one or more areas of interest such as goals or game pieces and multiple instances are returned. In the example below, several x, y, width, height, and areas are returned by the image processor and the robot program can sort out which of the returned values are interesting through further processing. Verify the NetworkTables Topics Being Published You can verify the names of the NetworkTables topics used for publishing the values by using the Outline Viewer application. It is a C++ program in your user directory in the wpilib/<YEAR>/tools folder. The application is started by selecting the “WPILib” menu in Visual Studio Code then Start Tool then “OutlineViewer”. In this case the values are stored in a table called GRIP and a sub-table called myContoursReport. You can see that the values are in brackets and there are 2 values in this case for each topic. The NetworkTables topic names are centerX, centerY, area, height, and width. Both of the following examples are extremely simplified programs that just illustrate the use of NetworkTables. All the code is in the robotInit() method so it’s only run when the program starts up. In your programs, you would more likely get the values in code that is evaluating which direction to aim the robot in a command or a control loop during the autonomous or teleop periods. Writing a Program to Access the Topics JAVA DoubleArraySubscriber areasSub ; public Robot () { NetworkTable table = NetworkTableInstance . getDefault (). getTable ( \"GRIP/mycontoursReport\" ); areasSub = table . getDoubleArrayTopic ( \"area\" ). subscribe ( new double [] {}); } @Override public void teleopPeriodic () { double [] areas = areasSub . get (); System . out . print ( \"areas: \" ); for ( double area : areas ) { System . out . print ( area + \" \" ); } System . out . println (); } C++ nt :: DoubleArraySubscriber areasSub ; Robot :: Robot () { auto table = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"GRIP/myContoursReport\" ); areasSub = table -> GetDoubleArrayTopic ( \"area\" ). Subscribe ({}); } void Robot :: TeleopPeriodic () override { std :: cout << \"Areas: \" ; std :: vector < double > arr = areasSub . Get (); for ( double val : arr ) { std :: cout << val << \" \" ; } std :: cout << std :: endl ; } PYTHON def robotInit ( self ): table = ntcore . NetworkTableInstance . getDefault () . getTable ( \"GRIP/mycontoursReport\" ) self . areasSub = table . getDoubleArrayTopic ( \"area\" ) . subscribe ([]) def teleopPeriodic ( self ): areas = self . areasSub . get () print ( \"Areas:\" , areas ) The steps to getting the values and, in this program, printing them are: Declare the table variable that will hold the instance of the subtable that have the values. Initialize the subtable instance so that it can be used later for retrieving the values. Read the array of values from NetworkTables. In the case of a communicating programs, it’s possible that the program producing the output being read here might not yet be available when the robot program starts up. To avoid issues of the data not being ready, a default array of values is supplied. This default value will be returned if the NetworkTables topic hasn’t yet been published. This code will loop over the value of areas every 20ms. Program Output In this case the program is only looking at the array of areas, but in a real example all the values would more likely be used. Using the Riolog in VS Code or the Driver Station log you can see the values as they are retrieved. This program is using a sample static image so they areas don’t change, but you can imagine with a camera on your robot, the values would be changing constantly.",
      "content_preview": "Reading Array Values Published by NetworkTables This article describes how to read values published by NetworkTables using a program running on the robot."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/multiple-instances.html",
      "title": "NetworkTables Instances",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Instances The NetworkTables implementation supports simultaneous operation of multiple “instances.” Each instance has a completely independent set of topics, publishers, subscribers, and client/server state. This feature is mainly useful for unit testing. It allows a single program to be a member of two NetworkTables “networks” that contain different (and unrelated) sets of topics, or running both client and server instances in a single program. For most general usage, you should use the “default” instance, as all current dashboard programs can only connect to a single NetworkTables server at a time. Normally the default instance is set up on the robot as a server, and used for communication with the dashboard program running on your driver station computer. This is what the SmartDashboard and LiveWindow classes use. However, if you wanted to do unit testing of your robot program’s NetworkTables communications, you could set up your unit tests such that they create a separate client instance (still within the same program) and have it connect to the server instance that the main robot code is running. The NetworkTableInstance ( Java , C++ , Python ) class provides the API abstraction for instances. The number of instances that can be simultaneously created is limited to 16 (including the default instance), so when using multiple instances in cases such as unit testing code, it’s important to destroy instances that are no longer needed. Destroying a NetworkTableInstance frees all resources related to the instance. All classes or handles that reference the instance (e.g. Topics, Publishers, and Subscribers) are invalidated and may result in unexpected behavior if used after the instance is destroyed–in particular, instance handles are reused so it’s possible for a handle “left over” from a previously destroyed instance to refer to an unexpected resource in a newly created instance. Java // get the default NetworkTable instance NetworkTableInstance defaultInst = NetworkTableInstance . getDefault (); // create a NetworkTable instance NetworkTableInstance inst = NetworkTableInstance . create (); // destroy a NetworkTable instance inst . close (); C++ // get the default NetworkTable instance nt :: NetworkTableInstance defaultInst = nt :: NetworkTableInstance :: GetDefault (); // create a NetworkTable instance nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: Create (); // destroy a NetworkTable instance; NetworkTableInstance objects are not RAII nt :: NetworkTableInstance :: Destroy ( inst ); C++ (Handle-based) // get the default NetworkTable instance NT_Instance defaultInst = nt :: GetDefaultInstance (); // create a NetworkTable instance NT_Instance inst = nt :: CreateInstance (); // destroy a NetworkTable instance nt :: DestroyInstance ( inst ); C // get the default NetworkTable instance NT_Instance defaultInst = NT_GetDefaultInstance (); // create a NetworkTable instance NT_Instance inst = NT_CreateInstance (); // destroy a NetworkTable instance NT_DestroyInstance ( inst ); Python import ntcore # get the default NetworkTable instance defaultInst = ntcore . NetworkTableInstance . getDefault () # create a NetworkTable instance inst = ntcore . NetworkTableInstance . create () # destroy a NetworkTable instance ntcore . NetworkTableInstance . destroy ( inst )",
      "content_preview": "NetworkTables Instances The NetworkTables implementation supports simultaneous operation of multiple “instances.” Each instance has a completely independent set of topics, publishers, subscribers, and client/server state. This feature is mainly useful for unit testing."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/networktables/multiple-instances.html?present",
      "title": "NetworkTables Instances",
      "section": "NetworkTables",
      "language": "All",
      "content": "NetworkTables Instances The NetworkTables implementation supports simultaneous operation of multiple “instances.” Each instance has a completely independent set of topics, publishers, subscribers, and client/server state. This feature is mainly useful for unit testing. It allows a single program to be a member of two NetworkTables “networks” that contain different (and unrelated) sets of topics, or running both client and server instances in a single program. For most general usage, you should use the “default” instance, as all current dashboard programs can only connect to a single NetworkTables server at a time. Normally the default instance is set up on the robot as a server, and used for communication with the dashboard program running on your driver station computer. This is what the SmartDashboard and LiveWindow classes use. However, if you wanted to do unit testing of your robot program’s NetworkTables communications, you could set up your unit tests such that they create a separate client instance (still within the same program) and have it connect to the server instance that the main robot code is running. The NetworkTableInstance ( Java , C++ , Python ) class provides the API abstraction for instances. The number of instances that can be simultaneously created is limited to 16 (including the default instance), so when using multiple instances in cases such as unit testing code, it’s important to destroy instances that are no longer needed. Destroying a NetworkTableInstance frees all resources related to the instance. All classes or handles that reference the instance (e.g. Topics, Publishers, and Subscribers) are invalidated and may result in unexpected behavior if used after the instance is destroyed–in particular, instance handles are reused so it’s possible for a handle “left over” from a previously destroyed instance to refer to an unexpected resource in a newly created instance. Java // get the default NetworkTable instance NetworkTableInstance defaultInst = NetworkTableInstance . getDefault (); // create a NetworkTable instance NetworkTableInstance inst = NetworkTableInstance . create (); // destroy a NetworkTable instance inst . close (); C++ // get the default NetworkTable instance nt :: NetworkTableInstance defaultInst = nt :: NetworkTableInstance :: GetDefault (); // create a NetworkTable instance nt :: NetworkTableInstance inst = nt :: NetworkTableInstance :: Create (); // destroy a NetworkTable instance; NetworkTableInstance objects are not RAII nt :: NetworkTableInstance :: Destroy ( inst ); C++ (Handle-based) // get the default NetworkTable instance NT_Instance defaultInst = nt :: GetDefaultInstance (); // create a NetworkTable instance NT_Instance inst = nt :: CreateInstance (); // destroy a NetworkTable instance nt :: DestroyInstance ( inst ); C // get the default NetworkTable instance NT_Instance defaultInst = NT_GetDefaultInstance (); // create a NetworkTable instance NT_Instance inst = NT_CreateInstance (); // destroy a NetworkTable instance NT_DestroyInstance ( inst ); Python import ntcore # get the default NetworkTable instance defaultInst = ntcore . NetworkTableInstance . getDefault () # create a NetworkTable instance inst = ntcore . NetworkTableInstance . create () # destroy a NetworkTable instance ntcore . NetworkTableInstance . destroy ( inst )",
      "content_preview": "NetworkTables Instances The NetworkTables implementation supports simultaneous operation of multiple “instances.” Each instance has a completely independent set of topics, publishers, subscribers, and client/server state. This feature is mainly useful for unit testing."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/index.html",
      "title": "CAN Devices",
      "section": "CAN Devices",
      "language": "All",
      "content": "CAN Devices Using CAN Devices Pneumatics Control Module Pneumatic Hub Power Distribution Module Third-Party CAN Devices FRC CAN Device Specifications",
      "content_preview": "CAN Devices Using CAN Devices Pneumatics Control Module Pneumatic Hub Power Distribution Module Third-Party CAN Devices FRC CAN Device Specifications"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/using-can-devices.html",
      "title": "Using CAN Devices",
      "section": "CAN Devices",
      "language": "All",
      "content": "Using CAN Devices CAN has many advantages over other methods of connection between the robot controller and peripheral devices. CAN connections are daisy-chained from device to device, which often results in much shorter wire runs than having to wire each device to the RIO itself. Much more data can be sent over a CAN connection than over a PWM connection - thus, CAN motor controllers are capable of a much more expansive feature-set than are PWM motor controllers. CAN is bi-directional, so CAN motor controllers can send data back to the RIO, again facilitating a more expansive feature-set than can be offered by PWM Controllers. For instructions on wiring CAN devices, see the relevant section of the robot wiring guide . CAN devices generally have their own WPILib classes. The following sections will describe the use of several of these classes.",
      "content_preview": "Using CAN Devices CAN has many advantages over other methods of connection between the robot controller and peripheral devices. CAN connections are daisy-chained from device to device, which often results in much shorter wire runs than having to wire each device to the RIO itself."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/using-can-devices.html?present",
      "title": "Using CAN Devices",
      "section": "CAN Devices",
      "language": "All",
      "content": "Using CAN Devices CAN has many advantages over other methods of connection between the robot controller and peripheral devices. CAN connections are daisy-chained from device to device, which often results in much shorter wire runs than having to wire each device to the RIO itself. Much more data can be sent over a CAN connection than over a PWM connection - thus, CAN motor controllers are capable of a much more expansive feature-set than are PWM motor controllers. CAN is bi-directional, so CAN motor controllers can send data back to the RIO, again facilitating a more expansive feature-set than can be offered by PWM Controllers. For instructions on wiring CAN devices, see the relevant section of the robot wiring guide . CAN devices generally have their own WPILib classes. The following sections will describe the use of several of these classes.",
      "content_preview": "Using CAN Devices CAN has many advantages over other methods of connection between the robot controller and peripheral devices. CAN connections are daisy-chained from device to device, which often results in much shorter wire runs than having to wire each device to the RIO itself."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/third-party-devices.html",
      "title": "Third",
      "section": "CAN Devices",
      "language": "Java",
      "content": "Third-Party CAN Devices A number of FRC® vendors offer their own CAN peripherals. As CAN devices offer expansive feature-sets, vendor CAN devices require similarly expansive code libraries to operate. As a result, these libraries are not maintained as an official part of WPILib, but are instead maintained by the vendors themselves. For a guide to installing third-party libraries, see 3rd Party Libraries A list of common third-party CAN devices from various vendors, along with links to corresponding external documentation, is provided below: CTR Electronics CTR Electronics (CTRE) offers several CAN peripherals with external libraries. General resources for all CTRE devices include: Phoenix Device Software Documentation CTRE Motor Controllers Talon FX (with Falcon 500 Motor, Kraken x60 motor, and Kraken x44) API Documentation (v6: Java , C++ ) Hardware User’s Manual ( Falcon 500 , Kraken x60 , Kraken x44 ) Software Documentation Talon SRX API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation Victor SPX API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CTRE Sensors CANcoder API Documentation (v6: Java , C++ ) Hardware User’s Manual Software Documentation Pigeon 2.0 API Documentation (v6: Java , C++ ) Hardware User’s Manual Software Documentation6 Pigeon IMU API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CANifier API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CTRE Other CAN Devices CANdle LED Controller API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation REV Robotics REV Robotics currently offers the SPARK MAX and SPARK Flex motor controllers which can be used for brushed and REV brushless (NEO, NEO 550, and NEO Vortex) motors. REV Motor Controllers SPARK MAX API Documentation ( Java , C++ ) Technical Manual SPARK Flex API Documentation ( Java , C++ ) Technical Manual Playing With Fusion Playing With Fusion (PWF) offers the Venom integrated motor/controller as well as a Time-of-Flight distance sensor: PWF Motor Controllers Venom API Documentation ( Java , C++ ) Technical Manual PWF Sensors Time of Flight Sensor API Documentation ( Java , C++ ) Technical Manual Redux Robotics Warning Redux Robotics is shutting down. While their devices remain legal for FRC use and software support will be provided for the 2026 season, no new hardware will be available. Redux Robotics offers the HELIUM Canandmag CAN + PWM magnetic encoder and the BORON Canandgyro CAN -enabled gyro. Redux Sensors HELIUM Canandmag API Documentation ( Java , C++ ) Technical Manual BORON Canandgyro API Documentation ( Java , C++ ) Technical Manual Grapple Robotics Grapple Robotics currently offers the LaserCAN CAN -enabled range finding sensor Grapple Sensors LaserCAN API Documentation ( Java , C++ ) Technical Manual",
      "content_preview": "Third-Party CAN Devices A number of FRC® vendors offer their own CAN peripherals. As CAN devices offer expansive feature-sets, vendor CAN devices require similarly expansive code libraries to operate."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/3rd-party-libraries.html",
      "title": "3rd Party Libraries",
      "section": "General",
      "language": "All",
      "content": "3rd Party Libraries Teams that are using non- PWM motor controllers or advanced sensors will most likely need to install external vendor dependencies. What Are Vendor Dependencies? A vendor dependency is a way for vendors to add their software library to robot projects. This library can interface with motor controllers and other devices. This way, teams can interact with their devices via CAN and have access to more complex and in-depth features than traditional PWM control. Managing Vendor Dependencies Vendor dependencies are installed on a per-project basis (so each robot project can have its own set of vendor dependencies). Vendor dependencies can be installed “online” or “offline”. The “online” functionality is done by downloading the dependencies over the internet, while offline is typically provided by a vendor-specific installer. Warning If installing a vendor dependency via the “online” mode, make sure to reconnect the computer to the internet and rebuild about every 30 days otherwise the cache will clear, completely deleting the downloaded library install. Note Vendors recommend using their offline installers when available, because the offline installer is typically bundled with additional programs that are extremely useful when working with their devices. Installing Libraries Java/C++ VS Code All vendordep operations can be controlled by the Dependency Manager. Click the WPILib logo in the activity bar as shown above to access the interface. Select the desired libraries to add to the project by clicking the Install button next to each. The JSON file will be copied to the vendordeps folder in the project, adding the library as a dependency to the project. When an update is available for an installed vendordep you will see the To Latest button become available. To update you can either press that or the Update All to move all vendordeps to the latest version. The button with the trash icon will uninstall the vendordep. The dropdown shows what version is currently installed but you can change that to a different version to update or downgrade to the specified version. Note The Dependency Manager will automatically build your program when it loses focus. This allows you to use the changed dependencies. Python All RobotPy project dependencies are specified in pyproject.toml . You can add additional vendor-specific dependencies either by: Adding the component name to robotpy_extras Adding the PyPI package name to requires See also pyproject.toml usage Optional WPILib components: robotpy_extras requires Apriltag apriltag robotpy-apriltag Commands commands2 robotpy-commands-v2 cscore cscore robotpy-cscore Romi romi robotpy-romi XRP xrp robotpy-xrp Optional vendor-specific components (not all are available at the beginning of the season): Origin robotpy_extras requires ChoreoLib Vendor sleipnirgroup-choreolib CTRE Phoenix 6 Vendor phoenix6 phoenix6 CTRE Phoenix 5 Community phoenix5 robotpy-ctre PathPlannerLib Vendor pathplannerlib robotpy-pathplannerlib PhotonVision Vendor photonvision photonlibpy Playing With Fusion Community playingwithfusion robotpy-playingwithfusion REVLib Community rev robotpy-rev Studica Community navx robotpy-navx URCL Community robotpy-urcl When using requires , you can specify a version by appending ==<version> to the package name, e.g. robotpy-commands-v2==2024.0.0 . If you do not specify a version, the latest version will be installed. To check what version of packages are currently installed, run the command pip list . Note that pinning versions may cause issues with incompatibilities between different components. Unpinning all versions, installing, then re-pinning to the latest set is a good practice when updating. Pinning versions is a good practice to do after most robot code is written and validated, before and during a competition. However, outside of this window, remaining on the latest version of the components is recommended, as it will ensure you have the latest bug fixes and features. See https://pip.pypa.io/en/stable/topics/repeatable-installs/ for more information on how to specify versions. Java/C++ (Legacy) VS Code To add a vendor library that has been installed by an offline installer, press Ctrl + Shift + P and type WPILib or click on the WPILib icon in the top right to open the WPILib Command Palette and begin typing Manage Vendor Libraries , then select it from the menu. Select the option to Install new libraries (offline) . Select the desired libraries to add to the project by checking the box next to each, then click OK . The JSON file will be copied to the vendordeps folder in the project, adding the library as a dependency to the project. In order to install a vendor library in online mode, press Ctrl + Shift + P and type WPILib or click on the WPILib icon in the top right to open the WPILib Command Palette and begin typing Manage Vendor Libraries and select it in the menu, and then click on Install new libraries (online) instead and copy + paste the vendor JSON URL. Checking for Updates (Offline) Since dependencies are version managed on a per-project basis, even when installed offline, you will need to Manage Vendor Libraries and select Check for updates (offline) for each project you wish to update. Checking for Updates (Online) Part of the JSON file that vendors may optionally populate is an online update location. If a library has an appropriate location specified, running Check for updates (online) will check if a newer version of the library is available from the remote location. Removing a Library Dependency To remove a library dependency from a project, select Manage Current Libraries from the Manage Vendor Libraries menu, check the box for any libraries to uninstall and click OK . These libraries will be removed as dependencies from the project. Command-Line Adding a vendor library dependency from the vendor URL can also be done through the command-line via a gradle task. Open a command-line instance at the project root, and enter gradlew vendordep --url=<url> where <url> is the vendor JSON URL. This will add the vendor library dependency JSON file to the vendordeps folder of the project. Vendor libraries can be updated the same way. The vendordep gradle task can also fetch vendordep JSONs from the user wpilib folder. To do so, pass FRCLOCAL/Filename.json as the file URL. For example, gradlew vendordep --url=FRCLOCAL/WPILibNewCommands.json will fetch the JSON for the command-based framework. How Does It Work? Java/C++ For Java and C++, a JSON file describing the vendor library is installed on your system to ~/wpilib/YYYY/vendordeps (where YYYY is the year and ~ is C:\\Users\\Public on Windows). This is often done by an offline installer, but may need to be done manually if a .zip of the .json files is provided. This file is then used from VS Code to add to the library to each individual project. Vendor library information is managed on a per-project basis to make sure that a project is always pointing to a consistent version of a given vendor library. The libraries themselves are placed in the Maven cache at C:\\Users\\Public\\wpilib\\YYYY\\maven . Vendors can place a local copy here with an offline installer (recommended) or require users to be connected to the internet for an initial build to fetch the library from a remote Maven location. This JSON file allows specification of complex libraries with multiple components (Java, C++, JNI, etc.) and also helps handle some complexities related to simulation. LabVIEW For LabVIEW teams, there might be a few new Third Party items on various palettes (specifically, one in Actuators , one in Actuators -> Motor Control labeled CAN Motor , and one in Sensors ). These correspond to folders in C:\\Program Files\\National Instruments\\LabVIEW 2023\\vi.lib\\Rock Robotics\\WPI\\Third Party In order to install third party libraries for LabVIEW, download the VIs from the vendor (typically via some sort of installer). Then drag and drop the third party VIs into the respective folder mentioned above just like any other VI. Python Third party libraries are packaged into Python wheels and uploaded to PyPI (if pure python) and/or WPILib’s artifactory. Users can enable them as dependencies either by adding the component name to robotpy_extras (recommended) or by adding an explicit dependency for the PyPI package in requires . The dependencies are downloaded when robotpy sync is executed, and installed on the roboRIO when robotpy deploy is executed.",
      "content_preview": "3rd Party Libraries Teams that are using non- PWM motor controllers or advanced sensors will most likely need to install external vendor dependencies. What Are Vendor Dependencies? A vendor dependency is a way for vendors to add their software library to robot projects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/index.html",
      "title": "VS Code Overview",
      "section": "General",
      "language": "All",
      "content": "VS Code Overview Visual Studio Code Basics and the WPILib Extension WPILib Commands in Visual Studio Code Creating a Robot Program 3rd Party Libraries Building and Deploying Robot Code Viewing Console Output Debugging a Robot Program Importing Last Year’s Robot Code",
      "content_preview": "VS Code Overview Visual Studio Code Basics and the WPILib Extension WPILib Commands in Visual Studio Code Creating a Robot Program 3rd Party Libraries Building and Deploying Robot Code Viewing Console Output Debugging a Robot Program Importing Last Year’s Robot Code"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/creating-robot-program.html",
      "title": "Creating a Robot Program",
      "section": "General",
      "language": "All",
      "content": "Creating a Robot Program Once everything is installed, we’re ready to create a robot program. WPILib comes with several templates for robot programs. Use of these templates is highly recommended for new users; however, advanced users are free to write their own robot code from scratch. Choosing a Base Class To start a project using one of the WPILib robot program templates, users must first choose a base class for their robot. Users subclass these base classes to create their primary Robot class, which controls the main flow of the robot program. There are various choices available for the base class: TimedRobot Documentation: Java - C++ Source: Java - C++ The TimedRobot class is the base class recommended for most users. It provides control of the robot program through a collection of init() , periodic() , and exit() methods, which are called by WPILib during specific robot states (e.g. autonomous or teleoperated). During these calls, your code typically polls each input device and acts according to the data it receives. For instance, you would typically determine the position of the joystick and state of the joystick buttons on each call and act accordingly. The TimedRobot class also provides an example of retrieving autonomous routines through SendableChooser ( Java / C++ ) Note A TimedRobot Skeleton template is available that removes some informative comments and the autonomous example. You can use this if you’re already familiar with TimedRobot . The example shown below is of TimedRobot Skeleton . JAVA 7 import edu.wpi.first.wpilibj.TimedRobot ; 8 9 /** 10 * The methods in this class are called automatically corresponding to each mode, as described in 11 * the TimedRobot documentation. If you change the name of this class or the package after creating 12 * this project, you must also update the Main.java file in the project. 13 */ 14 public class Robot extends TimedRobot { 15 /** 16 * This function is run when the robot is first started up and should be used for any 17 * initialization code. 18 */ 19 public Robot () {} 20 21 @Override 22 public void robotPeriodic () {} 23 24 @Override 25 public void autonomousInit () {} 26 27 @Override 28 public void autonomousPeriodic () {} 29 30 @Override 31 public void teleopInit () {} 32 33 @Override 34 public void teleopPeriodic () {} 35 36 @Override 37 public void disabledInit () {} 38 39 @Override 40 public void disabledPeriodic () {} 41 42 @Override 43 public void testInit () {} 44 45 @Override 46 public void testPeriodic () {} 47 48 @Override 49 public void simulationInit () {} 50 51 @Override 52 public void simulationPeriodic () {} 53 } C++ 5 #include \"Robot.h\" 6 7 Robot :: Robot () {} 8 void Robot :: RobotPeriodic () {} 9 10 void Robot :: AutonomousInit () {} 11 void Robot :: AutonomousPeriodic () {} 12 13 void Robot :: TeleopInit () {} 14 void Robot :: TeleopPeriodic () {} 15 16 void Robot :: DisabledInit () {} 17 void Robot :: DisabledPeriodic () {} 18 19 void Robot :: TestInit () {} 20 void Robot :: TestPeriodic () {} 21 22 void Robot :: SimulationInit () {} 23 void Robot :: SimulationPeriodic () {} 24 25 #ifndef RUNNING_FRC_TESTS 26 int main () { 27 return frc :: StartRobot < Robot > (); 28 } 29 #endif Periodic methods are called every 20 ms by default. This can be changed by calling the superclass constructor with the new desired update rate. Danger Changing your robot rate can cause some unintended behavior (loop overruns). Teams can also use Notifiers to schedule methods at a custom rate. JAVA public Robot () { super ( 0.03 ); // Periodic methods will now be called every 30 ms. } C++ Robot () : frc :: TimedRobot ( 30 _ms ) {} Timeslice Robot Documentation: Java - C++ Source: Java - C++ The TimesliceRobot class extends the TimedRobot framework to provide more control over the scheduling of periodic functions. It allows users to allocate specific time slices to different robot operations, running them sequentially within a defined period (typically shorter than TimedRobot’s default 20ms). This class is recommended for users who need more precise timing control and consistent starting times for their robot’s periodic functions. TimesliceRobot provides the same init() , periodic() , and exit() methods as TimedRobot , but adds the ability to schedule additional periodic functions with custom allocations. This allows for more efficient use of processing time and can lead to improved performance which can make odometry and estimators more accurate and controller outputs change more consistently. RobotBase Documentation: Java - C++ Source: Java - C++ The RobotBase class is the most minimal base-class offered, and is generally not recommended for direct use. No robot control flow is handled for the user; everything must be written from scratch inside the startCompetition() method. The template by default showcases how to process the different operation modes (teleop, auto, etc). Note A RobotBase Skeleton template is available that offers a blank startCompetition() method. Command Robot The Command Robot framework adds to the basic functionality of a Timed Robot by automatically polling inputs and converting the raw input data into events. These events are tied to user code, which is executed when the event is triggered. For instance, when a button is pressed, code tied to the pressing of that button is automatically called and it is not necessary to poll or keep track of the state of that button directly. The Command Robot framework makes it easier to write compact easy-to-read code with complex behavior, but requires an additional up-front time investment from a programmer in order to understand how the Command Robot framework works. Teams using Command Robot should see the Command-Based Programming Tutorial . Romi Teams using a Romi should use the Romi - Timed or Romi - Command Bot template. Romi - Timed The Romi - Timed template provides a RomiDrivetrain class that exposes an arcadeDrive(double xaxisSpeed, double zaxisRotate) method. It’s up to the user to feed this arcadeDrive function. This class also provides functions for retrieving and resetting the Romi’s onboard encoders. Romi - Command Bot The Romi - Command Bot template provides a RomiDrivetrain subsystem that exposes an arcadeDrive(double xaxisSpeed, double zaxisRotate) method. It’s up to the user to feed this arcadeDrive function. This subsystem also provides functions for retrieving and resetting the Romi’s onboard encoders. Not Using a Base Class If desired, users can omit a base class entirely and simply write their program in a main() method, as they would for any other program. This is highly discouraged - users should not “reinvent the wheel” when writing their robot code - but it is supported for those who wish to have absolute control over their program flow. Warning Users should not modify the main() method of a robot program unless they are absolutely sure of what they are doing. Creating a New WPILib Project Once we’ve decided on a base class, we can create our new robot project. Bring up the Visual Studio Code command palette with Ctrl + Shift + P . Then, type “WPILib” into the prompt. Since all WPILib commands start with “WPILib”, this will bring up the list of WPILib-specific VS Code commands. Now, select the Create a new project command: This will bring up the “New Project Creator Window:” The elements of the New Project Creator Window are explained below: Project Type : The kind of project we wish to create. This can be an example project, or one of the project templates provided by WPILib. Templates exist for each of the robot base classes. Additionally, a template exists for Command-based projects, which are built on the TimedRobot base class but include a number of additional features - this type of robot program is highly recommended for new teams. Language : This is the language (C++ or Java) that will be used for this project. Base Folder : If this is a template project, this specifies the type of template that will be used. Project Location : This determines the folder in which the robot project will be located. Project Name : The name of the robot project. This also specifies the name that the project folder will be given if the Create New Folder box is checked. Create a New Folder : If this is checked, a new folder will be created to hold the project within the previously-specified folder. If it is not checked, the project will be located directly in the previously-specified folder. An error will be thrown if the folder is not empty and this is not checked. Team Number : The team number for the project, which will be used for package names within the project and to locate the robot when deploying code. Enable Desktop Support : Enables unit test and simulation support (see Introduction to Robot Simulation ). Java : This option has no effect and can be left checked or unchecked C++ : Checking this option enables desktop compilation, which is required for simulation and unit tests Romi/XRP : This option has no effect for Romi and XRP templates and can be left checked or unchecked Note While WPILib fully supports desktop builds, some third-party vendor libraries may not. If a library doesn’t support desktop compilation, your C++ code may not compile or may crash when running simulation. Once all the above have been configured, click “Generate Project” and the robot project will be created. Note Any errors in project generation will appear in the bottom right-hand corner of the screen. Warning Creating projects on OneDrive is not supported as OneDrive’s caching interferes with the build system. Some Windows installations put the Documents and Desktop folders on OneDrive by default. An example after all options are selected is shown below. Opening The New Project After successfully creating your project, VS Code will give the option of opening the project as shown below. We can choose to do that now or later by typing Ctrl + K then Ctrl + O (or just Command + O on macOS) and select the folder where we saved our project. Once opened we will see the project hierarchy on the left. Double clicking on the file will open that file in the editor. C++ Configurations (C++ Only) For C++ projects, there is one more step to set up IntelliSense. Whenever we open a project, we should get a pop-up in the bottom right corner asking to refresh C++ configurations. Click “Yes” to set up IntelliSense.",
      "content_preview": "Creating a Robot Program Once everything is installed, we’re ready to create a robot program. WPILib comes with several templates for robot programs. Use of these templates is highly recommended for new users; however, advanced users are free to write their own robot code from scratch."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/index.html?present",
      "title": "VS Code Overview",
      "section": "General",
      "language": "All",
      "content": "VS Code Overview Visual Studio Code Basics and the WPILib Extension WPILib Commands in Visual Studio Code Creating a Robot Program 3rd Party Libraries Building and Deploying Robot Code Viewing Console Output Debugging a Robot Program Importing Last Year’s Robot Code",
      "content_preview": "VS Code Overview Visual Studio Code Basics and the WPILib Extension WPILib Commands in Visual Studio Code Creating a Robot Program 3rd Party Libraries Building and Deploying Robot Code Viewing Console Output Debugging a Robot Program Importing Last Year’s Robot Code"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/vscode-basics.html",
      "title": "Visual Studio Code Basics and the WPILib Extension",
      "section": "General",
      "language": "Java",
      "content": "Visual Studio Code Basics and the WPILib Extension Microsoft’s Visual Studio Code is the supported IDE for C++ and Java development in FRC. This article introduces some of the basics of using Visual Studio Code and the WPILib extension. Welcome Page When Visual Studio Code first opens, you are presented with a Welcome page. On this page you will find some quick links that allow you to customize Visual Studio Code as well as a number of links to help documents and videos that may help you learn about the basics of the IDE as well as some tips and tricks. You may also notice a small WPILib logo way up in the top right corner. This is one way to access the features provided by the WPILib extension (discussed further below). User Interface The most important link to take a look at is probably the basic User Interface document. This document describes a lot of the basics of using the UI and provides the majority of the information you should need to get started using Visual Studio Code for FRC. Command Palette The Command Palette can be used to access or run almost any function or feature in Visual Studio Code (including those from the WPILib extension). The Command Palette can be accessed from the View menu or by pressing Ctrl + Shift + P ( Cmd + Shift + P on macOS). Typing text into the window will dynamically narrow the search to relevant commands and show them in the dropdown. In the following example “wpilib” is typed into the search box after activating the Command Palette, and it narrows the list to functions containing WPILib. WPILib Extension The WPILib extension provides the FRC® specific functionality related to creating projects and project components, building, and downloading code to the roboRIO and more. You can access the WPILib commands one of two ways: By typing “WPILib” into the Command Palette By clicking on the WPILib icon in the top right of most windows. This will open the Command Palette with “WPILib” pre-entered Note It is not recommended to install the Visual Studio IntelliCode plugin with the FRC installation of VS Code as it is known to break IntelliSense in odd ways. For more information about specific WPILib extension commands, see the other articles in this chapter.",
      "content_preview": "Visual Studio Code Basics and the WPILib Extension Microsoft’s Visual Studio Code is the supported IDE for C++ and Java development in FRC. This article introduces some of the basics of using Visual Studio Code and the WPILib extension."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/debugging-robot-program.html",
      "title": "Debugging a Robot Program",
      "section": "General",
      "language": "All",
      "content": "Debugging a Robot Program Inevitably, a program will not behave in the way we expect it to behave. When this occurs, it becomes necessary to figure out why the program is doing what it is doing, so that we can make it do what we want it to do, instead. Such an undesired program behavior is called a “bug,” and this process is called “debugging.” A debugger is a tool used to control program flow and monitor variables in order to assist in debugging a program. This section will describe how to set up a debug session for an FRC® robot program. Note For beginning users who need to debug their programs but do not know/have time to learn how to use a debugger, it is often possible to debug a program simply by printing the relevant program state to the console. However, it is strongly recommended that students eventually learn to use a debugger. Running the Debugger Press Ctrl + Shift + P and type WPILib or click on the WPILib Menu Item to open the Command palette with WPILib pre-populated. Type Debug and select the Debug Robot Code menu item to start debugging. The code will download to the roboRIO and begin debugging. Breakpoints A “breakpoint” is a line of code at which the debugger will pause the program execution so that the user can examine the program state. This is extremely useful while debugging, as it allows the user to pause the program at specific points in problematic code to determine where exactly the program is deviating from the expected behavior. The debugger will automatically pause at the first breakpoint it encounters. Setting a Breakpoint Click in the left margin of the source code window (to the left of the line number) to set a breakpoint in your user program: A small red circle indicates the breakpoint has been set on the corresponding line. Debugging with Print Statements Another way to debug your program is to use print statements in your code and view them using the RioLog in Visual Studio Code or the Driver Station. Print statements should be added with care as they are not very efficient especially when used in high quantities. They should be removed for competition as they can cause loop overruns. JAVA System . out . print ( \"example\" ); C++ wpi :: outs () << \"example \\n \" ; Debugging with NetworkTables NetworkTables can be used to share robot information with your debugging computer. NetworkTables can be viewed with your favorite Dashboard or OutlineViewer . One advantage of NetworkTables is that tools like Shuffleboard can be used to graphically analyze the data. These same tools can then be used with same data to later provide an operator interface for your drivers. Learn More To learn more about debugging with VS Code see this link . Some of the features mentioned in this VS Code article will help you understand and diagnose problems with your code. The Quick Fix (yellow light bulb) feature can be very helpful with a variety of problems including what to import. One of the best ways to prevent having to debug so many issues is to do Unit Testing. Verifying that your robot works in Simulation is also a great way to prevent having to do complex debugging on the actual robot.",
      "content_preview": "Debugging a Robot Program Inevitably, a program will not behave in the way we expect it to behave. When this occurs, it becomes necessary to figure out why the program is doing what it is doing, so that we can make it do what we want it to do, instead."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/viewing-console-output.html",
      "title": "Viewing Console Output",
      "section": "General",
      "language": "All",
      "content": "Viewing Console Output For viewing the console output of text based programs the roboRIO implements a NetConsole. There are two main ways to view the NetConsole output from the roboRIO: The Console Viewer in the FRC Driver Station and the Riolog plugin in VS Code. Note On the roboRIO, the NetConsole is only for program output. If you want to interact with the system console you will need to use SSH or the Serial console. Console Viewer Opening the Console Viewer To open Console Viewer, first open the FRC® Driver Station. Then, click on the gear at the top of the message viewer window (1) and select “View Console”. Console Viewer Window The Console Viewer window displays the output from our robot program in green. The gear in the top right can clear the window and set the level of messages displayed. Riolog VS Code Plugin The Riolog plugin is a VS Code view that can be used to view the NetConsole output in VS Code (credit for the original Eclipse version: Manuel Stoeckl, FRC1511). Opening the RioLog View By default, the RioLog view will open automatically at the end of each roboRIO deploy. To launch the RioLog view manually, press Ctrl + Shift + P to open the command palette and start typing “RioLog”, then select the WPILib: Start RioLog option. Riolog Window The RioLog view should appear in the top pane. The Riolog contains a number of controls for manipulating the console: Pause/Resume Display - This will pause/resume the display. In the background, the new packets will still be received and will be displayed when the resume button is clicked. Discard/Accept Incoming - This will toggle whether to accept new packets. When packets are being discarded the display will be paused and all packets received will be discarded. Clicking the button again will resume receiving packets. Clear - This will clear the current contents of the display. Don’t Show/Show Prints - This shows or hides messages categorized as print statements Switch to Viewer - This switches to viewer for saved log files Don’t Show/Show Warnings - This shows or hides messages categorized as warnings Disconnect/Reconnect - This disconnects or reconnects to the console stream Show/Don’t Show Timestamps - Shows or hides timestamps on messages in the window Save Log - Copies the log contents into a file you can save and view or open later with the RioLog viewer (see Switch to Viewer above) Set Team Number - Sets the team number of the roboRIO to connect to the console stream on, set automatically if RioLog is launched by the deploy process",
      "content_preview": "Viewing Console Output For viewing the console output of text based programs the roboRIO implements a NetConsole. There are two main ways to view the NetConsole output from the roboRIO: The Console Viewer in the FRC Driver Station and the Riolog plugin in VS Code."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/importing-last-years-robot-code.html",
      "title": "Importing Last Year’s Robot Code",
      "section": "General",
      "language": "All",
      "content": "Importing Last Year’s Robot Code Due to changes in the project, it is necessary to update the build files for a previous years Gradle project. It is also necessary to import vendor libraries again, since last year’s vendor libraries must be updated to be compatible with this year’s projects. Automatic Import To make it easy for teams to import previous years gradle projects into the current year’s framework, WPILib includes a wizard for importing previous years projects into VS Code. This will generate the necessary gradle components and load the project into VS Code. In place upgrades are not supported. Important The import process copies your project source files from the current directory to a new directory and completely regenerates the gradle files. Additionally, it updates the code for the package changes made in 2025. If you made non-standard updates to the build.gradle , you will need to make those changes again. For this reason, in place upgrades are not supported. It is also necessary to import vendor libraries again, since last year’s vendor libraries must be updated to be compatible with this year’s projects. Launching the Import Wizard When you open a previous year’s project, you will be prompted to import that project. Click yes . Alternately, you can chose to import it from the menu. Press Ctrl + Shift + P and type “WPILib” or click the WPILib icon to locate the WPILib commands. Begin typing “Import a WPILib 2020-2024 Gradle project” and select it from the dropdown as shown below. You’ll be presented with the WPILib Project Importer window. This is similar to the process of creating a new project and the window and the steps are shown below. This window contains the following elements: Gradle Project : Selects the project to be imported. Users should select the build.gradle file in the root directory of the gradle project. Project Location : This determines the folder in which the robot project will be located. Project Name : The name of the robot project. This also specifies the name that the project folder will be given if the Create New Folder box is checked. This must be a different directory from the original location. Create a New Folder : If this is checked, a new folder will be created to hold the project within the previously-specified folder. If it is not checked, the project will be located directly in the previously-specified folder. An error will be thrown if the folder is not empty and this is not checked. Team Number : The team number for the project, which will be used for package names within the project and to locate the robot when deploying code. Enable Desktop Support : If this is checked, simulation and unit test support is enabled. However, there are some cases where this will do some unexpected things. In addition, all vendor libraries need desktop support which not all libraries do. Import Romi Project : If this is checked, the project is imported using the Romi gradle template. This should only be checked for Romi projects. Warning Creating projects on OneDrive is not supported as OneDrive’s caching interferes with the build system. Some Windows installations put the Documents and Desktop folders on OneDrive by default. Click Import Project to begin the upgrade. The gradle project will be upgraded and copied into the new project directory. You can then either open the new project immediately using the pop-up below or open it later using the Ctrl + O (or Command + O for macOS) shortcut. Click Yes I trust the authors . C++ Configurations (C++ Only) For C++ projects, there is one more step to set up IntelliSense. Whenever you open a project, you should get a pop-up in the bottom right corner asking to refresh C++ configurations. Click Yes to set up IntelliSense. 3rd Party Libraries It is necessary to update and re-import 3rd party libraries. See 3rd Party Libraries for details.",
      "content_preview": "Importing Last Year’s Robot Code Due to changes in the project, it is necessary to update the build files for a previous years Gradle project. It is also necessary to import vendor libraries again, since last year’s vendor libraries must be updated to be compatible with this year’s projects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/wpilib-commands-vscode.html",
      "title": "WPILib Commands in Visual Studio Code",
      "section": "General",
      "language": "Java",
      "content": "WPILib Commands in Visual Studio Code This document contains a complete list of the commands provided by the WPILib VS Code Extension and what they do. To access these commands, press Ctrl+Shift+P to open the Command Palette, then begin typing the command name as shown here to filter the list of commands. Click on the command name to execute it. WPILib: Build Robot Code - Builds open project using GradleRIO WPILib: Create a new project - Create a new robot project WPILib C++: Refresh C++ Intellisense - Force an update to the C++ Intellisense configuration. WPILib C++: Select Current C++ Toolchain - Select the toolchain to use for Intellisense (i.e. desktop vs. roboRIO vs…). This is the same as clicking the current mode in the bottom right status bar. WPILib C++: Select Enabled C++ Intellisense Binary Types - Switch Intellisense between static, shared, and executable WPILib: Cancel currently running tasks - Cancel any tasks the WPILib extension is currently running WPILib: Change Auto Save On Deploy Setting - Change whether files are saved automatically when doing a Deploy. This defaults to Enabled. WPILib: Change Auto Start RioLog on Deploy Setting - Change whether RioLog starts automatically on deploy. This defaults to Enabled. WPILib: Change Desktop Support Enabled Setting - Change whether building robot code on Desktop is enabled. Enable this for test and simulation purposes. This defaults to Desktop Support off. WPILib: Change Language Setting - Change whether the currently open project is C++ or Java. WPILib: Change Run Commands Except Deploy/Debug in Offline Mode Setting - Change whether GradleRIO is running in Online Mode for commands other then deploy/debug (will attempt to automatically pull dependencies from online). Defaults to enabled (online mode). WPILib: Change Run Deploy/Debug Command in Offline Mode Setting - Change whether GradleRIO is running in Online Mode for deploy/debug (will attempt to automatically pull dependencies from online). Defaults to disabled (offline mode). WPILib: Change Select Default Simulate Extension Setting - Change whether simulation extensions are enabled by default (all simulation extensions defined in build.gradle will be enabled) WPILib: Change Skip Tests On Deploy Setting - Change whether to skip tests on deploy. Defaults to disabled (tests are run on deploy) WPILib: Change Stop Simulation on Entry Setting - Change whether to stop robot code on entry when running simulation. Defaults to disabled (don’t stop on entry). WPILib: Change Use WinDbg Preview (From Store) as Windows Debugger Setting - Change whether to use the VS Code debugger or WinDbg Preview (from Windows Store). WPILib: Check for WPILib Updates - Check for an update to the WPILib GradleRIO version for the project. This does not update the Visual Studio Code extension, tools, or offline dependencies. Users are strongly recommended to use the offline wpilib installer WPILib: Debug Robot Code - Build and deploy robot code to roboRIO in debug mode and start debugging WPILib: Deploy Robot Code - Build and deploy robot code to roboRIO WPILib: Hardware Sim Robot Code - This builds the current robot code project on your PC and starts it running in simulation using hardware attached to the comupter rather then pure software simulation. Requires vendor support. WPILib: Import a WPILib 2020-202r Gradle Project - Open a wizard to help you create a new project from a existing VS Code Gradle project from 2020-2022. Further documentation is at importing gradle project WPILib: Install tools from GradleRIO - Install the WPILib Java tools (e.g. SmartDashboard, Shuffleboard, etc.). Note that this is done by default by the offline installer WPILib: Manage Vendor Libraries - Install/update 3rd party libraries WPILib: Open API Documentation - Opens either the WPILib Javadocs or C++ Doxygen documentation WPILib: Open Project Information - Opens a widget with project information (Project version, extension version, etc.) WPILib: Open WPILib Command Palette - This command is used to open a WPILib Command Palette (equivalent of hitting Ctrl + Shift + P and typing WPILib ) WPILib: Open WPILib Help - This opens a simple page which links to the WPILib documentation (this site) WPILib: Reset Ask for WPILib Updates Flag - This will clear the flag on the current project, allowing you to re-prompt to update a project to the latest WPILib version if you previously chose to not update. WPILib: Run a command in Gradle - This lets you run an arbitrary command in the GradleRIO command environment WPILib: run Gradle Clean - Run Gradle Clean to delete build artifacts WPILib: Set Team Number - Used to modify the team number associated with a project. This is only needed if you need to change the team number from the one initially specified when creating the project. WPILib: Set VS Code Java Home to FRC Home - Set the VS Code Java Home variable to point to the Java Home discovered by the FRC extension. This is needed if not using the offline installer to make sure the intellisense settings are in sync with the WPILib build settings. WPILib: Show Log Folder - Shows the folder where the WPILib extension stores internal logs. This may be useful when debugging/reporting an extension issue to the WPILib developers WPILib: Simulate Robot Code - This builds the current robot code project on your PC and starts it running in simulation. This requires Desktop Support to be set to Enabled. WPILib: Start RioLog - This starts the RioLog display used to view console output from a robot program WPILib: Start Tool - This allows you to launch WPILib tools (e.g. SmartDashboard, Shuffleboard, etc.) from inside VS Code WPILib: Test Robot Code - This builds the current robot code project and runs any created tests. This requires Desktop Support to be set to Enabled.",
      "content_preview": "WPILib Commands in Visual Studio Code This document contains a complete list of the commands provided by the WPILib VS Code Extension and what they do. To access these commands, press Ctrl+Shift+P to open the Command Palette, then begin typing the command name as shown here to filter the list of..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/deploying-robot-code.html",
      "title": "Building and Deploying Robot Code",
      "section": "General",
      "language": "All",
      "content": "Building and Deploying Robot Code Robot projects must be compiled (“built”) and deployed in order to run on the roboRIO. Since the code is not compiled natively on the robot controller, this is known as “cross-compilation.” To build and deploy a robot project, do one of: Open the Command Palette and enter/select “Build Robot Code” Open the shortcut menu indicated by the ellipses in the top right corner of the VS Code window and select “Build Robot Code” Right-click on the build.gradle file in the project hierarchy and select “Build Robot Code” Deploy robot code by selecting “Deploy Robot Code” from any of the three locations from the previous instructions. That will build (if necessary) and deploy the robot program to the roboRIO. Warning Avoid powering off the robot while deploying robot code. Interrupting the deployment process can corrupt the roboRIO filesystem and prevent your code from working until the roboRIO is re-imaged . If successful, we will see a “Build Successful” message (1) and the RioLog will open with the console output from the robot program as it runs (2).",
      "content_preview": "Building and Deploying Robot Code Robot projects must be compiled (“built”) and deployed in order to run on the roboRIO. Since the code is not compiled natively on the robot controller, this is known as “cross-compilation.” To build and deploy a robot project, do one of: Open the Command Palette..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/python/pyproject_toml.html",
      "title": "pyproject.toml usage",
      "section": "General",
      "language": "Python",
      "content": "pyproject.toml usage Note RobotPy projects are not required to have a pyproject.toml , but when you run robotpy sync one will automatically be created for you. pyproject.toml has become a standard way to store build and tooling configuration for Python projects. The [tool.XXX] section(s) of the TOML file is a place where tools can store their configuration information. Currently RobotPy only stores deployment related information in pyproject.toml , in the [tool.robotpy] section. Users can customize the other sections however they want, and robotpy will ignore them. The pyproject.toml file looks something like this: # # Use this configuration file to control what RobotPy packages are installed # on your RoboRIO # [tool.robotpy] # Version of robotpy this project depends on robotpy_version = \"2024.2.1.0\" # Which extra RobotPy components should be installed # -> equivalent to `pip install robotpy[extra1, ...] robotpy_extras = [ # \"all\" # \"apriltag\" # \"commands2\" # \"cscore\" # \"navx\" # \"pathplannerlib\" # \"phoenix5\" # \"phoenix6\" # \"playingwithfusion\" # \"rev\" # \"romi\" # \"sim\" ] # Other pip packages to install requires = [] Each of the following will instruct the deploy process to install packages to the roboRIO: robotpy_version is the version of the robotpy PyPI package that this robot code depends on. robotpy_extras defines extra RobotPy components that can be installed, as only the core RobotPy libraries are installed by default. requires is a list of strings, and each item is equivalent to a line of a requirements.txt file. You can install any pure python packages on the roboRIO and they will likely work, but any packages that have binary dependencies must be cross-compiled for the roboRIO. For example, if you needed to use numpy in your robot code: [tool.robotpy] ... requires = [ \"numpy\" ] The packages that can be installed are stored on the WPILib Artifactory server . If you find that you need a package that isn’t available on artifactory, consult the roborio-wheels repository.",
      "content_preview": "pyproject.toml usage Note RobotPy projects are not required to have a pyproject.toml , but when you run robotpy sync one will automatically be created for you. pyproject.toml has become a standard way to store build and tooling configuration for Python projects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/python/index.html",
      "title": "FRC Python Programming",
      "section": "General",
      "language": "Python",
      "content": "FRC Python Programming Python Installation Guide Installing the FRC Game Tools pyproject.toml usage RobotPy subcommands Deploy Python program to roboRIO",
      "content_preview": "FRC Python Programming Python Installation Guide Installing the FRC Game Tools pyproject.toml usage RobotPy subcommands Deploy Python program to roboRIO"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/python/pyproject_toml.html?present",
      "title": "pyproject.toml usage",
      "section": "General",
      "language": "Python",
      "content": "pyproject.toml usage Note RobotPy projects are not required to have a pyproject.toml , but when you run robotpy sync one will automatically be created for you. pyproject.toml has become a standard way to store build and tooling configuration for Python projects. The [tool.XXX] section(s) of the TOML file is a place where tools can store their configuration information. Currently RobotPy only stores deployment related information in pyproject.toml , in the [tool.robotpy] section. Users can customize the other sections however they want, and robotpy will ignore them. The pyproject.toml file looks something like this: # # Use this configuration file to control what RobotPy packages are installed # on your RoboRIO # [tool.robotpy] # Version of robotpy this project depends on robotpy_version = \"2024.2.1.0\" # Which extra RobotPy components should be installed # -> equivalent to `pip install robotpy[extra1, ...] robotpy_extras = [ # \"all\" # \"apriltag\" # \"commands2\" # \"cscore\" # \"navx\" # \"pathplannerlib\" # \"phoenix5\" # \"phoenix6\" # \"playingwithfusion\" # \"rev\" # \"romi\" # \"sim\" ] # Other pip packages to install requires = [] Each of the following will instruct the deploy process to install packages to the roboRIO: robotpy_version is the version of the robotpy PyPI package that this robot code depends on. robotpy_extras defines extra RobotPy components that can be installed, as only the core RobotPy libraries are installed by default. requires is a list of strings, and each item is equivalent to a line of a requirements.txt file. You can install any pure python packages on the roboRIO and they will likely work, but any packages that have binary dependencies must be cross-compiled for the roboRIO. For example, if you needed to use numpy in your robot code: [tool.robotpy] ... requires = [ \"numpy\" ] The packages that can be installed are stored on the WPILib Artifactory server . If you find that you need a package that isn’t available on artifactory, consult the roborio-wheels repository.",
      "content_preview": "pyproject.toml usage Note RobotPy projects are not required to have a pyproject.toml , but when you run robotpy sync one will automatically be created for you. pyproject.toml has become a standard way to store build and tooling configuration for Python projects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vscode-overview/3rd-party-libraries.html?present",
      "title": "3rd Party Libraries",
      "section": "General",
      "language": "All",
      "content": "3rd Party Libraries Teams that are using non- PWM motor controllers or advanced sensors will most likely need to install external vendor dependencies. What Are Vendor Dependencies? A vendor dependency is a way for vendors to add their software library to robot projects. This library can interface with motor controllers and other devices. This way, teams can interact with their devices via CAN and have access to more complex and in-depth features than traditional PWM control. Managing Vendor Dependencies Vendor dependencies are installed on a per-project basis (so each robot project can have its own set of vendor dependencies). Vendor dependencies can be installed “online” or “offline”. The “online” functionality is done by downloading the dependencies over the internet, while offline is typically provided by a vendor-specific installer. Warning If installing a vendor dependency via the “online” mode, make sure to reconnect the computer to the internet and rebuild about every 30 days otherwise the cache will clear, completely deleting the downloaded library install. Note Vendors recommend using their offline installers when available, because the offline installer is typically bundled with additional programs that are extremely useful when working with their devices. Installing Libraries Java/C++ VS Code All vendordep operations can be controlled by the Dependency Manager. Click the WPILib logo in the activity bar as shown above to access the interface. Select the desired libraries to add to the project by clicking the Install button next to each. The JSON file will be copied to the vendordeps folder in the project, adding the library as a dependency to the project. When an update is available for an installed vendordep you will see the To Latest button become available. To update you can either press that or the Update All to move all vendordeps to the latest version. The button with the trash icon will uninstall the vendordep. The dropdown shows what version is currently installed but you can change that to a different version to update or downgrade to the specified version. Note The Dependency Manager will automatically build your program when it loses focus. This allows you to use the changed dependencies. Python All RobotPy project dependencies are specified in pyproject.toml . You can add additional vendor-specific dependencies either by: Adding the component name to robotpy_extras Adding the PyPI package name to requires See also pyproject.toml usage Optional WPILib components: robotpy_extras requires Apriltag apriltag robotpy-apriltag Commands commands2 robotpy-commands-v2 cscore cscore robotpy-cscore Romi romi robotpy-romi XRP xrp robotpy-xrp Optional vendor-specific components (not all are available at the beginning of the season): Origin robotpy_extras requires ChoreoLib Vendor sleipnirgroup-choreolib CTRE Phoenix 6 Vendor phoenix6 phoenix6 CTRE Phoenix 5 Community phoenix5 robotpy-ctre PathPlannerLib Vendor pathplannerlib robotpy-pathplannerlib PhotonVision Vendor photonvision photonlibpy Playing With Fusion Community playingwithfusion robotpy-playingwithfusion REVLib Community rev robotpy-rev Studica Community navx robotpy-navx URCL Community robotpy-urcl When using requires , you can specify a version by appending ==<version> to the package name, e.g. robotpy-commands-v2==2024.0.0 . If you do not specify a version, the latest version will be installed. To check what version of packages are currently installed, run the command pip list . Note that pinning versions may cause issues with incompatibilities between different components. Unpinning all versions, installing, then re-pinning to the latest set is a good practice when updating. Pinning versions is a good practice to do after most robot code is written and validated, before and during a competition. However, outside of this window, remaining on the latest version of the components is recommended, as it will ensure you have the latest bug fixes and features. See https://pip.pypa.io/en/stable/topics/repeatable-installs/ for more information on how to specify versions. Java/C++ (Legacy) VS Code To add a vendor library that has been installed by an offline installer, press Ctrl + Shift + P and type WPILib or click on the WPILib icon in the top right to open the WPILib Command Palette and begin typing Manage Vendor Libraries , then select it from the menu. Select the option to Install new libraries (offline) . Select the desired libraries to add to the project by checking the box next to each, then click OK . The JSON file will be copied to the vendordeps folder in the project, adding the library as a dependency to the project. In order to install a vendor library in online mode, press Ctrl + Shift + P and type WPILib or click on the WPILib icon in the top right to open the WPILib Command Palette and begin typing Manage Vendor Libraries and select it in the menu, and then click on Install new libraries (online) instead and copy + paste the vendor JSON URL. Checking for Updates (Offline) Since dependencies are version managed on a per-project basis, even when installed offline, you will need to Manage Vendor Libraries and select Check for updates (offline) for each project you wish to update. Checking for Updates (Online) Part of the JSON file that vendors may optionally populate is an online update location. If a library has an appropriate location specified, running Check for updates (online) will check if a newer version of the library is available from the remote location. Removing a Library Dependency To remove a library dependency from a project, select Manage Current Libraries from the Manage Vendor Libraries menu, check the box for any libraries to uninstall and click OK . These libraries will be removed as dependencies from the project. Command-Line Adding a vendor library dependency from the vendor URL can also be done through the command-line via a gradle task. Open a command-line instance at the project root, and enter gradlew vendordep --url=<url> where <url> is the vendor JSON URL. This will add the vendor library dependency JSON file to the vendordeps folder of the project. Vendor libraries can be updated the same way. The vendordep gradle task can also fetch vendordep JSONs from the user wpilib folder. To do so, pass FRCLOCAL/Filename.json as the file URL. For example, gradlew vendordep --url=FRCLOCAL/WPILibNewCommands.json will fetch the JSON for the command-based framework. How Does It Work? Java/C++ For Java and C++, a JSON file describing the vendor library is installed on your system to ~/wpilib/YYYY/vendordeps (where YYYY is the year and ~ is C:\\Users\\Public on Windows). This is often done by an offline installer, but may need to be done manually if a .zip of the .json files is provided. This file is then used from VS Code to add to the library to each individual project. Vendor library information is managed on a per-project basis to make sure that a project is always pointing to a consistent version of a given vendor library. The libraries themselves are placed in the Maven cache at C:\\Users\\Public\\wpilib\\YYYY\\maven . Vendors can place a local copy here with an offline installer (recommended) or require users to be connected to the internet for an initial build to fetch the library from a remote Maven location. This JSON file allows specification of complex libraries with multiple components (Java, C++, JNI, etc.) and also helps handle some complexities related to simulation. LabVIEW For LabVIEW teams, there might be a few new Third Party items on various palettes (specifically, one in Actuators , one in Actuators -> Motor Control labeled CAN Motor , and one in Sensors ). These correspond to folders in C:\\Program Files\\National Instruments\\LabVIEW 2023\\vi.lib\\Rock Robotics\\WPI\\Third Party In order to install third party libraries for LabVIEW, download the VIs from the vendor (typically via some sort of installer). Then drag and drop the third party VIs into the respective folder mentioned above just like any other VI. Python Third party libraries are packaged into Python wheels and uploaded to PyPI (if pure python) and/or WPILib’s artifactory. Users can enable them as dependencies either by adding the component name to robotpy_extras (recommended) or by adding an explicit dependency for the PyPI package in requires . The dependencies are downloaded when robotpy sync is executed, and installed on the roboRIO when robotpy deploy is executed.",
      "content_preview": "3rd Party Libraries Teams that are using non- PWM motor controllers or advanced sensors will most likely need to install external vendor dependencies. What Are Vendor Dependencies? A vendor dependency is a way for vendors to add their software library to robot projects."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/third-party-devices.html?present",
      "title": "Third",
      "section": "CAN Devices",
      "language": "Java",
      "content": "Third-Party CAN Devices A number of FRC® vendors offer their own CAN peripherals. As CAN devices offer expansive feature-sets, vendor CAN devices require similarly expansive code libraries to operate. As a result, these libraries are not maintained as an official part of WPILib, but are instead maintained by the vendors themselves. For a guide to installing third-party libraries, see 3rd Party Libraries A list of common third-party CAN devices from various vendors, along with links to corresponding external documentation, is provided below: CTR Electronics CTR Electronics (CTRE) offers several CAN peripherals with external libraries. General resources for all CTRE devices include: Phoenix Device Software Documentation CTRE Motor Controllers Talon FX (with Falcon 500 Motor, Kraken x60 motor, and Kraken x44) API Documentation (v6: Java , C++ ) Hardware User’s Manual ( Falcon 500 , Kraken x60 , Kraken x44 ) Software Documentation Talon SRX API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation Victor SPX API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CTRE Sensors CANcoder API Documentation (v6: Java , C++ ) Hardware User’s Manual Software Documentation Pigeon 2.0 API Documentation (v6: Java , C++ ) Hardware User’s Manual Software Documentation6 Pigeon IMU API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CANifier API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation CTRE Other CAN Devices CANdle LED Controller API Documentation ( Java , C++ ) Hardware User’s Manual Software Documentation REV Robotics REV Robotics currently offers the SPARK MAX and SPARK Flex motor controllers which can be used for brushed and REV brushless (NEO, NEO 550, and NEO Vortex) motors. REV Motor Controllers SPARK MAX API Documentation ( Java , C++ ) Technical Manual SPARK Flex API Documentation ( Java , C++ ) Technical Manual Playing With Fusion Playing With Fusion (PWF) offers the Venom integrated motor/controller as well as a Time-of-Flight distance sensor: PWF Motor Controllers Venom API Documentation ( Java , C++ ) Technical Manual PWF Sensors Time of Flight Sensor API Documentation ( Java , C++ ) Technical Manual Redux Robotics Warning Redux Robotics is shutting down. While their devices remain legal for FRC use and software support will be provided for the 2026 season, no new hardware will be available. Redux Robotics offers the HELIUM Canandmag CAN + PWM magnetic encoder and the BORON Canandgyro CAN -enabled gyro. Redux Sensors HELIUM Canandmag API Documentation ( Java , C++ ) Technical Manual BORON Canandgyro API Documentation ( Java , C++ ) Technical Manual Grapple Robotics Grapple Robotics currently offers the LaserCAN CAN -enabled range finding sensor Grapple Sensors LaserCAN API Documentation ( Java , C++ ) Technical Manual",
      "content_preview": "Third-Party CAN Devices A number of FRC® vendors offer their own CAN peripherals. As CAN devices offer expansive feature-sets, vendor CAN devices require similarly expansive code libraries to operate."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/pneumatics-control-module.html",
      "title": "Pneumatics Control Module",
      "section": "CAN Devices",
      "language": "All",
      "content": "Pneumatics Control Module The Pneumatics Control Module ( PCM ) is a CAN -based device that provides complete control over the compressor and up to 8 solenoids per module. The PCM is integrated into WPILib through a series of classes that make it simple to use. The closed loop control of the Compressor and Pressure switch is handled by the Compressor class ( Java , C++ , Python ), and the Solenoids are handled by the Solenoid ( Java , C++ , Python ) and DoubleSolenoid ( Java , C++ , Python ) classes. An additional PCM module can be used where the module’s corresponding solenoids are differentiated by the module number in the constructors of the Solenoid and Compressor classes. For more information on controlling the compressor, see Operating a Compressor for Pneumatics . For more information on controlling solenoids, see Operating Pneumatic Cylinders .",
      "content_preview": "Pneumatics Control Module The Pneumatics Control Module ( PCM ) is a CAN -based device that provides complete control over the compressor and up to 8 solenoids per module. The PCM is integrated into WPILib through a series of classes that make it simple to use."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/pneumatics-control-module.html?present",
      "title": "Pneumatics Control Module",
      "section": "CAN Devices",
      "language": "All",
      "content": "Pneumatics Control Module The Pneumatics Control Module ( PCM ) is a CAN -based device that provides complete control over the compressor and up to 8 solenoids per module. The PCM is integrated into WPILib through a series of classes that make it simple to use. The closed loop control of the Compressor and Pressure switch is handled by the Compressor class ( Java , C++ , Python ), and the Solenoids are handled by the Solenoid ( Java , C++ , Python ) and DoubleSolenoid ( Java , C++ , Python ) classes. An additional PCM module can be used where the module’s corresponding solenoids are differentiated by the module number in the constructors of the Solenoid and Compressor classes. For more information on controlling the compressor, see Operating a Compressor for Pneumatics . For more information on controlling solenoids, see Operating Pneumatic Cylinders .",
      "content_preview": "Pneumatics Control Module The Pneumatics Control Module ( PCM ) is a CAN -based device that provides complete control over the compressor and up to 8 solenoids per module. The PCM is integrated into WPILib through a series of classes that make it simple to use."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/index.html?present",
      "title": "CAN Devices",
      "section": "CAN Devices",
      "language": "All",
      "content": "CAN Devices Using CAN Devices Pneumatics Control Module Pneumatic Hub Power Distribution Module Third-Party CAN Devices FRC CAN Device Specifications",
      "content_preview": "CAN Devices Using CAN Devices Pneumatics Control Module Pneumatic Hub Power Distribution Module Third-Party CAN Devices FRC CAN Device Specifications"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/pneumatic-hub.html",
      "title": "Pneumatic Hub",
      "section": "CAN Devices",
      "language": "All",
      "content": "Pneumatic Hub The Pneumatic Hub ( PH ) is a CAN -based device that provides complete control over the compressor and up to 16 solenoids per module. The PH is integrated into WPILib through a series of classes that make it simple to use. The closed loop control of the Compressor and Pressure switch is handled by the Compressor class ( Java , C++ , Python ), and the Solenoids are handled by the Solenoid ( Java , C++ , Python ) and DoubleSolenoid ( Java , C++ , Python ) classes. An additional PH module can be used where the module’s corresponding solenoids are differentiated by the module number in the constructors of the Solenoid and Compressor classes. For more information on controlling the compressor, see Operating a Compressor for Pneumatics . For more information on controlling solenoids, see Operating Pneumatic Cylinders .",
      "content_preview": "Pneumatic Hub The Pneumatic Hub ( PH ) is a CAN -based device that provides complete control over the compressor and up to 16 solenoids per module. The PH is integrated into WPILib through a series of classes that make it simple to use."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/pneumatic-hub.html?present",
      "title": "Pneumatic Hub",
      "section": "CAN Devices",
      "language": "All",
      "content": "Pneumatic Hub The Pneumatic Hub ( PH ) is a CAN -based device that provides complete control over the compressor and up to 16 solenoids per module. The PH is integrated into WPILib through a series of classes that make it simple to use. The closed loop control of the Compressor and Pressure switch is handled by the Compressor class ( Java , C++ , Python ), and the Solenoids are handled by the Solenoid ( Java , C++ , Python ) and DoubleSolenoid ( Java , C++ , Python ) classes. An additional PH module can be used where the module’s corresponding solenoids are differentiated by the module number in the constructors of the Solenoid and Compressor classes. For more information on controlling the compressor, see Operating a Compressor for Pneumatics . For more information on controlling solenoids, see Operating Pneumatic Cylinders .",
      "content_preview": "Pneumatic Hub The Pneumatic Hub ( PH ) is a CAN -based device that provides complete control over the compressor and up to 16 solenoids per module. The PH is integrated into WPILib through a series of classes that make it simple to use."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/can-addressing.html",
      "title": "FRC CAN Device Specifications",
      "section": "CAN Devices",
      "language": "All",
      "content": "FRC CAN Device Specifications This document seeks to describe the basic functions of the current FRC® CAN system and the requirements for any new CAN devices seeking to work with the system. Addressing FRC CAN nodes assign arbitration IDs based on a pre-defined scheme that breaks the ID into 5 components: Device Type This is a 5-bit value describing the type of device being addressed. A table of currently assigned device types can be found below. If you wish to have a new device type assigned from the Reserved pool, please submit a request to FIRST. Device Types Broadcast Messages 0 Robot Controller 1 Motor Controller 2 Relay Controller 3 Gyro Sensor 4 Accelerometer 5 Distance Sensor 6 Encoder 7 Power Distribution Module 8 Pneumatics Controller 9 Miscellaneous 10 IO Breakout 11 Servo Controller 12 Color Sensor 13 Reserved 14-30 Firmware Update 31 Manufacturer This is an 8-bit value indicating the manufacturer of the CAN device. Currently assigned values can be found in the table below. If you wish to have a manufacturer ID assigned from the Reserved pool, please submit a request to FIRST. Manufacturer Broadcast 0 NI 1 Luminary Micro 2 DEKA 3 CTR Electronics 4 REV Robotics 5 Grapple 6 MindSensors 7 Team Use 8 Kauai Labs 9 Copperforge 10 Playing With Fusion 11 Studica 12 The Thrifty Bot 13 Redux Robotics 14 AndyMark 15 Vivid Hosting 16 Vertos Robotics 17 SWYFT Robotics 18 Lumyn Labs 19 Brushland Labs 20 Reserved 21-255 API/Message Identifier The API or Message Identifier is a 10-bit value that identifies a particular command or message type. These identifiers are unique for each Manufacturer + Device Type combination (so an API identifier that may be a “Voltage Set” for a Luminary Micro Motor Controller may be a “Status Get” for a CTR Electronics Motor Controller or Current Get for a CTR Power Distribution Module). The Message identifier is further broken down into 2 sub-fields: the 6-bit API Class and the 4-bit API Index. API Class The API Class is a 6-bit identifier for an API grouping. Similar messages are grouped into a single API Class. An example of the API Classes for the Jaguar Motor Controller is shown in the table below. API Class Voltage Control Mode 0 Speed Control Mode 1 Voltage Compensation Mode 2 Position Control Mode 3 Current Control Mode 4 Status 5 Periodic Status 6 Configuration 7 Ack 8 API Index The API Index is a 4-bit identifier for a particular message within an API Class. An example of the API Index values for the Jaguar Motor Controller Speed Control API Class is shown in the table below. API Index Enable Control 0 Disable Control 1 Set Setpoint 2 P Constant 3 I Constant 4 D Constant 5 Set Reference 6 Trusted Enable 7 Trusted Set No Ack 8 Trusted Set Setpoint No Ack 10 Set Setpoint No Ack 11 Device Number Device Number is a 6-bit quantity indicating the number of the device of a particular type. Devices should default to device ID 0 to match other components of the FRC Control System. Device 0x3F may be reserved for device specific broadcast messages. Protected Frames FRC CAN Nodes which implement actuator control capability (motor controllers, relays, pneumatics controllers, etc.) must implement a way to verify that the robot is enabled and that commands originate with the main robot controller (i.e. the roboRIO). Broadcast Messages Broadcast messages are messages sent to all nodes by setting the device type and manufacturer fields to 0. The API Class for broadcast messages is 0. The currently defined broadcast messages are shown in the table below: Description Disable 0 System Halt 1 System Reset 2 Device Assign 3 Device Query 4 Heartbeat 5 Sync 6 Update 7 Firmware Version 8 Enumerate 9 System Resume 10 Devices should disable immediately when receiving the Disable message (arbID 0). Implementation of other broadcast messages is optional. Requirements for FRC CAN Nodes For CAN Nodes to be accepted for use in the FRC System, they must: Communicate using Arbitration IDs which match the prescribed FRC format: A valid, issued CAN Device Type (per Table 1 - CAN Device Types) A valid, issued Manufacturer ID (per Table 2 - CAN Manufacturer Codes) API Class(es) and Index(s) assigned and documented by the device manufacturer A user selectable device number if multiple units of the device type are intended to co-exist on the same network. Support the minimum Broadcast message requirements as detailed in the Broadcast Messages section. If controlling actuators, utilize a scheme to assure that the robot is issuing commands, is enabled, and is still present. Provide software library support for LabVIEW, C++, and Java or arrange with FIRST ® or FIRST’s Control System Partners to provide such interfaces. Universal Heartbeat The roboRIO provides a universal CAN heartbeat that any device on the bus can listen and react to. This heartbeat is sent every 20 ms. The heartbeat has a full CAN ID of 0x01011840 (which is the NI Manufacturer ID, RobotController type, Device ID 0 and API ID 0x061 ). It is an 8 byte CAN packet with the following bitfield layout. Description Byte Width (bits) Match time (seconds) 8 8 Match number 6-7 10 Replay number 6 6 Red alliance 5 1 Enabled 5 1 Autonomous mode 5 1 Test mode 5 1 System watchdog 5 1 Tournament type 5 3 Time of day (year) 4 6 Time of day (month) 3-4 4 Time of day (day) 3 5 Time of day (seconds) 2-3 6 Time of day (minutes) 1-2 6 Time of day (hours) 1 5 struct [[ gnu :: packed ]] RobotState { uint64_t matchTimeSeconds : 8 ; uint64_t matchNumber : 10 ; uint64_t replayNumber : 6 ; uint64_t redAlliance : 1 ; uint64_t enabled : 1 ; uint64_t autonomous : 1 ; uint64_t testMode : 1 ; uint64_t systemWatchdog : 1 ; uint64_t tournamentType : 3 ; uint64_t timeOfDay_yr : 6 ; uint64_t timeOfDay_month : 4 ; uint64_t timeOfDay_day : 5 ; uint64_t timeOfDay_sec : 6 ; uint64_t timeOfDay_min : 6 ; uint64_t timeOfDay_hr : 5 ; }; If the System watchdog flag is set, motor controllers are enabled. If 100 ms has passed since this packet was received, the robot program can be considered hung, and devices should act as if the robot has been disabled. Note that all fields except Enabled , Autonomous mode , Test mode , and System watchdog will contain invalid values until an arbitrary time after the Driver Station connects.",
      "content_preview": "FRC CAN Device Specifications This document seeks to describe the basic functions of the current FRC® CAN system and the requirements for any new CAN devices seeking to work with the system."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/can-addressing.html?present",
      "title": "FRC CAN Device Specifications",
      "section": "CAN Devices",
      "language": "All",
      "content": "FRC CAN Device Specifications This document seeks to describe the basic functions of the current FRC® CAN system and the requirements for any new CAN devices seeking to work with the system. Addressing FRC CAN nodes assign arbitration IDs based on a pre-defined scheme that breaks the ID into 5 components: Device Type This is a 5-bit value describing the type of device being addressed. A table of currently assigned device types can be found below. If you wish to have a new device type assigned from the Reserved pool, please submit a request to FIRST. Device Types Broadcast Messages 0 Robot Controller 1 Motor Controller 2 Relay Controller 3 Gyro Sensor 4 Accelerometer 5 Distance Sensor 6 Encoder 7 Power Distribution Module 8 Pneumatics Controller 9 Miscellaneous 10 IO Breakout 11 Servo Controller 12 Color Sensor 13 Reserved 14-30 Firmware Update 31 Manufacturer This is an 8-bit value indicating the manufacturer of the CAN device. Currently assigned values can be found in the table below. If you wish to have a manufacturer ID assigned from the Reserved pool, please submit a request to FIRST. Manufacturer Broadcast 0 NI 1 Luminary Micro 2 DEKA 3 CTR Electronics 4 REV Robotics 5 Grapple 6 MindSensors 7 Team Use 8 Kauai Labs 9 Copperforge 10 Playing With Fusion 11 Studica 12 The Thrifty Bot 13 Redux Robotics 14 AndyMark 15 Vivid Hosting 16 Vertos Robotics 17 SWYFT Robotics 18 Lumyn Labs 19 Brushland Labs 20 Reserved 21-255 API/Message Identifier The API or Message Identifier is a 10-bit value that identifies a particular command or message type. These identifiers are unique for each Manufacturer + Device Type combination (so an API identifier that may be a “Voltage Set” for a Luminary Micro Motor Controller may be a “Status Get” for a CTR Electronics Motor Controller or Current Get for a CTR Power Distribution Module). The Message identifier is further broken down into 2 sub-fields: the 6-bit API Class and the 4-bit API Index. API Class The API Class is a 6-bit identifier for an API grouping. Similar messages are grouped into a single API Class. An example of the API Classes for the Jaguar Motor Controller is shown in the table below. API Class Voltage Control Mode 0 Speed Control Mode 1 Voltage Compensation Mode 2 Position Control Mode 3 Current Control Mode 4 Status 5 Periodic Status 6 Configuration 7 Ack 8 API Index The API Index is a 4-bit identifier for a particular message within an API Class. An example of the API Index values for the Jaguar Motor Controller Speed Control API Class is shown in the table below. API Index Enable Control 0 Disable Control 1 Set Setpoint 2 P Constant 3 I Constant 4 D Constant 5 Set Reference 6 Trusted Enable 7 Trusted Set No Ack 8 Trusted Set Setpoint No Ack 10 Set Setpoint No Ack 11 Device Number Device Number is a 6-bit quantity indicating the number of the device of a particular type. Devices should default to device ID 0 to match other components of the FRC Control System. Device 0x3F may be reserved for device specific broadcast messages. Protected Frames FRC CAN Nodes which implement actuator control capability (motor controllers, relays, pneumatics controllers, etc.) must implement a way to verify that the robot is enabled and that commands originate with the main robot controller (i.e. the roboRIO). Broadcast Messages Broadcast messages are messages sent to all nodes by setting the device type and manufacturer fields to 0. The API Class for broadcast messages is 0. The currently defined broadcast messages are shown in the table below: Description Disable 0 System Halt 1 System Reset 2 Device Assign 3 Device Query 4 Heartbeat 5 Sync 6 Update 7 Firmware Version 8 Enumerate 9 System Resume 10 Devices should disable immediately when receiving the Disable message (arbID 0). Implementation of other broadcast messages is optional. Requirements for FRC CAN Nodes For CAN Nodes to be accepted for use in the FRC System, they must: Communicate using Arbitration IDs which match the prescribed FRC format: A valid, issued CAN Device Type (per Table 1 - CAN Device Types) A valid, issued Manufacturer ID (per Table 2 - CAN Manufacturer Codes) API Class(es) and Index(s) assigned and documented by the device manufacturer A user selectable device number if multiple units of the device type are intended to co-exist on the same network. Support the minimum Broadcast message requirements as detailed in the Broadcast Messages section. If controlling actuators, utilize a scheme to assure that the robot is issuing commands, is enabled, and is still present. Provide software library support for LabVIEW, C++, and Java or arrange with FIRST ® or FIRST’s Control System Partners to provide such interfaces. Universal Heartbeat The roboRIO provides a universal CAN heartbeat that any device on the bus can listen and react to. This heartbeat is sent every 20 ms. The heartbeat has a full CAN ID of 0x01011840 (which is the NI Manufacturer ID, RobotController type, Device ID 0 and API ID 0x061 ). It is an 8 byte CAN packet with the following bitfield layout. Description Byte Width (bits) Match time (seconds) 8 8 Match number 6-7 10 Replay number 6 6 Red alliance 5 1 Enabled 5 1 Autonomous mode 5 1 Test mode 5 1 System watchdog 5 1 Tournament type 5 3 Time of day (year) 4 6 Time of day (month) 3-4 4 Time of day (day) 3 5 Time of day (seconds) 2-3 6 Time of day (minutes) 1-2 6 Time of day (hours) 1 5 struct [[ gnu :: packed ]] RobotState { uint64_t matchTimeSeconds : 8 ; uint64_t matchNumber : 10 ; uint64_t replayNumber : 6 ; uint64_t redAlliance : 1 ; uint64_t enabled : 1 ; uint64_t autonomous : 1 ; uint64_t testMode : 1 ; uint64_t systemWatchdog : 1 ; uint64_t tournamentType : 3 ; uint64_t timeOfDay_yr : 6 ; uint64_t timeOfDay_month : 4 ; uint64_t timeOfDay_day : 5 ; uint64_t timeOfDay_sec : 6 ; uint64_t timeOfDay_min : 6 ; uint64_t timeOfDay_hr : 5 ; }; If the System watchdog flag is set, motor controllers are enabled. If 100 ms has passed since this packet was received, the robot program can be considered hung, and devices should act as if the robot has been disabled. Note that all fields except Enabled , Autonomous mode , Test mode , and System watchdog will contain invalid values until an arbitrary time after the Driver Station connects.",
      "content_preview": "FRC CAN Device Specifications This document seeks to describe the basic functions of the current FRC® CAN system and the requirements for any new CAN devices seeking to work with the system."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/power-distribution-module.html",
      "title": "Power Distribution Module",
      "section": "CAN Devices",
      "language": "All",
      "content": "Power Distribution Module The CTRE Power Distribution Panel ( PDP ) and Rev Power Distribution Hub ( PDH ) can use their CAN connectivity to communicate a wealth of status information regarding the robot’s power use to the roboRIO, for use in user code. This has the capability to report current temperature, the bus voltage, the total robot current draw, the total robot energy use, and the individual current draw of each device power channel. This data can be used for a number of advanced control techniques, such as motor torque limiting and brownout avoidance. Creating a Power Distribution Object To use the either Power Distribution module, create an instance of the PowerDistribution class ( Java , C++ , Python ). With no arguments, the Power Distribution object will be detected, and must use CAN ID of 0 for CTRE or 1 for REV. If the CAN ID is non-default, additional constructors are available to specify the CAN ID and type. JAVA PowerDistribution examplePD = new PowerDistribution (); PowerDistribution examplePD = new PowerDistribution ( 0 , ModuleType . kCTRE ); PowerDistribution examplePD = new PowerDistribution ( 1 , ModuleType . kRev ); C++ PowerDistribution examplePD {}; PowerDistribution examplePD { 0 , frc :: PowerDistribution :: ModuleType :: kCTRE }; PowerDistribution examplePD { 1 , frc :: PowerDistribution :: ModuleType :: kRev }; PYTHON from wpilib import PowerDistribution examplePD = PowerDistribution () examplePD = PowerDistribution ( 0 , PowerDistribution . ModuleType . kCTRE ) examplePD = PowerDistribution ( 1 , PowerDistribution . ModuleType . kRev ) Note: it is not necessary to create a PowerDistribution object unless you need to read values from it. The board will work and supply power on all the channels even if the object is never created. Reading the Bus Voltage JAVA // Get the voltage going into the PDP, in Volts. // The PDP returns the voltage in increments of 0.05 Volts. double voltage = m_pdp . getVoltage (); SmartDashboard . putNumber ( \"Voltage\" , voltage ); C++ // Get the voltage going into the PDP, in Volts. // The PDP returns the voltage in increments of 0.05 Volts. double voltage = m_pdp . GetVoltage (); frc :: SmartDashboard :: PutNumber ( \"Voltage\" , voltage ); PYTHON # Get the voltage going into the PDP, in Volts. # The PDP returns the voltage in increments of 0.05 Volts. voltage = self . pdp . getVoltage () wpilib . SmartDashboard . putNumber ( \"Voltage\" , voltage ) Monitoring the bus voltage can be useful for (among other things) detecting when the robot is near a brownout, so that action can be taken to avoid brownout in a controlled manner. See the roboRIO Brownouts document for more information. Reading the Temperature JAVA // Retrieves the temperature of the PDP, in degrees Celsius. double temperatureCelsius = m_pdp . getTemperature (); SmartDashboard . putNumber ( \"Temperature\" , temperatureCelsius ); C++ // Retrieves the temperature of the PDP, in degrees Celsius. double temperatureCelsius = m_pdp . GetTemperature (); frc :: SmartDashboard :: PutNumber ( \"Temperature\" , temperatureCelsius ); PYTHON # Retrieves the temperature of the PDP, in degrees Celsius. temperatureCelsius = self . pdp . getTemperature () wpilib . SmartDashboard . putNumber ( \"Temperature\" , temperatureCelsius ) Monitoring the temperature can be useful for detecting if the robot has been drawing too much power and needs to be shut down for a while, or if there is a short or other wiring problem. Reading the Total Current, Power, and Energy JAVA // Get the total current of all channels. double totalCurrent = m_pdp . getTotalCurrent (); SmartDashboard . putNumber ( \"Total Current\" , totalCurrent ); // Get the total power of all channels. // Power is the bus voltage multiplied by the current with the units Watts. double totalPower = m_pdp . getTotalPower (); SmartDashboard . putNumber ( \"Total Power\" , totalPower ); // Get the total energy of all channels. // Energy is the power summed over time with units Joules. double totalEnergy = m_pdp . getTotalEnergy (); SmartDashboard . putNumber ( \"Total Energy\" , totalEnergy ); C++ // Get the total current of all channels. double totalCurrent = m_pdp . GetTotalCurrent (); frc :: SmartDashboard :: PutNumber ( \"Total Current\" , totalCurrent ); // Get the total power of all channels. // Power is the bus voltage multiplied by the current with the units Watts. double totalPower = m_pdp . GetTotalPower (); frc :: SmartDashboard :: PutNumber ( \"Total Power\" , totalPower ); // Get the total energy of all channels. // Energy is the power summed over time with units Joules. double totalEnergy = m_pdp . GetTotalEnergy (); frc :: SmartDashboard :: PutNumber ( \"Total Energy\" , totalEnergy ); PYTHON # Get the total current of all channels. totalCurrent = self . pdp . getTotalCurrent () wpilib . SmartDashboard . putNumber ( \"Total Current\" , totalCurrent ) # Get the total power of all channels. # Power is the bus voltage multiplied by the current with the units Watts. totalPower = self . pdp . getTotalPower () wpilib . SmartDashboard . putNumber ( \"Total Power\" , totalPower ) # Get the total energy of all channels. # Energy is the power summed over time with units Joules. totalEnergy = self . pdp . getTotalEnergy () wpilib . SmartDashboard . putNumber ( \"Total Energy\" , totalEnergy ) Monitoring the total current, power, and energy can be useful for controlling how much power is being drawn from the battery, both for preventing brownouts and ensuring that mechanisms have sufficient power available to perform the actions required. Power is the bus voltage multiplied by the current with the units Watts. Energy is the power summed over time with units Joules. Reading Individual Channel Currents The PDP/PDH also allows users to monitor the current drawn by the individual device power channels. You can read the current on any of the 16 PDP channels (0-15) or 24 PDH channels (0-23). JAVA // Get the current going through channel 7, in Amperes. // The PDP returns the current in increments of 0.125A. // At low currents the current readings tend to be less accurate. double current7 = m_pdp . getCurrent ( 7 ); SmartDashboard . putNumber ( \"Current Channel 7\" , current7 ); C++ // Get the current going through channel 7, in Amperes. // The PDP returns the current in increments of 0.125A. // At low currents the current readings tend to be less accurate. double current7 = m_pdp . GetCurrent ( 7 ); frc :: SmartDashboard :: PutNumber ( \"Current Channel 7\" , current7 ); PYTHON # Get the current going through channel 7, in Amperes. # The PDP returns the current in increments of 0.125A. # At low currents the current readings tend to be less accurate. current7 = self . pdp . getCurrent ( 7 ) wpilib . SmartDashboard . putNumber ( \"Current Channel 7\" , current7 ) Monitoring individual device current draws can be useful for detecting shorts or stalled motors. Using the Switchable Channel (PDH) The REV PDH has one channel that can be switched on or off to control custom circuits. JAVA examplePD . setSwitchableChannel ( true ); examplePD . setSwitchableChannel ( false ); C++ examplePD . SetSwitchableChannel ( true ); examplePD . SetSwitchableChannel ( false ); PYTHON examplePD . setSwitchableChannel ( True ) examplePD . setSwitchableChannel ( False )",
      "content_preview": "Power Distribution Module The CTRE Power Distribution Panel ( PDP ) and Rev Power Distribution Hub ( PDH ) can use their CAN connectivity to communicate a wealth of status information regarding the robot’s power use to the roboRIO, for use in user code."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/roborio-info/roborio-brownouts.html",
      "title": "roboRIO Brownout and Understanding Current Draw",
      "section": "General",
      "language": "All",
      "content": "roboRIO Brownout and Understanding Current Draw In order to help maintain battery voltage to preserve itself and other control system components such as the radio during high current draw events, the roboRIO contains a staged brownout protection scheme. This article describes this scheme, provides information about proactively planning for system current draw, and describes how to use the new functionality of the PDP as well as the DS Log File Viewer to understand brownout events if they do happen on your robot. roboRIO Brownout Protection The roboRIO uses a staged brownout protection scheme to attempt to preserve the input voltage to itself and other control system components in order to prevent device resets in the event of large current draws pulling the battery voltage dangerously low. Stage 1 - 6v output drop Voltage Trigger - 6.8V When the voltage drops below 6.8V, the 6V output on the PWM pins will start to drop. Stage 2 - Output Disable Voltage Trigger - 6.3V When the voltage drops below 6.3V, the controller will enter the brownout protection state. The following indicators will show that this condition has occurred: Power LED on the roboRIO will turn Amber Background of the voltage display on the Driver Station will turn red Mode display on the Driver Station will change to Voltage Brownout The CAN/Power tab of the DS will increment the 12V fault counter by 1. The DS will record a brownout event in the DS log. The controller will take the following steps to attempt to preserve the battery voltage: PWM outputs will be disabled. For PWM outputs which have set their neutral value (all motor controllers in WPILib) a single neutral pulse will be sent before the output is disabled. 6V, 5V, 3.3V User Rails disabled (This includes the 6V outputs on the PWM pins, the 5V pins in the DIO connector bank, the 5V pins in the Analog bank, the 3.3V pins in the SPI and I2C bank and the 5V and 3.3V pins in the MXP bank) GPIO configured as outputs go to High-Z Relay Outputs are disabled (driven low) CAN-based motor controllers are sent an explicit disable command Pneumatic Devices such as the CTRE Pneumatics Control Module and REV Pneumatic Hub are disabled The controller will remain in this state until the voltage rises to greater than 7.5V or drops below the trigger for the next stage of the brownout Stage 3 - Device Blackout Voltage Trigger - 4.5V Below 4.5V the device may blackout. The exact voltage may be lower than this and depends on the load on the device. The controller will remain in this state until the voltage rises above 4.65V when the device will begin the normal boot sequence. Avoiding Brownout - Proactive Current Draw Planning The key to avoiding a brownout condition is to proactively plan for the current draw of your robot. The best way to do this is to create some form of power budget. This can be a complex document that attempts to quantify both estimated current draw and time in an effort to most completely understand power usage and therefore battery state at the end of a match, or it can be a simple inventory of current usage. To do this: Establish the max “sustained” current draw (with sustained being loosely defined here as not momentary). This is probably the most difficult part of creating the power budget. The exact current draw a battery can sustain while maintaining a voltage of 7+ volts is dependent on a variety of factors such as battery health (see this article for measuring battery health) and state of charge. As shown in the NP18-12 data sheet , the terminal voltage chart gets very steep as state of charge decreases, especially as current draw increases. This datasheet shows that at 3CA continuous load (54A) a brand new battery can be continuously run for over 6 minutes while maintaining a terminal voltage of over 7V. As shown in the image above (used with permission from Team 234s Drive System Testing document ), even with a fresh battery, drawing 240A for more than a second or two is likely to cause an issue. This gives us some bounds on setting our sustained current draw. For the purposes of this exercise, we’ll set our limit at 180A. List out the different functions of your robot such as drivetrain, manipulator, main game mechanism, etc. Start assigning your available current to these functions. You will likely find that you run out pretty quickly. Many teams gear their drivetrain to have enough torque to slip their wheels at 40-50A of current draw per motor. If we have 4 motors on the drivetrain, that eats up most, or even exceeds, our power budget! This means that we may need to put together a few scenarios and understand what functions can (and need to be) be used at the same time. In many cases, this will mean that you really need to limit the current draw of the other functions if/while your robot is maxing out the drivetrain (such as trying to push something). Benchmarking the “driving” current requirements of a drivetrain for some of these alternative scenarios is a little more complex, as it depends on many factors such as number of motors, robot weight, gearing, and efficiency. Current numbers for other functions can be done by calculating the power required to complete the function and estimating efficiency (if the mechanism has not been designed) or by determining the torque load on the motor and using the torque-current curve to determine the current draw of the motors. If you have determined mutually exclusive functions in your analysis, consider enforcing the exclusion in software. You may also use the current monitoring of the PDP (covered in more detail below) in your robot program to provide output limits or exclusions dynamically (such as don’t run a mechanism motor when the drivetrain current is over X or only let the motor run up to half output when the drivetrain current is over Y). Settable Brownout The NI roboRIO 1.0 does not support custom brownout voltages. It is fixed at 6.3V as mentioned in Stage 2 above. The NI roboRIO 2.0 adds the option for a software settable brownout level. The default brownout level (Stage 2) of the roboRIO 2.0 is 6.75V. JAVA RobotController . setBrownoutVoltage ( 7.0 ); C++ frc :: RobotController :: SetBrownoutVoltage ( 7 _V ); Measuring Current Draw using the PDP/PDH The FRC® Driver Station works in conjunction with the roboRIO and PDP/PDH to extract logged data from the PDP/PDH and log it on your DS PC. A viewer for this data is still under development. In the meantime, teams can use their robot code and manual logging, a LabVIEW front panel or the SmartDashboard to visualize current draw on their robot as mechanisms are developed. In LabVIEW, you can read the current on a PDP/PDH channel using the Get PD Currents VI found on the Power pallet. For C++ and Java teams, use the PowerDistribution class as described in the Power Distribution article. Plotting this information over time (easiest with a LV Front Panel or with the SmartDashboard by using a Graph indicator can provide information to compare against and update your power budget or can locate mechanisms which do not seem to be performing as expected (due to incorrect load calculation, incorrect efficiency assumptions, or mechanism issues such as binding). Identifying Brownouts The easiest way to identify a brownout is by clicking on the CAN\\Power tab of the DS and checking the 12V fault count. Alternately, you can review the Driver Station Log after the fact using the Driver Station Log Viewer. The log will identify brownouts with a bright orange line, such as in the image above (note that these brownouts were induced with a benchtop supply and may not reflect the duration and behavior of brownouts on a typical FRC robot).",
      "content_preview": "roboRIO Brownout and Understanding Current Draw In order to help maintain battery voltage to preserve itself and other control system components such as the radio during high current draw events, the roboRIO contains a staged brownout protection scheme."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/roborio-info/roborio-brownouts.html?present",
      "title": "roboRIO Brownout and Understanding Current Draw",
      "section": "General",
      "language": "All",
      "content": "roboRIO Brownout and Understanding Current Draw In order to help maintain battery voltage to preserve itself and other control system components such as the radio during high current draw events, the roboRIO contains a staged brownout protection scheme. This article describes this scheme, provides information about proactively planning for system current draw, and describes how to use the new functionality of the PDP as well as the DS Log File Viewer to understand brownout events if they do happen on your robot. roboRIO Brownout Protection The roboRIO uses a staged brownout protection scheme to attempt to preserve the input voltage to itself and other control system components in order to prevent device resets in the event of large current draws pulling the battery voltage dangerously low. Stage 1 - 6v output drop Voltage Trigger - 6.8V When the voltage drops below 6.8V, the 6V output on the PWM pins will start to drop. Stage 2 - Output Disable Voltage Trigger - 6.3V When the voltage drops below 6.3V, the controller will enter the brownout protection state. The following indicators will show that this condition has occurred: Power LED on the roboRIO will turn Amber Background of the voltage display on the Driver Station will turn red Mode display on the Driver Station will change to Voltage Brownout The CAN/Power tab of the DS will increment the 12V fault counter by 1. The DS will record a brownout event in the DS log. The controller will take the following steps to attempt to preserve the battery voltage: PWM outputs will be disabled. For PWM outputs which have set their neutral value (all motor controllers in WPILib) a single neutral pulse will be sent before the output is disabled. 6V, 5V, 3.3V User Rails disabled (This includes the 6V outputs on the PWM pins, the 5V pins in the DIO connector bank, the 5V pins in the Analog bank, the 3.3V pins in the SPI and I2C bank and the 5V and 3.3V pins in the MXP bank) GPIO configured as outputs go to High-Z Relay Outputs are disabled (driven low) CAN-based motor controllers are sent an explicit disable command Pneumatic Devices such as the CTRE Pneumatics Control Module and REV Pneumatic Hub are disabled The controller will remain in this state until the voltage rises to greater than 7.5V or drops below the trigger for the next stage of the brownout Stage 3 - Device Blackout Voltage Trigger - 4.5V Below 4.5V the device may blackout. The exact voltage may be lower than this and depends on the load on the device. The controller will remain in this state until the voltage rises above 4.65V when the device will begin the normal boot sequence. Avoiding Brownout - Proactive Current Draw Planning The key to avoiding a brownout condition is to proactively plan for the current draw of your robot. The best way to do this is to create some form of power budget. This can be a complex document that attempts to quantify both estimated current draw and time in an effort to most completely understand power usage and therefore battery state at the end of a match, or it can be a simple inventory of current usage. To do this: Establish the max “sustained” current draw (with sustained being loosely defined here as not momentary). This is probably the most difficult part of creating the power budget. The exact current draw a battery can sustain while maintaining a voltage of 7+ volts is dependent on a variety of factors such as battery health (see this article for measuring battery health) and state of charge. As shown in the NP18-12 data sheet , the terminal voltage chart gets very steep as state of charge decreases, especially as current draw increases. This datasheet shows that at 3CA continuous load (54A) a brand new battery can be continuously run for over 6 minutes while maintaining a terminal voltage of over 7V. As shown in the image above (used with permission from Team 234s Drive System Testing document ), even with a fresh battery, drawing 240A for more than a second or two is likely to cause an issue. This gives us some bounds on setting our sustained current draw. For the purposes of this exercise, we’ll set our limit at 180A. List out the different functions of your robot such as drivetrain, manipulator, main game mechanism, etc. Start assigning your available current to these functions. You will likely find that you run out pretty quickly. Many teams gear their drivetrain to have enough torque to slip their wheels at 40-50A of current draw per motor. If we have 4 motors on the drivetrain, that eats up most, or even exceeds, our power budget! This means that we may need to put together a few scenarios and understand what functions can (and need to be) be used at the same time. In many cases, this will mean that you really need to limit the current draw of the other functions if/while your robot is maxing out the drivetrain (such as trying to push something). Benchmarking the “driving” current requirements of a drivetrain for some of these alternative scenarios is a little more complex, as it depends on many factors such as number of motors, robot weight, gearing, and efficiency. Current numbers for other functions can be done by calculating the power required to complete the function and estimating efficiency (if the mechanism has not been designed) or by determining the torque load on the motor and using the torque-current curve to determine the current draw of the motors. If you have determined mutually exclusive functions in your analysis, consider enforcing the exclusion in software. You may also use the current monitoring of the PDP (covered in more detail below) in your robot program to provide output limits or exclusions dynamically (such as don’t run a mechanism motor when the drivetrain current is over X or only let the motor run up to half output when the drivetrain current is over Y). Settable Brownout The NI roboRIO 1.0 does not support custom brownout voltages. It is fixed at 6.3V as mentioned in Stage 2 above. The NI roboRIO 2.0 adds the option for a software settable brownout level. The default brownout level (Stage 2) of the roboRIO 2.0 is 6.75V. JAVA RobotController . setBrownoutVoltage ( 7.0 ); C++ frc :: RobotController :: SetBrownoutVoltage ( 7 _V ); Measuring Current Draw using the PDP/PDH The FRC® Driver Station works in conjunction with the roboRIO and PDP/PDH to extract logged data from the PDP/PDH and log it on your DS PC. A viewer for this data is still under development. In the meantime, teams can use their robot code and manual logging, a LabVIEW front panel or the SmartDashboard to visualize current draw on their robot as mechanisms are developed. In LabVIEW, you can read the current on a PDP/PDH channel using the Get PD Currents VI found on the Power pallet. For C++ and Java teams, use the PowerDistribution class as described in the Power Distribution article. Plotting this information over time (easiest with a LV Front Panel or with the SmartDashboard by using a Graph indicator can provide information to compare against and update your power budget or can locate mechanisms which do not seem to be performing as expected (due to incorrect load calculation, incorrect efficiency assumptions, or mechanism issues such as binding). Identifying Brownouts The easiest way to identify a brownout is by clicking on the CAN\\Power tab of the DS and checking the 12V fault count. Alternately, you can review the Driver Station Log after the fact using the Driver Station Log Viewer. The log will identify brownouts with a bright orange line, such as in the image above (note that these brownouts were induced with a benchtop supply and may not reflect the duration and behavior of brownouts on a typical FRC robot).",
      "content_preview": "roboRIO Brownout and Understanding Current Draw In order to help maintain battery voltage to preserve itself and other control system components such as the radio during high current draw events, the roboRIO contains a staged brownout protection scheme."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/roborio-info/index.html",
      "title": "roboRIO",
      "section": "General",
      "language": "All",
      "content": "roboRIO roboRIO Introduction Imaging your roboRIO 1 Imaging your roboRIO 2 roboRIO Web Dashboard roboRIO FTP roboRIO User Accounts and SSH roboRIO Brownout and Understanding Current Draw Recovering a roboRIO using Safe Mode Additional Help",
      "content_preview": "roboRIO roboRIO Introduction Imaging your roboRIO 1 Imaging your roboRIO 2 roboRIO Web Dashboard roboRIO FTP roboRIO User Accounts and SSH roboRIO Brownout and Understanding Current Draw Recovering a roboRIO using Safe Mode Additional Help"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/can-devices/power-distribution-module.html?present",
      "title": "Power Distribution Module",
      "section": "CAN Devices",
      "language": "All",
      "content": "Power Distribution Module The CTRE Power Distribution Panel ( PDP ) and Rev Power Distribution Hub ( PDH ) can use their CAN connectivity to communicate a wealth of status information regarding the robot’s power use to the roboRIO, for use in user code. This has the capability to report current temperature, the bus voltage, the total robot current draw, the total robot energy use, and the individual current draw of each device power channel. This data can be used for a number of advanced control techniques, such as motor torque limiting and brownout avoidance. Creating a Power Distribution Object To use the either Power Distribution module, create an instance of the PowerDistribution class ( Java , C++ , Python ). With no arguments, the Power Distribution object will be detected, and must use CAN ID of 0 for CTRE or 1 for REV. If the CAN ID is non-default, additional constructors are available to specify the CAN ID and type. JAVA PowerDistribution examplePD = new PowerDistribution (); PowerDistribution examplePD = new PowerDistribution ( 0 , ModuleType . kCTRE ); PowerDistribution examplePD = new PowerDistribution ( 1 , ModuleType . kRev ); C++ PowerDistribution examplePD {}; PowerDistribution examplePD { 0 , frc :: PowerDistribution :: ModuleType :: kCTRE }; PowerDistribution examplePD { 1 , frc :: PowerDistribution :: ModuleType :: kRev }; PYTHON from wpilib import PowerDistribution examplePD = PowerDistribution () examplePD = PowerDistribution ( 0 , PowerDistribution . ModuleType . kCTRE ) examplePD = PowerDistribution ( 1 , PowerDistribution . ModuleType . kRev ) Note: it is not necessary to create a PowerDistribution object unless you need to read values from it. The board will work and supply power on all the channels even if the object is never created. Reading the Bus Voltage JAVA // Get the voltage going into the PDP, in Volts. // The PDP returns the voltage in increments of 0.05 Volts. double voltage = m_pdp . getVoltage (); SmartDashboard . putNumber ( \"Voltage\" , voltage ); C++ // Get the voltage going into the PDP, in Volts. // The PDP returns the voltage in increments of 0.05 Volts. double voltage = m_pdp . GetVoltage (); frc :: SmartDashboard :: PutNumber ( \"Voltage\" , voltage ); PYTHON # Get the voltage going into the PDP, in Volts. # The PDP returns the voltage in increments of 0.05 Volts. voltage = self . pdp . getVoltage () wpilib . SmartDashboard . putNumber ( \"Voltage\" , voltage ) Monitoring the bus voltage can be useful for (among other things) detecting when the robot is near a brownout, so that action can be taken to avoid brownout in a controlled manner. See the roboRIO Brownouts document for more information. Reading the Temperature JAVA // Retrieves the temperature of the PDP, in degrees Celsius. double temperatureCelsius = m_pdp . getTemperature (); SmartDashboard . putNumber ( \"Temperature\" , temperatureCelsius ); C++ // Retrieves the temperature of the PDP, in degrees Celsius. double temperatureCelsius = m_pdp . GetTemperature (); frc :: SmartDashboard :: PutNumber ( \"Temperature\" , temperatureCelsius ); PYTHON # Retrieves the temperature of the PDP, in degrees Celsius. temperatureCelsius = self . pdp . getTemperature () wpilib . SmartDashboard . putNumber ( \"Temperature\" , temperatureCelsius ) Monitoring the temperature can be useful for detecting if the robot has been drawing too much power and needs to be shut down for a while, or if there is a short or other wiring problem. Reading the Total Current, Power, and Energy JAVA // Get the total current of all channels. double totalCurrent = m_pdp . getTotalCurrent (); SmartDashboard . putNumber ( \"Total Current\" , totalCurrent ); // Get the total power of all channels. // Power is the bus voltage multiplied by the current with the units Watts. double totalPower = m_pdp . getTotalPower (); SmartDashboard . putNumber ( \"Total Power\" , totalPower ); // Get the total energy of all channels. // Energy is the power summed over time with units Joules. double totalEnergy = m_pdp . getTotalEnergy (); SmartDashboard . putNumber ( \"Total Energy\" , totalEnergy ); C++ // Get the total current of all channels. double totalCurrent = m_pdp . GetTotalCurrent (); frc :: SmartDashboard :: PutNumber ( \"Total Current\" , totalCurrent ); // Get the total power of all channels. // Power is the bus voltage multiplied by the current with the units Watts. double totalPower = m_pdp . GetTotalPower (); frc :: SmartDashboard :: PutNumber ( \"Total Power\" , totalPower ); // Get the total energy of all channels. // Energy is the power summed over time with units Joules. double totalEnergy = m_pdp . GetTotalEnergy (); frc :: SmartDashboard :: PutNumber ( \"Total Energy\" , totalEnergy ); PYTHON # Get the total current of all channels. totalCurrent = self . pdp . getTotalCurrent () wpilib . SmartDashboard . putNumber ( \"Total Current\" , totalCurrent ) # Get the total power of all channels. # Power is the bus voltage multiplied by the current with the units Watts. totalPower = self . pdp . getTotalPower () wpilib . SmartDashboard . putNumber ( \"Total Power\" , totalPower ) # Get the total energy of all channels. # Energy is the power summed over time with units Joules. totalEnergy = self . pdp . getTotalEnergy () wpilib . SmartDashboard . putNumber ( \"Total Energy\" , totalEnergy ) Monitoring the total current, power, and energy can be useful for controlling how much power is being drawn from the battery, both for preventing brownouts and ensuring that mechanisms have sufficient power available to perform the actions required. Power is the bus voltage multiplied by the current with the units Watts. Energy is the power summed over time with units Joules. Reading Individual Channel Currents The PDP/PDH also allows users to monitor the current drawn by the individual device power channels. You can read the current on any of the 16 PDP channels (0-15) or 24 PDH channels (0-23). JAVA // Get the current going through channel 7, in Amperes. // The PDP returns the current in increments of 0.125A. // At low currents the current readings tend to be less accurate. double current7 = m_pdp . getCurrent ( 7 ); SmartDashboard . putNumber ( \"Current Channel 7\" , current7 ); C++ // Get the current going through channel 7, in Amperes. // The PDP returns the current in increments of 0.125A. // At low currents the current readings tend to be less accurate. double current7 = m_pdp . GetCurrent ( 7 ); frc :: SmartDashboard :: PutNumber ( \"Current Channel 7\" , current7 ); PYTHON # Get the current going through channel 7, in Amperes. # The PDP returns the current in increments of 0.125A. # At low currents the current readings tend to be less accurate. current7 = self . pdp . getCurrent ( 7 ) wpilib . SmartDashboard . putNumber ( \"Current Channel 7\" , current7 ) Monitoring individual device current draws can be useful for detecting shorts or stalled motors. Using the Switchable Channel (PDH) The REV PDH has one channel that can be switched on or off to control custom circuits. JAVA examplePD . setSwitchableChannel ( true ); examplePD . setSwitchableChannel ( false ); C++ examplePD . SetSwitchableChannel ( true ); examplePD . SetSwitchableChannel ( false ); PYTHON examplePD . setSwitchableChannel ( True ) examplePD . setSwitchableChannel ( False )",
      "content_preview": "Power Distribution Module The CTRE Power Distribution Panel ( PDP ) and Rev Power Distribution Hub ( PDH ) can use their CAN connectivity to communicate a wealth of status information regarding the robot’s power use to the roboRIO, for use in user code."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/index.html",
      "title": "Vision Processing",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision Processing Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image Morphological Operations Working with Contours Basic Vision Example AprilTag Introduction What Are AprilTags? Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface",
      "content_preview": "Vision Processing Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples Vision with WPILibPi A Video Walkthrough of using WPILibPi with the..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/the-raspberry-pi-frc-console.html",
      "title": "The Raspberry PI",
      "section": "Vision Processing",
      "language": "All",
      "content": "The Raspberry PI FRC Console The FRC® image for the Raspberry PI includes a console that can be viewed in any web browser that makes it easy to: Look at the Raspberry PI status View the status of the background process running the camera View or change network settings Look at each camera plugged into the rPI and add additional cameras Load a new vision program onto the rPI Setting the rPI to be Read-Only vs. Writable The rPI is normally set to Read-Only which means that the file system cannot be changed. This ensures that if power is removed without first shutting down the rPi the file system isn’t corrupted. When settings are changed (following sections), the new settings cannot be saved while the rPI file system is set as Read-Only. Buttons are provided that allow the file system to be changed from Read-Only to Writable and back whenever changes are made. If the other buttons that change information stored on the rPI cannot be press, check the Read-Only status of the system. Status of the network connection to the rPI There is a label in the top right corner of the console that indicates if the rPi is currently connected. It will change from Connected to Disconnected if there is no longer a network connection to the rPi. System status The system status shows what the CPU on the rPI is doing at any time. There are two columns of status values, on being a 1 second average and the other a 5 second average. Shown is: Free and available RAM on the PI CPU usage for user processes and system processes as well as idle time Network bandwidth - which allows one to determine if the used camera bandwidth is exceeding the maximum bandwidth allowed in the robot rules for any year Vision Status Allows monitoring of the task which is running the camera code in the rPI, either one of the default programs or your own program in Java, C++, or Python. You can also enable and view the console output to see messages coming from the background camera service. In this case there are number of messages about being unable to connect to NetworkTables (NT: connect()) because in this example the rPI is simply connected to a laptop with no NetworkTables server running (usually the roboRIO.) Network Settings The rPI network settings have options to connect to the PI: DHCP - the default name resolution usually used by the roboRIO. The default name is wpilibpi.local. Static - where a fixed IP address, network mask, and router settings are filled in explicitly DHCP with Static Fallback - DHCP with Static Fallback - the PI will try to get an IP address via DHCP, but if it can’t find a DHCP server, it will use the provided static IP address and parameters The picture above is showing the settings for both DHCP and Static IP Addressing. The mDNS name for the rPi should always work regardless of the options selected above. Vision Settings The Vision Settings are to set the parameters for each camera and whether the rPI should be a NetworkTables client or server. There can only be one server on the network and the roboRIO is always a server. Therefore when connected to a roboRIO, the rPI should always be in client mode with the team number filled in. If testing on a desktop setup with no roboRIO or anything acting as a server then it should be set to Server (Client switch is off). To view and manipulate all the camera settings click on the camera in question. In this case the camera is called “Camera rPi Camera 0” and clicking on the name reveals the current camera view and the associated settings. Manipulating the camera settings is reflected in the current camera view. The bottom of the page shows all the possible camera modes (combinations of Width, Height, and frame rates) that are supported by this camera. Note If the camera image is not visible on the Open Stream screen then check the supported video modes at the bottom of the page. Then go back to ‘Vision Settings’ and click on the camera in question and verify that the pixel format, width, height, and FPS are listed in the supported video modes. Getting the current settings to persist over reboots The rPi will load all the camera settings on startup. Editing the camera configuration in the above screen is temporary. To make the values persist click on the “Load Source Config From Camera” button and the current settings will be filled in on the camera settings fields. Then click “Save” at the bottom of the page. Note: you must set the file system Writeable in order to save the settings. The Writeable button is at the top of the page. There are some commonly used camera settings values shown in the camera settings (above). These values Brightness, White Balance, and Exposure are loaded into the camera before the user JSON file is applied. So if a user JSON file contains those settings they will overwrite the ones from the text field. Application The Application tab shows the application that is currently running on the rPi. Vision workflows There is a sample vision program using OpenCV in each of the supported languages, C++, Java, or Python. Each sample program can capture and stream video from the rPi. In addition, the samples have some minimal OpenCV. They are all set up to be extended to replace the provided OpenCV sample code with the code needed for the robot application. The rPi Application tab supports a number of programming workflows: Stream one or more cameras from the rPi for consumption on the driver station computer and displayed using ShuffleBoard Edit and build one of the sample programs (one for each language: Java, C++ or Python) on the rPi using the included toolchains Download a sample program for the chosen language and edit and build it on your development computer. Then upload that built program back to the rPi Do everything yourself using completely custom applications and scripts (probably based on one of the samples) The running application can be changed by selecting one of the choices in the drop-down menu. The choices are: Built-in multi camera streaming which streams whatever cameras are plugged into the rPi. The camera configuration including number of cameras can be set on the “Vision Settings” tab. Custom application which doesn’t upload anything to the rPi and assumes that the developer wants to have a custom program and script. Java, C++ or Python pre-installed sample programs that can be edited into your own application. Java, C++, or Python uploaded program. Java programs require a .jar file with the compiled program and C++ programs require an rPi executable to be uploaded to the rPI. When selecting one of the Upload options, a file chooser is presented where the jar, executable, or Python program can be selected and uploaded to the rPi. In the following picture an Uploaded Java jar is chosen and the “Choose File” button will select a file and clicking on the “Save” button will upload the selected file. Note: in order to Save a new file onto the rPi, the file system has to be set writeable using the “Writable” button at the top left of the web page. After saving the new file, set the file system back to “Read-Only” so that it is protected against accidental changes.",
      "content_preview": "The Raspberry PI FRC Console The FRC® image for the Raspberry PI includes a console that can be viewed in any web browser that makes it easy to: Look at the Raspberry PI status View the status of the background process running the camera View or change network settings Look at each camera plugged..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/index.html",
      "title": "Vision with WPILibPi",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image Morphological Operations Working with Contours Basic Vision Example",
      "content_preview": "Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/morphological-operations.html",
      "title": "Morphological Operations",
      "section": "Vision Processing",
      "language": "All",
      "content": "Morphological Operations Sometimes, after thresholding your image, you have unwanted noise in your binary image. Morphological operations can help remove that noise from the image. Kernel The kernel is a simple shape where the origin is superimposed on each pixel of value 1 of the binary image. OpenCV limits the kernel to a NxN matrix where N is an odd number. The origin of the kernel is the center. A common kernel is \\[\\begin{split}kernel = \\begin{pmatrix} 1 & 1 & 1\\\\ 1 & 1 & 1\\\\ 1 & 1 & 1 \\end{pmatrix}\\end{split}\\] Different kernels can affect the image differently, such as only eroding or dilating vertically. For reference, this is our binary image we created: Erosion Erosion in computer vision is similar to erosion on soil. It takes away from the borders of foreground objects. This process can remove noise from the background. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . erode ( binary_img , kernel , iterations = 1 ) During erosion, if the superimposed kernel’s pixels are not contained completely by the binary image’s pixels, the pixel that it was superimposed on is deleted. Dilation Dilation is opposite of erosion. Instead of taking away from the borders, it adds to them. This process can remove small holes inside a larger region. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . dilate ( binary_img , kernel , iterations = 1 ) During dilation, every pixel of every superimposed kernel is included in the dilation. Opening Opening is erosion followed by dilation. This process removes noise without affecting the shape of larger features. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . morphologyEx ( binary_img , cv2 . MORPH_OPEN , kernel ) Note In this specific case, it is appropriate to do more iterations of opening in order to get rid of the pixels in the top right. Closing Closing is dilation followed by erosion. This process removes small holes or breaks without affecting the shape of larger features. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . morphologyEx ( binary_img , cv2 . MORPH_CLOSE , kernel )",
      "content_preview": "Morphological Operations Sometimes, after thresholding your image, you have unwanted noise in your binary image. Morphological operations can help remove that noise from the image. Kernel The kernel is a simple shape where the origin is superimposed on each pixel of value 1 of the binary image."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/morphological-operations.html?present",
      "title": "Morphological Operations",
      "section": "Vision Processing",
      "language": "All",
      "content": "Morphological Operations Sometimes, after thresholding your image, you have unwanted noise in your binary image. Morphological operations can help remove that noise from the image. Kernel The kernel is a simple shape where the origin is superimposed on each pixel of value 1 of the binary image. OpenCV limits the kernel to a NxN matrix where N is an odd number. The origin of the kernel is the center. A common kernel is \\[\\begin{split}kernel = \\begin{pmatrix} 1 & 1 & 1\\\\ 1 & 1 & 1\\\\ 1 & 1 & 1 \\end{pmatrix}\\end{split}\\] Different kernels can affect the image differently, such as only eroding or dilating vertically. For reference, this is our binary image we created: Erosion Erosion in computer vision is similar to erosion on soil. It takes away from the borders of foreground objects. This process can remove noise from the background. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . erode ( binary_img , kernel , iterations = 1 ) During erosion, if the superimposed kernel’s pixels are not contained completely by the binary image’s pixels, the pixel that it was superimposed on is deleted. Dilation Dilation is opposite of erosion. Instead of taking away from the borders, it adds to them. This process can remove small holes inside a larger region. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . dilate ( binary_img , kernel , iterations = 1 ) During dilation, every pixel of every superimposed kernel is included in the dilation. Opening Opening is erosion followed by dilation. This process removes noise without affecting the shape of larger features. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . morphologyEx ( binary_img , cv2 . MORPH_OPEN , kernel ) Note In this specific case, it is appropriate to do more iterations of opening in order to get rid of the pixels in the top right. Closing Closing is dilation followed by erosion. This process removes small holes or breaks without affecting the shape of larger features. PY kernel = np . ones (( 3 , 3 ), np . uint8 ) binary_img = cv2 . morphologyEx ( binary_img , cv2 . MORPH_CLOSE , kernel )",
      "content_preview": "Morphological Operations Sometimes, after thresholding your image, you have unwanted noise in your binary image. Morphological operations can help remove that noise from the image. Kernel The kernel is a simple shape where the origin is superimposed on each pixel of value 1 of the binary image."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/image-thresholding.html",
      "title": "Thresholding an Image",
      "section": "Vision Processing",
      "language": "All",
      "content": "Thresholding an Image In order to turn a colored image, such as the one captured by your camera, into a binary image, with the target as the “foreground”, we need to threshold the image using the hue, saturation, and value of each pixel. The HSV Model Unlike RGB, HSV allows you to not only filter based on the colors of the pixels, but also by the intensity of color and the brightness. Hue: Measures the color of the pixel. Saturation: Measures the intensity of color of the pixel. Value: Measures the brightness of the pixel. You can use OpenCV to convert a BGR image matrix to HSV. PY hsv_img = cv2 . cvtColor ( input_img , cv2 . COLOR_BGR2HSV ) Note OpenCV’s hue range is from 1° to 180° instead of the common 1° to 360°. In order to convert a common hue value to OpenCV, divide by 2. Thresholding We will use this field image as an example for the whole process of image processing. By thresholding the image using HSV, you can separate the image into the vision target (foreground), and the other things that the camera sees (background). The following code example converts a HSV image into a binary image by thresholding with HSV values. PY binary_img = cv2 . inRange ( hsv_img , ( min_hue , min_sat , min_val ), ( max_hue , max_sat , max_val )) Note These values may have to be tuned on an per-venue basis, as ambient lighting may differ across venues. It is recommended to allow editing of these values through NetworkTables in order to facilitate on-the-fly editing. After thresholding, your image should look like this. As you can see, the thresholding process may not be 100% clean. You can use morphological operations to deal with the noise.",
      "content_preview": "Thresholding an Image In order to turn a colored image, such as the one captured by your camera, into a binary image, with the target as the “foreground”, we need to threshold the image using the hue, saturation, and value of each pixel."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/image-thresholding.html?present",
      "title": "Thresholding an Image",
      "section": "Vision Processing",
      "language": "All",
      "content": "Thresholding an Image In order to turn a colored image, such as the one captured by your camera, into a binary image, with the target as the “foreground”, we need to threshold the image using the hue, saturation, and value of each pixel. The HSV Model Unlike RGB, HSV allows you to not only filter based on the colors of the pixels, but also by the intensity of color and the brightness. Hue: Measures the color of the pixel. Saturation: Measures the intensity of color of the pixel. Value: Measures the brightness of the pixel. You can use OpenCV to convert a BGR image matrix to HSV. PY hsv_img = cv2 . cvtColor ( input_img , cv2 . COLOR_BGR2HSV ) Note OpenCV’s hue range is from 1° to 180° instead of the common 1° to 360°. In order to convert a common hue value to OpenCV, divide by 2. Thresholding We will use this field image as an example for the whole process of image processing. By thresholding the image using HSV, you can separate the image into the vision target (foreground), and the other things that the camera sees (background). The following code example converts a HSV image into a binary image by thresholding with HSV values. PY binary_img = cv2 . inRange ( hsv_img , ( min_hue , min_sat , min_val ), ( max_hue , max_sat , max_val )) Note These values may have to be tuned on an per-venue basis, as ambient lighting may differ across venues. It is recommended to allow editing of these values through NetworkTables in order to facilitate on-the-fly editing. After thresholding, your image should look like this. As you can see, the thresholding process may not be 100% clean. You can use morphological operations to deal with the noise.",
      "content_preview": "Thresholding an Image In order to turn a colored image, such as the one captured by your camera, into a binary image, with the target as the “foreground”, we need to threshold the image using the hue, saturation, and value of each pixel."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/working-with-contours.html",
      "title": "Working with Contours",
      "section": "Vision Processing",
      "language": "All",
      "content": "Working with Contours After thresholding and removing noise with morphological operations, you are now ready to use OpenCV’s findContours method. This method allows you to generate contours based on your binary image. Finding and Filtering Contours PY _ , contours , _ = cv2 . findContours ( binary_img , cv2 . RETR_EXTERNAL , cv2 . CHAIN_APPROX_SIMPLE ) In cases where there is only one vision target, you can just take the largest contour and assume that is the target you are looking for. When there is more than one vision target, you can use size, shape, fullness, and other properties to filter unwanted contours out. PY if len ( contours ) > 0 : largest = contours [ 0 ] for contour in contours : if cv2 . contourArea ( contour ) > cv2 . contourArea ( largest ): largest = contour # # Contour processing code # If you draw the contour you just found, it should look something like this: Extracting Information from Contours Now that you’ve found the contour(s) that you want, you now want to get information about it, such as the center, corners, and rotation. Center PY rect = cv2 . minAreaRect ( contour ) center , _ , _ = rect center_x , center_y = center Corners PY corners = cv2 . convexHull ( contour ) corners = cv2 . approxPolyDP ( corners , 0.1 * cv2 . arcLength ( contour ), True ) Rotation PY _ , _ , rotation = cv2 . fitEllipse ( contour ) For more information on how you can use these values, see Measurements Publishing to NetworkTables You can use NetworkTables to send these properties to the Driver Station and the RoboRIO. Additional processing could be done on the Raspberry Pi, or the RoboRIO itself. PY import ntcore nt = ntcore . NetworkTableInstance . getDefault () . getTable ( 'vision' ) # # Initialization code here # while True : # # Image processing code here # nt . putNumber ( 'center_x' , center_x ) nt . putNumber ( 'center_y' , center_y )",
      "content_preview": "Working with Contours After thresholding and removing noise with morphological operations, you are now ready to use OpenCV’s findContours method. This method allows you to generate contours based on your binary image. Finding and Filtering Contours PY _ , contours , _ = cv2 ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/working-with-contours.html?present",
      "title": "Working with Contours",
      "section": "Vision Processing",
      "language": "All",
      "content": "Working with Contours After thresholding and removing noise with morphological operations, you are now ready to use OpenCV’s findContours method. This method allows you to generate contours based on your binary image. Finding and Filtering Contours PY _ , contours , _ = cv2 . findContours ( binary_img , cv2 . RETR_EXTERNAL , cv2 . CHAIN_APPROX_SIMPLE ) In cases where there is only one vision target, you can just take the largest contour and assume that is the target you are looking for. When there is more than one vision target, you can use size, shape, fullness, and other properties to filter unwanted contours out. PY if len ( contours ) > 0 : largest = contours [ 0 ] for contour in contours : if cv2 . contourArea ( contour ) > cv2 . contourArea ( largest ): largest = contour # # Contour processing code # If you draw the contour you just found, it should look something like this: Extracting Information from Contours Now that you’ve found the contour(s) that you want, you now want to get information about it, such as the center, corners, and rotation. Center PY rect = cv2 . minAreaRect ( contour ) center , _ , _ = rect center_x , center_y = center Corners PY corners = cv2 . convexHull ( contour ) corners = cv2 . approxPolyDP ( corners , 0.1 * cv2 . arcLength ( contour ), True ) Rotation PY _ , _ , rotation = cv2 . fitEllipse ( contour ) For more information on how you can use these values, see Measurements Publishing to NetworkTables You can use NetworkTables to send these properties to the Driver Station and the RoboRIO. Additional processing could be done on the Raspberry Pi, or the RoboRIO itself. PY import ntcore nt = ntcore . NetworkTableInstance . getDefault () . getTable ( 'vision' ) # # Initialization code here # while True : # # Image processing code here # nt . putNumber ( 'center_x' , center_x ) nt . putNumber ( 'center_y' , center_y )",
      "content_preview": "Working with Contours After thresholding and removing noise with morphological operations, you are now ready to use OpenCV’s findContours method. This method allows you to generate contours based on your binary image. Finding and Filtering Contours PY _ , contours , _ = cv2 ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/identifying-and-processing-the-targets.html",
      "title": "Identifying and Processing the Targets",
      "section": "Vision Processing",
      "language": "All",
      "content": "Identifying and Processing the Targets Once an image is captured, the next step is to identify Vision Target(s) in the image. This document will walk through one approach to identifying the 2016 targets. Note that the images used in this section were taken with the camera intentionally set to underexpose the images, producing very dark images with the exception of the lit targets, see the section on Camera Settings for details. Original Image The image shown below is the starting image for the example described here. The image was taken using the green ring light available in FIRST ® Choice combined with an additional ring light of a different size. Additional sample images are provided with the vision code examples. What is HSL/HSV? The Hue or tone of the color is commonly seen on the artist’s color wheel and contains the colors of the rainbow Red, Orange, Yellow, Green, Blue, Indigo, and Violet. The hue is specified using a radial angle on the wheel, but in imaging the circle typically contains only 256 units, starting with red at zero, cycling through the rainbow, and wrapping back to red at the upper end. Saturation of a color specifies amount of color, or the ratio of the hue color to a shade of gray. Higher ratio means more colorful, less gray. Zero saturation has no hue and is completely gray. Luminance or Value indicates the shade of gray that the hue is blended with. Black is 0 and white is 255. The example code uses the HSV color space to specify the color of the target. The primary reason is that it readily allows for using the brightness of the targets relative to the rest of the image as a filtering criteria by using the Value (HSV) or Luminance (HSL) component. Another reason to use the HSV color system is that the thresholding operation used in the example runs more efficiently on the roboRIO when done in the HSV color space. Masking In this initial step, pixel values are compared to constant color or brightness values to create a binary mask shown below in yellow. This single step eliminates most of the pixels that are not part of a target’s retro-reflective tape. Color based masking works well provided the color is relatively saturated, bright, and consistent. Color inequalities are generally more accurate when specified using the HSL (Hue, Saturation, and Luminance) or HSV (Hue, Saturation, and Value) color space than the RGB (Red, Green, and Blue) space. This is especially true when the color range is quite large in one or more dimension. Notice that in addition to the target, other bright parts of the image (overhead light and tower lighting) are also caught by the masking step. Particle Analysis After the masking operation, a particle report operation is used to examine the area, bounding rectangle, and equivalent rectangle for the particles. These are used to compute several scored terms to help pick the shapes that are most rectangular. Each test described below generates a score (0-100) which is then compared to pre-defined score limits to decide if the particle is a target or not. Coverage Area The Area score is calculated by comparing the area of the particle compared to the area of the bounding box drawn around the particle. The area of the retroreflective strips is 80 square inches (~516 \\(cm^2\\) ). The area of the rectangle that contains the target is 240 square inches (~0.15 \\(m^2\\) ). This means that the ideal ratio between area and bounding box area is 1/3. Area ratios close to 1/3 will produce a score near 100, as the ratio diverges from 1/3 the score will approach 0. Aspect Ratio The aspect ratio score is based on (Particle Width / Particle Height). The width and height of the particle are determined using something called the “equivalent rectangle”. The equivalent rectangle is the rectangle with side lengths \\(x\\) and \\(y\\) where \\(2x+2y\\) equals the particle perimeter and \\(x \\cdot y\\) equals the particle area. The equivalent rectangle is used for the aspect ratio calculation as it is less affected by skewing of the rectangle than using the bounding box. When using the bounding box rectangle for aspect ratio, as the rectangle is skewed the height increases and the width decreases. The target is 20” (508 mm) wide by 12” (304.8 mm) tall, for a ratio of 1.6. The detected aspect ratio is compared to this ideal ratio. The aspect ratio score is normalized to return 100 when the ratio matches the target ratio and drops linearly as the ratio varies below or above. Moment The “moment” measurement calculates how spread out each pixel is from the center of the blob. This measurement provides a representation of the pixel distribution in the particle. It can be thought of as analogous to a physics moment of inertia calculation. The ideal score for this test is ~0.28. X/Y Profiles The edge score describes whether the particle matches the appropriate profile in both the X and Y directions. As shown, it is calculated using the row and column averages across the bounding box extracted from the original image and comparing that to a profile mask. The score ranges from 0 to 100 based on the number of values within the row or column averages that are between the upper and lower limit values. Measurements If a particle scores well enough to be considered a target, it makes sense to calculate some real-world measurements such as position and distance. The example code includes these basic measurements, so let’s look at the math involved to better understand it. Position The target position is well described by both the particle and the bounding box, but all coordinates are in pixels with 0,0 being at the top left of the screen and the right and bottom edges determined by the camera resolution. This is a useful system for pixel math, but not nearly as useful for driving a robot; so let’s change it to something that may be more useful. To convert a point from the pixel system to the aiming system, we can use the formula shown below. The resulting coordinates are close to what you may want, but the Y axis is inverted. This could be corrected by multiplying the point by [1,-1] (Note: this is not done in the sample code). This coordinate system is useful because it has a centered origin and the scale is similar to joystick outputs and Drive inputs. \\[A_{x,y} = \\left(P_{x,y} - \\frac{\\textit{resolution}_{x,y}}{2}\\right) / \\frac{\\textit{resolution}_{x,y}}{2}\\] Field of View You can use known constants and the position of the target on the coordinate plane to determine your distance, yaw, and pitch from the target. However, in order to calculate these, you must determine your FOV (field of view). In order to empirically determine vertical field of view, set your camera a set distance away from an flat surface, and measure the distance between the topmost and bottommost row of pixels. \\[\\frac{1}{2}FOV_{vertical}=tan\\left(\\frac{\\frac{1}{2}distance_{y}}{distance_{z}}\\right)\\] You can find the horizontal FOV using the same method, but using the distance between the first and last column of pixels. Pitch and Yaw Finding the pitch and yaw of the target relative to your robot is simple once you know your FOVs and the location of your target in the aiming coordinate system. \\[pitch=\\frac{A_y}{2}FOV_{vertical}\\] \\[yaw=\\frac{A_x}{2}FOV_{horizontal}\\] Distance If your target is at a significantly different height than your robot, you can use known constants, such as the physical height of the target and your camera, as well as the angle your camera is mounted, to calculate the distance between your camera and the target. \\[distance=\\frac{height_{target}-height_{camera}}{tan(angle_{camera}+pitch)}\\] Another option is to create a lookup table for area to distance, or to estimate the inverse variation constant of area and distance. However, this method is less accurate. Note For best results for the above methods of estimating angle and distance, you can calibrate your camera using OpenCV to get rid of any distortions that may be affecting accuracy by reprojecting the pixels of the target using the calibration matrix.",
      "content_preview": "Identifying and Processing the Targets Once an image is captured, the next step is to identify Vision Target(s) in the image. This document will walk through one approach to identifying the 2016 targets."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/index.html?present",
      "title": "Vision with WPILibPi",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image Morphological Operations Working with Contours Basic Vision Example",
      "content_preview": "Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/using-the-raspberry-pi-for-frc.html",
      "title": "Using the Raspberry Pi for FRC",
      "section": "Vision Processing",
      "language": "All",
      "content": "Using the Raspberry Pi for FRC One of the most popular coprocessor choices is the Raspberry Pi because: Low cost - around $35 High availability - it’s easy to find Raspberry Pis from a number of suppliers, including Amazon Very good performance - the current Raspberry Pi 3b+ has the following specifications: Technical Specifications: - Broadcom BCM2837BO 64 bit ARMv8 QUAD Core A53 64bit Processor powered Single Board Computer run at 1.4GHz - 1GB RAM - BCM43143 WiFi on board - Bluetooth Low Energy (BLE) on board - 40 pin extended GPIO - 4 x USB2 ports - 4 pole Stereo output and Composite video port - Full size HDMI - CSI camera port for connecting the Raspberry - Pi camera - DSI display port for connecting the Raspberry - Pi touch screen display - MicroSD port for loading your operating system and storing data - Upgraded switched Micro USB power source (now supports up to 2.5 Amps. Pre-built Raspberry Pi image To make using the Raspberry Pi as easy as possible for teams, there is a provided Raspberry Pi image. The image can be copied to a micro SD card, inserted into the Pi, and booted. By default it supports: A web interface for configuring it for the most common functions Supports an arbitrary number camera streams (defaults to one) that are published on the network interface OpenCV, NetworkTables , Camera Server, and language libraries for C++, Java, and Python custom programs If the only requirement is to stream one or more cameras to the network (and dashboard) then no programming is required and can be completely set up through the web interface. The next section discusses how to install the image onto a flash card and boot the Pi.",
      "content_preview": "Using the Raspberry Pi for FRC One of the most popular coprocessor choices is the Raspberry Pi because: Low cost - around $35 High availability - it’s easy to find Raspberry Pis from a number of suppliers, including Amazon Very good performance - the current Raspberry Pi 3b+ has the following..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/using-cameraserver.html",
      "title": "Using CameraServer",
      "section": "Vision Processing",
      "language": "All",
      "content": "Using CameraServer Grabbing Frames from CameraServer The WPILibPi image comes with all the necessary libraries to make your own vision processing system. In order to get the current frame from the camera, you can use the CameraServer library. For information about CameraServer, the Read and Process Video: CameraServer Class . PY from cscore import CameraServer import cv2 import numpy as np CameraServer . enableLogging () camera = CameraServer . startAutomaticCapture () camera . setResolution ( width , height ) sink = CameraServer . getVideo () input_img = np . zeros ( shape = ( height , width , 3 ), dtype = np . uint8 ) while True : time , input_img = sink . grabFrame ( input_img ) if time == 0 : # There is an error continue Note OpenCV reads in the image as BGR , not RGB for historical reasons. Use cv2.cvtColor if you want to change it to RGB. Below is an example of an image that might be grabbed from CameraServer. Sending frames to CameraServer Sometimes, you may want to send processed video frames back to the CameraServer instance for debugging purposes, or viewing in a dashboard application like Shuffleboard. PY # # CameraServer initialization code here # output = CameraServer . putVideo ( \"Name\" , width , height ) input_img = np . zeros ( shape = ( height , width , 3 ), dtype = np . uint8 ) while True : time , input_img = sink . grabFrame ( input_img ) if time == 0 : # There is an error output . notifyError ( sink . getError ()) continue # # Insert processing code here # output . putFrame ( processed_img ) As an example, the processing code could outline the target in red, and show the corners in yellow for debugging purposes. Below is an example of a fully processed image that would be sent back to CameraServer and displayed on the Driver Station computer.",
      "content_preview": "Using CameraServer Grabbing Frames from CameraServer The WPILibPi image comes with all the necessary libraries to make your own vision processing system. In order to get the current frame from the camera, you can use the CameraServer library."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/what-you-need-to-get-the-pi-image-running.html",
      "title": "What you need to get the Pi image running",
      "section": "Vision Processing",
      "language": "All",
      "content": "What you need to get the Pi image running To start using the Raspberry Pi as a video or image coprocessor you need the following: A Raspberry Pi 3 B, Raspberry Pi 3 B+, or a Raspberry Pi 4 B A micro SD card that is at least 8 GB to hold all the provided software, with a recommended Speed Class of 10 (10MB/s) An ethernet cable to connect the Pi to your roboRIO network A USB micro power cable to connect to the Voltage Regulator Module (VRM) on your robot. It is recommended to use the VRM connection for power rather than powering it from one of the roboRIO USB ports for higher reliability A laptop that can write the MicroSD card, either using a USB dongle (preferred) or a SD to MicroSD adapter that ships with most MicroSD cards Shown is an inexpensive USB dongle that will write the FRC® image to the MicroSD card.",
      "content_preview": "What you need to get the Pi image running To start using the Raspberry Pi as a video or image coprocessor you need the following: A Raspberry Pi 3 B, Raspberry Pi 3 B+, or a Raspberry Pi 4 B A micro SD card that is at least 8 GB to hold all the provided software, with a recommended Speed Class of..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/installing-the-image-to-your-microsd-card.html",
      "title": "Installing the image to your MicroSD card",
      "section": "Vision Processing",
      "language": "All",
      "content": "Installing the image to your MicroSD card Getting the FRC Raspberry PI image The image is stored on the GitHub release page for the WPILibPi repository . In addition to the instructions on this page, see the documentation on the GitHub web page (below). The image is fairly large so have a fast internet connection when downloading it. Always use the most recent release from the top of the list of releases. Copy the image to your MicroSD card Download and install Etcher to image the micro SD card. The micro SD card needs to be at least 8 GB. A micro SD to USB dongle works well for writing to micro SD cards. Flash the MicroSD card with the image using Etcher by selecting the zip file as the source, your SD card as the destination and click “Flash”. Expect the process to take about 3 minutes on a fairly fast laptop. Testing the Raspberry PI Put the micro SD card in a rPi 3 and apply power. Connect the rPi 3 ethernet to a LAN or PC. Open a web browser and connect to http://wpilibpi.local/ to open the web dashboard. On the first bootup the filesystem will be writable, but later bootups will default to read only, so it’s necessary to click the “writable” button to make changes. Logging into the Raspberry PI Most tasks with the rPi can be done from the web console interface. Sometimes for advanced use such as program development on the rPi it is necessary to log in. To log in, use the default Raspberry PI password: Username : pi Password : raspberry",
      "content_preview": "Installing the image to your MicroSD card Getting the FRC Raspberry PI image The image is stored on the GitHub release page for the WPILibPi repository . In addition to the instructions on this page, see the documentation on the GitHub web page (below)."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/using-a-coprocessor-for-vision-processing.html",
      "title": "Using a Coprocessor for vision processing",
      "section": "Vision Processing",
      "language": "All",
      "content": "Using a Coprocessor for vision processing Vision processing using libraries like OpenCV for recognizing field targets or game pieces can often be a CPU intensive process. Often the load isn’t too significant and the processing can easily be handled by the roboRIO. In cases where there are more camera streams or the image processing is complex, it is desirable to off-load the roboRIO by putting the code and the camera connection on a different processor. There are a number of choices of processors that are popular in FRC® such as the Raspberry PI, the intel-based Kangaroo, the LimeLight for the ultimate in simplicity, or for more complex vision code a graphics accelerator such as one of the nVidia Jetson models. Strategy Generally the idea is to set up the coprocessor with the required software that generally includes: OpenCV - the open source computer vision library NetworkTables - to commute the results of the image processing to the roboRIO program Camera server library - to handle the camera connections and publish streams that can be viewed on a dashboard The language library for whatever computer language is used for the vision program The actual vision program that does the object detection The coprocessor is connected to the roboRIO network by plugging it into the extra ethernet port on the network router or, for more connections, adding a small network switch to the robot. The cameras are plugged into the coprocessor, it acquires the images, processes them, and publishes the results, usually target location information, to NetworkTables so it is can be consumed by the robot program for steering and aiming. Streaming camera data to the dashboard It is often desirable to simply stream the camera data to the dashboard over the robot network. In this case one or more camera connections can be sent to the network and viewed on a dashboard such as Shuffleboard or a web browser. Using Shuffleboard has the advantage of having easy controls to set the camera resolution and bit rate as well as integrating the camera streams with other data sent from the robot. It is also possible to process images and add annotation to the image, such as target lines or boxes showing what the image processing code has detected then send it forward to the dashboard to make it easier for operators to see a clear picture of what’s around the robot.",
      "content_preview": "Using a Coprocessor for vision processing Vision processing using libraries like OpenCV for recognizing field targets or game pieces can often be a CPU intensive process. Often the load isn’t too significant and the processing can easily be handled by the roboRIO."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/basic-vision-example.html",
      "title": "Basic Vision Example",
      "section": "Vision Processing",
      "language": "All",
      "content": "Basic Vision Example This is an example of a basic vision setup that posts the target’s location in the aiming coordinate system described here to NetworkTables, and uses CameraServer to display a bounding rectangle of the contour detected. This example will display the framerate of the processing code on the images sent to CameraServer. PY from cscore import CameraServer import ntcore import cv2 import json import numpy as np import time def main (): with open ( '/boot/frc.json' ) as f : config = json . load ( f ) camera = config [ 'cameras' ][ 0 ] width = camera [ 'width' ] height = camera [ 'height' ] nt = ntcore . NetworkTableInstance . getDefault () CameraServer . startAutomaticCapture () input_stream = CameraServer . getVideo () output_stream = CameraServer . putVideo ( 'Processed' , width , height ) # Table for vision output information vision_nt = nt . getTable ( 'Vision' ) # Allocating new images is very expensive, always try to preallocate img = np . zeros ( shape = ( 240 , 320 , 3 ), dtype = np . uint8 ) # Wait for NetworkTables to start time . sleep ( 0.5 ) while True : start_time = time . time () frame_time , input_img = input_stream . grabFrame ( img ) output_img = np . copy ( input_img ) # Notify output of error and skip iteration if frame_time == 0 : output_stream . notifyError ( input_stream . getError ()) continue # Convert to HSV and threshold image hsv_img = cv2 . cvtColor ( input_img , cv2 . COLOR_BGR2HSV ) binary_img = cv2 . inRange ( hsv_img , ( 0 , 0 , 100 ), ( 85 , 255 , 255 )) _ , contour_list = cv2 . findContours ( binary_img , mode = cv2 . RETR_EXTERNAL , method = cv2 . CHAIN_APPROX_SIMPLE ) x_list = [] y_list = [] for contour in contour_list : # Ignore small contours that could be because of noise/bad thresholding if cv2 . contourArea ( contour ) < 15 : continue cv2 . drawContours ( output_img , contour , - 1 , color = ( 255 , 255 , 255 ), thickness =- 1 ) rect = cv2 . minAreaRect ( contour ) center , size , angle = rect center = tuple ([ int ( dim ) for dim in center ]) # Convert to int so we can draw # Draw rectangle and circle cv2 . drawContours ( output_img , [ cv2 . boxPoints ( rect ) . astype ( int )], - 1 , color = ( 0 , 0 , 255 ), thickness = 2 ) cv2 . circle ( output_img , center = center , radius = 3 , color = ( 0 , 0 , 255 ), thickness =- 1 ) x_list . append (( center [ 0 ] - width / 2 ) / ( width / 2 )) x_list . append (( center [ 1 ] - width / 2 ) / ( width / 2 )) vision_nt . putNumberArray ( 'target_x' , x_list ) vision_nt . putNumberArray ( 'target_y' , y_list ) processing_time = time . time () - start_time fps = 1 / processing_time cv2 . putText ( output_img , str ( round ( fps , 1 )), ( 0 , 40 ), cv2 . FONT_HERSHEY_SIMPLEX , 1 , ( 255 , 255 , 255 )) output_stream . putFrame ( output_img ) main ()",
      "content_preview": "Basic Vision Example This is an example of a basic vision setup that posts the target’s location in the aiming coordinate system described here to NetworkTables, and uses CameraServer to display a bounding rectangle of the contour detected."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/walkthrough-video.html",
      "title": "A Video Walkthrough of using WPILibPi with the Raspberry Pi",
      "section": "Vision Processing",
      "language": "All",
      "content": "A Video Walkthrough of using WPILibPi with the Raspberry Pi Note The video mentions FRCVision which is the old name of WPILibPi. At the “RSN Spring Conference, Presented by WPI” in 2020, Peter Johnson from the WPILib team gave a presentation on FRC® Vision with a Raspberry Pi. The link to the presentation is available here .",
      "content_preview": "A Video Walkthrough of using WPILibPi with the Raspberry Pi Note The video mentions FRCVision which is the old name of WPILibPi. At the “RSN Spring Conference, Presented by WPI” in 2020, Peter Johnson from the WPILib team gave a presentation on FRC® Vision with a Raspberry Pi."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/wpilibpi/the-raspberry-pi-frc-console.html?present",
      "title": "The Raspberry PI",
      "section": "Vision Processing",
      "language": "All",
      "content": "The Raspberry PI FRC Console The FRC® image for the Raspberry PI includes a console that can be viewed in any web browser that makes it easy to: Look at the Raspberry PI status View the status of the background process running the camera View or change network settings Look at each camera plugged into the rPI and add additional cameras Load a new vision program onto the rPI Setting the rPI to be Read-Only vs. Writable The rPI is normally set to Read-Only which means that the file system cannot be changed. This ensures that if power is removed without first shutting down the rPi the file system isn’t corrupted. When settings are changed (following sections), the new settings cannot be saved while the rPI file system is set as Read-Only. Buttons are provided that allow the file system to be changed from Read-Only to Writable and back whenever changes are made. If the other buttons that change information stored on the rPI cannot be press, check the Read-Only status of the system. Status of the network connection to the rPI There is a label in the top right corner of the console that indicates if the rPi is currently connected. It will change from Connected to Disconnected if there is no longer a network connection to the rPi. System status The system status shows what the CPU on the rPI is doing at any time. There are two columns of status values, on being a 1 second average and the other a 5 second average. Shown is: Free and available RAM on the PI CPU usage for user processes and system processes as well as idle time Network bandwidth - which allows one to determine if the used camera bandwidth is exceeding the maximum bandwidth allowed in the robot rules for any year Vision Status Allows monitoring of the task which is running the camera code in the rPI, either one of the default programs or your own program in Java, C++, or Python. You can also enable and view the console output to see messages coming from the background camera service. In this case there are number of messages about being unable to connect to NetworkTables (NT: connect()) because in this example the rPI is simply connected to a laptop with no NetworkTables server running (usually the roboRIO.) Network Settings The rPI network settings have options to connect to the PI: DHCP - the default name resolution usually used by the roboRIO. The default name is wpilibpi.local. Static - where a fixed IP address, network mask, and router settings are filled in explicitly DHCP with Static Fallback - DHCP with Static Fallback - the PI will try to get an IP address via DHCP, but if it can’t find a DHCP server, it will use the provided static IP address and parameters The picture above is showing the settings for both DHCP and Static IP Addressing. The mDNS name for the rPi should always work regardless of the options selected above. Vision Settings The Vision Settings are to set the parameters for each camera and whether the rPI should be a NetworkTables client or server. There can only be one server on the network and the roboRIO is always a server. Therefore when connected to a roboRIO, the rPI should always be in client mode with the team number filled in. If testing on a desktop setup with no roboRIO or anything acting as a server then it should be set to Server (Client switch is off). To view and manipulate all the camera settings click on the camera in question. In this case the camera is called “Camera rPi Camera 0” and clicking on the name reveals the current camera view and the associated settings. Manipulating the camera settings is reflected in the current camera view. The bottom of the page shows all the possible camera modes (combinations of Width, Height, and frame rates) that are supported by this camera. Note If the camera image is not visible on the Open Stream screen then check the supported video modes at the bottom of the page. Then go back to ‘Vision Settings’ and click on the camera in question and verify that the pixel format, width, height, and FPS are listed in the supported video modes. Getting the current settings to persist over reboots The rPi will load all the camera settings on startup. Editing the camera configuration in the above screen is temporary. To make the values persist click on the “Load Source Config From Camera” button and the current settings will be filled in on the camera settings fields. Then click “Save” at the bottom of the page. Note: you must set the file system Writeable in order to save the settings. The Writeable button is at the top of the page. There are some commonly used camera settings values shown in the camera settings (above). These values Brightness, White Balance, and Exposure are loaded into the camera before the user JSON file is applied. So if a user JSON file contains those settings they will overwrite the ones from the text field. Application The Application tab shows the application that is currently running on the rPi. Vision workflows There is a sample vision program using OpenCV in each of the supported languages, C++, Java, or Python. Each sample program can capture and stream video from the rPi. In addition, the samples have some minimal OpenCV. They are all set up to be extended to replace the provided OpenCV sample code with the code needed for the robot application. The rPi Application tab supports a number of programming workflows: Stream one or more cameras from the rPi for consumption on the driver station computer and displayed using ShuffleBoard Edit and build one of the sample programs (one for each language: Java, C++ or Python) on the rPi using the included toolchains Download a sample program for the chosen language and edit and build it on your development computer. Then upload that built program back to the rPi Do everything yourself using completely custom applications and scripts (probably based on one of the samples) The running application can be changed by selecting one of the choices in the drop-down menu. The choices are: Built-in multi camera streaming which streams whatever cameras are plugged into the rPi. The camera configuration including number of cameras can be set on the “Vision Settings” tab. Custom application which doesn’t upload anything to the rPi and assumes that the developer wants to have a custom program and script. Java, C++ or Python pre-installed sample programs that can be edited into your own application. Java, C++, or Python uploaded program. Java programs require a .jar file with the compiled program and C++ programs require an rPi executable to be uploaded to the rPI. When selecting one of the Upload options, a file chooser is presented where the jar, executable, or Python program can be selected and uploaded to the rPi. In the following picture an Uploaded Java jar is chosen and the “Choose File” button will select a file and clicking on the “Save” button will upload the selected file. Note: in order to Save a new file onto the rPi, the file system has to be set writeable using the “Writable” button at the top left of the web page. After saving the new file, set the file system back to “Read-Only” so that it is protected against accidental changes.",
      "content_preview": "The Raspberry PI FRC Console The FRC® image for the Raspberry PI includes a console that can be viewed in any web browser that makes it easy to: Look at the Raspberry PI status View the status of the background process running the camera View or change network settings Look at each camera plugged..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/index.html?present",
      "title": "Vision Processing",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision Processing Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples Vision with WPILibPi A Video Walkthrough of using WPILibPi with the Raspberry Pi Using a Coprocessor for vision processing Using the Raspberry Pi for FRC What you need to get the Pi image running Installing the image to your MicroSD card The Raspberry PI Using CameraServer Thresholding an Image Morphological Operations Working with Contours Basic Vision Example AprilTag Introduction What Are AprilTags? Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface",
      "content_preview": "Vision Processing Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples Vision with WPILibPi A Video Walkthrough of using WPILibPi with the..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/what-is-vision.html",
      "title": "What is Vision?",
      "section": "Vision Processing",
      "language": "All",
      "content": "What is Vision? Vision in FRC® uses a camera connected to the robot in order to help teams score and drive, during both the autonomous and teleoperated periods. Vision Methods There are two main method that most teams use for vision in FRC. Streaming This method involves streaming the camera to the Driver Station so that the driver and manipulator can get visual information from the robot’s point of view. This method is simple and takes little time to implement, making it a good option if you do not need features of vision processing. Streaming using the roboRIO Processing Instead of only streaming the camera to the Driver Station, this method involves using the frames captured by the camera to compute information, such as a game piece’s or target’s angle and distance from the camera. This method requires more technical knowledge and time in order to implement, as well as being more computationally expensive. However, this method can help improve autonomous performance and assist in “auto-scoring” operations during the teleoperated period. This method can be done using the roboRIO or a coprocessor such as the Raspberry Pi using OpenCV. Vision Processing with Raspberry Pi Vision Processing with the roboRIO For additional information on the pros and cons of using a coprocessor for vision processing, see the next page, Strategies for Vision Programming .",
      "content_preview": "What is Vision? Vision in FRC® uses a camera connected to the robot in order to help teams score and drive, during both the autonomous and teleoperated periods. Vision Methods There are two main method that most teams use for vision in FRC."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/what-is-vision.html?present",
      "title": "What is Vision?",
      "section": "Vision Processing",
      "language": "All",
      "content": "What is Vision? Vision in FRC® uses a camera connected to the robot in order to help teams score and drive, during both the autonomous and teleoperated periods. Vision Methods There are two main method that most teams use for vision in FRC. Streaming This method involves streaming the camera to the Driver Station so that the driver and manipulator can get visual information from the robot’s point of view. This method is simple and takes little time to implement, making it a good option if you do not need features of vision processing. Streaming using the roboRIO Processing Instead of only streaming the camera to the Driver Station, this method involves using the frames captured by the camera to compute information, such as a game piece’s or target’s angle and distance from the camera. This method requires more technical knowledge and time in order to implement, as well as being more computationally expensive. However, this method can help improve autonomous performance and assist in “auto-scoring” operations during the teleoperated period. This method can be done using the roboRIO or a coprocessor such as the Raspberry Pi using OpenCV. Vision Processing with Raspberry Pi Vision Processing with the roboRIO For additional information on the pros and cons of using a coprocessor for vision processing, see the next page, Strategies for Vision Programming .",
      "content_preview": "What is Vision? Vision in FRC® uses a camera connected to the robot in order to help teams score and drive, during both the autonomous and teleoperated periods. Vision Methods There are two main method that most teams use for vision in FRC."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/using-the-cameraserver-on-the-roborio.html",
      "title": "Using the CameraServer on the roboRIO",
      "section": "Vision Processing",
      "language": "All",
      "content": "Using the CameraServer on the roboRIO Simple CameraServer Program The following program starts automatic capture of a USB camera like the Microsoft LifeCam that is connected to the roboRIO. In this mode, the camera will capture frames and send them to the dashboard. To view the images, create a CameraServer Stream Viewer widget using the “View”, then “Add” menu in the dashboard. The images are unprocessed and just forwarded from the camera to the dashboard. JAVA 7 import edu.wpi.first.cameraserver.CameraServer ; 8 import edu.wpi.first.wpilibj.TimedRobot ; 9 10 /** 11 * Uses the CameraServer class to automatically capture video from a USB webcam and send it to the 12 * FRC dashboard without doing any vision processing. This is the easiest way to get camera images 13 * to the dashboard. Just add this to the robot class constructor. 14 */ 15 public class Robot extends TimedRobot { 16 public Robot () { 17 CameraServer . startAutomaticCapture (); 18 } 19 } C++ #include <cameraserver/CameraServer.h> #include <frc/TimedRobot.h> class Robot : public frc :: TimedRobot { public : Robot () { frc :: CameraServer :: StartAutomaticCapture (); } }; #ifndef RUNNING_FRC_TESTS int main () { return frc :: StartRobot < Robot > (); } PYTHON 1 import wpilib 2 from wpilib.cameraserver import CameraServer 3 4 5 class MyRobot ( wpilib . TimedRobot ): 6 \"\"\" 7 Uses the CameraServer class to automatically capture video from a USB webcam and send it to the 8 FRC dashboard without doing any vision processing. This is the easiest way to get camera images 9 to the dashboard. Just add this to the robotInit() method in your program. 10 \"\"\" 11 12 def robotInit ( self ): 13 CameraServer () . launch () Advanced Camera Server Program In the following example a thread created in Robot constructor gets the Camera Server instance. Each frame of the video is individually processed, in this case drawing a rectangle on the image using the OpenCV rectangle() method. The resultant images are then passed to the output stream and sent to the dashboard. You can replace the rectangle operation with any image processing code that is necessary for your application. You can even annotate the image using OpenCV methods to write targeting information onto the image being sent to the dashboard. Java 7 import edu.wpi.first.cameraserver.CameraServer ; 8 import edu.wpi.first.cscore.CvSink ; 9 import edu.wpi.first.cscore.CvSource ; 10 import edu.wpi.first.cscore.UsbCamera ; 11 import edu.wpi.first.wpilibj.TimedRobot ; 12 import org.opencv.core.Mat ; 13 import org.opencv.core.Point ; 14 import org.opencv.core.Scalar ; 15 import org.opencv.imgproc.Imgproc ; 16 17 /** 18 * This is a demo program showing the use of OpenCV to do vision processing. The image is acquired 19 * from the USB camera, then a rectangle is put on the image and sent to the dashboard. OpenCV has 20 * many methods for different types of processing. 21 */ 22 public class Robot extends TimedRobot { 23 Thread m_visionThread ; 24 25 /** Called once at the beginning of the robot program. */ 26 public Robot () { 27 m_visionThread = 28 new Thread ( 29 () -> { 30 // Get the UsbCamera from CameraServer 31 UsbCamera camera = CameraServer . startAutomaticCapture (); 32 // Set the resolution 33 camera . setResolution ( 640 , 480 ); 34 35 // Get a CvSink. This will capture Mats from the camera 36 CvSink cvSink = CameraServer . getVideo (); 37 // Setup a CvSource. This will send images back to the Dashboard 38 CvSource outputStream = CameraServer . putVideo ( \"Rectangle\" , 640 , 480 ); 39 40 // Mats are very memory expensive. Lets reuse this Mat. 41 Mat mat = new Mat (); 42 43 // This cannot be 'true'. The program will never exit if it is. This 44 // lets the robot stop this thread when restarting robot code or 45 // deploying. 46 while ( ! Thread . interrupted ()) { 47 // Tell the CvSink to grab a frame from the camera and put it 48 // in the source mat. If there is an error notify the output. 49 if ( cvSink . grabFrame ( mat ) == 0 ) { 50 // Send the output the error. 51 outputStream . notifyError ( cvSink . getError ()); 52 // skip the rest of the current iteration 53 continue ; 54 } 55 // Put a rectangle on the image 56 Imgproc . rectangle ( 57 mat , new Point ( 100 , 100 ), new Point ( 400 , 400 ), new Scalar ( 255 , 255 , 255 ), 5 ); 58 // Give the output stream a new image to display 59 outputStream . putFrame ( mat ); 60 } 61 }); 62 m_visionThread . setDaemon ( true ); 63 m_visionThread . start (); 64 } 65 } c++ #include <cstdio> #include <thread> #include <cameraserver/CameraServer.h> #include <frc/TimedRobot.h> #include <opencv2/core/core.hpp> #include <opencv2/core/types.hpp> #include <opencv2/imgproc/imgproc.hpp> /** * This is a demo program showing the use of OpenCV to do vision processing. The * image is acquired from the USB camera, then a rectangle is put on the image * and sent to the dashboard. OpenCV has many methods for different types of * processing. */ class Robot : public frc :: TimedRobot { public : Robot () { // We need to run our vision program in a separate thread. If not, our robot // program will not run. std :: thread visionThread ( VisionThread ); visionThread . detach (); } private : static void VisionThread () { // Get the USB camera from CameraServer cs :: UsbCamera camera = frc :: CameraServer :: StartAutomaticCapture (); // Set the resolution camera . SetResolution ( 640 , 480 ); // Get a CvSink. This will capture Mats from the Camera cs :: CvSink cvSink = frc :: CameraServer :: GetVideo (); // Setup a CvSource. This will send images back to the Dashboard cs :: CvSource outputStream = frc :: CameraServer :: PutVideo ( \"Rectangle\" , 640 , 480 ); // Mats are very memory expensive. Lets reuse this Mat. cv :: Mat mat ; while ( true ) { // Tell the CvSink to grab a frame from the camera and // put it // in the source mat. If there is an error notify the // output. if ( cvSink . GrabFrame ( mat ) == 0 ) { // Send the output the error. outputStream . NotifyError ( cvSink . GetError ()); // skip the rest of the current iteration continue ; } // Put a rectangle on the image rectangle ( mat , cv :: Point ( 100 , 100 ), cv :: Point ( 400 , 400 ), cv :: Scalar ( 255 , 255 , 255 ), 5 ); // Give the output stream a new image to display outputStream . PutFrame ( mat ); } } }; #ifndef RUNNING_FRC_TESTS int main () { return frc :: StartRobot < Robot > (); } #endif PYTHON Image processing on the roboRIO when using Python is slightly different from C++/Java. Instead of using a separate thread, we need to launch the image processing code in a completely separate process. Warning Image processing is a CPU intensive task, and because of the Python Global Interpreter Lock (GIL) we do NOT recommend using cscore directly in your robot process . Don’t do it. Really. For more information on the GIL and its effects, you may wish to read the following resources: Python Wiki: Global Interpreter Lock Efficiently Exploiting Multiple Cores with Python This introduces a number of rules that your image processing code must follow to efficiently and safely run on the RoboRIO: Your image processing code must be in its own file. It’s easiest to just place it next to your robot.py Never import the cscore package from your robot code, it will just waste memory Never import the wpilib or hal packages from your image processing file The camera code will be killed when the robot.py program exits. If you wish to perform cleanup, you should register an atexit handler. robotpy-cscore is not installed on the roboRIO by default, you need to update your pyproject.toml file to install it Warning wpilib may not be imported from two programs on the RoboRIO. If this happens, the second program will attempt to kill the first program. Here’s what your robot.py needs to contain to launch the image processing process: 1 import wpilib 2 3 4 class MyRobot ( wpilib . TimedRobot ): 5 \"\"\" 6 This is a demo program showing the use of OpenCV to do vision processing. The image is acquired 7 from the USB camera, then a rectangle is put on the image and sent to the dashboard. OpenCV has 8 many methods for different types of processing. 9 \"\"\" 10 The launch(\"vision.py\") function says to launch vision.py and call the run function in that file. Here’s what is in vision.py : 1 # NOTE: This code runs in its own process, so we cannot access the robot here, 2 # nor can we create/use/see wpilib objects 3 # 4 # To try this code out locally (if you have robotpy-cscore installed), you 5 # can execute `python3 -m cscore vision.py:main` 6 # 7 8 import cv2 9 import numpy as np 10 11 from cscore import CameraServer as CS 12 13 14 def main (): 15 CS . enableLogging () 16 17 # Get the UsbCamera from CameraServer 18 camera = CS . startAutomaticCapture () 19 # Set the resolution 20 camera . setResolution ( 640 , 480 ) 21 22 # Get a CvSink. This will capture images from the camera 23 cvSink = CS . getVideo () 24 # Setup a CvSource. This will send images back to the Dashboard 25 outputStream = CS . putVideo ( \"Rectangle\" , 640 , 480 ) 26 27 # Allocating new images is very expensive, always try to preallocate 28 mat = np . zeros ( shape = ( 480 , 640 , 3 ), dtype = np . uint8 ) 29 30 while True : 31 # Tell the CvSink to grab a frame from the camera and put it 32 # in the source image. If there is an error notify the output. 33 time , mat = cvSink . grabFrame ( mat ) 34 if time == 0 : 35 # Send the output the error. 36 outputStream . notifyError ( cvSink . getError ()) 37 # skip the rest of the current iteration 38 continue 39 40 # Put a rectangle on the image 41 cv2 . rectangle ( mat , ( 100 , 100 ), ( 400 , 400 ), ( 255 , 255 , 255 ), 5 ) 42 43 # Give the output stream a new image to display 44 outputStream . putFrame ( mat ) You need to update pyproject.toml contents to include cscore in the robotpy-extras key (this only shows the portions you need to update): [tool.robotpy] ... # Add cscore to the robotpy-extras list robotpy_extras = [ \"cscore\" ] Notice that in these examples, the PutVideo() method writes the video to a named stream. To view that stream on SmartDashboard or Shuffleboard, select that named stream. In this case that is “Rectangle”.",
      "content_preview": "Using the CameraServer on the roboRIO Simple CameraServer Program The following program starts automatic capture of a USB camera like the Microsoft LifeCam that is connected to the roboRIO. In this mode, the camera will capture frames and send them to the dashboard."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/index.html",
      "title": "Vision Introduction",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples",
      "content_preview": "Vision Introduction What is Vision? Strategies for Vision Programming Target Info and Retroreflection Identifying and Processing the Targets Read and Process Video: CameraServer Class 2017 Vision Examples"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/2017-vision-examples.html",
      "title": "2017 Vision Examples",
      "section": "Vision Processing",
      "language": "All",
      "content": "2017 Vision Examples LabVIEW The 2017 LabVIEW Vision Example is included with the other LabVIEW examples. From the Splash screen, click Support->Find FRC® Examples or from any other LabVIEW window, click Help->Find Examples and locate the Vision folder to find the 2017 Vision Example. The example images are bundled with the example.",
      "content_preview": "2017 Vision Examples LabVIEW The 2017 LabVIEW Vision Example is included with the other LabVIEW examples. From the Splash screen, click Support->Find FRC® Examples or from any other LabVIEW window, click Help->Find Examples and locate the Vision folder to find the 2017 Vision Example."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/2017-vision-examples.html?present",
      "title": "2017 Vision Examples",
      "section": "Vision Processing",
      "language": "All",
      "content": "2017 Vision Examples LabVIEW The 2017 LabVIEW Vision Example is included with the other LabVIEW examples. From the Splash screen, click Support->Find FRC® Examples or from any other LabVIEW window, click Help->Find Examples and locate the Vision folder to find the 2017 Vision Example. The example images are bundled with the example.",
      "content_preview": "2017 Vision Examples LabVIEW The 2017 LabVIEW Vision Example is included with the other LabVIEW examples. From the Splash screen, click Support->Find FRC® Examples or from any other LabVIEW window, click Help->Find Examples and locate the Vision folder to find the 2017 Vision Example."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/index.html",
      "title": "Vision on the RoboRIO",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface",
      "content_preview": "Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/cameraserver-webserver.html",
      "title": "CameraServer Web Interface",
      "section": "Vision Processing",
      "language": "All",
      "content": "CameraServer Web Interface When CameraServer opens a camera, it creates a webpage that you can use to view the camera stream and view the effects of various camera settings. To connect to the web interface, use a web browser to navigate to http://roboRIO-TEAM-frc.local:1181 . There is no additional code needed other than the Simple CameraServer Program . Note The port 1181 is used for the first camera. The port increments for additional camera, so if you have two cameras, the replace 1181 above with 1182 . Camera Settings The web server will show a live camera image and has sliders to adjust various camera settings, such as brightness, contrast, sharpness, and many other options. You can adjust the values and see the results live, and then use the VideoCamera class to set those in your robot code. Camera Video Modes One useful feature is the list of supported video modes at the bottom of the web page. This shows all the supported modes that the camera supports to enable you to choose the one that is the best combination of resolution and frame rate for your requirements.",
      "content_preview": "CameraServer Web Interface When CameraServer opens a camera, it creates a webpage that you can use to view the camera stream and view the effects of various camera settings. To connect to the web interface, use a web browser to navigate to http://roboRIO-TEAM-frc.local:1181 ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/cameraserver-webserver.html?present",
      "title": "CameraServer Web Interface",
      "section": "Vision Processing",
      "language": "All",
      "content": "CameraServer Web Interface When CameraServer opens a camera, it creates a webpage that you can use to view the camera stream and view the effects of various camera settings. To connect to the web interface, use a web browser to navigate to http://roboRIO-TEAM-frc.local:1181 . There is no additional code needed other than the Simple CameraServer Program . Note The port 1181 is used for the first camera. The port increments for additional camera, so if you have two cameras, the replace 1181 above with 1182 . Camera Settings The web server will show a live camera image and has sliders to adjust various camera settings, such as brightness, contrast, sharpness, and many other options. You can adjust the values and see the results live, and then use the VideoCamera class to set those in your robot code. Camera Video Modes One useful feature is the list of supported video modes at the bottom of the web page. This shows all the supported modes that the camera supports to enable you to choose the one that is the best combination of resolution and frame rate for your requirements.",
      "content_preview": "CameraServer Web Interface When CameraServer opens a camera, it creates a webpage that you can use to view the camera stream and view the effects of various camera settings. To connect to the web interface, use a web browser to navigate to http://roboRIO-TEAM-frc.local:1181 ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/index.html?present",
      "title": "Vision on the RoboRIO",
      "section": "Vision Processing",
      "language": "All",
      "content": "Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface",
      "content_preview": "Vision on the RoboRIO Using the CameraServer on the roboRIO Using Multiple Cameras CameraServer Web Interface"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/roborio/using-multiple-cameras.html",
      "title": "Using Multiple Cameras",
      "section": "Vision Processing",
      "language": "All",
      "content": "Using Multiple Cameras Switching the Driver Views If you’re interested in just switching what the driver sees, and are using SmartDashboard, the SmartDashboard CameraServer Stream Viewer has an option (“Selected Camera Path”) that reads the given NetworkTables key and changes the “Camera Choice” to that value (displaying that camera). The robot code then just needs to set the NetworkTables key to the correct camera name. Assuming “Selected Camera Path” is set to “CameraSelection”, the following code uses the joystick 1 trigger button state to show camera1 and camera2. Java UsbCamera camera1 ; UsbCamera camera2 ; Joystick joy1 = new Joystick ( 0 ); NetworkTableEntry cameraSelection ; public Robot () { camera1 = CameraServer . startAutomaticCapture ( 0 ); camera2 = CameraServer . startAutomaticCapture ( 1 ); cameraSelection = NetworkTableInstance . getDefault (). getTable ( \"\" ). getEntry ( \"CameraSelection\" ); } @Override public void teleopPeriodic () { if ( joy1 . getTriggerPressed ()) { System . out . println ( \"Setting camera 2\" ); cameraSelection . setString ( camera2 . getName ()); } else if ( joy1 . getTriggerReleased ()) { System . out . println ( \"Setting camera 1\" ); cameraSelection . setString ( camera1 . getName ()); } } C++ cs :: UsbCamera camera1 ; cs :: UsbCamera camera2 ; frc :: Joystick joy1 { 0 }; nt :: NetworkTableEntry cameraSelection ; Robot () { camera1 = frc :: CameraServer :: StartAutomaticCapture ( 0 ); camera2 = frc :: CameraServer :: StartAutomaticCapture ( 1 ); cameraSelection = nt :: NetworkTableInstance :: GetDefault (). GetTable ( \"\" ) -> GetEntry ( \"CameraSelection\" ); } void TeleopPeriodic () override { if ( joy1 . GetTriggerPressed ()) { std :: cout << \"Setting Camera 2\" << std :: endl ; cameraSelection . SetString ( camera2 . GetName ()); } else if ( joy1 . GetTriggerReleased ()) { std :: cout << \"Setting Camera 1\" << std :: endl ; cameraSelection . SetString ( camera1 . GetName ()); } } PYTHON Note Python requires you to place your image processing code in a separate file from your robot code. You can create robot.py and vision.py in the same directory. robot.py contents: import wpilib from ntcore import NetworkTableInstance class MyRobot ( wpilib . TimedRobot ): def robotInit ( self ): self . joy1 = wpilib . Joystick ( 0 ) self . cameraSelection = NetworkTableInstance . getDefault () . getTable ( \"\" ) . getEntry ( \"CameraSelection\" ) wpilib . CameraServer . launch ( \"vision.py:main\" ) def teleopPeriodic ( self ): if self . joy1 . getTriggerPressed (): print ( \"Setting camera 2\" ) self . cameraSelection . setString ( \"USB Camera 1\" ) elif self . joy1 . getTriggerReleased (): print ( \"Setting camera 1\" ) self . cameraSelection . setString ( \"USB Camera 0\" ) vision.py contents: from cscore import CameraServer def main (): CameraServer . enableLogging () camera1 = CameraServer . startAutomaticCapture ( 0 ) camera2 = CameraServer . startAutomaticCapture ( 1 ) CameraServer . waitForever () pyproject.toml contents (this only shows the portions you need to update): [tool.robotpy] ... # Add cscore to the robotpy-extras list robotpy_extras = [ \"cscore\" ] If you’re using some other dashboard, you can change the camera used by the camera server dynamically. If you open a stream viewer nominally to camera1, the robot code will change the stream contents to either camera1 or camera2 based on the joystick trigger. JAVA UsbCamera camera1 ; UsbCamera camera2 ; VideoSink server ; Joystick joy1 = new Joystick ( 0 ); public Robot () { camera1 = CameraServer . startAutomaticCapture ( 0 ); camera2 = CameraServer . startAutomaticCapture ( 1 ); server = CameraServer . getServer (); } @Override public void teleopPeriodic () { if ( joy1 . getTriggerPressed ()) { System . out . println ( \"Setting camera 2\" ); server . setSource ( camera2 ); } else if ( joy1 . getTriggerReleased ()) { System . out . println ( \"Setting camera 1\" ); server . setSource ( camera1 ); } } C++ cs :: UsbCamera camera1 ; cs :: UsbCamera camera2 ; cs :: VideoSink server ; frc :: Joystick joy1 { 0 }; bool prevTrigger = false ; Robot () { camera1 = frc :: CameraServer :: StartAutomaticCapture ( 0 ); camera2 = frc :: CameraServer :: StartAutomaticCapture ( 1 ); server = frc :: CameraServer :: GetServer (); } void TeleopPeriodic () override { if ( joy1 . GetTrigger () && ! prevTrigger ) { std :: cout << \"Setting Camera 2\" << std :: endl ; server . SetSource ( camera2 ); } else if ( ! joy1 . GetTrigger () && prevTrigger ) { std :: cout << \"Setting Camera 1\" << std :: endl ; server . SetSource ( camera1 ); } prevTrigger = joy1 . GetTrigger (); } PYTHON # Setting the source directly via joystick isn't possible in Python, you # should use NetworkTables as shown above instead Keeping Streams Open By default, the cscore library is pretty aggressive in turning off cameras not in use. What this means is that when you switch cameras, it may disconnect from the camera not in use, so switching back will have some delay as it reconnects to the camera. To keep both camera connections open, use the SetConnectionStrategy() method to tell the library to keep the streams open, even if you aren’t using them. Java UsbCamera camera1 ; UsbCamera camera2 ; VideoSink server ; Joystick joy1 = new Joystick ( 0 ); public Robot () { camera1 = CameraServer . startAutomaticCapture ( 0 ); camera2 = CameraServer . startAutomaticCapture ( 1 ); server = CameraServer . getServer (); camera1 . setConnectionStrategy ( ConnectionStrategy . kKeepOpen ); camera2 . setConnectionStrategy ( ConnectionStrategy . kKeepOpen ); } @Override public void teleopPeriodic () { if ( joy1 . getTriggerPressed ()) { System . out . println ( \"Setting camera 2\" ); server . setSource ( camera2 ); } else if ( joy1 . getTriggerReleased ()) { System . out . println ( \"Setting camera 1\" ); server . setSource ( camera1 ); } } C++ cs :: UsbCamera camera1 ; cs :: UsbCamera camera2 ; cs :: VideoSink server ; frc :: Joystick joy1 { 0 }; bool prevTrigger = false ; Robot () { camera1 = frc :: CameraServer :: StartAutomaticCapture ( 0 ); camera2 = frc :: CameraServer :: StartAutomaticCapture ( 1 ); server = frc :: CameraServer :: GetServer (); camera1 . SetConnectionStrategy ( cs :: VideoSource :: ConnectionStrategy :: kConnectionKeepOpen ); camera2 . SetConnectionStrategy ( cs :: VideoSource :: ConnectionStrategy :: kConnectionKeepOpen ); } void TeleopPeriodic () override { if ( joy1 . GetTrigger () && ! prevTrigger ) { std :: cout << \"Setting Camera 2\" << std :: endl ; server . SetSource ( camera2 ); } else if ( ! joy1 . GetTrigger () && prevTrigger ) { std :: cout << \"Setting Camera 1\" << std :: endl ; server . SetSource ( camera1 ); } prevTrigger = joy1 . GetTrigger (); } PYTHON Note Python requires you to place your image processing code in a separate file from your robot code. You can create robot.py and vision.py in the same directory. robot.py contents: import wpilib from ntcore import NetworkTableInstance class MyRobot ( wpilib . TimedRobot ): def robotInit ( self ): self . joy1 = wpilib . Joystick ( 0 ) self . cameraSelection = NetworkTableInstance . getDefault () . getTable ( \"\" ) . getEntry ( \"CameraSelection\" ) wpilib . CameraServer . launch ( \"vision.py:main\" ) def teleopPeriodic ( self ): if self . joy1 . getTriggerPressed (): print ( \"Setting camera 2\" ) self . cameraSelection . setString ( \"USB Camera 1\" ) elif self . joy1 . getTriggerReleased (): print ( \"Setting camera 1\" ) self . cameraSelection . setString ( \"USB Camera 0\" ) vision.py contents: from cscore import CameraServer , VideoSource def main (): CameraServer . enableLogging () camera1 = CameraServer . startAutomaticCapture ( 0 ) camera2 = CameraServer . startAutomaticCapture ( 1 ) camera1 . setConnectionStrategy ( VideoSource . ConnectionStrategy . kConnectionKeepOpen ) camera2 . setConnectionStrategy ( VideoSource . ConnectionStrategy . kConnectionKeepOpen ) CameraServer . waitForever () pyproject.toml contents (this only shows the portions you need to update): [tool.robotpy] ... # Add cscore to the robotpy-extras list robotpy_extras = [ \"cscore\" ] Note If both cameras are USB, you may run into USB bandwidth limitations with higher resolutions, as in all of these cases the roboRIO is going to be streaming data from both cameras to the roboRIO simultaneously (for a short period in options 1 and 2, and continuously in option 3). It is theoretically possible for the library to avoid this simultaneity in the option 2 case (only), but this is not currently implemented. Different cameras report bandwidth usage differently. The library will tell you if you’re hitting the limit; you’ll get this error message: could not start streaming due to USB bandwidth limitations; try a lower resolution or a different pixel format (VIDIOC_STREAMON: No space left on device) If you’re using Option 3 it will give you this error during the Robot constructor. Thus you should just try your desired resolution and adjusting as necessary until you both don’t get that error and don’t exceed the radio bandwidth limitations.",
      "content_preview": "Using Multiple Cameras Switching the Driver Views If you’re interested in just switching what the driver sees, and are using SmartDashboard, the SmartDashboard CameraServer Stream Viewer has an option (“Selected Camera Path”) that reads the given NetworkTables key and changes the “Camera Choice” to..."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/target-info-and-retroreflection.html",
      "title": "Target Info and Retroreflection",
      "section": "Vision Processing",
      "language": "All",
      "content": "Target Info and Retroreflection Many FRC® games have retroreflective tape attached to field elements to aid in vision processing. This document describes the Vision Targets from the 2016 FRC game and the visual properties of the material making up the targets. Note For official dimensions and drawings of all field components, please see the Official Field Drawings. Targets Each 2016 vision target consists of a 1’ 8” wide, 1’ tall U-shape made of 2” wide retroreflective material (3M 8830 Silver Marking Film). The targets are located immediately adjacent to the bottom of each high goal. When properly lit, the retroreflective tape produces a bright and/or color-saturated marker. Retroreflectivity vs. Reflectivity Highly reflective materials are generally mirrored so that light “bounces off” at a supplementary angle. As shown above-left, the blue and red angles sum to 180 degrees. An equivalent explanation is that the light reflects about the surface normal the green line drawn perpendicular to the surface. Notice that a light pointed at the surface will return to the light source only if the blue angle is ~90 degrees. Retro-reflective materials are not mirrored, but it will typically have either shiny facets across the surface, or it will have a pearl-like appearance. Not all faceted or pearl-like materials exhibit retro-reflection , however. Retro-reflective materials return the majority of light back to the light source, and they do this for a wide range of angles between the surface and the light source, not just the 90 degree case. Retro-reflective materials accomplish this using small prisms, such as found on a bicycle or roadside reflector, or by using small spheres with the appropriate index of refraction that accomplish multiple internal reflections. In nature, the eyes of some animals, including house cats, also exhibit the retro-reflective effect typically referred to as night-shine. Examples of Retroreflection This material should be relatively familiar as it is often used to enhance nighttime visibility of road signs, bicycles, and pedestrians. Initially, retro-reflection may not seem like a useful property for nighttime safety, but when the light and eye are near one another, as shown above, the reflected light returns to the eye, and the material shines brightly even at large distances. Due to the small angle between the driver’s eyes and vehicle headlights, retro-reflective materials can greatly increase visibility of distant objects during nighttime driving. Demonstration To further explore retro-reflective material properties: Place a piece of the material on a wall or vertical surface Stand 10-20 feet away, and shine a small flashlight at the material. Start with the light held at your belly button, and raise it slowly until it is between your eyes. As the light nears your eyes, the intensity of the returned light will increase rapidly. Alter the angle by moving to other locations in the room and repeating. The bright reflection should occur over a wide range of viewing angles, but the angle from light source to eye is key and must be quite small. Experiment with different light sources. The material is hundreds of times more reflective than white paint; so dim light sources will work fine. For example, a red bicycle safety light will demonstrate that the color of the light source determines the color of the reflected light. If possible, position several team members at different locations, each with their own light source. This will show that the effects are largely independent, and the material can simultaneously appear different colors to various team members. This also demonstrates that the material is largely immune to environmental lighting. The light returning to the viewer is almost entirely determined by a light source they control or one directly behind them. Using the flashlight, identify other retro-reflective articles already in your environment: on clothing, backpacks, shoes, etc. Lighting We have seen that the retro-reflective tape will not shine unless a light source is directed at it, and the light source must pass very near the camera lens or the observer’s eyes. While there are a number of ways to accomplish this, a very useful type of light source to investigate is the ring flash, or ring light, shown above. It places the light source directly on or around the camera lens and provides very even lighting. Because of their bright output and small size, LEDs are particularly useful for constructing this type of device. As shown above, inexpensive circular arrangements of LEDs are available in a variety of colors and sizes and are easy to attach to cameras, and some can even be powered off of a Raspberry Pi. While not designed for diffuse even lighting, they work quite well for causing retro-reflective tape to shine. A small green LED ring is available through FIRST Choice. Other similar LED rings are available from suppliers such as SuperBrightLEDs. Sample Images Sample images are located with the code examples for each language (packaged with LabVIEW, and in a separate ZIP in the same location as the C++/Java samples).",
      "content_preview": "Target Info and Retroreflection Many FRC® games have retroreflective tape attached to field elements to aid in vision processing. This document describes the Vision Targets from the 2016 FRC game and the visual properties of the material making up the targets."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/target-info-and-retroreflection.html?present",
      "title": "Target Info and Retroreflection",
      "section": "Vision Processing",
      "language": "All",
      "content": "Target Info and Retroreflection Many FRC® games have retroreflective tape attached to field elements to aid in vision processing. This document describes the Vision Targets from the 2016 FRC game and the visual properties of the material making up the targets. Note For official dimensions and drawings of all field components, please see the Official Field Drawings. Targets Each 2016 vision target consists of a 1’ 8” wide, 1’ tall U-shape made of 2” wide retroreflective material (3M 8830 Silver Marking Film). The targets are located immediately adjacent to the bottom of each high goal. When properly lit, the retroreflective tape produces a bright and/or color-saturated marker. Retroreflectivity vs. Reflectivity Highly reflective materials are generally mirrored so that light “bounces off” at a supplementary angle. As shown above-left, the blue and red angles sum to 180 degrees. An equivalent explanation is that the light reflects about the surface normal the green line drawn perpendicular to the surface. Notice that a light pointed at the surface will return to the light source only if the blue angle is ~90 degrees. Retro-reflective materials are not mirrored, but it will typically have either shiny facets across the surface, or it will have a pearl-like appearance. Not all faceted or pearl-like materials exhibit retro-reflection , however. Retro-reflective materials return the majority of light back to the light source, and they do this for a wide range of angles between the surface and the light source, not just the 90 degree case. Retro-reflective materials accomplish this using small prisms, such as found on a bicycle or roadside reflector, or by using small spheres with the appropriate index of refraction that accomplish multiple internal reflections. In nature, the eyes of some animals, including house cats, also exhibit the retro-reflective effect typically referred to as night-shine. Examples of Retroreflection This material should be relatively familiar as it is often used to enhance nighttime visibility of road signs, bicycles, and pedestrians. Initially, retro-reflection may not seem like a useful property for nighttime safety, but when the light and eye are near one another, as shown above, the reflected light returns to the eye, and the material shines brightly even at large distances. Due to the small angle between the driver’s eyes and vehicle headlights, retro-reflective materials can greatly increase visibility of distant objects during nighttime driving. Demonstration To further explore retro-reflective material properties: Place a piece of the material on a wall or vertical surface Stand 10-20 feet away, and shine a small flashlight at the material. Start with the light held at your belly button, and raise it slowly until it is between your eyes. As the light nears your eyes, the intensity of the returned light will increase rapidly. Alter the angle by moving to other locations in the room and repeating. The bright reflection should occur over a wide range of viewing angles, but the angle from light source to eye is key and must be quite small. Experiment with different light sources. The material is hundreds of times more reflective than white paint; so dim light sources will work fine. For example, a red bicycle safety light will demonstrate that the color of the light source determines the color of the reflected light. If possible, position several team members at different locations, each with their own light source. This will show that the effects are largely independent, and the material can simultaneously appear different colors to various team members. This also demonstrates that the material is largely immune to environmental lighting. The light returning to the viewer is almost entirely determined by a light source they control or one directly behind them. Using the flashlight, identify other retro-reflective articles already in your environment: on clothing, backpacks, shoes, etc. Lighting We have seen that the retro-reflective tape will not shine unless a light source is directed at it, and the light source must pass very near the camera lens or the observer’s eyes. While there are a number of ways to accomplish this, a very useful type of light source to investigate is the ring flash, or ring light, shown above. It places the light source directly on or around the camera lens and provides very even lighting. Because of their bright output and small size, LEDs are particularly useful for constructing this type of device. As shown above, inexpensive circular arrangements of LEDs are available in a variety of colors and sizes and are easy to attach to cameras, and some can even be powered off of a Raspberry Pi. While not designed for diffuse even lighting, they work quite well for causing retro-reflective tape to shine. A small green LED ring is available through FIRST Choice. Other similar LED rings are available from suppliers such as SuperBrightLEDs. Sample Images Sample images are located with the code examples for each language (packaged with LabVIEW, and in a separate ZIP in the same location as the C++/Java samples).",
      "content_preview": "Target Info and Retroreflection Many FRC® games have retroreflective tape attached to field elements to aid in vision processing. This document describes the Vision Targets from the 2016 FRC game and the visual properties of the material making up the targets."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/apriltag/index.html",
      "title": "AprilTag Introduction",
      "section": "Vision Processing",
      "language": "All",
      "content": "AprilTag Introduction What Are AprilTags? Application to FRC Software Support Processing Technique Usage 2D to 3D Ambiguity Adjustable Parameters Further Learning",
      "content_preview": "AprilTag Introduction What Are AprilTags? Application to FRC Software Support Processing Technique Usage 2D to 3D Ambiguity Adjustable Parameters Further Learning"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/apriltag/index.html?present",
      "title": "AprilTag Introduction",
      "section": "Vision Processing",
      "language": "All",
      "content": "AprilTag Introduction What Are AprilTags? Application to FRC Software Support Processing Technique Usage 2D to 3D Ambiguity Adjustable Parameters Further Learning",
      "content_preview": "AprilTag Introduction What Are AprilTags? Application to FRC Software Support Processing Technique Usage 2D to 3D Ambiguity Adjustable Parameters Further Learning"
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/apriltag/apriltag-intro.html",
      "title": "What Are AprilTags?",
      "section": "Vision Processing",
      "language": "All",
      "content": "What Are AprilTags? AprilTags are a system of visual tags developed by researchers at the University of Michigan to provide low overhead, high accuracy localization for many different applications. Additional information about the tag system and its creators can be found on their website . This document attempts to summarize the content for FIRST robotics related purposes. Application to FRC In the context of FRC, AprilTags are useful for helping your robot know where it is at on the field, so it can align itself to some goal position. AprilTags have been in development since 2011, and have been refined over the years to increase the robustness and speed of detection. Starting in 2023, FIRST is providing a number of tags, scattered throughout the field, each at a known pose . What is the 36h11 family? The AprilTag library implementation defines standards on how sets of tags should be designed. Some of the possible tag families are described here . Starting from 2024, FIRST has chosen the 36h11 family. This family of tags is made of a 6x6 grid of pixels, each representing one bit of information. An additional black and white border must be present around the outside of the bits. While there are \\(2^{36} = 68,719,476,736\\) theoretical possible tags, only 587 are actually used. These are chosen to: Be robust against some bit flips (IE, issues where a bit has its color incorrectly identified). Not involve “simple” geometric patterns likely to be found on things which are not tags. (IE, squares, stripes, etc.) Ensure the geometric pattern is asymmetric enough that you can always figure out which way is up. All tags will be printed such that the tag’s main “body” is 6.5 inches in length. For home usage, tag files may be printed off and placed around your practice area. Mount them to a rigid backing material to ensure the tag stays flat, as the processing algorithm assumes the tags are flat. Software Support The main repository for the source code that detects and decodes AprilTags is located here . WPILib has forked the repository to add new features for FRC. These include: Building the source code for common FRC targets, including the roboRIO and Raspberry Pi. Adding Java Native Interface (JNI) support to allow invoking its functionality from Java Gradle & Maven publishing support Processing Technique While most FRC teams should not have to implement their own code to identify AprilTags in a camera image, it is useful to know the basics of how the underlying libraries function. Original Image An image from a camera is simply an array of values, corresponding to the color and brightness of each pixel. Remove Colors The first step is to convert the image to a grey-scale (brightness-only) image. Color information is not needed to detect the black-and-white tags. Decimate The next step is to convert the image to a lower resolution. Working with fewer pixels helps the algorithm work faster. The full-resolution image will be used later to refine early estimates. Adaptive Threshold An adaptive threshold algorithm is run to classify each pixel as “definitely light”, “definitely dark”, or “not sure”. The threshold is calculated by looking at the pixel’s brightness, compared to a small neighborhood of pixels around it. Segmentation Next, the known pixels are clumped together. Any clumps which are too small to reasonably be a meaningful part of a tag are discarded. Quad Detection An algorithm for fitting a quadrilateral to each clump is now run: Identify likely “corner” candidates by pixels which are outliers in both dimensions. Iterate through all possible combinations of corners, evaluating the fit each time Pick the best-fit quadrilateral Given the set of all quadralaterals, Identify a subset of quadrilaterals which is likely a tag. A single large exterior quadrilateral with many interior quadrilateral is likely a good candidate. If all has gone well so far, we are left with a four-sided region of pixels that is likely a valid tag. Decode ID Now that we have one or more regions of pixels which we believe to be a valid AprilTag, we need to identify which tag we are looking at. This is done by “decoding” the pattern of light and dark squares on the inside. Calculate the expected interior pixel coordinates where the center of each bit should be Mark each location as “1” or “0” by comparing the pixel intensity to a threshold Find the tag ID which most closely matches what was seen in the image, allowing for one or two bit errors. It is possible there is no valid tag ID which matches the suspect tag. In this case, the decoding process stops. Fit External Quad Now that we have a tag ID for the region of pixels, we need to do something useful with it. For most FRC applications, we care about knowing the precise location of the corners of the tag, or its center. In both cases, we expect the resolution-lowering operation we did at the beginning to have distorted the image, and we want to undo those effects. The algorithm to do this is: Use the detected tag location to define a region of interest in the original-resolution image Calculate the gradient at pre-defined points in the region of interest to detect where the image most sharply transitions between black to white Use these gradient measurements to rapidly re-fit an exterior quadrilateral at full resolution Use geometry to calculate the exact center of the re-fit quadrilateral Note that this step is optional, and can be skipped for faster image processing. However, skipping it can induce significant errors into your robot’s behavior, depending on how you are using the tag outputs. Usage 2D Alignment A simple strategy for using targets is to move the robot until the target is centered in the image. Assuming the field and robot are constructed such that the gamepiece, scoring location, vision target, and camera are all aligned, this method should proved a straightforward method to automatically align the robot to the scoring position. Using a camera, identify the centroid of the AprilTags in view. If the tag’s ID is correct, apply drivetrain commands to rotate the robot left or right until the tag is centered in the camera image. This method does not require calibrating the camera or performing the homography step. 3D Alignment A more advanced usage of AprilTags is to use their corner locations to help perform pose estimation . Each image is searched for AprilTags using the algorithm described on this page. Using assumptions about how the camera’s lense distorts the 3d world onto the 2d array of pixels in the camera, an estimate of the camera’s position relative to the tag is calculated. A good camera calibration is required for the assumptions about its lens behavior to be accurate. The tag’s ID is also decoded. from the image. Given each tag’s ID, the position of the tag on the field can be looked up. Knowing the position of the tag on the field, and the position of the camera relative to the tag, the 3D geometry classes can be used to estimate the position of the camera on the field. If the camera’s position on the robot is known, the robot’s position on the field can also be estimated. These estimates can be incorporated into the WPILib pose estimation classes. 2D to 3D Ambiguity The process of translating the four known corners of the target in the image (two-dimensional) into a real-world position relative to the camera (three-dimensional) is inherently ambiguous. That is to say, there are multiple real-world positions that result in the target corners ending up in the same spot in the camera image. Humans can often use lighting or background clues to understand how objects are oriented in space. However, computers do not have this benefit. They can be tricked by similar-looking targets: Resolving which position is “correct” can be done in a few different ways: Use your odometry history from all sensors to pick the pose closest to where you expect the robot to be. Reject poses which are very unlikely (ex: outside the field perimeter, or up in the air) Ignore pose estimates which are very close together (and hard to differentiate) Use multiple cameras to look at the same target, such that at least one camera can generate a good pose estimate Look at many targets at once, using each to generate multiple pose estimates. Discard the outlying estimates, use the ones which are tightly clustered together. Adjustable Parameters Decimation factor impacts how much the image is down-sampled before processing. Increasing it will increase detection speed, at the cost of not being able to see tags which are far away. Blur applies smoothing to the input image to decrease noise, which increases speed when fitting quads to pixels, at the cost of precision. For most good cameras, this may be left at zero. Threads changes the number of parallel threads which the algorithm uses to process the image. Certain steps may be sped up by allowing multithreading. In general, you want this to be approximately equal to the number of physical cores in your CPU, minus the number of cores which will be used for other processing tasks. Detailed information about the tunable parameters can be found here . Further Learning The three major versions of AprilTags are described in three academic papers. It’s recommended to read them in order, as each builds upon the previous: AprilTags v1 AprilTags v2 AprilTags v3 Pose Ambiguity",
      "content_preview": "What Are AprilTags? AprilTags are a system of visual tags developed by researchers at the University of Michigan to provide low overhead, high accuracy localization for many different applications. Additional information about the tag system and its creators can be found on their website ."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/cameraserver-class.html",
      "title": "Read and Process Video: CameraServer Class",
      "section": "Vision Processing",
      "language": "All",
      "content": "Read and Process Video: CameraServer Class Concepts The cameras typically used in FRC® (commodity USB and Ethernet cameras) offer relatively limited modes of operation. In general, they provide only a single image output (typically in an RGB compressed format such as JPG) at a single resolution and frame rate. USB cameras are particularly limited as only one application may access the camera at a time. CameraServer supports multiple cameras. It handles details such as automatically reconnecting when a camera is disconnected, and also makes images from the camera available to multiple “clients” (e.g. both your robot code and the dashboard can connect to the camera simultaneously). Camera Names Each camera in CameraServer must be uniquely named. This is also the name that appears for the camera in the Dashboard. Some variants of the CameraServer startAutomaticCapture() functions will automatically name the camera (e.g. “USB Camera 0”), or you can give the camera a more descriptive name (e.g. “Intake Cam”). The only requirement is that each camera have a unique name. USB Camera Notes CPU Usage The CameraServer is designed to minimize CPU usage by only performing compression and decompression operations when required and automatically disabling streaming when no clients are connected. To minimize CPU usage, the dashboard resolution should be set to the same resolution as the camera; this allows the CameraServer to not decompress and recompress the image, instead, it can simply forward the JPEG image received from the camera directly to the dashboard. It’s important to note that changing the resolution on the dashboard does not change the camera resolution; changing the camera resolution may be done by calling setResolution() on the camera object. USB Bandwidth The roboRIO can only transmit and receive so much data at a time over its USB interfaces. Camera images can require a lot of data, and so it is relatively easy to run into this limit. The most common cause of a USB bandwidth error is selecting a non-JPEG video mode or running too high of a resolution, particularly when multiple cameras are connected. Architecture The CameraServer consists of two layers, the high level WPILib CameraServer class and the low level cscore library . CameraServer Class The CameraServer class (part of WPILib) provides a high level interface for adding cameras to your robot code. It also is responsible for publishing information about the cameras and camera servers to NetworkTables so that Driver Station dashboards such as the LabVIEW Dashboard and Shuffleboard can list the cameras and determine where their streams are located. It uses a singleton pattern to maintain a database of all created cameras and servers. Some key functions in CameraServer are: startAutomaticCapture() : Add a USB camera (e.g. Microsoft LifeCam) and starts a server for it so it can be viewed from the dashboard. getVideo() : Get OpenCV access to a camera. This allows you to get images from the camera for image processing on the roboRIO (in your robot code). putVideo() : Start a server that you can feed OpenCV images to. This allows you to pass custom processed and/or annotated images to the dashboard. cscore Library The cscore library provides the lower level implementation to: Get images from USB and HTTP cameras Change camera settings (e.g. contrast and brightness) Change camera video modes (pixel format, resolution, and frame rate) Act as a web server and serve images as a standard MJPEG stream Convert images to/from OpenCV Mat objects for image processing Sources and Sinks The basic architecture of the cscore library is similar to that of MJPGStreamer, with functionality split between sources and sinks. There can be multiple sources and multiple sinks created and operating simultaneously. An object that generates images is a source and an object that accepts/consumes images is a sink. The generate/consume is from the perspective of the library. Thus cameras are sources (they generate images). The MJPEG web server is a sink because it accepts images from within the program (even though it may be forwarding those images on to a web browser or dashboard). Sources may be connected to multiple sinks, but sinks can be connected to one and only one source. When a sink is connected to a source, the cscore library takes care of passing each image from the source to the sink. Sources obtain individual frames (such as provided by a USB camera) and fire an event when a new frame is available. If no sinks are listening to a particular source, the library may pause or disconnect from a source to save processor and I/O resources. The library autonomously handles camera disconnects/reconnects by simply pausing and resuming firing of events (e.g. a disconnect results in no new frames, not an error). Sinks listen to a particular source’s event, grab the latest image, and forward it to its destination in the appropriate format. Similarly to sources, if a particular sink is inactive (e.g. no client is connected to a configured MJPEG over HTTP server), the library may disable parts of its processing to save processor resources. User code (such as that used in a FRC robot program) can act as either a source (providing processed frames as if it were a camera) or as a sink (receiving a frame for processing) via OpenCV source and sink objects. Thus an image processing pipeline that gets images from a camera and serves the processed images out looks like the below graph: Because sources can have multiple sinks connected, the pipeline may branch. For example, the original camera image can also be served by connecting the UsbCamera source to a second MjpegServer sink in addition to the CvSink, resulting in the below graph: When a new image is captured by the camera, both the CvSink and the MjpegServer [1] receive it. The above graph is what the following CameraServer snippet creates: JAVA import edu.wpi.first.cameraserver.CameraServer ; import edu.wpi.cscore.CvSink ; import edu.wpi.cscore.CvSource ; // Creates UsbCamera and MjpegServer [1] and connects them CameraServer . startAutomaticCapture (); // Creates the CvSink and connects it to the UsbCamera CvSink cvSink = CameraServer . getVideo (); // Creates the CvSource and MjpegServer [2] and connects them CvSource outputStream = CameraServer . putVideo ( \"Blur\" , 640 , 480 ); C++ #include \"cameraserver/CameraServer.h\" // Creates UsbCamera and MjpegServer [1] and connects them frc :: CameraServer :: StartAutomaticCapture (); // Creates the CvSink and connects it to the UsbCamera cs :: CvSink cvSink = frc :: CameraServer :: GetVideo (); // Creates the CvSource and MjpegServer [2] and connects them cs :: CvSource outputStream = frc :: CameraServer :: PutVideo ( \"Blur\" , 640 , 480 ); The CameraServer implementation effectively does the following at the cscore level (for explanation purposes). CameraServer takes care of many of the details such as creating unique names for all cscore objects and automatically selecting port numbers. CameraServer also keeps a singleton registry of created objects so they aren’t destroyed if they go out of scope. JAVA import edu.wpi.cscore.CvSink ; import edu.wpi.cscore.CvSource ; import edu.wpi.cscore.MjpegServer ; import edu.wpi.cscore.UsbCamera ; // Creates UsbCamera and MjpegServer [1] and connects them UsbCamera usbCamera = new UsbCamera ( \"USB Camera 0\" , 0 ); MjpegServer mjpegServer1 = new MjpegServer ( \"serve_USB Camera 0\" , 1181 ); mjpegServer1 . setSource ( usbCamera ); // Creates the CvSink and connects it to the UsbCamera CvSink cvSink = new CvSink ( \"opencv_USB Camera 0\" ); cvSink . setSource ( usbCamera ); // Creates the CvSource and MjpegServer [2] and connects them CvSource outputStream = new CvSource ( \"Blur\" , PixelFormat . kMJPEG , 640 , 480 , 30 ); MjpegServer mjpegServer2 = new MjpegServer ( \"serve_Blur\" , 1182 ); mjpegServer2 . setSource ( outputStream ); C++ #include \"cscore_oo.h\" // Creates UsbCamera and MjpegServer [1] and connects them cs :: UsbCamera usbCamera ( \"USB Camera 0\" , 0 ); cs :: MjpegServer mjpegServer1 ( \"serve_USB Camera 0\" , 1181 ); mjpegServer1 . SetSource ( usbCamera ); // Creates the CvSink and connects it to the UsbCamera cs :: CvSink cvSink ( \"opencv_USB Camera 0\" ); cvSink . SetSource ( usbCamera ); // Creates the CvSource and MjpegServer [2] and connects them cs :: CvSource outputStream ( \"Blur\" , cs :: PixelFormat :: kMJPEG , 640 , 480 , 30 ); cs :: MjpegServer mjpegServer2 ( \"serve_Blur\" , 1182 ); mjpegServer2 . SetSource ( outputStream ); Reference Counting All cscore objects are internally reference counted. Connecting a sink to a source increments the source’s reference count, so it’s only strictly necessary to keep the sink in scope. The CameraServer class keeps a registry of all objects created with CameraServer functions, so sources and sinks created in that way effectively never go out of scope (unless explicitly removed).",
      "content_preview": "Read and Process Video: CameraServer Class Concepts The cameras typically used in FRC® (commodity USB and Ethernet cameras) offer relatively limited modes of operation."
    },
    {
      "url": "https://docs.wpilib.org/en/stable/docs/software/vision-processing/introduction/cameraserver-class.html?present",
      "title": "Read and Process Video: CameraServer Class",
      "section": "Vision Processing",
      "language": "All",
      "content": "Read and Process Video: CameraServer Class Concepts The cameras typically used in FRC® (commodity USB and Ethernet cameras) offer relatively limited modes of operation. In general, they provide only a single image output (typically in an RGB compressed format such as JPG) at a single resolution and frame rate. USB cameras are particularly limited as only one application may access the camera at a time. CameraServer supports multiple cameras. It handles details such as automatically reconnecting when a camera is disconnected, and also makes images from the camera available to multiple “clients” (e.g. both your robot code and the dashboard can connect to the camera simultaneously). Camera Names Each camera in CameraServer must be uniquely named. This is also the name that appears for the camera in the Dashboard. Some variants of the CameraServer startAutomaticCapture() functions will automatically name the camera (e.g. “USB Camera 0”), or you can give the camera a more descriptive name (e.g. “Intake Cam”). The only requirement is that each camera have a unique name. USB Camera Notes CPU Usage The CameraServer is designed to minimize CPU usage by only performing compression and decompression operations when required and automatically disabling streaming when no clients are connected. To minimize CPU usage, the dashboard resolution should be set to the same resolution as the camera; this allows the CameraServer to not decompress and recompress the image, instead, it can simply forward the JPEG image received from the camera directly to the dashboard. It’s important to note that changing the resolution on the dashboard does not change the camera resolution; changing the camera resolution may be done by calling setResolution() on the camera object. USB Bandwidth The roboRIO can only transmit and receive so much data at a time over its USB interfaces. Camera images can require a lot of data, and so it is relatively easy to run into this limit. The most common cause of a USB bandwidth error is selecting a non-JPEG video mode or running too high of a resolution, particularly when multiple cameras are connected. Architecture The CameraServer consists of two layers, the high level WPILib CameraServer class and the low level cscore library . CameraServer Class The CameraServer class (part of WPILib) provides a high level interface for adding cameras to your robot code. It also is responsible for publishing information about the cameras and camera servers to NetworkTables so that Driver Station dashboards such as the LabVIEW Dashboard and Shuffleboard can list the cameras and determine where their streams are located. It uses a singleton pattern to maintain a database of all created cameras and servers. Some key functions in CameraServer are: startAutomaticCapture() : Add a USB camera (e.g. Microsoft LifeCam) and starts a server for it so it can be viewed from the dashboard. getVideo() : Get OpenCV access to a camera. This allows you to get images from the camera for image processing on the roboRIO (in your robot code). putVideo() : Start a server that you can feed OpenCV images to. This allows you to pass custom processed and/or annotated images to the dashboard. cscore Library The cscore library provides the lower level implementation to: Get images from USB and HTTP cameras Change camera settings (e.g. contrast and brightness) Change camera video modes (pixel format, resolution, and frame rate) Act as a web server and serve images as a standard MJPEG stream Convert images to/from OpenCV Mat objects for image processing Sources and Sinks The basic architecture of the cscore library is similar to that of MJPGStreamer, with functionality split between sources and sinks. There can be multiple sources and multiple sinks created and operating simultaneously. An object that generates images is a source and an object that accepts/consumes images is a sink. The generate/consume is from the perspective of the library. Thus cameras are sources (they generate images). The MJPEG web server is a sink because it accepts images from within the program (even though it may be forwarding those images on to a web browser or dashboard). Sources may be connected to multiple sinks, but sinks can be connected to one and only one source. When a sink is connected to a source, the cscore library takes care of passing each image from the source to the sink. Sources obtain individual frames (such as provided by a USB camera) and fire an event when a new frame is available. If no sinks are listening to a particular source, the library may pause or disconnect from a source to save processor and I/O resources. The library autonomously handles camera disconnects/reconnects by simply pausing and resuming firing of events (e.g. a disconnect results in no new frames, not an error). Sinks listen to a particular source’s event, grab the latest image, and forward it to its destination in the appropriate format. Similarly to sources, if a particular sink is inactive (e.g. no client is connected to a configured MJPEG over HTTP server), the library may disable parts of its processing to save processor resources. User code (such as that used in a FRC robot program) can act as either a source (providing processed frames as if it were a camera) or as a sink (receiving a frame for processing) via OpenCV source and sink objects. Thus an image processing pipeline that gets images from a camera and serves the processed images out looks like the below graph: Because sources can have multiple sinks connected, the pipeline may branch. For example, the original camera image can also be served by connecting the UsbCamera source to a second MjpegServer sink in addition to the CvSink, resulting in the below graph: When a new image is captured by the camera, both the CvSink and the MjpegServer [1] receive it. The above graph is what the following CameraServer snippet creates: JAVA import edu.wpi.first.cameraserver.CameraServer ; import edu.wpi.cscore.CvSink ; import edu.wpi.cscore.CvSource ; // Creates UsbCamera and MjpegServer [1] and connects them CameraServer . startAutomaticCapture (); // Creates the CvSink and connects it to the UsbCamera CvSink cvSink = CameraServer . getVideo (); // Creates the CvSource and MjpegServer [2] and connects them CvSource outputStream = CameraServer . putVideo ( \"Blur\" , 640 , 480 ); C++ #include \"cameraserver/CameraServer.h\" // Creates UsbCamera and MjpegServer [1] and connects them frc :: CameraServer :: StartAutomaticCapture (); // Creates the CvSink and connects it to the UsbCamera cs :: CvSink cvSink = frc :: CameraServer :: GetVideo (); // Creates the CvSource and MjpegServer [2] and connects them cs :: CvSource outputStream = frc :: CameraServer :: PutVideo ( \"Blur\" , 640 , 480 ); The CameraServer implementation effectively does the following at the cscore level (for explanation purposes). CameraServer takes care of many of the details such as creating unique names for all cscore objects and automatically selecting port numbers. CameraServer also keeps a singleton registry of created objects so they aren’t destroyed if they go out of scope. JAVA import edu.wpi.cscore.CvSink ; import edu.wpi.cscore.CvSource ; import edu.wpi.cscore.MjpegServer ; import edu.wpi.cscore.UsbCamera ; // Creates UsbCamera and MjpegServer [1] and connects them UsbCamera usbCamera = new UsbCamera ( \"USB Camera 0\" , 0 ); MjpegServer mjpegServer1 = new MjpegServer ( \"serve_USB Camera 0\" , 1181 ); mjpegServer1 . setSource ( usbCamera ); // Creates the CvSink and connects it to the UsbCamera CvSink cvSink = new CvSink ( \"opencv_USB Camera 0\" ); cvSink . setSource ( usbCamera ); // Creates the CvSource and MjpegServer [2] and connects them CvSource outputStream = new CvSource ( \"Blur\" , PixelFormat . kMJPEG , 640 , 480 , 30 ); MjpegServer mjpegServer2 = new MjpegServer ( \"serve_Blur\" , 1182 ); mjpegServer2 . setSource ( outputStream ); C++ #include \"cscore_oo.h\" // Creates UsbCamera and MjpegServer [1] and connects them cs :: UsbCamera usbCamera ( \"USB Camera 0\" , 0 ); cs :: MjpegServer mjpegServer1 ( \"serve_USB Camera 0\" , 1181 ); mjpegServer1 . SetSource ( usbCamera ); // Creates the CvSink and connects it to the UsbCamera cs :: CvSink cvSink ( \"opencv_USB Camera 0\" ); cvSink . SetSource ( usbCamera ); // Creates the CvSource and MjpegServer [2] and connects them cs :: CvSource outputStream ( \"Blur\" , cs :: PixelFormat :: kMJPEG , 640 , 480 , 30 ); cs :: MjpegServer mjpegServer2 ( \"serve_Blur\" , 1182 ); mjpegServer2 . SetSource ( outputStream ); Reference Counting All cscore objects are internally reference counted. Connecting a sink to a source increments the source’s reference count, so it’s only strictly necessary to keep the sink in scope. The CameraServer class keeps a registry of all objects created with CameraServer functions, so sources and sinks created in that way effectively never go out of scope (unless explicitly removed).",
      "content_preview": "Read and Process Video: CameraServer Class Concepts The cameras typically used in FRC® (commodity USB and Ethernet cameras) offer relatively limited modes of operation."
    }
  ]
}